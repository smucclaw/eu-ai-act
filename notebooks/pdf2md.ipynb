{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "\n",
    "from markdownify import markdownify as md\n",
    "from cleantext import clean\n",
    "\n",
    "from toolz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: try to use a parsing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jun14act = Path('../data/Jun14_2023.pdf')\n",
    "# https://artificialintelligenceact.eu/wp-content/uploads/2023/06/AIA-%E2%80%93-IMCO-LIBE-Draft-Compromise-Amendments-14-June-2023.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_wrt_thresholds(file_path, x_threshold, y_threshold):\n",
    "    text_content = []\n",
    "\n",
    "    for page_layout in extract_pages(file_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                # Check if this text block's X-coordinate is greater than the threshold\n",
    "                # If it is, it's in the second column\n",
    "                if element.x0 > x_threshold and element.y0 > y_threshold:\n",
    "                    text_content.append(element.get_text())\n",
    "\n",
    "    return text_content\n",
    "\n",
    "def our_clean(input_txt):\n",
    "    return clean(input_txt,\n",
    "                fix_unicode=True,               # fix various unicode errors\n",
    "                to_ascii=False,                  # transliterate to closest ASCII representation\n",
    "                lower=False,                     # lowercase text\n",
    "                no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "                no_urls=False,                  # replace all URLs with a special token\n",
    "                no_emails=False,                # replace all email addresses with a special token\n",
    "                no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "                no_numbers=False,               # replace all numbers with a special token\n",
    "                no_digits=False,                # replace all digits with a special token\n",
    "                no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "                no_punct=False,                 # remove punctuations\n",
    "                replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                replace_with_url=\"<URL>\",\n",
    "                replace_with_email=\"<EMAIL>\",\n",
    "                replace_with_phone_number=\"<PHONE>\",\n",
    "                replace_with_number=\"<NUMBER>\",\n",
    "                replace_with_digit=\"0\",\n",
    "                replace_with_currency_symbol=\"<CUR>\",\n",
    "                lang=\"en\"                       # set to 'de' for German special handling\n",
    ") \n",
    "\n",
    "def discard_unwanted_strs(str):\n",
    "    str = str.lower().strip()\n",
    "    return str != \"deleted\" and str != \"amendment\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_threshold, y_threshold = 300, 50\n",
    "text_content = pipe(\n",
    "                    extract_text_wrt_thresholds(path_jun14act, x_threshold, y_threshold), \n",
    "                    partial(filter, discard_unwanted_strs),\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content_str = our_clean(\"\\n\".join(text_content))\n",
    "\n",
    "# text_content now holds a list of strings, each string corresponding to a block of text in the second column.\n",
    "\n",
    "markdown_content = md(text_content_str) # this prob isn't useful for this particular pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/exp_1_extracted_txt.txt', 'w') as file:\n",
    "    file.write(text_content_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO next time:** there were headers in the left column that the above basically ignores.\n",
    "\n",
    "Adding the headers would probably only take about 5min of work, though it's worth thinking about how to come up with a process that wouldn't require as much manual and tailored-to-the-specific-pdf coding effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Try to leverage LLMs to do (even) more of the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from simpleaichat import AIChat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful references\n",
    "\n",
    "[Making A Structured TTRPG Story with simpleaichat](https://github.com/minimaxir/simpleaichat/blob/main/examples/notebooks/schema_ttrpg.ipynb)\n",
    "https://colab.research.google.com/github/minimaxir/simpleaichat/blob/main/examples/notebooks/schema_ttrpg.ipynb#scrollTo=t9H6TkTXcRia\n",
    "\n",
    "https://github.com/minimaxir/simpleaichat/tree/main\n",
    "\n",
    "https://platform.openai.com/playground?mode=chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do simple text dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dump = extract_text(path_jun14act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/simple_text_dump.txt', 'w') as file:\n",
    "    file.write(text_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK the results of my initial prompting weren't good -- will need to provide a more concrete spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(markdown_output)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load our env vars and LLM prompting infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-exps-2rZRJaQ_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
