European Parliament
2019-2024

TEXTS AD

P9_TA(2023)0236
Artificial Intelligence Act

Amendments adopted by the European Parlia
a regulation of the European Parliament and
rules on artificial intelligence (Artificial Intel
legislative acts (COM(2021)0206 – C9-0146/2

(Ordinary legislative procedure: first reading

1

The matter was referred back for interinsti
responsible, pursuant to Rule 59(4), fourth

Amendment 1
Proposal for a regulation
Citation 4 a (new)
Text proposed by the Commission

Amendment 2
Proposal for a regulation
Citation 4 b (new)
Text proposed by the Commission

Amendment 3
Proposal for a regulation
Recital 1
Text proposed by the Commission
(1) The purpose of this Regulation is to
improve the functioning of the internal
market by laying down a uniform legal
framework in particular for the
development, marketing and use of
artificial intelligence in conformity with
Union values. This Regulation pursues a
number of overriding reasons of public
interest, such as a high level of protection
of health, safety and fundamental rights,
and it ensures the free movement of AIbased goods and services cross-border,
thus preventing Member States from
imposing restrictions on the development,
marketing and use of AI systems, unless
explicitly authorised by this Regulation.

Amendment 4
Proposal for a regulation
Recital 1 a (new)
Text proposed by the Commission

Amendment 5
Proposal for a regulation
Recital 2
Text proposed by the Commission
(2) Artificial intelligence systems (AI
systems) can be easily deployed in multiple
sectors of the economy and society,
including cross border, and circulate
throughout the Union. Certain Member
States have already explored the adoption
of national rules to ensure that artificial
intelligence is safe and is developed and
used in compliance with fundamental
rights obligations. Differing national rules
may lead to fragmentation of the internal
market and decrease legal certainty for

operators that develop or use AI systems.
A consistent and high level of protection
throughout the Union should therefore be
ensured, while divergences hampering the
free circulation of AI systems and related
products and services within the internal
market should be prevented, by laying
down uniform obligations for operators and
guaranteeing the uniform protection of
overriding reasons of public interest and of
rights of persons throughout the internal
market based on Article 114 of the Treaty
on the Functioning of the European Union
(TFEU). To the extent that this Regulation
contains specific rules on the protection
of individuals with regard to the
processing of personal data concerning
restrictions of the use of AI systems for
‘real-time’ remote biometric identification
in publicly accessible spaces for the
purpose of law enforcement, it is
appropriate to base this Regulation, in as
far as those specific rules are concerned,
on Article 16 of the TFEU. In light of
those specific rules and the recourse to
Article 16 TFEU, it is appropriate to
consult the European Data Protection
Board.

Amendment 6
Proposal for a regulation
Recital 2 a (new)
Text proposed by the Commission

Amendment 7
Proposal for a regulation
Recital 2 b (new)
Text proposed by the Commission

Amendment 8
Proposal for a regulation
Recital 2 c (new)
Text proposed by the Commission

Amendment 9
Proposal for a regulation
Recital 2 d (new)
Text proposed by the Commission

Amendment 10

Proposal for a regulation
Recital 2 e (new)
Text proposed by the Commission

Amendment 11
Proposal for a regulation
Recital 2 f (new)
Text proposed by the Commission

Amendment 12
Proposal for a regulation
Recital 3
Text proposed by the Commission
(3) Artificial intelligence is a fast
evolving family of technologies that can
contribute to a wide array of economic and
societal benefits across the entire spectrum
of industries and social activities. By
improving prediction, optimising

operations and resource allocation, and
personalising digital solutions available for
individuals and organisations, the use of
artificial intelligence can provide key
competitive advantages to companies and
support socially and environmentally
beneficial outcomes, for example in
healthcare, farming, education and training,
infrastructure management, energy,
transport and logistics, public services,
security, justice, resource and energy
efficiency, and climate change mitigation
and adaptation.

Amendment 13
Proposal for a regulation
Recital 3 a (new)
Text proposed by the Commission

Amendment 14

Proposal for a regulation
Recital 4
Text proposed by the Commission
(4) At the same time, depending on the
circumstances regarding its specific
application and use, artificial intelligence
may generate risks and cause harm to
public interests and rights that are
protected by Union law. Such harm might
be material or immaterial.

Amendment 15
Proposal for a regulation
Recital 4 a (new)
Text proposed by the Commission

Amendment 16
Proposal for a regulation
Recital 5

Text proposed by the Commission
(5) A Union legal framework laying
down harmonised rules on artificial
intelligence is therefore needed to foster
the development, use and uptake of
artificial intelligence in the internal market
that at the same time meets a high level of
protection of public interests, such as
health and safety and the protection of
fundamental rights, as recognised and
protected by Union law. To achieve that
objective, rules regulating the placing on
the market and putting into service of
certain AI systems should be laid down,
thus ensuring the smooth functioning of the
internal market and allowing those systems
to benefit from the principle of free
movement of goods and services. By
laying down those rules, this Regulation
supports the objective of the Union of
being a global leader in the development of
secure, trustworthy and ethical artificial
intelligence, as stated by the European
Council33 , and it ensures the protection of
ethical principles, as specifically requested
by the European Parliament34 .

__________________
33 European Council, Special meeting of

the European Council (1 and 2 October
2020) – Conclusions, EUCO 13/20, 2020,
p. 6.
34 European Parliament resolution of 20

October 2020 with recommendations to the
Commission on a framework of ethical
aspects of artificial intelligence, robotics
and related technologies, 2020/2012(INL).

Amendment 17
Proposal for a regulation
Recital 5 a (new)
Text proposed by the Commission

Amendment 18
Proposal for a regulation
Recital 6
Text proposed by the Commission
(6) The notion of AI system should be
clearly defined to ensure legal certainty,
while providing the flexibility to
accommodate future technological
developments. The definition should be
based on the key functional characteristics
of the software, in particular the ability,
for a given set of human-defined
objectives, to generate outputs such as
content, predictions, recommendations, or
decisions which influence the
environment with which the system
interacts, be it in a physical or digital
dimension. AI systems can be designed to
operate with varying levels of autonomy

and be used on a stand-alone basis or as a
component of a product, irrespective of
whether the system is physically
integrated into the product (embedded) or
serve the functionality of the product
without being integrated therein (nonembedded). The definition of AI system
should be complemented by a list of
specific techniques and approaches used
for its development, which should be kept
up-to–date in the light of market and
technological developments through the
adoption of delegated acts by the
Commission to amend that list.

Amendment 19
Proposal for a regulation
Recital 6 a (new)
Text proposed by the Commission

Amendment 20
Proposal for a regulation
Recital 6 b (new)
Text proposed by the Commission

Amendment 21
Proposal for a regulation
Recital 7

Text proposed by the Commission
(7) The notion of biometric data used in
this Regulation is in line with and should
be interpreted consistently with the notion
of biometric data as defined in Article
4(14) of Regulation (EU) 2016/679 of the
European Parliament and of the Council35 ,
Article 3(18) of Regulation (EU)
2018/1725 of the European Parliament
and of the Council36 and Article 3(13) of
Directive (EU) 2016/680 of the European
Parliament and of the Council37 .

__________________
35 Regulation (EU) 2016/679 of the

European Parliament and of the Council of
27 April 2016 on the protection of natural
persons with regard to the processing of
personal data and on the free movement of
such data, and repealing Directive
95/46/EC (General Data Protection
Regulation) (OJ L 119, 4.5.2016, p. 1).
36 Regulation (EU) 2018/1725 of the

European Parliament and of the Council
of 23 October 2018 on the protection of
natural persons with regard to the
processing of personal data by the Union
institutions, bodies, offices and agencies
and on the free movement of such data,
and repealing Regulation (EC) No
45/2001 and Decision No 1247/2002/EC
(OJ L 295, 21.11.2018, p. 39)
37 Directive (EU) 2016/680 of the

European Parliament and of the Council
of 27 April 2016 on the protection of
natural persons with regard to the
processing of personal data by competent
authorities for the purposes of the
prevention, investigation, detection or
prosecution of criminal offences or the
execution of criminal penalties, and on
the free movement of such data, and
repealing Council Framework Decision
2008/977/JHA (Law Enforcement

Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 22
Proposal for a regulation
Recital 7 a (new)
Text proposed by the Commission

Amendment 23
Proposal for a regulation
Recital 7 b (new)
Text proposed by the Commission

Amendment 24
Proposal for a regulation
Recital 8
Text proposed by the Commission
(8) The notion of remote biometric
identification system as used in this
Regulation should be defined functionally,
as an AI system intended for the
identification of natural persons at a
distance through the comparison of a
person’s biometric data with the biometric
data contained in a reference database, and
without prior knowledge whether the
targeted person will be present and can be
identified, irrespectively of the particular
technology, processes or types of biometric
data used. Considering their different
characteristics and manners in which they
are used, as well as the different risks
involved, a distinction should be made
between ‘real-time’ and ‘post’ remote
biometric identification systems. In the
case of ‘real-time’ systems, the capturing
of the biometric data, the comparison and
the identification occur all instantaneously,
near-instantaneously or in any event
without a significant delay. In this regard,
there should be no scope for circumventing
the rules of this Regulation on the ‘realtime’ use of the AI systems in question by
providing for minor delays. ‘Real-time’
systems involve the use of ‘live’ or ‘near‘live’ material, such as video footage,
generated by a camera or other device with
similar functionality. In the case of ‘post’
systems, in contrast, the biometric data
have already been captured and the
comparison and identification occur only
after a significant delay. This involves
material, such as pictures or video footage
generated by closed circuit television
cameras or private devices, which has been
generated before the use of the system in
respect of the natural persons concerned.

Amendment 25
Proposal for a regulation
Recital 8 a (new)
Text proposed by the Commission

Amendment 26
Proposal for a regulation
Recital 9
Text proposed by the Commission
(9) For the purposes of this Regulation
the notion of publicly accessible space
should be understood as referring to any
physical place that is accessible to the
public, irrespective of whether the place in
question is privately or publicly owned.
Therefore, the notion does not cover places
that are private in nature and normally not
freely accessible for third parties, including
law enforcement authorities, unless those
parties have been specifically invited or

authorised, such as homes, private clubs,
offices, warehouses and factories. Online
spaces are not covered either, as they are
not physical spaces. However, the mere
fact that certain conditions for accessing a
particular space may apply, such as
admission tickets or age restrictions, does
not mean that the space is not publicly
accessible within the meaning of this
Regulation. Consequently, in addition to
public spaces such as streets, relevant parts
of government buildings and most
transport infrastructure, spaces such as
cinemas, theatres, shops and shopping
centres are normally also publicly
accessible. Whether a given space is
accessible to the public should however be
determined on a case-by-case basis, having
regard to the specificities of the individual
situation at hand.

Amendment 27
Proposal for a regulation
Recital 9 a (new)
Text proposed by the Commission

Amendment 28
Proposal for a regulation
Recital 9 b (new)
Text proposed by the Commission

Amendment 29
Proposal for a regulation
Recital 10
Text proposed by the Commission
(10) In order to ensure a level playing
field and an effective protection of rights
and freedoms of individuals across the
Union, the rules established by this
Regulation should apply to providers of AI
systems in a non-discriminatory manner,
irrespective of whether they are established
within the Union or in a third country, and
to users of AI systems established within

the Union.

Amendment 30
Proposal for a regulation
Recital 11
Text proposed by the Commission
(11) In light of their digital nature, certain
AI systems should fall within the scope of
this Regulation even when they are neither
placed on the market, nor put into service,
nor used in the Union. This is the case for
example of an operator established in the
Union that contracts certain services to an
operator established outside the Union in
relation to an activity to be performed by
an AI system that would qualify as highrisk and whose effects impact natural
persons located in the Union. In those
circumstances, the AI system used by the
operator outside the Union could process
data lawfully collected in and transferred
from the Union, and provide to the
contracting operator in the Union the
output of that AI system resulting from that
processing, without that AI system being
placed on the market, put into service or
used in the Union. To prevent the
circumvention of this Regulation and to
ensure an effective protection of natural
persons located in the Union, this
Regulation should also apply to providers
and users of AI systems that are established
in a third country, to the extent the output
produced by those systems is used in the

Union. Nonetheless, to take into account
existing arrangements and special needs for
cooperation with foreign partners with
whom information and evidence is
exchanged, this Regulation should not
apply to public authorities of a third
country and international organisations
when acting in the framework of
international agreements concluded at
national or European level for law
enforcement and judicial cooperation with
the Union or with its Member States. Such
agreements have been concluded
bilaterally between Member States and
third countries or between the European
Union, Europol and other EU agencies and
third countries and international
organisations.

Amendment 31
Proposal for a regulation
Recital 12
Text proposed by the Commission
(12) This Regulation should also apply to
Union institutions, offices, bodies and
agencies when acting as a provider or user
of an AI system. AI systems exclusively
developed or used for military purposes
should be excluded from the scope of this
Regulation where that use falls under the
exclusive remit of the Common Foreign
and Security Policy regulated under Title V
of the Treaty on the European Union
(TEU). This Regulation should be without
prejudice to the provisions regarding the
liability of intermediary service providers
set out in Directive 2000/31/EC of the
European Parliament and of the Council
[as amended by the Digital Services Act].

Amendment 32
Proposal for a regulation
Recital 12 a (new)
Text proposed by the Commission

Amendment 33
Proposal for a regulation
Recital 12 b (new)
Text proposed by the Commission

Amendment 34
Proposal for a regulation
Recital 12 c (new)
Text proposed by the Commission

Amendment 35
Proposal for a regulation
Recital 13
Text proposed by the Commission
(13) In order to ensure a consistent and
high level of protection of public interests
as regards health, safety and fundamental
rights, common normative standards for all
high-risk AI systems should be established.
Those standards should be consistent with
the Charter of fundamental rights of the

European Union (the Charter) and should
be non-discriminatory and in line with the
Union’s international trade commitments.

Amendment 36
Proposal for a regulation
Recital 14
Text proposed by the Commission
(14) In order to introduce a proportionate
and effective set of binding rules for AI
systems, a clearly defined risk-based
approach should be followed. That
approach should tailor the type and content
of such rules to the intensity and scope of
the risks that AI systems can generate. It is
therefore necessary to prohibit certain
artificial intelligence practices, to lay down
requirements for high-risk AI systems and
obligations for the relevant operators, and
to lay down transparency obligations for
certain AI systems.

Amendment 37
Proposal for a regulation
Recital 15
Text proposed by the Commission
(15) Aside from the many beneficial uses
of artificial intelligence, that technology
can also be misused and provide novel and
powerful tools for manipulative,
exploitative and social control practices.
Such practices are particularly harmful and
should be prohibited because they
contradict Union values of respect for
human dignity, freedom, equality,

democracy and the rule of law and Union
fundamental rights, including the right to
non-discrimination, data protection and
privacy and the rights of the child.

Amendment 38
Proposal for a regulation
Recital 16
Text proposed by the Commission
(16) The placing on the market, putting
into service or use of certain AI systems
intended to distort human behaviour,
whereby physical or psychological harms
are likely to occur, should be forbidden.
Such AI systems deploy subliminal
components individuals cannot perceive or
exploit vulnerabilities of children and
people due to their age, physical or mental
incapacities. They do so with the intention
to materially distort the behaviour of a
person and in a manner that causes or is
likely to cause harm to that or another
person. The intention may not be presumed
if the distortion of human behaviour
results from factors external to the AI
system which are outside of the control of
the provider or the user. Research for
legitimate purposes in relation to such AI
systems should not be stifled by the
prohibition, if such research does not
amount to use of the AI system in humanmachine relations that exposes natural
persons to harm and such research is
carried out in accordance with recognised
ethical standards for scientific research.

Amendment 39
Proposal for a regulation
Recital 16 a (new)
Text proposed by the Commission

Amendment 40
Proposal for a regulation
Recital 17
Text proposed by the Commission
(17) AI systems providing social scoring
of natural persons for general purpose by
public authorities or on their behalf may
lead to discriminatory outcomes and the
exclusion of certain groups. They may
violate the right to dignity and nondiscrimination and the values of equality
and justice. Such AI systems evaluate or
classify the trustworthiness of natural
persons based on their social behaviour in
multiple contexts or known or predicted
personal or personality characteristics. The
social score obtained from such AI systems
may lead to the detrimental or
unfavourable treatment of natural persons
or whole groups thereof in social contexts,
which are unrelated to the context in which
the data was originally generated or
collected or to a detrimental treatment that
is disproportionate or unjustified to the
gravity of their social behaviour. Such AI
systems should be therefore prohibited.

Amendment 41
Proposal for a regulation
Recital 18
Text proposed by the Commission
(18) The use of AI systems for ‘real-time’
remote biometric identification of natural
persons in publicly accessible spaces for
the purpose of law enforcement is
considered particularly intrusive in the
rights and freedoms of the concerned
persons, to the extent that it may affect the

private life of a large part of the
population, evoke a feeling of constant
surveillance and indirectly dissuade the
exercise of the freedom of assembly and
other fundamental rights. In addition, the
immediacy of the impact and the limited
opportunities for further checks or
corrections in relation to the use of such
systems operating in ‘real-time’ carry
heightened risks for the rights and
freedoms of the persons that are concerned
by law enforcement activities.

Amendment 42
Proposal for a regulation
Recital 19
Text proposed by the Commission
(19) The use of those systems for the
purpose of law enforcement should
therefore be prohibited, except in three
exhaustively listed and narrowly defined
situations, where the use is strictly
necessary to achieve a substantial public
interest, the importance of which
outweighs the risks. Those situations

involve the search for potential victims of
crime, including missing children; certain
threats to the life or physical safety of
natural persons or of a terrorist attack;
and the detection, localisation,
identification or prosecution of
perpetrators or suspects of the criminal
offences referred to in Council
Framework Decision 2002/584/JHA38 if
those criminal offences are punishable in
the Member State concerned by a
custodial sentence or a detention order for
a maximum period of at least three years
and as they are defined in the law of that
Member State. Such threshold for the
custodial sentence or detention order in
accordance with national law contributes
to ensure that the offence should be
serious enough to potentially justify the
use of ‘real-time’ remote biometric
identification systems. Moreover, of the 32
criminal offences listed in the Council
Framework Decision 2002/584/JHA,
some are in practice likely to be more
relevant than others, in that the recourse
to ‘real-time’ remote biometric
identification will foreseeably be
necessary and proportionate to highly
varying degrees for the practical pursuit
of the detection, localisation,
identification or prosecution of a
perpetrator or suspect of the different
criminal offences listed and having regard
to the likely differences in the seriousness,
probability and scale of the harm or
possible negative consequences.
__________________
38 Council Framework Decision

2002/584/JHA of 13 June 2002 on the
European arrest warrant and the
surrender procedures between Member
States (OJ L 190, 18.7.2002, p. 1).

Amendment 43
Proposal for a regulation
Recital 20

Text proposed by the Commission
(20) In order to ensure that those systems
are used in a responsible and
proportionate manner, it is also important
to establish that, in each of those three
exhaustively listed and narrowly defined
situations, certain elements should be
taken into account, in particular as
regards the nature of the situation giving
rise to the request and the consequences
of the use for the rights and freedoms of
all persons concerned and the safeguards
and conditions provided for with the use.
In addition, the use of ‘real-time’ remote
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement should be subject to
appropriate limits in time and space,
having regard in particular to the
evidence or indications regarding the
threats, the victims or perpetrator. The
reference database of persons should be
appropriate for each use case in each of
the three situations mentioned above.

Amendment 44
Proposal for a regulation
Recital 21
Text proposed by the Commission
(21) Each use of a ‘real-time’ remote
biometric identification system in publicly
accessible spaces for the purpose of law
enforcement should be subject to an
express and specific authorisation by a
judicial authority or by an independent
administrative authority of a Member
State. Such authorisation should in
principle be obtained prior to the use,
except in duly justified situations of
urgency, that is, situations where the need
to use the systems in question is such as to
make it effectively and objectively
impossible to obtain an authorisation
before commencing the use. In such

situations of urgency, the use should be
restricted to the absolute minimum
necessary and be subject to appropriate
safeguards and conditions, as determined
in national law and specified in the
context of each individual urgent use case
by the law enforcement authority itself. In
addition, the law enforcement authority
should in such situations seek to obtain
an authorisation as soon as possible,
whilst providing the reasons for not
having been able to request it earlier.

Amendment 45
Proposal for a regulation
Recital 22
Text proposed by the Commission
(22) Furthermore, it is appropriate to
provide, within the exhaustive framework
set by this Regulation that such use in the
territory of a Member State in accordance
with this Regulation should only be
possible where and in as far as the
Member State in question has decided to
expressly provide for the possibility to
authorise such use in its detailed rules of
national law. Consequently, Member
States remain free under this Regulation
not to provide for such a possibility at all
or to only provide for such a possibility in
respect of some of the objectives capable
of justifying authorised use identified in
this Regulation.

Amendment 46
Proposal for a regulation
Recital 23
Text proposed by the Commission
(23) The use of AI systems for ‘real-time’
remote biometric identification of natural
persons in publicly accessible spaces for
the purpose of law enforcement

necessarily involves the processing of
biometric data. The rules of this
Regulation that prohibit, subject to
certain exceptions, such use, which are
based on Article 16 TFEU, should apply
as lex specialis in respect of the rules on
the processing of biometric data contained
in Article 10 of Directive (EU) 2016/680,
thus regulating such use and the
processing of biometric data involved in
an exhaustive manner. Therefore, such
use and processing should only be
possible in as far as it is compatible with
the framework set by this Regulation,
without there being scope, outside that
framework, for the competent authorities,
where they act for purpose of law
enforcement, to use such systems and
process such data in connection thereto
on the grounds listed in Article 10 of
Directive (EU) 2016/680. In this context,
this Regulation is not intended to provide
the legal basis for the processing of
personal data under Article 8 of Directive
2016/680. However, the use of ‘real-time’
remote biometric identification systems in
publicly accessible spaces for purposes
other than law enforcement, including by
competent authorities, should not be
covered by the specific framework
regarding such use for the purpose of law
enforcement set by this Regulation. Such
use for purposes other than law
enforcement should therefore not be
subject to the requirement of an
authorisation under this Regulation and
the applicable detailed rules of national
law that may give effect to it.

Amendment 47
Proposal for a regulation
Recital 24
Text proposed by the Commission
(24) Any processing of biometric data and
other personal data involved in the use of
AI systems for biometric identification,

other than in connection to the use of ‘realtime’ remote biometric identification
systems in publicly accessible spaces for
the purpose of law enforcement as
regulated by this Regulation, including
where those systems are used by
competent authorities in publicly
accessible spaces for other purposes than
law enforcement, should continue to
comply with all requirements resulting
from Article 9(1) of Regulation (EU)
2016/679, Article 10(1) of Regulation (EU)
2018/1725 and Article 10 of Directive
(EU) 2016/680, as applicable.

Amendment 48
Proposal for a regulation
Recital 25
Text proposed by the Commission
(25) In accordance with Article 6a of
Protocol No 21 on the position of the
United Kingdom and Ireland in respect of
the area of freedom, security and justice, as
annexed to the TEU and to the TFEU,
Ireland is not bound by the rules laid down
in Article 5(1), point (d), (2) and (3) of this
Regulation adopted on the basis of Article
16 of the TFEU which relate to the
processing of personal data by the Member
States when carrying out activities falling
within the scope of Chapter 4 or Chapter 5
of Title V of Part Three of the TFEU,
where Ireland is not bound by the rules
governing the forms of judicial cooperation
in criminal matters or police cooperation
which require compliance with the
provisions laid down on the basis of Article
16 of the TFEU.

Amendment 49
Proposal for a regulation
Recital 26

Text proposed by the Commission
(26) In accordance with Articles 2 and 2a
of Protocol No 22 on the position of
Denmark, annexed to the TEU and TFEU,
Denmark is not bound by rules laid down
in Article 5(1), point (d), (2) and (3) of this
Regulation adopted on the basis of Article
16 of the TFEU, or subject to their
application, which relate to the processing
of personal data by the Member States
when carrying out activities falling within
the scope of Chapter 4 or Chapter 5 of Title
V of Part Three of the TFEU.

Amendment 50
Proposal for a regulation
Recital 26 a (new)
Text proposed by the Commission

Amendment 51
Proposal for a regulation
Recital 26 b (new)

Text proposed by the Commission

Amendment 52
Proposal for a regulation
Recital 26 c (new)
Text proposed by the Commission

Amendment 53
Proposal for a regulation
Recital 26 d (new)
Text proposed by the Commission

Amendment 54
Proposal for a regulation
Recital 27
Text proposed by the Commission
(27) High-risk AI systems should only be
placed on the Union market or put into
service if they comply with certain
mandatory requirements. Those
requirements should ensure that high-risk
AI systems available in the Union or whose
output is otherwise used in the Union do
not pose unacceptable risks to important
Union public interests as recognised and
protected by Union law. AI systems
identified as high-risk should be limited to
those that have a significant harmful
impact on the health, safety and
fundamental rights of persons in the Union
and such limitation minimises any potential
restriction to international trade, if any.

Amendment 55
Proposal for a regulation
Recital 28
Text proposed by the Commission
(28) AI systems could produce adverse
outcomes to health and safety of persons,
in particular when such systems operate as
components of products. Consistently with
the objectives of Union harmonisation
legislation to facilitate the free movement
of products in the internal market and to
ensure that only safe and otherwise
compliant products find their way into the
market, it is important that the safety risks
that may be generated by a product as a
whole due to its digital components,
including AI systems, are duly prevented
and mitigated. For instance, increasingly
autonomous robots, whether in the context
of manufacturing or personal assistance
and care should be able to safely operate
and performs their functions in complex
environments. Similarly, in the health
sector where the stakes for life and health
are particularly high, increasingly
sophisticated diagnostics systems and
systems supporting human decisions
should be reliable and accurate. The extent
of the adverse impact caused by the AI
system on the fundamental rights
protected by the Charter is of particular
relevance when classifying an AI system
as high-risk. Those rights include the
right to human dignity, respect for private

and family life, protection of personal
data, freedom of expression and
information, freedom of assembly and of
association, and non-discrimination,
consumer protection, workers’ rights,
rights of persons with disabilities, right to
an effective remedy and to a fair trial,
right of defence and the presumption of
innocence, right to good administration.
In addition to those rights, it is important
to highlight that children have specific
rights as enshrined in Article 24 of the
EU Charter and in the United Nations
Convention on the Rights of the Child
(further elaborated in the UNCRC
General Comment No. 25 as regards the
digital environment), both of which
require consideration of the children’s
vulnerabilities and provision of such
protection and care as necessary for their
well-being. The fundamental right to a
high level of environmental protection
enshrined in the Charter and
implemented in Union policies should
also be considered when assessing the
severity of the harm that an AI system can
cause, including in relation to the health
and safety of persons.

Amendment 56
Proposal for a regulation
Recital 28 a (new)
Text proposed by the Commission

Amendment 57
Proposal for a regulation
Recital 29
Text proposed by the Commission
(29) As regards high-risk AI systems that
are safety components of products or
systems, or which are themselves products
or systems falling within the scope of
Regulation (EC) No 300/2008 of the
European Parliament and of the Council39 ,
Regulation (EU) No 167/2013 of the
European Parliament and of the Council40 ,
Regulation (EU) No 168/2013 of the
European Parliament and of the Council41 ,
Directive 2014/90/EU of the European
Parliament and of the Council42 , Directive
(EU) 2016/797 of the European Parliament
and of the Council43 , Regulation (EU)
2018/858 of the European Parliament and
of the Council44 , Regulation (EU)
2018/1139 of the European Parliament and

of the Council45 , and Regulation (EU)
2019/2144 of the European Parliament and
of the Council46 , it is appropriate to amend
those acts to ensure that the Commission
takes into account, on the basis of the
technical and regulatory specificities of
each sector, and without interfering with
existing governance, conformity
assessment and enforcement mechanisms
and authorities established therein, the
mandatory requirements for high-risk AI
systems laid down in this Regulation when
adopting any relevant future delegated or
implementing acts on the basis of those
acts.
__________________
39 Regulation (EC) No 300/2008 of the

European Parliament and of the Council of
11 March 2008 on common rules in the
field of civil aviation security and
repealing Regulation (EC) No 2320/2002
(OJ L 97, 9.4.2008, p. 72).
40 Regulation (EU) No 167/2013 of the

European Parliament and of the Council of
5 February 2013 on the approval and
market surveillance of agricultural and
forestry vehicles (OJ L 60, 2.3.2013, p. 1).
41 Regulation (EU) No 168/2013 of the

European Parliament and of the Council of
15 January 2013 on the approval and
market surveillance of two- or three-wheel
vehicles and quadricycles (OJ L 60,
2.3.2013, p. 52).
42 Directive 2014/90/EU of the European

Parliament and of the Council of 23 July
2014 on marine equipment and repealing
Council Directive 96/98/EC (OJ L 257,
28.8.2014, p. 146).
43 Directive (EU) 2016/797 of the

European Parliament and of the Council of
11 May 2016 on the interoperability of the
rail system within the European Union (OJ
L 138, 26.5.2016, p. 44).
44 Regulation (EU) 2018/858 of the

European Parliament and of the Council of
30 May 2018 on the approval and market
surveillance of motor vehicles and their

trailers, and of systems, components and
separate technical units intended for such
vehicles, amending Regulations (EC) No
715/2007 and (EC) No 595/2009 and
repealing Directive 2007/46/EC (OJ L 151,
14.6.2018, p. 1).
45 Regulation (EU) 2018/1139 of the

European Parliament and of the Council of
4 July 2018 on common rules in the field
of civil aviation and establishing a
European Union Aviation Safety Agency,
and amending Regulations (EC) No
2111/2005, (EC) No 1008/2008, (EU) No
996/2010, (EU) No 376/2014 and
Directives 2014/30/EU and 2014/53/EU of
the European Parliament and of the
Council, and repealing Regulations (EC)
No 552/2004 and (EC) No 216/2008 of the
European Parliament and of the Council
and Council Regulation (EEC) No 3922/91
(OJ L 212, 22.8.2018, p. 1).
46 Regulation (EU) 2019/2144 of the

European Parliament and of the Council of
27 November 2019 on type-approval
requirements for motor vehicles and their
trailers, and systems, components and
separate technical units intended for such
vehicles, as regards their general safety and
the protection of vehicle occupants and
vulnerable road users, amending
Regulation (EU) 2018/858 of the European
Parliament and of the Council and
repealing Regulations (EC) No 78/2009,
(EC) No 79/2009 and (EC) No 661/2009 of
the European Parliament and of the
Council and Commission Regulations (EC)
No 631/2009, (EU) No 406/2010, (EU) No
672/2010, (EU) No 1003/2010, (EU) No
1005/2010, (EU) No 1008/2010, (EU) No
1009/2010, (EU) No 19/2011, (EU) No
109/2011, (EU) No 458/2011, (EU) No
65/2012, (EU) No 130/2012, (EU) No
347/2012, (EU) No 351/2012, (EU) No
1230/2012 and (EU) 2015/166 (OJ L 325,
16.12.2019, p. 1).

Amendment 58

Proposal for a regulation
Recital 30
Text proposed by the Commission
(30) As regards AI systems that are safety
components of products, or which are
themselves products, falling within the
scope of certain Union harmonisation
legislation, it is appropriate to classify
them as high-risk under this Regulation if
the product in question undergoes the
conformity assessment procedure with a
third-party conformity assessment body
pursuant to that relevant Union
harmonisation legislation. In particular,
such products are machinery, toys, lifts,
equipment and protective systems intended
for use in potentially explosive
atmospheres, radio equipment, pressure
equipment, recreational craft equipment,
cableway installations, appliances burning
gaseous fuels, medical devices, and in vitro
diagnostic medical devices.

Amendment 59
Proposal for a regulation
Recital 31
Text proposed by the Commission
(31) The classification of an AI system as
high-risk pursuant to this Regulation
should not necessarily mean that the
product whose safety component is the AI
system, or the AI system itself as a
product, is considered ‘high-risk’ under the
criteria established in the relevant Union
harmonisation legislation that applies to
the product. This is notably the case for
Regulation (EU) 2017/745 of the European
Parliament and of the Council47 and
Regulation (EU) 2017/746 of the European
Parliament and of the Council48 , where a
third-party conformity assessment is
provided for medium-risk and high-risk

products.
__________________
47 Regulation (EU) 2017/745 of the

European Parliament and of the Council of
5 April 2017 on medical devices, amending
Directive 2001/83/EC, Regulation (EC) No
178/2002 and Regulation (EC) No
1223/2009 and repealing Council
Directives 90/385/EEC and 93/42/EEC (OJ
L 117, 5.5.2017, p. 1).
48 Regulation (EU) 2017/746 of the

European Parliament and of the Council of
5 April 2017 on in vitro diagnostic medical
devices and repealing Directive 98/79/EC
and Commission Decision 2010/227/EU
(OJ L 117, 5.5.2017, p. 176).

Amendment 60
Proposal for a regulation
Recital 32
Text proposed by the Commission
(32) As regards stand-alone AI systems,
meaning high-risk AI systems other than
those that are safety components of
products, or which are themselves
products, it is appropriate to classify them
as high-risk if, in the light of their intended
purpose, they pose a high risk of harm to
the health and safety or the fundamental
rights of persons, taking into account both
the severity of the possible harm and its
probability of occurrence and they are
used in a number of specifically predefined areas specified in the Regulation.
The identification of those systems is based
on the same methodology and criteria
envisaged also for any future amendments
of the list of high-risk AI systems.

Amendment 61
Proposal for a regulation
Recital 32 a (new)
Text proposed by the Commission

Amendment 62
Proposal for a regulation
Recital 33
Text proposed by the Commission
(33) Technical inaccuracies of AI
systems intended for the remote biometric
identification of natural persons can lead
to biased results and entail discriminatory
effects. This is particularly relevant when
it comes to age, ethnicity, sex or
disabilities. Therefore, ‘real-time’ and
‘post’ remote biometric identification
systems should be classified as high-risk.
In view of the risks that they pose, both
types of remote biometric identification
systems should be subject to specific
requirements on logging capabilities and
human oversight.

Amendment 63
Proposal for a regulation
Recital 33 a (new)
Text proposed by the Commission

Amendment 64
Proposal for a regulation
Recital 34
Text proposed by the Commission
(34) As regards the management and
operation of critical infrastructure, it is
appropriate to classify as high-risk the AI
systems intended to be used as safety
components in the management and
operation of road traffic and the supply of
water, gas, heating and electricity, since
their failure or malfunctioning may put at
risk the life and health of persons at large
scale and lead to appreciable disruptions in
the ordinary conduct of social and
economic activities.

Amendment 65
Proposal for a regulation
Recital 35
Text proposed by the Commission
(35) AI systems used in education or
vocational training, notably for
determining access or assigning persons to
educational and vocational training
institutions or to evaluate persons on tests
as part of or as a precondition for their
education should be considered high-risk,
since they may determine the educational
and professional course of a person’s life
and therefore affect their ability to secure
their livelihood. When improperly
designed and used, such systems may
violate the right to education and training
as well as the right not to be discriminated
against and perpetuate historical patterns of
discrimination.

Amendment 66
Proposal for a regulation
Recital 36
Text proposed by the Commission
(36) AI systems used in employment,
workers management and access to selfemployment, notably for the recruitment
and selection of persons, for making
decisions on promotion and termination
and for task allocation, monitoring or
evaluation of persons in work-related
contractual relationships, should also be
classified as high-risk, since those systems
may appreciably impact future career
prospects and livelihoods of these persons.
Relevant work-related contractual
relationships should involve employees
and persons providing services through
platforms as referred to in the Commission
Work Programme 2021. Such persons
should in principle not be considered
users within the meaning of this
Regulation. Throughout the recruitment
process and in the evaluation, promotion,
or retention of persons in work-related
contractual relationships, such systems
may perpetuate historical patterns of
discrimination, for example against
women, certain age groups, persons with
disabilities, or persons of certain racial or
ethnic origins or sexual orientation. AI
systems used to monitor the performance
and behaviour of these persons may also
impact their rights to data protection and
privacy.

Amendment 67
Proposal for a regulation
Recital 37
Text proposed by the Commission
(37) Another area in which the use of AI
systems deserves special consideration is
the access to and enjoyment of certain
essential private and public services and
benefits necessary for people to fully
participate in society or to improve one’s
standard of living. In particular, AI systems
used to evaluate the credit score or
creditworthiness of natural persons should
be classified as high-risk AI systems, since
they determine those persons’ access to
financial resources or essential services
such as housing, electricity, and
telecommunication services. AI systems
used for this purpose may lead to
discrimination of persons or groups and
perpetuate historical patterns of
discrimination, for example based on racial
or ethnic origins, disabilities, age, sexual
orientation, or create new forms of
discriminatory impacts. Considering the
very limited scale of the impact and the
available alternatives on the market, it is
appropriate to exempt AI systems for the
purpose of creditworthiness assessment
and credit scoring when put into service
by small-scale providers for their own use.
Natural persons applying for or receiving
public assistance benefits and services
from public authorities are typically
dependent on those benefits and services
and in a vulnerable position in relation to
the responsible authorities. If AI systems
are used for determining whether such
benefits and services should be denied,
reduced, revoked or reclaimed by
authorities, they may have a significant

impact on persons’ livelihood and may
infringe their fundamental rights, such as
the right to social protection, nondiscrimination, human dignity or an
effective remedy. Those systems should
therefore be classified as high-risk.
Nonetheless, this Regulation should not
hamper the development and use of
innovative approaches in the public
administration, which would stand to
benefit from a wider use of compliant and
safe AI systems, provided that those
systems do not entail a high risk to legal
and natural persons. Finally, AI systems
used to dispatch or establish priority in the
dispatching of emergency first response
services should also be classified as highrisk since they make decisions in very
critical situations for the life and health of
persons and their property.

Amendment 68
Proposal for a regulation
Recital 37 a (new)
Text proposed by the Commission

Amendment 69
Proposal for a regulation
Recital 38
Text proposed by the Commission
(38) Actions by law enforcement
authorities involving certain uses of AI
systems are characterised by a significant
degree of power imbalance and may lead to
surveillance, arrest or deprivation of a
natural person’s liberty as well as other
adverse impacts on fundamental rights
guaranteed in the Charter. In particular, if
the AI system is not trained with high
quality data, does not meet adequate
requirements in terms of its accuracy or
robustness, or is not properly designed and
tested before being put on the market or
otherwise put into service, it may single
out people in a discriminatory or otherwise
incorrect or unjust manner. Furthermore,
the exercise of important procedural
fundamental rights, such as the right to an
effective remedy and to a fair trial as well
as the right of defence and the presumption
of innocence, could be hampered, in
particular, where such AI systems are not
sufficiently transparent, explainable and
documented. It is therefore appropriate to
classify as high-risk a number of AI
systems intended to be used in the law
enforcement context where accuracy,
reliability and transparency is particularly
important to avoid adverse impacts, retain
public trust and ensure accountability and
effective redress. In view of the nature of
the activities in question and the risks
relating thereto, those high-risk AI systems
should include in particular AI systems

intended to be used by law enforcement
authorities for individual risk assessments,
polygraphs and similar tools or to detect
the emotional state of natural person, to
detect ‘deep fakes’, for the evaluation of
the reliability of evidence in criminal
proceedings, for predicting the occurrence
or reoccurrence of an actual or potential
criminal offence based on profiling of
natural persons, or assessing personality
traits and characteristics or past criminal
behaviour of natural persons or groups,
for profiling in the course of detection,
investigation or prosecution of criminal
offences, as well as for crime analytics
regarding natural persons. AI systems
specifically intended to be used for
administrative proceedings by tax and
customs authorities should not be
considered high-risk AI systems used by
law enforcement authorities for the
purposes of prevention, detection,
investigation and prosecution of criminal
offences.

Amendment 70
Proposal for a regulation
Recital 39
Text proposed by the Commission
(39) AI systems used in migration, asylum
and border control management affect
people who are often in particularly
vulnerable position and who are dependent
on the outcome of the actions of the
competent public authorities. The
accuracy, non-discriminatory nature and
transparency of the AI systems used in
those contexts are therefore particularly
important to guarantee the respect of the

fundamental rights of the affected persons,
notably their rights to free movement, nondiscrimination, protection of private life
and personal data, international protection
and good administration. It is therefore
appropriate to classify as high-risk AI
systems intended to be used by the
competent public authorities charged with
tasks in the fields of migration, asylum and
border control management as polygraphs
and similar tools or to detect the emotional
state of a natural person; for assessing
certain risks posed by natural persons
entering the territory of a Member State or
applying for visa or asylum; for verifying
the authenticity of the relevant documents
of natural persons; for assisting competent
public authorities for the examination of
applications for asylum, visa and residence
permits and associated complaints with
regard to the objective to establish the
eligibility of the natural persons applying
for a status. AI systems in the area of
migration, asylum and border control
management covered by this Regulation
should comply with the relevant procedural
requirements set by the Directive
2013/32/EU of the European Parliament
and of the Council49 , the Regulation (EC)
No 810/2009 of the European Parliament
and of the Council50 and other relevant
legislation.

__________________
49 Directive 2013/32/EU of the European

Parliament and of the Council of 26 June
2013 on common procedures for granting
and withdrawing international protection
(OJ L 180, 29.6.2013, p. 60).
50 Regulation (EC) No 810/2009 of the

European Parliament and of the Council of
13 July 2009 establishing a Community
Code on Visas (Visa Code) (OJ L 243,
15.9.2009, p. 1).

Amendment 71
Proposal for a regulation
Recital 40
Text proposed by the Commission
(40) Certain AI systems intended for the
administration of justice and democratic
processes should be classified as high-risk,
considering their potentially significant
impact on democracy, rule of law,
individual freedoms as well as the right to
an effective remedy and to a fair trial. In
particular, to address the risks of potential
biases, errors and opacity, it is appropriate
to qualify as high-risk AI systems intended
to assist judicial authorities in researching
and interpreting facts and the law and in
applying the law to a concrete set of facts.
Such qualification should not extend,
however, to AI systems intended for purely
ancillary administrative activities that do
not affect the actual administration of
justice in individual cases, such as
anonymisation or pseudonymisation of
judicial decisions, documents or data,
communication between personnel,
administrative tasks or allocation of

resources.

Amendment 72
Proposal for a regulation
Recital 40 a (new)
Text proposed by the Commission

Amendment 73
Proposal for a regulation
Recital 40 b (new)
Text proposed by the Commission

Amendment 74
Proposal for a regulation
Recital 41
Text proposed by the Commission
(41) The fact that an AI system is
classified as high risk under this
Regulation should not be interpreted as
indicating that the use of the system is
necessarily lawful under other acts of
Union law or under national law
compatible with Union law, such as on the
protection of personal data, on the use of
polygraphs and similar tools or other

systems to detect the emotional state of
natural persons. Any such use should
continue to occur solely in accordance with
the applicable requirements resulting from
the Charter and from the applicable acts of
secondary Union law and national law.
This Regulation should not be understood
as providing for the legal ground for
processing of personal data, including
special categories of personal data, where
relevant.

Amendment 75
Proposal for a regulation
Recital 41 a (new)
Text proposed by the Commission

Amendment 76
Proposal for a regulation
Recital 42

Text proposed by the Commission
(42) To mitigate the risks from high-risk
AI systems placed or otherwise put into
service on the Union market for users and
affected persons, certain mandatory
requirements should apply, taking into
account the intended purpose of the use of
the system and according to the risk
management system to be established by
the provider.

Amendment 77
Proposal for a regulation
Recital 43
Text proposed by the Commission
(43) Requirements should apply to highrisk AI systems as regards the quality of
data sets used, technical documentation
and record-keeping, transparency and the
provision of information to users, human
oversight, and robustness, accuracy and
cybersecurity. Those requirements are
necessary to effectively mitigate the risks
for health, safety and fundamental rights,
as applicable in the light of the intended
purpose of the system, and no other less
trade restrictive measures are reasonably
available, thus avoiding unjustified
restrictions to trade.

Amendment 78
Proposal for a regulation
Recital 44

Text proposed by the Commission
(44) High data quality is essential for the
performance of many AI systems,
especially when techniques involving the
training of models are used, with a view to
ensure that the high-risk AI system
performs as intended and safely and it does
not become the source of discrimination
prohibited by Union law. High quality
training, validation and testing data sets
require the implementation of appropriate
data governance and management
practices. Training, validation and testing
data sets should be sufficiently relevant,
representative and free of errors and
complete in view of the intended purpose
of the system. They should also have the
appropriate statistical properties, including
as regards the persons or groups of persons
on which the high-risk AI system is
intended to be used. In particular, training,
validation and testing data sets should take
into account, to the extent required in the
light of their intended purpose, the
features, characteristics or elements that
are particular to the specific geographical,
behavioural or functional setting or context
within which the AI system is intended to
be used. In order to protect the right of
others from the discrimination that might
result from the bias in AI systems, the
providers shouldbe able to process also
special categories of personal data, as a
matter of substantial public interest, in
order to ensure the bias monitoring,
detection and correction in relation to highrisk AI systems.

Amendment 79
Proposal for a regulation
Recital 45
Text proposed by the Commission
(45) For the development of high-risk AI
systems, certain actors, such as providers,
notified bodies and other relevant entities,
such as digital innovation hubs, testing
experimentation facilities and researchers,
should be able to access and use high
quality datasets within their respective
fields of activities which are related to this
Regulation. European common data spaces
established by the Commission and the
facilitation of data sharing between
businesses and with government in the
public interest will be instrumental to
provide trustful, accountable and nondiscriminatory access to high quality data
for the training, validation and testing of

AI systems. For example, in health, the
European health data space will facilitate
non-discriminatory access to health data
and the training of artificial intelligence
algorithms on those datasets, in a privacypreserving, secure, timely, transparent and
trustworthy manner, and with an
appropriate institutional governance.
Relevant competent authorities, including
sectoral ones, providing or supporting the
access to data may also support the
provision of high-quality data for the
training, validation and testing of AI
systems.

Amendment 80
Proposal for a regulation
Recital 45 a (new)
Text proposed by the Commission

Amendment 81

Proposal for a regulation
Recital 46
Text proposed by the Commission
(46) Having information on how high-risk
AI systems have been developed and how
they perform throughout their lifecycle is
essential to verify compliance with the
requirements under this Regulation. This
requires keeping records and the
availability of a technical documentation,
containing information which is necessary
to assess the compliance of the AI system
with the relevant requirements. Such
information should include the general
characteristics, capabilities and limitations
of the system, algorithms, data, training,
testing and validation processes used as
well as documentation on the relevant risk
management system. The technical
documentation should be kept up to date.

Amendment 82
Proposal for a regulation
Recital 46 a (new)
Text proposed by the Commission

Amendment 83
Proposal for a regulation
Recital 46 b (new)

Text proposed by the Commission

Amendment 84
Proposal for a regulation
Recital 47 a (new)
Text proposed by the Commission

Amendment 85
Proposal for a regulation
Recital 49

Text proposed by the Commission
(49) High-risk AI systems should perform
consistently throughout their lifecycle and
meet an appropriate level of accuracy,
robustness and cybersecurity in accordance
with the generally acknowledged state of
the art. The level of accuracy and
accuracy metrics should be communicated
to the users.

Amendment 86
Proposal for a regulation
Recital 50
Text proposed by the Commission
(50) The technical robustness is a key
requirement for high-risk AI systems. They
should be resilient against risks connected
to the limitations of the system (e.g. errors,
faults, inconsistencies, unexpected
situations) as well as against malicious
actions that may compromise the security
of the AI system and result in harmful or

otherwise undesirable behaviour. Failure to
protect against these risks could lead to
safety impacts or negatively affect the
fundamental rights, for example due to
erroneous decisions or wrong or biased
outputs generated by the AI system.

Amendment 87
Proposal for a regulation
Recital 51
Text proposed by the Commission
(51) Cybersecurity plays a crucial role in
ensuring that AI systems are resilient
against attempts to alter their use,
behaviour, performance or compromise
their security properties by malicious third
parties exploiting the system’s
vulnerabilities. Cyberattacks against AI
systems can leverage AI specific assets,
such as training data sets (e.g. data
poisoning) or trained models (e.g.
adversarial attacks), or exploit
vulnerabilities in the AI system’s digital
assets or the underlying ICT infrastructure.
To ensure a level of cybersecurity
appropriate to the risks, suitable measures
should therefore be taken by the providers
of high-risk AI systems, also taking into
account as appropriate the underlying ICT
infrastructure.

Amendment 88

Proposal for a regulation
Recital 53 a (new)
Text proposed by the Commission

Amendment 89
Proposal for a regulation
Recital 54
Text proposed by the Commission
(54) The provider should establish a
sound quality management system, ensure
the accomplishment of the required
conformity assessment procedure, draw up
the relevant documentation and establish a

robust post-market monitoring system.
Public authorities which put into service
high-risk AI systems for their own use may
adopt and implement the rules for the
quality management system as part of the
quality management system adopted at a
national or regional level, as appropriate,
taking into account the specificities of the
sector and the competences and
organisation of the public authority in
question.

Amendment 90
Proposal for a regulation
Recital 56
Text proposed by the Commission
(56) To enable enforcement of this
Regulation and create a level-playing field
for operators, and taking into account the
different forms of making available of
digital products, it is important to ensure
that, under all circumstances, a person
established in the Union can provide
authorities with all the necessary
information on the compliance of an AI
system. Therefore, prior to making their AI
systems available in the Union, where an
importer cannot be identified, providers
established outside the Union shall, by
written mandate, appoint an authorised
representative established in the Union.

Amendment 91

Proposal for a regulation
Recital 58
Text proposed by the Commission
(58) Given the nature of AI systems and
the risks to safety and fundamental rights
possibly associated with their use,
including as regard the need to ensure
proper monitoring of the performance of an
AI system in a real-life setting, it is
appropriate to set specific responsibilities
for users. Users should in particular use
high-risk AI systems in accordance with
the instructions of use and certain other
obligations should be provided for with
regard to monitoring of the functioning of
the AI systems and with regard to recordkeeping, as appropriate.

Amendment 92
Proposal for a regulation
Recital 58 a (new)
Text proposed by the Commission

Amendment 93

Proposal for a regulation
Recital 59
Text proposed by the Commission
(59) It is appropriate to envisage that the
user of the AI system should be the natural
or legal person, public authority, agency or
other body under whose authority the AI
system is operated except where the use is
made in the course of a personal nonprofessional activity.

Amendment 94
Proposal for a regulation
Recital 60
Text proposed by the Commission
(60) In the light of the complexity of the
artificial intelligence value chain, relevant
third parties, notably the ones involved in
the sale and the supply of software,
software tools and components, pre-trained
models and data, or providers of network
services, should cooperate, as appropriate,
with providers and users to enable their
compliance with the obligations under this
Regulation and with competent
authorities established under this
Regulation.

Amendment 95
Proposal for a regulation
Recital 60 a (new)
Text proposed by the Commission

Amendment 96
Proposal for a regulation
Recital 60 b (new)
Text proposed by the Commission

Amendment 97
Proposal for a regulation
Recital 60 c (new)
Text proposed by the Commission

Amendment 98
Proposal for a regulation
Recital 60 d (new)
Text proposed by the Commission

Amendment 99
Proposal for a regulation
Recital 60 e (new)
Text proposed by the Commission

Amendment 100
Proposal for a regulation
Recital 60 f (new)
Text proposed by the Commission

Amendment 101
Proposal for a regulation
Recital 60 g (new)
Text proposed by the Commission

Amendment 102
Proposal for a regulation
Recital 60 h (new)
Text proposed by the Commission

Amendment 103
Proposal for a regulation
Recital 61
Text proposed by the Commission
(61) Standardisation should play a key
role to provide technical solutions to
providers to ensure compliance with this
Regulation. Compliance with harmonised
standards as defined in Regulation (EU)
No 1025/2012 of the European Parliament
and of the Council54 should be a means for
providers to demonstrate conformity with
the requirements of this Regulation.
However, the Commission could adopt
common technical specifications in areas
where no harmonised standards exist or
where they are insufficient.

__________________
54 Regulation (EU) No 1025/2012 of the

European Parliament and of the Council of
25 October 2012 on European
standardisation, amending Council
Directives 89/686/EEC and 93/15/EEC and
Directives 94/9/EC, 94/25/EC, 95/16/EC,
97/23/EC, 98/34/EC, 2004/22/EC,
2007/23/EC, 2009/23/EC and 2009/105/EC
of the European Parliament and of the
Council and repealing Council Decision
87/95/EEC and Decision No

1673/2006/EC of the European Parliament
and of the Council (OJ L 316, 14.11.2012,
p. 12).

Amendment 104
Proposal for a regulation
Recital 61 a (new)
Text proposed by the Commission

Amendment 105
Proposal for a regulation
Recital 61 b (new)
Text proposed by the Commission

Amendment 106
Proposal for a regulation
Recital 61 c (new)
Text proposed by the Commission

Amendment 107
Proposal for a regulation
Recital 61 d (new)
Text proposed by the Commission

Amendment 108
Proposal for a regulation
Recital 62

Text proposed by the Commission
(62) In order to ensure a high level of
trustworthiness of high-risk AI systems,
those systems should be subject to a
conformity assessment prior to their
placing on the market or putting into
service.

Amendment 109
Proposal for a regulation
Recital 64
Text proposed by the Commission
(64) Given the more extensive experience
of professional pre-market certifiers in the
field of product safety and the different
nature of risks involved, it is appropriate to
limit, at least in an initial phase of
application of this Regulation, the scope of
application of third-party conformity
assessment for high-risk AI systems other
than those related to products. Therefore,
the conformity assessment of such systems
should be carried out as a general rule by
the provider under its own responsibility,
with the only exception of AI systems
intended to be used for the remote
biometric identification of persons, for
which the involvement of a notified body
in the conformity assessment should be
foreseen, to the extent they are not
prohibited.

Amendment 110
Proposal for a regulation
Recital 65
Text proposed by the Commission
(65) In order to carry out third-party
conformity assessment for AI systems
intended to be used for the remote
biometric identification of persons,
notified bodies should be designated under
this Regulation by the national competent
authorities, provided they are compliant
with a set of requirements, notably on
independence, competence and absence of
conflicts of interests.

Amendment 111
Proposal for a regulation
Recital 65 a (new)
Text proposed by the Commission

Amendment 112
Proposal for a regulation
Recital 66
Text proposed by the Commission
(66) In line with the commonly
established notion of substantial
modification for products regulated by
Union harmonisation legislation, it is
appropriate that an AI system undergoes a
new conformity assessment whenever a
change occurs which may affect the
compliance of the system with this
Regulation or when the intended purpose
of the system changes. In addition, as
regards AI systems which continue to
‘learn’ after being placed on the market or
put into service (i.e. they automatically
adapt how functions are carried out), it is
necessary to provide rules establishing that
changes to the algorithm and its
performance that have been pre-determined
by the provider and assessed at the moment
of the conformity assessment should not
constitute a substantial modification.

Amendment 113
Proposal for a regulation
Recital 67
Text proposed by the Commission
(67) High-risk AI systems should bear the
CE marking to indicate their conformity
with this Regulation so that they can move
freely within the internal market. Member
States should not create unjustified
obstacles to the placing on the market or
putting into service of high-risk AI systems
that comply with the requirements laid
down in this Regulation and bear the CE
marking.

Amendment 114
Proposal for a regulation
Recital 68
Text proposed by the Commission
(68) Under certain conditions, rapid
availability of innovative technologies may
be crucial for health and safety of persons
and for society as a whole. It is thus
appropriate that under exceptional reasons
of public security or protection of life and
health of natural persons and the protection
of industrial and commercial property,
Member States could authorise the placing
on the market or putting into service of AI
systems which have not undergone a
conformity assessment.

Amendment 115

Proposal for a regulation
Recital 69
Text proposed by the Commission
(69) In order to facilitate the work of the
Commission and the Member States in the
artificial intelligence field as well as to
increase the transparency towards the
public, providers of high-risk AI systems
other than those related to products falling
within the scope of relevant existing Union
harmonisation legislation, should be
required to register their high-risk AI
system in a EU database, to be established
and managed by the Commission. The
Commission should be the controller of
that database, in accordance with
Regulation (EU) 2018/1725 of the
European Parliament and of the Council55 .
In order to ensure the full functionality of
the database, when deployed, the procedure
for setting the database should include the
elaboration of functional specifications by
the Commission and an independent audit
report.

__________________
55 Regulation (EU) 2016/679 of the

European Parliament and of the Council of
27 April 2016 on the protection of natural
persons with regard to the processing of
personal data and on the free movement of
such data, and repealing Directive
95/46/EC (General Data Protection
Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 116
Proposal for a regulation
Recital 71
Text proposed by the Commission
(71) Artificial intelligence is a rapidly
developing family of technologies that
requires novel forms of regulatory
oversight and a safe space for
experimentation, while ensuring
responsible innovation and integration of
appropriate safeguards and risk mitigation
measures. To ensure a legal framework that
is innovation-friendly, future-proof and
resilient to disruption, national competent
authorities from one or more Member
States should be encouraged to establish
artificial intelligence regulatory sandboxes
to facilitate the development and testing of
innovative AI systems under strict
regulatory oversight before these systems
are placed on the market or otherwise put
into service.

Amendment 117
Proposal for a regulation
Recital 72
Text proposed by the Commission
(72) The objectives of the regulatory
sandboxes should be to foster AI
innovation by establishing a controlled
experimentation and testing environment
in the development and pre-marketing
phase with a view to ensuring compliance
of the innovative AI systems with this
Regulation and other relevant Union and
Member States legislation; to enhance legal
certainty for innovators and the competent
authorities’ oversight and understanding
of the opportunities, emerging risks and
the impacts of AI use, and to accelerate
access to markets, including by removing
barriers for small and medium enterprises
(SMEs) and start-ups. To ensure uniform
implementation across the Union and
economies of scale, it is appropriate to
establish common rules for the regulatory
sandboxes’ implementation and a
framework for cooperation between the
relevant authorities involved in the
supervision of the sandboxes. This
Regulation should provide the legal basis

for the use of personal data collected for
other purposes for developing certain AI
systems in the public interest within the
AI regulatory sandbox, in line with Article
6(4) of Regulation (EU) 2016/679, and
Article 6 of Regulation (EU) 2018/1725,
and without prejudice to Article 4(2) of
Directive (EU) 2016/680. Participants in
the sandbox should ensure appropriate
safeguards and cooperate with the
competent authorities, including by
following their guidance and acting
expeditiously and in good faith to mitigate
any high-risks to safety and fundamental
rights that may arise during the
development and experimentation in the
sandbox. The conduct of the participants
in the sandbox should be taken into
account when competent authorities
decide whether to impose an
administrative fine under Article 83(2) of
Regulation 2016/679 and Article 57 of
Directive 2016/680.

Amendment 118
Proposal for a regulation
Recital 72 a (new)
Text proposed by the Commission

Amendment 119
Proposal for a regulation
Recital 72 b (new)
Text proposed by the Commission

Amendment 120
Proposal for a regulation
Recital 73
Text proposed by the Commission
(73) In order to promote and protect
innovation, it is important that the interests
of small-scale providers and users of AI
systems are taken into particular account.
To this objective, Member States should
develop initiatives, which are targeted at

those operators, including on awareness
raising and information communication.
Moreover, the specific interests and needs
of small-scale providers shall be taken into
account when Notified Bodies set
conformity assessment fees. Translation
costs related to mandatory documentation
and communication with authorities may
constitute a significant cost for providers
and other operators, notably those of a
smaller scale. Member States should
possibly ensure that one of the languages
determined and accepted by them for
relevant providers’ documentation and for
communication with operators is one
which is broadly understood by the largest
possible number of cross-border users.

Amendment 121
Proposal for a regulation
Recital 74
Text proposed by the Commission
(74) In order to minimise the risks to
implementation resulting from lack of
knowledge and expertise in the market as
well as to facilitate compliance of
providers and notified bodies with their
obligations under this Regulation, the AIon demand platform, the European Digital
Innovation Hubs and the Testing and
Experimentation Facilities established by
the Commission and the Member States at
national or EU level should possibly
contribute to the implementation of this
Regulation. Within their respective mission
and fields of competence, they may
provide in particular technical and
scientific support to providers and notified
bodies.

Amendment 122
Proposal for a regulation
Recital 76
Text proposed by the Commission
(76) In order to facilitate a smooth,
effective and harmonised implementation
of this Regulation a European Artificial
Intelligence Board should be established.
The Board should be responsible for a
number of advisory tasks, including issuing
opinions, recommendations, advice or

guidance on matters related to the
implementation of this Regulation,
including on technical specifications or
existing standards regarding the
requirements established in this
Regulation and providing advice to and
assisting the Commission on specific
questions related to artificial intelligence.

Amendment 123
Proposal for a regulation
Recital 77
Text proposed by the Commission
(77) Member States hold a key role in the
application and enforcement of this

Regulation. In this respect, each Member
State should designate one or more
national competent authorities for the
purpose of supervising the application and
implementation of this Regulation. In order
to increase organisation efficiency on the
side of Member States and to set an official
point of contact vis-à-vis the public and
other counterparts at Member State and
Union levels, in each Member State one
national authority should be designated as
national supervisory authority.

Amendment 124
Proposal for a regulation
Recital 77 a (new)
Text proposed by the Commission

Amendment 125
Proposal for a regulation
Recital 77 b (new)
Text proposed by the Commission

Amendment 126
Proposal for a regulation
Recital 78
Text proposed by the Commission
(78) In order to ensure that providers of
high-risk AI systems can take into account
the experience on the use of high-risk AI
systems for improving their systems and
the design and development process or can
take any possible corrective action in a
timely manner, all providers should have a
post-market monitoring system in place.
This system is also key to ensure that the
possible risks emerging from AI systems
which continue to ‘learn’ after being
placed on the market or put into service
can be more efficiently and timely
addressed. In this context, providers should
also be required to have a system in place
to report to the relevant authorities any
serious incidents or any breaches to
national and Union law protecting
fundamental rights resulting from the use
of their AI systems.

Amendment 127
Proposal for a regulation
Recital 79
Text proposed by the Commission
(79) In order to ensure an appropriate and

effective enforcement of the requirements
and obligations set out by this Regulation,
which is Union harmonisation legislation,
the system of market surveillance and
compliance of products established by
Regulation (EU) 2019/1020 should apply
in its entirety. Where necessary for their
mandate, national public authorities or
bodies, which supervise the application of
Union law protecting fundamental rights,
including equality bodies, should also have
access to any documentation created under
this Regulation.

Amendment 128
Proposal for a regulation
Recital 80
Text proposed by the Commission
(80) Union legislation on financial
services includes internal governance and
risk management rules and requirements
which are applicable to regulated financial
institutions in the course of provision of
those services, including when they make
use of AI systems. In order to ensure
coherent application and enforcement of
the obligations under this Regulation and
relevant rules and requirements of the
Union financial services legislation, the
authorities responsible for the supervision
and enforcement of the financial services
legislation, including where applicable the
European Central Bank, should be
designated as competent authorities for the
purpose of supervising the implementation
of this Regulation, including for market
surveillance activities, as regards AI
systems provided or used by regulated and
supervised financial institutions. To further
enhance the consistency between this

Regulation and the rules applicable to
credit institutions regulated under Directive
2013/36/EU of the European Parliament
and of the Council56 , it is also appropriate
to integrate the conformity assessment
procedure and some of the providers’
procedural obligations in relation to risk
management, post marketing monitoring
and documentation into the existing
obligations and procedures under Directive
2013/36/EU. In order to avoid overlaps,
limited derogations should also be
envisaged in relation to the quality
management system of providers and the
monitoring obligation placed on users of
high-risk AI systems to the extent that
these apply to credit institutions regulated
by Directive 2013/36/EU.
__________________
56 Directive 2013/36/EU of the European

Parliament and of the Council of 26 June
2013 on access to the activity of credit
institutions and the prudential supervision
of credit institutions and investment firms,
amending Directive 2002/87/EC and
repealing Directives 2006/48/EC and
2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 129
Proposal for a regulation
Recital 80 a (new)
Text proposed by the Commission

Amendment 130
Proposal for a regulation
Recital 82
Text proposed by the Commission
(82) It is important that AI systems related
to products that are not high-risk in
accordance with this Regulation and thus
are not required to comply with the
requirements set out herein are
nevertheless safe when placed on the
market or put into service. To contribute to
this objective, the Directive 2001/95/EC of
the European Parliament and of the
Council57 would apply as a safety net.
__________________
57 Directive 2001/95/EC of the European

Parliament and of the Council of 3
December 2001 on general product safety
(OJ L 11, 15.1.2002, p. 4).

Amendment 131
Proposal for a regulation
Recital 83

Text proposed by the Commission
(83) In order to ensure trustful and
constructive cooperation of competent
authorities on Union and national level, all
parties involved in the application of this
Regulation should respect the
confidentiality of information and data
obtained in carrying out their tasks.

Amendment 132
Proposal for a regulation
Recital 84
Text proposed by the Commission
(84) Member States should take all
necessary measures to ensure that the
provisions of this Regulation are
implemented, including by laying down
effective, proportionate and dissuasive
penalties for their infringement. For certain
specific infringements, Member States
should take into account the margins and
criteria set out in this Regulation. The
European Data Protection Supervisor
should have the power to impose fines on
Union institutions, agencies and bodies
falling within the scope of this Regulation.

Amendment 133
Proposal for a regulation
Recital 84 a (new)
Text proposed by the Commission

Amendment 134
Proposal for a regulation
Recital 84 b (new)
Text proposed by the Commission

Amendment 135
Proposal for a regulation
Recital 84 c (new)
Text proposed by the Commission

Amendment 136
Proposal for a regulation
Recital 85
Text proposed by the Commission
(85) In order to ensure that the regulatory
framework can be adapted where
necessary, the power to adopt acts in
accordance with Article 290 TFEU should
be delegated to the Commission to amend
the techniques and approaches referred to
in Annex I to define AI systems, the Union
harmonisation legislation listed in Annex
II, the high-risk AI systems listed in Annex
III, the provisions regarding technical
documentation listed in Annex IV, the
content of the EU declaration of
conformity in Annex V, the provisions
regarding the conformity assessment
procedures in Annex VI and VII and the
provisions establishing the high-risk AI
systems to which the conformity
assessment procedure based on assessment
of the quality management system and
assessment of the technical documentation
should apply. It is of particular importance
that the Commission carry out appropriate
consultations during its preparatory work,
including at expert level, and that those
consultations be conducted in accordance
with the principles laid down in the
Interinstitutional Agreement of 13 April
2016 on Better Law-Making58 . In
particular, to ensure equal participation in
the preparation of delegated acts, the
European Parliament and the Council
receive all documents at the same time as
Member States’ experts, and their experts
systematically have access to meetings of
Commission expert groups dealing with the
preparation of delegated acts.

__________________
58 OJ L 123, 12.5.2016, p. 1.

Amendment 137
Proposal for a regulation
Recital 85 a (new)
Text proposed by the Commission

Amendment 138
Proposal for a regulation
Recital 87 a (new)
Text proposed by the Commission

Amendment 139
Proposal for a regulation
Recital 89

Text proposed by the Commission
(89) The European Data Protection
Supervisor and the European Data
Protection Board were consulted in
accordance with Article 42(2) of
Regulation (EU) 2018/1725 and delivered
an opinion on […]”.

Amendment 140
Proposal for a regulation
Article 1 – paragraph 1 (new)
Text proposed by the Commission

Amendment 141
Proposal for a regulation
Article 1 – paragraph 1 – point d
Text proposed by the Commission
(d) harmonised transparency rules for AI
systems intended to interact with natural
persons, emotion recognition systems and
biometric categorisation systems, and AI
systems used to generate or manipulate
image, audio or video content;

Amendment 142
Proposal for a regulation
Article 1 – paragraph 1 – point e
Text proposed by the Commission

(e) rules on market monitoring and
surveillance.

Amendment 143
Proposal for a regulation
Article 1 – paragraph 1 – point e a (new)
Text proposed by the Commission

Amendment 144
Proposal for a regulation
Article 1 – paragraph 1 – point e b (new)
Text proposed by the Commission

Amendment 145
Proposal for a regulation
Article 2 – paragraph 1 – point b
Text proposed by the Commission
(b) users of AI systems located within
the Union;

Amendment 146
Proposal for a regulation
Article 2 – paragraph 1 – point c

Text proposed by the Commission
(c) providers and users of AI systems
that are located in a third country, where
the output produced by the system is used
in the Union;

Amendment 147
Proposal for a regulation
Article 2 – paragraph 1 – point c a (new)
Text proposed by the Commission

Amendment 148
Proposal for a regulation
Article 2 – paragraph 1 – point c b (new)
Text proposed by the Commission

Amendment 149
Proposal for a regulation
Article 2 – paragraph 1 – point c c (new)
Text proposed by the Commission

Amendment 150
Proposal for a regulation
Article 2 – paragraph 2 – introductory part
Text proposed by the Commission
2.
For high-risk AI systems that are
safety components of products or systems,
or which are themselves products or
systems, falling within the scope of the
following acts, only Article 84 of this
Regulation shall apply:

Amendment 151
Proposal for a regulation
Article 2 – paragraph 2 – point a
Text proposed by the Commission
(a)

Regulation (EC) 300/2008;

Amendment 152
Proposal for a regulation
Article 2 – paragraph 2 – point b
Text proposed by the Commission
(b)

Regulation (EU) No 167/2013;

Amendment 153
Proposal for a regulation
Article 2 – paragraph 2 – point c

Text proposed by the Commission
(c)

Regulation (EU) No 168/2013;

Amendment 154
Proposal for a regulation
Article 2 – paragraph 2 – point d
Text proposed by the Commission
(d)

Directive 2014/90/EU;

Amendment 155
Proposal for a regulation
Article 2 – paragraph 2 – point e
Text proposed by the Commission
(e)

Directive (EU) 2016/797;

Amendment 156
Proposal for a regulation
Article 2 – paragraph 2 – point f
Text proposed by the Commission
(f)

Regulation (EU) 2018/858;

Amendment 157
Proposal for a regulation
Article 2 – paragraph 2 – point g
Text proposed by the Commission
(g)

Regulation (EU) 2018/1139;

Amendment 158

Proposal for a regulation
Article 2 – paragraph 2 – point h
Text proposed by the Commission
(h)

Regulation (EU) 2019/2144.

Amendment 159
Proposal for a regulation
Article 2 – paragraph 4
Text proposed by the Commission
4.
This Regulation shall not apply to
public authorities in a third country nor to
international organisations falling within
the scope of this Regulation pursuant to
paragraph 1, where those authorities or
organisations use AI systems in the
framework of international agreements for
law enforcement and judicial cooperation
with the Union or with one or more
Member States.

Amendment 160
Proposal for a regulation
Article 2 – paragraph 5 a (new)
Text proposed by the Commission

Amendment 161
Proposal for a regulation
Article 2 – paragraph 5 b (new)
Text proposed by the Commission

Amendment 162
Proposal for a regulation
Article 2 – paragraph 5 c (new)
Text proposed by the Commission

Amendment 163
Proposal for a regulation
Article 2 – paragraph 5 d (new)

Text proposed by the Commission

Amendment 164
Proposal for a regulation
Article 2 – paragraph 5 e (new)
Text proposed by the Commission

Amendment 165
Proposal for a regulation
Article 3 – paragraph 1 – point 1

Text proposed by the Commission
(1) ‘artificial intelligence system’ (AI
system) means software that is developed
with one or more of the techniques and
approaches listed in Annex I and can, for
a given set of human-defined objectives,
generate outputs such as content,
predictions, recommendations, or decisions
influencing the environments they interact
with;

Amendment 166
Proposal for a regulation
Article 3 – paragraph 1 – point 1 a (new)
Text proposed by the Commission

Amendment 167
Proposal for a regulation
Article 3 – paragraph 1 – point 1 b (new)
Text proposed by the Commission

Amendment 168
Proposal for a regulation
Article 3 – paragraph 1 – point 1 c (new)

Text proposed by the Commission

Amendment 169
Proposal for a regulation
Article 3 – paragraph 1 – point 1 d (new)
Text proposed by the Commission

Amendment 170
Proposal for a regulation
Article 3 – paragraph 1 – point 1 e (new)
Text proposed by the Commission

Amendment 171
Proposal for a regulation
Article 3 – paragraph 1 – point 3
Text proposed by the Commission
(3) ‘small-scale provider’ means a
provider that is a micro or small
enterprise within the meaning of
Commission Recommendation
2003/361/EC61 ;

__________________
61 Commission Recommendation of 6 May

2003 concerning the definition of micro,
small and medium-sized enterprises (OJ L
124, 20.5.2003, p. 36).

Amendment 172
Proposal for a regulation
Article 3 – paragraph 1 – point 4
Text proposed by the Commission
(4) ‘user’ means any natural or legal
person, public authority, agency or other
body using an AI system under its
authority, except where the AI system is
used in the course of a personal nonprofessional activity;

Amendment 173
Proposal for a regulation
Article 3 – paragraph 1 – point 8
Text proposed by the Commission
(8) ‘operator’ means the provider, the
user, the authorised representative, the
importer and the distributor;

Amendment 174
Proposal for a regulation
Article 3 – paragraph 1 – point 8 a (new)
Text proposed by the Commission

Amendment 175

Proposal for a regulation
Article 3 – paragraph 1 – point 11
Text proposed by the Commission
(11) ‘putting into service’ means the
supply of an AI system for first use directly
to the user or for own use on the Union
market for its intended purpose;

Amendment 176
Proposal for a regulation
Article 3 – paragraph 1 – point 13
Text proposed by the Commission
(13) ‘reasonably foreseeable misuse’
means the use of an AI system in a way
that is not in accordance with its intended
purpose, but which may result from
reasonably foreseeable human behaviour or
interaction with other systems;

Amendment 177
Proposal for a regulation
Article 3 – paragraph 1 – point 14
Text proposed by the Commission
(14) ‘safety component of a product or
system’ means a component of a product or
of a system which fulfils a safety function
for that product or system or the failure or
malfunctioning of which endangers the
health and safety of persons or property;

Amendment 178
Proposal for a regulation
Article 3 – paragraph 1 – point 15

Text proposed by the Commission
(15) ‘instructions for use’ means the
information provided by the provider to
inform the user of in particular an AI
system’s intended purpose and proper use,
inclusive of the specific geographical,
behavioural or functional setting within
which the high-risk AI system is intended
to be used;

Amendment 179
Proposal for a regulation
Article 3 – paragraph 1 – point 16
Text proposed by the Commission
(16) ‘recall of an AI system’ means any
measure aimed at achieving the return to
the provider of an AI system made
available to users;

Amendment 180
Proposal for a regulation
Article 3 – paragraph 1 – point 20
Text proposed by the Commission
(20) ‘conformity assessment’ means the
process of verifying whether the
requirements set out in Title III, Chapter 2
of this Regulation relating to an AI system
have been fulfilled;

Amendment 181
Proposal for a regulation
Article 3 – paragraph 1 – point 22
Text proposed by the Commission
(22) ‘notified body’ means a conformity
assessment body designated in accordance

with this Regulation and other relevant
Union harmonisation legislation;

Amendment 182
Proposal for a regulation
Article 3 – paragraph 1 – point 23
Text proposed by the Commission
(23) ‘substantial modification’ means a
change to the AI system following its
placing on the market or putting into
service which affects the compliance of the
AI system with the requirements set out in
Title III, Chapter 2 of this Regulation or
results in a modification to the intended
purpose for which the AI system has been
assessed;

Amendment 183
Proposal for a regulation
Article 3 – paragraph 1 – point 24
Text proposed by the Commission
(24) ‘CE marking of conformity’ (CE
marking) means a marking by which a
provider indicates that an AI system is in
conformity with the requirements set out in
Title III, Chapter 2 of this Regulation and
other applicable Union legislation
harmonising the conditions for the
marketing of products (‘Union
harmonisation legislation’) providing for
its affixing;

Amendment 184
Proposal for a regulation
Article 3 – paragraph 1 – point 29

Text proposed by the Commission
(29) ‘training data’ means data used for
training an AI system through fitting its
learnable parameters, including the
weights of a neural network;

Amendment 185
Proposal for a regulation
Article 3 – paragraph 1 – point 30
Text proposed by the Commission
(30) ‘validation data’ means data used for
providing an evaluation of the trained AI
system and for tuning its non-learnable
parameters and its learning process, among
other things, in order to prevent overfitting;
whereas the validation dataset can be a
separate dataset or part of the training
dataset, either as a fixed or variable split;

Amendment 186
Proposal for a regulation
Article 3 – paragraph 1 – point 33
Text proposed by the Commission
(33) ‘biometric data’ means personal data
resulting from specific technical
processing relating to the physical,
physiological or behavioural
characteristics of a natural person, which
allow or confirm the unique identification
of that natural person, such as facial
images or dactyloscopic data;

Amendment 187
Proposal for a regulation
Article 3 – paragraph 1 – point 33 a (new)

Text proposed by the Commission

Amendment 188
Proposal for a regulation
Article 3 – paragraph 1 – point 33 b (new)
Text proposed by the Commission

Amendment 189
Proposal for a regulation
Article 3 – paragraph 1 – point 33 c (new)
Text proposed by the Commission

Amendment 190
Proposal for a regulation
Article 3 – paragraph 1 – point 33 d (new)

Text proposed by the Commission

Amendment 191
Proposal for a regulation
Article 3 – paragraph 1 – point 34
Text proposed by the Commission
(34) ‘emotion recognition system’ means
an AI system for the purpose of identifying
or inferring emotions or intentions of
natural persons on the basis of their
biometric data;

Amendment 192
Proposal for a regulation
Article 3 – paragraph 1 – point 35
Text proposed by the Commission
(35) ‘biometric categorisation system’
means an AI system for the purpose of
assigning natural persons to specific
categories, such as sex, age, hair colour,
eye colour, tattoos, ethnic origin or sexual
or political orientation, on the basis of
their biometric data;

Amendment 193
Proposal for a regulation
Article 3 – paragraph 1 – point 36
Text proposed by the Commission
(36) ‘remote biometric identification
system’ means an AI system for the
purpose of identifying natural persons at a

distance through the comparison of a
person’s biometric data with the biometric
data contained in a reference database, and
without prior knowledge of the user of the
AI system whether the person will be
present and can be identified ;

Amendment 194
Proposal for a regulation
Article 3 – paragraph 1 – point 37
Text proposed by the Commission
(37) ‘‘real-time’ remote biometric
identification system’ means a remote
biometric identification system whereby
the capturing of biometric data, the
comparison and the identification all occur
without a significant delay. This comprises
not only instant identification, but also
limited short delays in order to avoid
circumvention.

Amendment 195
Proposal for a regulation
Article 3 – paragraph 1 – point 39
Text proposed by the Commission
(39) ‘publicly accessible space’ means
any physical place accessible to the public,
regardless of whether certain conditions for
access may apply;

Amendment 196
Proposal for a regulation
Article 3 – paragraph 1 – point 41
Text proposed by the Commission
(41) ‘law enforcement’ means activities
carried out by law enforcement authorities

for the prevention, investigation, detection
or prosecution of criminal offences or the
execution of criminal penalties, including
the safeguarding against and the prevention
of threats to public security;

Amendment 197
Proposal for a regulation
Article 3 – paragraph 1 – point 42
Text proposed by the Commission
(42) ‘national supervisory authority’
means the authority to which a Member
State assigns the responsibility for the
implementation and application of this
Regulation, for coordinating the activities
entrusted to that Member State, for acting
as the single contact point for the
Commission, and for representing the
Member State at the European Artificial
Intelligence Board;

Amendment 198
Proposal for a regulation
Article 3 – paragraph 1 – point 43
Text proposed by the Commission
(43) ‘national competent authority’ means
the national supervisory authority, the
notifying authority and the market
surveillance authority;

Amendment 199

Proposal for a regulation
Article 3 – paragraph 1 – point 44 – introduc
Text proposed by the Commission
(44) ‘serious incident’ means any incident
that directly or indirectly leads, might have

led or might lead to any of the following:
(a) the death of a person or serious
damage to a person’s health, to property or
the environment,
(b) a serious disruption of the
management and operation of critical
infrastructure.

Amendment 200
Proposal for a regulation
Article 3 – paragraph 1 – point 44 a (new)
Text proposed by the Commission

Amendment 201
Proposal for a regulation
Article 3 – paragraph 1 – point 44 b (new)
Text proposed by the Commission

Amendment 202
Proposal for a regulation
Article 3 – paragraph 1 – point 44 c (new)
Text proposed by the Commission

Amendment 203
Proposal for a regulation
Article 3 – paragraph 1 – point 44 d (new)
Text proposed by the Commission

Amendment 204
Proposal for a regulation
Article 3 – paragraph 1 – point 44 e (new)
Text proposed by the Commission

Amendment 205
Proposal for a regulation
Article 3 – paragraph 1 – point 44 f (new)
Text proposed by the Commission

Amendment 206
Proposal for a regulation
Article 3 – paragraph 1 – point 44 g (new)
Text proposed by the Commission

Amendment 207
Proposal for a regulation
Article 3 – paragraph 1 – point 44 h (new)

Text proposed by the Commission

Amendment 208
Proposal for a regulation
Article 3 – paragraph 1 – point 44 k (new)
Text proposed by the Commission

Amendment 209
Proposal for a regulation
Article 3 – paragraph 1 – point 44 l (new)
Text proposed by the Commission

Amendment 210
Proposal for a regulation
Article 3 – paragraph 1 – point 44 m (new)
Text proposed by the Commission

Amendment 211
Proposal for a regulation
Article 3 – paragraph 1 – point 44 n (new)
Text proposed by the Commission

Amendment 212
Proposal for a regulation
Article 4
Text proposed by the Commission
Article 4
Amendments to Annex I
The Commission is empowered to adopt
delegated acts in accordance with Article
73 to amend the list of techniques and
approaches listed in Annex I, in order to
update that list to market and
technological developments on the basis
of characteristics that are similar to the
techniques and approaches listed therein.

Amendment 213
Proposal for a regulation
Article 4 a (new)
Text proposed by the Commission

Amendment 214

Proposal for a regulation
Article 4 b (new)
Text proposed by the Commission

Amendment 215
Proposal for a regulation
Article 5 – paragraph 1 – point a

Text proposed by the Commission
(a) the placing on the market, putting
into service or use of an AI system that
deploys subliminal techniques beyond a
person’s consciousness in order to
materially distort a person’s behaviour in a
manner that causes or is likely to cause that
person or another person physical or
psychological harm;

Amendment 216
Proposal for a regulation
Article 5 – paragraph 1 – point b
Text proposed by the Commission
(b) the placing on the market, putting
into service or use of an AI system that
exploits any of the vulnerabilities of a
specific group of persons due to their age,
physical or mental disability, in order to
materially distort the behaviour of a person
pertaining to that group in a manner that
causes or is likely to cause that person or
another person physical or psychological
harm;

Amendment 217
Proposal for a regulation
Article 5 – paragraph 1 – point b a (new)
Text proposed by the Commission

Amendment 218

Proposal for a regulation
Article 5 – paragraph 1 – point c – introducto
Text proposed by the Commission
(c) the placing on the market, putting
into service or use of AI systems by public
authorities or on their behalf for the
evaluation or classification of the
trustworthiness of natural persons over a
certain period of time based on their social
behaviour or known or predicted personal
or personality characteristics, with the
social score leading to either or both of the
following:

Amendment 219
Proposal for a regulation
Article 5 – paragraph 1 – point c – point i

Text proposed by the Commission
(i) detrimental or unfavourable
treatment of certain natural persons or
whole groups thereof in social contexts
which are unrelated to the contexts in
which the data was originally generated or
collected;

Amendment 220

Proposal for a regulation
Article 5 – paragraph 1 – point d – introducto
Text proposed by the Commission
(d) the use of ‘real-time’ remote
biometric identification systems in publicly
accessible spaces for the purpose of law
enforcement, unless and in as far as such
use is strictly necessary for one of the
following objectives:

Amendment 221
Proposal for a regulation
Article 5 – paragraph 1 – point d – point i
Text proposed by the Commission
(i) the targeted search for specific
potential victims of crime, including
missing children;

Amendment 222
Proposal for a regulation
Article 5 – paragraph 1 – point d – point ii
Text proposed by the Commission
(ii) the prevention of a specific,
substantial and imminent threat to the life
or physical safety of natural persons or of
a terrorist attack;

Amendment 223
Proposal for a regulation
Article 5 – paragraph 1 – point d – point iii
Text proposed by the Commission
(iii) the detection, localisation,
identification or prosecution of a
perpetrator or suspect of a criminal
offence referred to in Article 2(2) of
Council Framework Decision
2002/584/JHA62 and punishable in the
Member State concerned by a custodial
sentence or a detention order for a
maximum period of at least three years, as
determined by the law of that Member
State.
__________________
62 Council Framework Decision

2002/584/JHA of 13 June 2002 on the
European arrest warrant and the
surrender procedures between Member
States (OJ L 190, 18.7.2002, p. 1).

Amendment 224
Proposal for a regulation
Article 5 – paragraph 1 – point d a (new)
Text proposed by the Commission

Amendment 225
Proposal for a regulation
Article 5 – paragraph 1 – point d b (new)
Text proposed by the Commission

Amendment 226
Proposal for a regulation
Article 5 – paragraph 1 – point d c (new)
Text proposed by the Commission

Amendment 227
Proposal for a regulation
Article 5 – paragraph 1 – point d d (new)
Text proposed by the Commission

Amendment 228
Proposal for a regulation
Article 5 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 229
Proposal for a regulation
Article 5 – paragraph 2
Text proposed by the Commission
2.
The use of ‘real-time’ remote
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement for any of the
objectives referred to in paragraph 1 point
d) shall take into account the following
elements:
(a) the nature of the situation giving
rise to the possible use, in particular the
seriousness, probability and scale of the
harm caused in the absence of the use of
the system;
(b) the consequences of the use of the
system for the rights and freedoms of all
persons concerned, in particular the
seriousness, probability and scale of those
consequences.
In addition, the use of ‘real-time’ remote
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement for any of the
objectives referred to in paragraph 1 point
d) shall comply with necessary and
proportionate safeguards and conditions
in relation to the use, in particular as

regards the temporal, geographic and
personal limitations.

Amendment 230
Proposal for a regulation
Article 5 – paragraph 3
Text proposed by the Commission
3.
As regards paragraphs 1, point (d)
and 2, each individual use for the purpose
of law enforcement of a ‘real-time’
remote biometric identification system in
publicly accessible spaces shall be subject
to a prior authorisation granted by a
judicial authority or by an independent
administrative authority of the Member
State in which the use is to take place,
issued upon a reasoned request and in
accordance with the detailed rules of
national law referred to in paragraph 4.
However, in a duly justified situation of
urgency, the use of the system may be
commenced without an authorisation and
the authorisation may be requested only
during or after the use.
The competent judicial or administrative
authority shall only grant the
authorisation where it is satisfied, based
on objective evidence or clear indications
presented to it, that the use of the ‘realtime’ remote biometric identification
system at issue is necessary for and
proportionate to achieving one of the
objectives specified in paragraph 1, point
(d), as identified in the request. In
deciding on the request, the competent
judicial or administrative authority shall
take into account the elements referred to
in paragraph 2.

Amendment 231
Proposal for a regulation
Article 5 – paragraph 4

Text proposed by the Commission
4.
A Member State may decide to
provide for the possibility to fully or
partially authorise the use of ‘real-time’
remote biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement within the limits and
under the conditions listed in paragraphs
1, point (d), 2 and 3. That Member State
shall lay down in its national law the
necessary detailed rules for the request,
issuance and exercise of, as well as
supervision relating to, the authorisations
referred to in paragraph 3. Those rules
shall also specify in respect of which of
the objectives listed in paragraph 1, point
(d), including which of the criminal
offences referred to in point (iii) thereof,
the competent authorities may be
authorised to use those systems for the
purpose of law enforcement.

Amendment 232
Proposal for a regulation
Article 6 – paragraph 1 – point a
Text proposed by the Commission
(a) the AI system is intended to be used
as a safety component of a product, or is
itself a product, covered by the Union
harmonisation legislation listed in Annex
II;

Amendment 233
Proposal for a regulation
Article 6 – paragraph 1 – point b
Text proposed by the Commission
(b) the product whose safety component
is the AI system, or the AI system itself as
a product, is required to undergo a thirdparty conformity assessment with a view to

the placing on the market or putting into
service of that product pursuant to the
Union harmonisation legislation listed in
Annex II.

Amendment 234
Proposal for a regulation
Article 6 – paragraph 2
Text proposed by the Commission
2.
In addition to the high-risk AI
systems referred to in paragraph 1, AI
systems referred to in Annex III shall also
be considered high-risk.

Amendment 235
Proposal for a regulation
Article 6 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 236
Proposal for a regulation
Article 6 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 237
Proposal for a regulation
Article 6 – paragraph 2 b (new)
Text proposed by the Commission

Amendment 238

Proposal for a regulation
Article 7 – paragraph 1 – introductory part
Text proposed by the Commission
1.
The Commission is empowered to
adopt delegated acts in accordance with
Article 73 to update the list in Annex III
by adding high-risk AI systems where both
of the following conditions are fulfilled:

Amendment 239
Proposal for a regulation
Article 7 – paragraph 1 – point a
Text proposed by the Commission
(a) the AI systems are intended to be
used in any of the areas listed in points 1
to 8 of Annex III;

Amendment 240
Proposal for a regulation
Article 7 – paragraph 1 – point b
Text proposed by the Commission
(b) the AI systems pose a risk of harm
to the health and safety, or a risk of
adverse impact on fundamental rights,
that is, in respect of its severity and
probability of occurrence, equivalent to or
greater than the risk of harm or of
adverse impact posed by the high-risk AI
systems already referred to in Annex III.

Amendment 241
Proposal for a regulation
Article 7 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 242
Proposal for a regulation
Article 7 – paragraph 2 – introductory part
Text proposed by the Commission
2.
When assessing for the purposes of
paragraph 1 whether an AI system poses a
risk of harm to the health and safety or a
risk of adverse impact on fundamental
rights that is equivalent to or greater than
the risk of harm posed by the high-risk AI
systems already referred to in Annex III,
the Commission shall take into account the
following criteria:

Amendment 243
Proposal for a regulation
Article 7 – paragraph 2 – point a a (new)
Text proposed by the Commission

Amendment 244
Proposal for a regulation
Article 7 – paragraph 2 – point b a (new)

Text proposed by the Commission

Amendment 245
Proposal for a regulation
Article 7 – paragraph 2 – point b b (new)
Text proposed by the Commission

Amendment 246
Proposal for a regulation
Article 7 – paragraph 2 – point c
Text proposed by the Commission
(c) the extent to which the use of an AI
system has already caused harm to the
health and safety or adverse impact on the
fundamental rights or has given rise to
significant concerns in relation to the
materialisation of such harm or adverse
impact, as demonstrated by reports or
documented allegations submitted to
national competent authorities;

Amendment 247
Proposal for a regulation
Article 7 – paragraph 2 – point d
Text proposed by the Commission
(d) the potential extent of such harm or
such adverse impact, in particular in terms

of its intensity and its ability to affect a
plurality of persons;

Amendment 248
Proposal for a regulation
Article 7 – paragraph 2 – point e
Text proposed by the Commission
(e) the extent to which potentially
harmed or adversely impacted persons are
dependent on the outcome produced with
an AI system, in particular because for
practical or legal reasons it is not
reasonably possible to opt-out from that
outcome;

Amendment 249
Proposal for a regulation
Article 7 – paragraph 2 – point e a (new)
Text proposed by the Commission

Amendment 250
Proposal for a regulation
Article 7 – paragraph 2 – point f
Text proposed by the Commission
(f) the extent to which potentially
harmed or adversely impacted persons are
in a vulnerable position in relation to the
user of an AI system, in particular due to
an imbalance of power, knowledge,
economic or social circumstances, or age;

Amendment 251
Proposal for a regulation
Article 7 – paragraph 2 – point g
Text proposed by the Commission
(g) the extent to which the outcome
produced with an AI system is easily
reversible, whereby outcomes having an
impact on the health or safety of persons
shall not be considered as easily reversible;

Amendment 252
Proposal for a regulation
Article 7 – paragraph 2 – point g a (new)
Text proposed by the Commission

Amendment 253
Proposal for a regulation
Article 7 – paragraph 2 – point g b (new)
Text proposed by the Commission

Amendment 254

Proposal for a regulation
Article 7 – paragraph 2 – point g c (new)
Text proposed by the Commission

Amendment 255
Proposal for a regulation
Article 7 – paragraph 2 – point h –
Text proposed by the Commission
(i) effective measures of redress in
relation to the risks posed by an AI system,
with the exclusion of claims for damages;

Amendment 256
Proposal for a regulation
Article 7 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 257
Proposal for a regulation
Article 7 – paragraph 2 b (new)
Text proposed by the Commission

Amendment 258
Proposal for a regulation
Article 8 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 259
Proposal for a regulation
Article 8 – paragraph 2
Text proposed by the Commission
2.
The intended purpose of the high-risk
AI system and the risk management system
referred to in Article 9 shall be taken into
account when ensuring compliance with
those requirements.

Amendment 260
Proposal for a regulation
Article 8 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 261
Proposal for a regulation
Article 9 – paragraph 1
Text proposed by the Commission
1.
A risk management system shall be
established, implemented, documented and
maintained in relation to high-risk AI
systems.

Amendment 262
Proposal for a regulation
Article 9 – paragraph 2 – introductory part
Text proposed by the Commission
2.
The risk management system shall
consist of a continuous iterative process
run throughout the entire lifecycle of a
high-risk AI system, requiring regular
systematic updating. It shall comprise the
following steps:

Amendment 263
Proposal for a regulation
Article 9 – paragraph 2 – point a
Text proposed by the Commission
(a) identification and analysis of the
known and foreseeable risks associated
with each high-risk AI system;

Amendment 264
Proposal for a regulation
Article 9 – paragraph 2 – point b

Text proposed by the Commission
(b) estimation and evaluation of the
risks that may emerge when the high-risk
AI system is used in accordance with its
intended purpose and under conditions of
reasonably foreseeable misuse;

Amendment 265
Proposal for a regulation
Article 9 – paragraph 2 – point c
Text proposed by the Commission
(c) evaluation of other possibly arising
risks based on the analysis of data gathered
from the post-market monitoring system
referred to in Article 61;

Amendment 266
Proposal for a regulation
Article 9 – paragraph 2 – point d
Text proposed by the Commission
(d) adoption of suitable risk
management measures in accordance with
the provisions of the following paragraphs.

Amendment 267
Proposal for a regulation
Article 9 – paragraph 3
Text proposed by the Commission
3.
The risk management measures
referred to in paragraph 2, point (d) shall
give due consideration to the effects and
possible interactions resulting from the

combined application of the requirements
set out in this Chapter 2. They shall take
into account the generally acknowledged
state of the art, including as reflected in
relevant harmonised standards or
common specifications.

Amendment 268
Proposal for a regulation
Article 9 – paragraph 4 – introductory part
Text proposed by the Commission
4.
The risk management measures
referred to in paragraph 2, point (d) shall
be such that any residual risk associated
with each hazard as well as the overall
residual risk of the high-risk AI systems is
judged acceptable, provided that the highrisk AI system is used in accordance with
its intended purpose or under conditions of
reasonably foreseeable misuse. Those
residual risks shall be communicated to the
user.

Amendment 269

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – p
Text proposed by the Commission
(a) elimination or reduction of risks as
far as possible through adequate design and
development;

Amendment 270

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – p
Text proposed by the Commission
(b) where appropriate, implementation of
adequate mitigation and control measures
in relation to risks that cannot be
eliminated;

Amendment 271

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – p
Text proposed by the Commission
(c) provision of adequate information
pursuant to Article 13, in particular as
regards the risks referred to in paragraph
2, point (b) of this Article, and, where
appropriate, training to users.

Amendment 272
Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 2
Text proposed by the Commission
In eliminating or reducing risks related to
the use of the high-risk AI system, due
consideration shall be given to the
technical knowledge, experience,
education, training to be expected by the
user and the environment in which the
system is intended to be used.

Amendment 273
Proposal for a regulation
Article 9 – paragraph 5
Text proposed by the Commission
5.

High-risk AI systems shall be tested

for the purposes of identifying the most
appropriate risk management measures.
Testing shall ensure that high-risk AI
systems perform consistently for their
intended purpose and they are in
compliance with the requirements set out
in this Chapter.

Amendment 274
Proposal for a regulation
Article 9 – paragraph 6
Text proposed by the Commission
6.
Testing procedures shall be suitable
to achieve the intended purpose of the AI
system and do not need to go beyond what
is necessary to achieve that purpose.

Amendment 275
Proposal for a regulation
Article 9 – paragraph 7
Text proposed by the Commission
7.
The testing of the high-risk AI
systems shall be performed, as
appropriate, at any point in time
throughout the development process, and,
in any event, prior to the placing on the
market or the putting into service. Testing
shall be made against preliminarily defined
metrics and probabilistic thresholds that are
appropriate to the intended purpose of the
high-risk AI system.

Amendment 276
Proposal for a regulation
Article 9 – paragraph 8

Text proposed by the Commission
8.
When implementing the risk
management system described in
paragraphs 1 to 7, specific consideration
shall be given to whether the high-risk AI
system is likely to be accessed by or have
an impact on children.

Amendment 277
Proposal for a regulation
Article 9 – paragraph 9
Text proposed by the Commission
9.
For credit institutions regulated by
Directive 2013/36/EU, the aspects
described in paragraphs 1 to 8 shall be part
of the risk management procedures
established by those institutions pursuant
to Article 74 of that Directive.

Amendment 278
Proposal for a regulation
Article 10 – paragraph 1
Text proposed by the Commission
1.
High-risk AI systems which make
use of techniques involving the training of
models with data shall be developed on the
basis of training, validation and testing data
sets that meet the quality criteria referred to
in paragraphs 2 to 5.

Amendment 279
Proposal for a regulation
Article 10 – paragraph 2 – introductory part
Text proposed by the Commission
2.
Training, validation and testing data
sets shall be subject to appropriate data
governance and management practices.
Those practices shall concern in particular,

Amendment 280
Proposal for a regulation
Article 10 – paragraph 2 – point a a (new)
Text proposed by the Commission

Amendment 281
Proposal for a regulation
Article 10 – paragraph 2 – point b
Text proposed by the Commission
(b)

data collection;

Amendment 282
Proposal for a regulation
Article 10 – paragraph 2 – point c
Text proposed by the Commission
(c) relevant data preparation processing
operations, such as annotation, labelling,

cleaning, enrichment and aggregation;

Amendment 283
Proposal for a regulation
Article 10 – paragraph 2 – point d
Text proposed by the Commission
(d) the formulation of relevant
assumptions, notably with respect to the
information that the data are supposed to
measure and represent;

Amendment 284
Proposal for a regulation
Article 10 – paragraph 2 – point e
Text proposed by the Commission
(e) a prior assessment of the availability,
quantity and suitability of the data sets that
are needed;

Amendment 285
Proposal for a regulation
Article 10 – paragraph 2 – point f
Text proposed by the Commission
(f) examination in view of possible
biases;

Amendment 286

Proposal for a regulation
Article 10 – paragraph 2 – point f a (new)
Text proposed by the Commission

Amendment 287
Proposal for a regulation
Article 10 – paragraph 2 – point g
Text proposed by the Commission
(g) the identification of any possible data
gaps or shortcomings, and how those gaps
and shortcomings can be addressed.

Amendment 288
Proposal for a regulation
Article 10 – paragraph 3
Text proposed by the Commission
3.
Training, validation and testing data
sets shall be relevant, representative, free
of errors and complete. They shall have the
appropriate statistical properties, including,
where applicable, as regards the persons or
groups of persons on which the high-risk
AI system is intended to be used. These
characteristics of the data sets may be met
at the level of individual data sets or a
combination thereof.

Amendment 289
Proposal for a regulation
Article 10 – paragraph 4

Text proposed by the Commission
4.
Training, validation and testing data
sets shall take into account, to the extent
required by the intended purpose, the
characteristics or elements that are
particular to the specific geographical,
behavioural or functional setting within
which the high-risk AI system is intended
to be used.

Amendment 290
Proposal for a regulation
Article 10 – paragraph 5
Text proposed by the Commission
5.
To the extent that it is strictly
necessary for the purposes of ensuring bias
monitoring, detection and correction in
relation to the high-risk AI systems, the
providers of such systems may process
special categories of personal data referred
to in Article 9(1) of Regulation (EU)
2016/679, Article 10 of Directive (EU)
2016/680 and Article 10(1) of Regulation
(EU) 2018/1725, subject to appropriate
safeguards for the fundamental rights and
freedoms of natural persons, including
technical limitations on the re-use and use
of state-of-the-art security and privacypreserving measures, such as
pseudonymisation, or encryption where
anonymisation may significantly affect
the purpose pursued.

Amendment 291
Proposal for a regulation
Article 10 – paragraph 6 a (new)
Text proposed by the Commission

Amendment 292

Proposal for a regulation
Article 11 – paragraph 1 – subparagraph 1
Text proposed by the Commission
The technical documentation shall be
drawn up in such a way to demonstrate that
the high-risk AI system complies with the
requirements set out in this Chapter and
provide national competent authorities and
notified bodies with all the necessary
information to assess the compliance of the
AI system with those requirements. It shall
contain, at a minimum, the elements set out
in Annex IV.

Amendment 293
Proposal for a regulation
Article 11 – paragraph 2
Text proposed by the Commission
2.
Where a high-risk AI system related
to a product, to which the legal acts listed
in Annex II, section A apply, is placed on
the market or put into service one single
technical documentation shall be drawn up
containing all the information set out in
Annex IV as well as the information
required under those legal acts.

Amendment 294
Proposal for a regulation
Article 11 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 295
Proposal for a regulation
Article 12 – paragraph 1
Text proposed by the Commission
1.
High-risk AI systems shall be
designed and developed with capabilities
enabling the automatic recording of events
(‘logs’) while the high-risk AI systems is
operating. Those logging capabilities shall
conform to recognised standards or
common specifications.

Amendment 296
Proposal for a regulation
Article 12 – paragraph 2
Text proposed by the Commission
2.
The logging capabilities shall ensure
a level of traceability of the AI system’s
functioning throughout its lifecycle that is
appropriate to the intended purpose of the
system.

Amendment 297

Proposal for a regulation
Article 12 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 298
Proposal for a regulation
Article 12 – paragraph 3
Text proposed by the Commission
3.
In particular, logging capabilities
shall enable the monitoring of the
operation of the high-risk AI system with
respect to the occurrence of situations
that may result in the AI system
presenting a risk within the meaning of
Article 65(1) or lead to a substantial
modification, and facilitate the postmarket monitoring referred to in Article
61.

Amendment 299
Proposal for a regulation
Article 13 – title
Text proposed by the Commission
Transparency and provision of information
to users

Amendment 300
Proposal for a regulation
Article 13 – paragraph 1

Text proposed by the Commission
1.
High-risk AI systems shall be
designed and developed in such a way to
ensure that their operation is sufficiently
transparent to enable users to interpret the
system’s output and use it appropriately.
An appropriate type and degree of
transparency shall be ensured, with a view
to achieving compliance with the relevant
obligations of the user and of the provider
set out in Chapter 3 of this Title.

Amendment 301
Proposal for a regulation
Article 13 – paragraph 2
Text proposed by the Commission
2.
High-risk AI systems shall be
accompanied by instructions for use in an
appropriate digital format or otherwise that
include concise, complete, correct and
clear information that is relevant,
accessible and comprehensible to users.

Amendment 302
Proposal for a regulation
Article 13 – paragraph 3 – introductory part
Text proposed by the Commission
3.
The information referred to in
paragraph 2 shall specify:

Amendment 303
Proposal for a regulation
Article 13 – paragraph 3 – point a
Text proposed by the Commission
(a) the identity and the contact details of
the provider and, where applicable, of its
authorised representative;

Amendment 304
Proposal for a regulation
Article 13 – paragraph 3 – point a a (new)
Text proposed by the Commission

Amendment 305

Proposal for a regulation
Article 13 – paragraph 3 – point b – introduc
Text proposed by the Commission
(b) the characteristics, capabilities and
limitations of performance of the high-risk
AI system, including:

Amendment 306
Proposal for a regulation
Article 13 – paragraph 3 – point b – point ii
Text proposed by the Commission
(ii) the level of accuracy, robustness and
cybersecurity referred to in Article 15
against which the high-risk AI system has
been tested and validated and which can be
expected, and any known and foreseeable
circumstances that may have an impact on
that expected level of accuracy, robustness
and cybersecurity;

Amendment 307
Proposal for a regulation
Article 13 – paragraph 3 – point b – point iii
Text proposed by the Commission
(iii) any known or foreseeable
circumstance, related to the use of the
high-risk AI system in accordance with its
intended purpose or under conditions of
reasonably foreseeable misuse, which may
lead to risks to the health and safety or
fundamental rights;

Amendment 308

Proposal for a regulation
Article 13 – paragraph 3 – point b – point iii a
Text proposed by the Commission

Amendment 309
Proposal for a regulation
Article 13 – paragraph 3 – point b – point v
Text proposed by the Commission
(v) when appropriate, specifications for
the input data, or any other relevant
information in terms of the training,
validation and testing data sets used, taking
into account the intended purpose of the AI
system.

Amendment 310
Proposal for a regulation
Article 13 – paragraph 3 – point e
Text proposed by the Commission
(e) the expected lifetime of the high-risk
AI system and any necessary maintenance
and care measures to ensure the proper
functioning of that AI system, including as
regards software updates.

Amendment 311
Proposal for a regulation
Article 13 – paragraph 3 – point e a (new)
Text proposed by the Commission

Amendment 312
Proposal for a regulation
Article 13 – paragraph 3 – point e b (new)

Text proposed by the Commission

Amendment 313
Proposal for a regulation
Article 13 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 314
Proposal for a regulation
Article 14 – paragraph 1
Text proposed by the Commission
1.
High-risk AI systems shall be
designed and developed in such a way,
including with appropriate human-machine
interface tools, that they can be effectively
overseen by natural persons during the
period in which the AI system is in use.

Amendment 315
Proposal for a regulation
Article 14 – paragraph 2

Text proposed by the Commission
2.
Human oversight shall aim at
preventing or minimising the risks to
health, safety or fundamental rights that
may emerge when a high-risk AI system is
used in accordance with its intended
purpose or under conditions of reasonably
foreseeable misuse, in particular when such
risks persist notwithstanding the
application of other requirements set out in
this Chapter.

Amendment 316
Proposal for a regulation
Article 14 – paragraph 3 – introductory part
Text proposed by the Commission
3.
Human oversight shall be ensured
through either one or all of the following
measures:

Amendment 317
Proposal for a regulation
Article 14 – paragraph 4 – introductory part
Text proposed by the Commission
4.
The measures referred to in
paragraph 3 shall enable the individuals
to whom human oversight is assigned to do
the following, as appropriate to the
circumstances:

Amendment 318
Proposal for a regulation
Article 14 – paragraph 4 – point a
Text proposed by the Commission
(a) fully understand the capacities and
limitations of the high-risk AI system and
be able to duly monitor its operation, so
that signs of anomalies, dysfunctions and
unexpected performance can be detected
and addressed as soon as possible;

Amendment 319
Proposal for a regulation
Article 14 – paragraph 4 – point e
Text proposed by the Commission
(e) be able to intervene on the operation
of the high-risk AI system or interrupt the
system through a “stop” button or a similar
procedure.

Amendment 320
Proposal for a regulation
Article 14 – paragraph 5
Text proposed by the Commission
5.
For high-risk AI systems referred to
in point 1(a) of Annex III, the measures
referred to in paragraph 3 shall be such as
to ensure that, in addition, no action or
decision is taken by the user on the basis of
the identification resulting from the system
unless this has been verified and confirmed
by at least two natural persons.

Amendment 321
Proposal for a regulation
Article 15 – paragraph 1
Text proposed by the Commission
1.
High-risk AI systems shall be
designed and developed in such a way that
they achieve, in the light of their intended
purpose, an appropriate level of accuracy,
robustness and cybersecurity, and perform
consistently in those respects throughout
their lifecycle.

Amendment 322
Proposal for a regulation
Article 15 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 323
Proposal for a regulation
Article 15 – paragraph 1 b (new)

Text proposed by the Commission

Amendment 324
Proposal for a regulation
Article 15 – paragraph 2
Text proposed by the Commission
2.
The levels of accuracy and the
relevant accuracy metrics of high-risk AI
systems shall be declared in the
accompanying instructions of use.

Amendment 325
Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 1
Text proposed by the Commission
High-risk AI systems shall be resilient as
regards errors, faults or inconsistencies
that may occur within the system or the
environment in which the system operates,
in particular due to their interaction with
natural persons or other systems.

Amendment 326
Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 2

Text proposed by the Commission
The robustness of high-risk AI systems
may be achieved through technical
redundancy solutions, which may include
backup or fail-safe plans.

Amendment 327
Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 3
Text proposed by the Commission
High-risk AI systems that continue to learn
after being placed on the market or put into
service shall be developed in such a way to
ensure that possibly biased outputs due to
outputs used as an input for future
operations (‘feedback loops’) are duly
addressed with appropriate mitigation
measures.

Amendment 328
Proposal for a regulation
Article 15 – paragraph 4 – subparagraph 1
Text proposed by the Commission
High-risk AI systems shall be resilient as
regards attempts by unauthorised third
parties to alter their use or performance by
exploiting the system vulnerabilities.

Amendment 329
Proposal for a regulation
Article 15 – paragraph 4 – subparagraph 3

Text proposed by the Commission
The technical solutions to address AI
specific vulnerabilities shall include, where
appropriate, measures to prevent and
control for attacks trying to manipulate the
training dataset (‘data poisoning’), inputs
designed to cause the model to make a
mistake (‘adversarial examples’), or model
flaws.

Amendment 330
Proposal for a regulation
Title III – Chapter 3 – title
Text proposed by the Commission
OBLIGATIONS OF PROVIDERS AND
USERS OF HIGH-RISK AI SYSTEMS
and other parties

Amendment 331
Proposal for a regulation
Article 16 – title
Text proposed by the Commission
Obligations of providers of high-risk AI
systems

Amendment 332
Proposal for a regulation
Article 16 – paragraph 1 – point a
Text proposed by the Commission
(a) ensure that their high-risk AI systems
are compliant with the requirements set out

in Chapter 2 of this Title;

Amendment 333
Proposal for a regulation
Article 16 – paragraph 1 – point a a (new)
Text proposed by the Commission

Amendment 334
Proposal for a regulation
Article 16 – paragraph 1 – point a b (new)
Text proposed by the Commission

Amendment 335
Proposal for a regulation
Article 16 – paragraph 1 – point a c (new)
Text proposed by the Commission

Amendment 336
Proposal for a regulation
Article 16 – paragraph 1 – point c
Text proposed by the Commission
(c) draw-up the technical documentation
of the high-risk AI system;

Amendment 337
Proposal for a regulation
Article 16 – paragraph 1 – point d
Text proposed by the Commission
(d) when under their control, keep the
logs automatically generated by their highrisk AI systems;

Amendment 338
Proposal for a regulation
Article 16 – paragraph 1 – point e
Text proposed by the Commission
(e) ensure that the high-risk AI system
undergoes the relevant conformity
assessment procedure, prior to its placing
on the market or putting into service;

Amendment 339
Proposal for a regulation
Article 16 – paragraph 1 – point e a (new)
Text proposed by the Commission

Amendment 340
Proposal for a regulation
Article 16 – paragraph 1 – point e b (new)
Text proposed by the Commission

Amendment 341
Proposal for a regulation
Article 16 – paragraph 1 – point g
Text proposed by the Commission
(g) take the necessary corrective actions,
if the high-risk AI system is not in
conformity with the requirements set out
in Chapter 2 of this Title;

Amendment 342
Proposal for a regulation
Article 16 – paragraph 1 – point h
Text proposed by the Commission
(h) inform the national competent
authorities of the Member States in which
they made the AI system available or put
it into service and, where applicable, the
notified body of the non-compliance and
of any corrective actions taken;

Amendment 343
Proposal for a regulation
Article 16 – paragraph 1 – point i

Text proposed by the Commission
(i) to affix the CE marking to their
high-risk AI systems to indicate the
conformity with this Regulation in
accordance with Article 49;

Amendment 344
Proposal for a regulation
Article 16 – paragraph 1 – point j
Text proposed by the Commission
(j) upon request of a national competent
authority, demonstrate the conformity of
the high-risk AI system with the
requirements set out in Chapter 2 of this
Title.

Amendment 345
Proposal for a regulation
Article 16 – paragraph 1 – point j a (new)
Text proposed by the Commission

Amendment 346
Proposal for a regulation
Article 17 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Providers of high-risk AI systems
shall put a quality management system in
place that ensures compliance with this
Regulation. That system shall be
documented in a systematic and orderly
manner in the form of written policies,
procedures and instructions, and shall
include at least the following aspects:

Amendment 347
Proposal for a regulation
Article 17 – paragraph 1 – point a
Text proposed by the Commission
(a) a strategy for regulatory
compliance, including compliance with
conformity assessment procedures and
procedures for the management of
modifications to the high-risk AI system;

Amendment 348
Proposal for a regulation
Article 17 – paragraph 1 – point e
Text proposed by the Commission
(e) technical specifications, including
standards, to be applied and, where the
relevant harmonised standards are not
applied in full, the means to be used to
ensure that the high-risk AI system
complies with the requirements set out in
Chapter 2 of this Title;

Amendment 349
Proposal for a regulation
Article 17 – paragraph 1 – point f
Text proposed by the Commission
(f) systems and procedures for data
management, including data collection,
data analysis, data labelling, data storage,
data filtration, data mining, data
aggregation, data retention and any other
operation regarding the data that is
performed before and for the purposes of
the placing on the market or putting into

service of high-risk AI systems;

Amendment 350
Proposal for a regulation
Article 17 – paragraph 1 – point j
Text proposed by the Commission
(j) the handling of communication with
national competent authorities, competent
authorities, including sectoral ones,
providing or supporting the access to data,
notified bodies, other operators,
customers or other interested parties;

Amendment 351
Proposal for a regulation
Article 17 – paragraph 2
Text proposed by the Commission
2.
The implementation of aspects
referred to in paragraph 1 shall be
proportionate to the size of the provider’s
organisation.

Amendment 352
Proposal for a regulation
Article 18 – title
Text proposed by the Commission
Obligation to draw up technical
documentation

Amendment 353

Proposal for a regulation
Article 18 – paragraph 1
Text proposed by the Commission
1.
Providers of high-risk AI systems
shall draw up the technical documentation referred to in Article 11 in
accordance with Annex IV.

Amendment 354
Proposal for a regulation
Article 18 – paragraph 2
Text proposed by the Commission
2.
Providers that are credit institutions
regulated by Directive 2013/36/EU shall
maintain the technical documentation as
part of the documentation concerning
internal governance, arrangements,
processes and mechanisms pursuant to
Article 74 of that Directive.

Amendment 355
Proposal for a regulation
Article 19
Text proposed by the Commission
Article 19
Conformity assessment
1.
Providers of high-risk AI systems
shall ensure that their systems undergo
the relevant conformity assessment
procedure in accordance with Article 43,
prior to their placing on the market or
putting into service. Where the
compliance of the AI systems with the
requirements set out in Chapter 2 of this
Title has been demonstrated following
that conformity assessment, the providers
shall draw up an EU declaration of
conformity in accordance with Article 48
and affix the CE marking of conformity

in accordance with Article 49.
2.
For high-risk AI systems referred to
in point 5(b) of Annex III that are placed
on the market or put into service by
providers that are credit institutions
regulated by Directive 2013/36/EU, the
conformity assessment shall be carried
out as part of the procedure referred to in
Articles 97 to101 of that Directive.

Amendment 356
Proposal for a regulation
Article 20 – paragraph 1
Text proposed by the Commission
1.
Providers of high-risk AI systems
shall keep the logs automatically generated
by their high-risk AI systems, to the extent
such logs are under their control by virtue
of a contractual arrangement with the
user or otherwise by law. The logs shall be
kept for a period that is appropriate in the
light of the intended purpose of high-risk
AI system and applicable legal obligations
under Union or national law.

Amendment 357
Proposal for a regulation
Article 21 – paragraph 1
Text proposed by the Commission
Providers of high-risk AI systems which
consider or have reason to consider that a
high-risk AI system which they have
placed on the market or put into service is
not in conformity with this Regulation
shall immediately take the necessary
corrective actions to bring that system into
conformity, to withdraw it or to recall it, as
appropriate. They shall inform the
distributors of the high-risk AI system in
question and, where applicable, the
authorised representative and importers

accordingly.

Amendment 358
Proposal for a regulation
Article 21 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 359
Proposal for a regulation
Article 22 – paragraph 1
Text proposed by the Commission
Where the high-risk AI system presents a
risk within the meaning of Article 65(1)
and that risk is known to the provider of
the system, that provider shall immediately
inform the national competent authorities
of the Member States in which it made the
system available and, where applicable, the
notified body that issued a certificate for
the high-risk AI system, in particular of the
non-compliance and of any corrective

actions taken.

Amendment 360
Proposal for a regulation
Article 22 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 361
Proposal for a regulation
Article 22 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 362
Proposal for a regulation
Article 23 – title
Text proposed by the Commission
Cooperation with competent authorities

Amendment 363

Proposal for a regulation
Article 23 – paragraph 1
Text proposed by the Commission
Providers of high-risk AI systems shall,
upon request by a national competent
authority, provide that authority with all
the information and documentation
necessary to demonstrate the conformity of
the high-risk AI system with the
requirements set out in Chapter 2 of this
Title, in an official Union language
determined by the Member State
concerned. Upon a reasoned request from
a national competent authority, providers
shall also give that authority access to the
logs automatically generated by the highrisk AI system, to the extent such logs are
under their control by virtue of a
contractual arrangement with the user or
otherwise by law.

Amendment 364
Proposal for a regulation
Article 23 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 365
Proposal for a regulation
Article 23 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 366
Proposal for a regulation
Article 25 – paragraph 1
Text proposed by the Commission
1.
Prior to making their systems
available on the Union market, where an
importer cannot be identified, providers
established outside the Union shall, by
written mandate, appoint an authorised
representative which is established in the
Union.

Amendment 367
Proposal for a regulation
Article 25 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 368
Proposal for a regulation
Article 25 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 369
Proposal for a regulation
Article 25 – paragraph 2 – introductory part
Text proposed by the Commission
2.
The authorised representative shall
perform the tasks specified in the mandate
received from the provider. The mandate
shall empower the authorised
representative to carry out the following
tasks:

Amendment 370
Proposal for a regulation
Article 25 – paragraph 2 – point a
Text proposed by the Commission
(a) keep a copy of the EU declaration of
conformity and the technical
documentation at the disposal of the
national competent authorities and
national authorities referred to in Article
63(7);

Amendment 371
Proposal for a regulation
Article 25 – paragraph 2 – point a a (new)
Text proposed by the Commission

Amendment 372
Proposal for a regulation
Article 25 – paragraph 2 – point b
Text proposed by the Commission
(b) provide a national competent
authority, upon a reasoned request, with all
the information and documentation
necessary to demonstrate the conformity of
a high-risk AI system with the
requirements set out in Chapter 2 of this
Title, including access to the logs
automatically generated by the high-risk AI
system to the extent such logs are under the
control of the provider by virtue of a
contractual arrangement with the user or
otherwise by law;

Amendment 373
Proposal for a regulation
Article 25 – paragraph 2 – point c
Text proposed by the Commission
(c) cooperate with competent national
authorities, upon a reasoned request, on
any action the latter takes in relation to the
high-risk AI system.

Amendment 374
Proposal for a regulation
Article 25 – paragraph 2 – point c a (new)
Text proposed by the Commission

Amendment 375
Proposal for a regulation
Article 25 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 376
Proposal for a regulation
Article 25 – paragraph 2 b (new)
Text proposed by the Commission

Amendment 377
Proposal for a regulation
Article 26 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Before placing a high-risk AI system
on the market, importers of such system

shall ensure that:

Amendment 378
Proposal for a regulation
Article 26 – paragraph 1 – point a
Text proposed by the Commission
(a) the appropriate conformity
assessment procedure has been carried out
by the provider of that AI system

Amendment 379
Proposal for a regulation
Article 26 – paragraph 1 – point b
Text proposed by the Commission
(b) the provider has drawn up the
technical documentation in accordance
with Annex IV;

Amendment 380
Proposal for a regulation
Article 26 – paragraph 1 – point c a (new)
Text proposed by the Commission

Amendment 381
Proposal for a regulation
Article 26 – paragraph 2
Text proposed by the Commission
2.
Where an importer considers or has
reason to consider that a high-risk AI

system is not in conformity with this
Regulation, it shall not place that system
on the market until that AI system has been
brought into conformity. Where the highrisk AI system presents a risk within the
meaning of Article 65(1), the importer
shall inform the provider of the AI system
and the market surveillance authorities to
that effect.

Amendment 382
Proposal for a regulation
Article 26 – paragraph 3
Text proposed by the Commission
3.
Importers shall indicate their name,
registered trade name or registered trade
mark, and the address at which they can be
contacted on the high-risk AI system or,
where that is not possible, on its packaging
or its accompanying documentation, as
applicable.

Amendment 383
Proposal for a regulation
Article 26 – paragraph 5
Text proposed by the Commission
5.
Importers shall provide national
competent authorities, upon a reasoned
request, with all necessary information and
documentation to demonstrate the
conformity of a high-risk AI system with
the requirements set out in Chapter 2 of
this Title in a language which can be easily
understood by that national competent
authority, including access to the logs
automatically generated by the high-risk AI
system to the extent such logs are under the
control of the provider by virtue of a
contractual arrangement with the user or
otherwise by law. They shall also
cooperate with those authorities on any

action national competent authority takes
in relation to that system.

Amendment 384
Proposal for a regulation
Article 26 – paragraph 5 a (new)
Text proposed by the Commission

Amendment 385
Proposal for a regulation
Article 27 – paragraph 1
Text proposed by the Commission
1.
Before making a high-risk AI system
available on the market, distributors shall
verify that the high-risk AI system bears
the required CE conformity marking, that it
is accompanied by the required
documentation and instruction of use, and
that the provider and the importer of the
system, as applicable, have complied with
the obligations set out in this Regulation.

Amendment 386
Proposal for a regulation
Article 27 – paragraph 2
Text proposed by the Commission
2.
Where a distributor considers or has
reason to consider that a high-risk AI
system is not in conformity with the
requirements set out in Chapter 2 of this
Title, it shall not make the high-risk AI
system available on the market until that

system has been brought into conformity
with those requirements. Furthermore,
where the system presents a risk within the
meaning of Article 65(1), the distributor
shall inform the provider or the importer of
the system, as applicable, to that effect.

Amendment 387
Proposal for a regulation
Article 27 – paragraph 4
Text proposed by the Commission
4.
A distributor that considers or has
reason to consider that a high-risk AI
system which it has made available on the
market is not in conformity with the
requirements set out in Chapter 2 of this
Title shall take the corrective actions
necessary to bring that system into
conformity with those requirements, to
withdraw it or recall it or shall ensure that
the provider, the importer or any relevant
operator, as appropriate, takes those
corrective actions. Where the high-risk AI
system presents a risk within the meaning
of Article 65(1), the distributor shall
immediately inform the national competent
authorities of the Member States in which
it has made the product available to that
effect, giving details, in particular, of the
non-compliance and of any corrective
actions taken.

Amendment 388
Proposal for a regulation
Article 27 – paragraph 5
Text proposed by the Commission
5.

Upon a reasoned request from a

national competent authority, distributors
of high-risk AI systems shall provide that
authority with all the information and
documentation necessary to demonstrate
the conformity of a high-risk system with
the requirements set out in Chapter 2 of
this Title. Distributors shall also cooperate
with that national competent authority on
any action taken by that authority.

Amendment 389
Proposal for a regulation
Article 27 – paragraph 5 a (new)
Text proposed by the Commission

Amendment 390
Proposal for a regulation
Article 28 – title
Text proposed by the Commission
Obligations of distributors, importers,
users or any other third-party

Amendment 391
Proposal for a regulation
Article 28 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Any distributor, importer, user or
other third-party shall be considered a
provider for the purposes of this
Regulation and shall be subject to the
obligations of the provider under Article

16, in any of the following circumstances:

Amendment 392
Proposal for a regulation
Article 28 – paragraph 1 – point a
Text proposed by the Commission
(a) they place on the market or put into
service a high-risk AI system under their
name or trademark;

Amendment 393
Proposal for a regulation
Article 28 – paragraph 1 – point b
Text proposed by the Commission
(b) they modify the intended purpose of
a high-risk AI system already placed on the
market or put into service;

Amendment 394
Proposal for a regulation
Article 28 – paragraph 1 – point b a (new)
Text proposed by the Commission

Amendment 395

Proposal for a regulation
Article 28 – paragraph 2
Text proposed by the Commission
2.
Where the circumstances referred to
in paragraph 1, point (b) or (c), occur, the
provider that initially placed the high-risk
AI system on the market or put it into
service shall no longer be considered a
provider for the purposes of this
Regulation.

Amendment 396
Proposal for a regulation
Article 28 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 397
Proposal for a regulation
Article 28 – paragraph 2 b (new)
Text proposed by the Commission

Amendment 398
Proposal for a regulation
Article 28 a (new)
Text proposed by the Commission

Amendment 399
Proposal for a regulation
Article 28 b (new)
Text proposed by the Commission

Amendment 400
Proposal for a regulation
Article 29 – paragraph 1
Text proposed by the Commission
1.
Users of high-risk AI systems shall
use such systems in accordance with the
instructions of use accompanying the
systems, pursuant to paragraphs 2 and 5.

Amendment 401
Proposal for a regulation
Article 29 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 402
Proposal for a regulation
Article 29 – paragraph 2
Text proposed by the Commission
2.
The obligations in paragraph 1 are
without prejudice to other user obligations
under Union or national law and to the
user’s discretion in organising its own
resources and activities for the purpose of
implementing the human oversight
measures indicated by the provider.

Amendment 403
Proposal for a regulation
Article 29 – paragraph 3
Text proposed by the Commission
3.
Without prejudice to paragraph 1, to
the extent the user exercises control over
the input data, that user shall ensure that
input data is relevant in view of the
intended purpose of the high-risk AI
system.

Amendment 404
Proposal for a regulation
Article 29 – paragraph 4 – introductory part
Text proposed by the Commission
4.
Users shall monitor the operation of
the high-risk AI system on the basis of the
instructions of use. When they have
reasons to consider that the use in
accordance with the instructions of use
may result in the AI system presenting a
risk within the meaning of Article 65(1)
they shall inform the provider or distributor
and suspend the use of the system. They
shall also inform the provider or distributor
when they have identified any serious
incident or any malfunctioning within the
meaning of Article 62 and interrupt the use
of the AI system. In case the user is not
able to reach the provider, Article 62 shall
apply mutatis mutandis.

Amendment 405
Proposal for a regulation
Article 29 – paragraph 4 – subparagraph 1
Text proposed by the Commission
For users that are credit institutions
regulated by Directive 2013/36/EU, the
monitoring obligation set out in the first
subparagraph shall be deemed to be
fulfilled by complying with the rules on
internal governance arrangements,
processes and mechanisms pursuant to
Article 74 of that Directive.

Amendment 406
Proposal for a regulation
Article 29 – paragraph 5 – introductory part
Text proposed by the Commission
5.
Users of high-risk AI systems shall
keep the logs automatically generated by
that high-risk AI system, to the extent such
logs are under their control. The logs shall
be kept for a period that is appropriate in
the light of the intended purpose of the
high-risk AI system and applicable legal
obligations under Union or national law.

Amendment 407
Proposal for a regulation
Article 29 – paragraph 5 – subparagraph 1
Text proposed by the Commission
Users that are credit institutions regulated
by Directive 2013/36/EU shall maintain the
logs as part of the documentation
concerning internal governance
arrangements, processes and mechanisms
pursuant to Article 74 of that Directive.

Amendment 408
Proposal for a regulation
Article 29 – paragraph 5 a (new)

Text proposed by the Commission

Amendment 409
Proposal for a regulation
Article 29 – paragraph 5 b (new)
Text proposed by the Commission

Amendment 410
Proposal for a regulation
Article 29 – paragraph 6
Text proposed by the Commission
6.
Users of high-risk AI systems shall
use the information provided under Article
13 to comply with their obligation to carry
out a data protection impact assessment
under Article 35 of Regulation (EU)
2016/679 or Article 27 of Directive (EU)
2016/680, where applicable.

Amendment 411
Proposal for a regulation
Article 29 – paragraph 6 a (new)
Text proposed by the Commission

Amendment 412
Proposal for a regulation
Article 29 – paragraph 6 b (new)
Text proposed by the Commission

Amendment 413
Proposal for a regulation
Article 29 a (new)
Text proposed by the Commission

Amendment 414
Proposal for a regulation
Article 30 – paragraph 1
Text proposed by the Commission
1.
Each Member State shall designate
or establish a notifying authority
responsible for setting up and carrying out
the necessary procedures for the
assessment, designation and notification of
conformity assessment bodies and for their
monitoring.

Amendment 415
Proposal for a regulation
Article 30 – paragraph 7
Text proposed by the Commission
7.
Notifying authorities shall have a
sufficient number of competent personnel
at their disposal for the proper performance
of their tasks.

Amendment 416
Proposal for a regulation
Article 30 – paragraph 8
Text proposed by the Commission
8.

Notifying authorities shall make sure

that conformity assessments are carried out
in a proportionate manner, avoiding
unnecessary burdens for providers and that
notified bodies perform their activities
taking due account of the size of an
undertaking, the sector in which it
operates, its structure and the degree of
complexity of the AI system in question.

Amendment 417
Proposal for a regulation
Article 32 – paragraph 1
Text proposed by the Commission
1.
Notifying authorities may notify only
conformity assessment bodies which have
satisfied the requirements laid down in
Article 33.

Amendment 418
Proposal for a regulation
Article 32 – paragraph 2
Text proposed by the Commission
2.
Notifying authorities shall notify the
Commission and the other Member States
using the electronic notification tool
developed and managed by the
Commission.

Amendment 419
Proposal for a regulation
Article 32 – paragraph 3

Text proposed by the Commission
3.
The notification shall include full
details of the conformity assessment
activities, the conformity assessment
module or modules and the artificial
intelligence technologies concerned.

Amendment 420
Proposal for a regulation
Article 32 – paragraph 4
Text proposed by the Commission
4.
The conformity assessment body
concerned may perform the activities of a
notified body only where no objections are
raised by the Commission or the other
Member States within one month of a
notification.

Amendment 421
Proposal for a regulation
Article 32 – paragraph 4 a (new)
Text proposed by the Commission

Amendment 422
Proposal for a regulation
Article 32 – paragraph 4 b (new)
Text proposed by the Commission

Amendment 423
Proposal for a regulation
Article 33 – paragraph 2
Text proposed by the Commission
2.
Notified bodies shall satisfy the
organisational, quality management,
resources and process requirements that are
necessary to fulfil their tasks.

Amendment 424
Proposal for a regulation
Article 33 – paragraph 4
Text proposed by the Commission
4.
Notified bodies shall be independent
of the provider of a high-risk AI system in
relation to which it performs conformity
assessment activities. Notified bodies shall
also be independent of any other operator
having an economic interest in the highrisk AI system that is assessed, as well as
of any competitors of the provider.

Amendment 425
Proposal for a regulation
Article 33 – paragraph 4 a (new)
Text proposed by the Commission

Amendment 426
Proposal for a regulation
Article 33 – paragraph 6
Text proposed by the Commission
6.
Notified bodies shall have
documented procedures in place ensuring
that their personnel, committees,
subsidiaries, subcontractors and any
associated body or personnel of external
bodies respect the confidentiality of the
information which comes into their
possession during the performance of
conformity assessment activities, except
when disclosure is required by law. The
staff of notified bodies shall be bound to
observe professional secrecy with regard to
all information obtained in carrying out
their tasks under this Regulation, except in
relation to the notifying authorities of the
Member State in which their activities are
carried out.

Amendment 427
Proposal for a regulation
Article 34 – paragraph 3
Text proposed by the Commission
3.
Activities may be subcontracted or
carried out by a subsidiary only with the
agreement of the provider.

Amendment 428
Proposal for a regulation
Article 34 – paragraph 4
Text proposed by the Commission
4.
Notified bodies shall keep at the
disposal of the notifying authority the
relevant documents concerning the
assessment of the qualifications of the
subcontractor or the subsidiary and the
work carried out by them under this
Regulation.

Amendment 429
Proposal for a regulation
Article 35 – title
Text proposed by the Commission
Identification numbers and lists of notified
bodies designated under this Regulation

Amendment 430

Proposal for a regulation
Article 36 – paragraph 1
Text proposed by the Commission
1.
Where a notifying authority has
suspicions or has been informed that a
notified body no longer meets the
requirements laid down in Article 33, or
that it is failing to fulfil its obligations, that
authority shall without delay investigate
the matter with the utmost diligence. In
that context, it shall inform the notified
body concerned about the objections raised
and give it the possibility to make its views
known. If the notifying authority comes to
the conclusion that the notified body
investigation no longer meets the
requirements laid down in Article 33 or
that it is failing to fulfil its obligations, it
shall restrict, suspend or withdraw the
notification as appropriate, depending on
the seriousness of the failure. It shall also
immediately inform the Commission and
the other Member States accordingly.

Amendment 431
Proposal for a regulation
Article 36 – paragraph 2
Text proposed by the Commission
2.
In the event of restriction, suspension
or withdrawal of notification, or where the
notified body has ceased its activity, the
notifying authority shall take appropriate
steps to ensure that the files of that notified
body are either taken over by another
notified body or kept available for the
responsible notifying authorities at their
request.

Amendment 432
Proposal for a regulation
Article 37 – paragraph 1

Text proposed by the Commission
1.
The Commission shall, where
necessary, investigate all cases where there
are reasons to doubt whether a notified
body complies with the requirements laid
down in Article 33.

Amendment 433
Proposal for a regulation
Article 37 – paragraph 2
Text proposed by the Commission
2.
The Notifying authority shall provide
the Commission, on request, with all
relevant information relating to the
notification of the notified body concerned.

Amendment 434
Proposal for a regulation
Article 37 – paragraph 3
Text proposed by the Commission
3.
The Commission shall ensure that all
confidential information obtained in the
course of its investigations pursuant to this
Article is treated confidentially.

Amendment 435
Proposal for a regulation
Article 37 – paragraph 4
Text proposed by the Commission
4.
Where the Commission ascertains
that a notified body does not meet or no
longer meets the requirements laid down in
Article 33, it shall adopt a reasoned

decision requesting the notifying Member
State to take the necessary corrective
measures, including withdrawal of
notification if necessary. That
implementing act shall be adopted in
accordance with the examination procedure
referred to in Article 74(2).

Amendment 436
Proposal for a regulation
Article 38 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 437
Proposal for a regulation
Article 40 – paragraph 1
Text proposed by the Commission
High-risk AI systems which are in
conformity with harmonised standards or
parts thereof the references of which have
been published in the Official Journal of
the European Union shall be presumed to
be in conformity with the requirements set
out in Chapter 2 of this Title, to the extent
those standards cover those requirements.

Amendment 438

Proposal for a regulation
Article 40 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 439
Proposal for a regulation
Article 40 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 440
Proposal for a regulation
Article 40 – paragraph 1 c (new)
Text proposed by the Commission

Amendment 441
Proposal for a regulation
Article 41 – paragraph 1
Text proposed by the Commission
1.
Where harmonised standards
referred to in Article 40 do not exist or
where the Commission considers that the
relevant harmonised standards are
insufficient or that there is a need to
address specific safety or fundamental
right concerns, the Commission may, by
means of implementing acts, adopt
common specifications in respect of the
requirements set out in Chapter 2 of this
Title. Those implementing acts shall be
adopted in accordance with the
examination procedure referred to in
Article 74(2).

Amendment 442
Proposal for a regulation
Article 41 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 443
Proposal for a regulation
Article 41 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 444
Proposal for a regulation
Article 41 – paragraph 1 c (new)
Text proposed by the Commission

Amendment 445
Proposal for a regulation
Article 41 – paragraph 2
Text proposed by the Commission
2.
The Commission, when preparing
the common specifications referred to in
paragraph 1, shall gather the views of
relevant bodies or expert groups
established under relevant sectorial Union
law.

Amendment 446
Proposal for a regulation
Article 41 – paragraph 3

Text proposed by the Commission
3.
High-risk AI systems which are in
conformity with the common specifications
referred to in paragraph 1 shall be
presumed to be in conformity with the
requirements set out in Chapter 2 of this
Title, to the extent those common
specifications cover those requirements.

Amendment 447
Proposal for a regulation
Article 41 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 448
Proposal for a regulation
Article 41 – paragraph 4
Text proposed by the Commission
4.
Where providers do not comply with
the common specifications referred to in
paragraph 1, they shall duly justify that
they have adopted technical solutions that
are at least equivalent thereto.

Amendment 449
Proposal for a regulation
Article 42 – paragraph 1
Text proposed by the Commission
1.
Taking into account their intended
purpose, high-risk AI systems that have
been trained and tested on data concerning
the specific geographical, behavioural and
functional setting within which they are
intended to be used shall be presumed to be
in compliance with the requirement set out
in Article 10(4).

Amendment 450
Proposal for a regulation
Article 43 – paragraph 1 – introductory part
Text proposed by the Commission
1.
For high-risk AI systems listed in
point 1 of Annex III, where, in
demonstrating the compliance of a highrisk AI system with the requirements set
out in Chapter 2 of this Title, the provider
has applied harmonised standards referred
to in Article 40, or, where applicable,
common specifications referred to in
Article 41, the provider shall follow one of
the following procedures:

Amendment 451
Proposal for a regulation
Article 43 – paragraph 1 – point a
Text proposed by the Commission
(a) the conformity assessment procedure
based on internal control referred to in
Annex VI;

Amendment 452
Proposal for a regulation
Article 43 – paragraph 1 – point b
Text proposed by the Commission
(b) the conformity assessment procedure
based on assessment of the quality
management system and assessment of the
technical documentation, with the
involvement of a notified body, referred to
in Annex VII.

Amendment 453
Proposal for a regulation
Article 43 – paragraph 1 – subparagraph 1
Text proposed by the Commission
Where, in demonstrating the compliance of
a high-risk AI system with the
requirements set out in Chapter 2 of this
Title, the provider has not applied or has
applied only in part harmonised standards
referred to in Article 40, or where such
harmonised standards do not exist and
common specifications referred to in
Article 41 are not available, the provider
shall follow the conformity assessment
procedure set out in Annex VII.

Amendment 454
Proposal for a regulation
Article 43 – paragraph 1 – subparagraph 2
Text proposed by the Commission
For the purpose of the conformity
assessment procedure referred to in Annex
VII, the provider may choose any of the
notified bodies. However, when the system
is intended to be put into service by law
enforcement, immigration or asylum
authorities as well as EU institutions,
bodies or agencies, the market surveillance
authority referred to in Article 63(5) or (6),
as applicable, shall act as a notified body.

Amendment 455
Proposal for a regulation
Article 43 – paragraph 4 – introductory part
Text proposed by the Commission
4.
High-risk AI systems shall undergo a
new conformity assessment procedure
whenever they are substantially modified,
regardless of whether the modified system
is intended to be further distributed or
continues to be used by the current user.

Amendment 456
Proposal for a regulation
Article 43 – paragraph 4 a (new)

Text proposed by the Commission

Amendment 457
Proposal for a regulation
Article 43 – paragraph 5
Text proposed by the Commission
5.
The Commission is empowered to
adopt delegated acts in accordance with
Article 73 for the purpose of updating
Annexes VI and Annex VII in order to
introduce elements of the conformity
assessment procedures that become
necessary in light of technical progress.

Amendment 458
Proposal for a regulation
Article 43 – paragraph 6
Text proposed by the Commission
6.
The Commission is empowered to
adopt delegated acts to amend paragraphs 1
and 2 in order to subject high-risk AI
systems referred to in points 2 to 8 of
Annex III to the conformity assessment
procedure referred to in Annex VII or parts
thereof. The Commission shall adopt such
delegated acts taking into account the
effectiveness of the conformity assessment
procedure based on internal control
referred to in Annex VI in preventing or
minimizing the risks to health and safety
and protection of fundamental rights posed
by such systems as well as the availability

of adequate capacities and resources
among notified bodies.

Amendment 459
Proposal for a regulation
Article 44 – paragraph 1
Text proposed by the Commission
1.
Certificates issued by notified bodies
in accordance with Annex VII shall be
drawn-up in an official Union language
determined by the Member State in which
the notified body is established or in an
official Union language otherwise
acceptable to the notified body.

Amendment 460
Proposal for a regulation
Article 44 – paragraph 2
Text proposed by the Commission
2.
Certificates shall be valid for the
period they indicate, which shall not
exceed five years. On application by the
provider, the validity of a certificate may
be extended for further periods, each not
exceeding five years, based on a reassessment in accordance with the
applicable conformity assessment
procedures.

Amendment 461
Proposal for a regulation
Article 44 – paragraph 3
Text proposed by the Commission
3.

Where a notified body finds that an

AI system no longer meets the
requirements set out in Chapter 2 of this
Title, it shall, taking account of the
principle of proportionality, suspend or
withdraw the certificate issued or impose
any restrictions on it, unless compliance
with those requirements is ensured by
appropriate corrective action taken by the
provider of the system within an
appropriate deadline set by the notified
body. The notified body shall give reasons
for its decision.

Amendment 462
Proposal for a regulation
Article 45 – paragraph 1
Text proposed by the Commission
Member States shall ensure that an appeal
procedure against decisions of the notified
bodies is available to parties having a
legitimate interest in that decision.

Amendment 463
Proposal for a regulation
Article 46 – paragraph 3
Text proposed by the Commission
3.
Each notified body shall provide the
other notified bodies carrying out similar
conformity assessment activities covering
the same artificial intelligence
technologies with relevant information on
issues relating to negative and, on request,
positive conformity assessment results.

Amendment 464
Proposal for a regulation
Article 47 – paragraph 1

Text proposed by the Commission
1.
By way of derogation from Article
43, any market surveillance authority may
authorise the placing on the market or
putting into service of specific high-risk AI
systems within the territory of the Member
State concerned, for exceptional reasons of
public security or the protection of life and
health of persons, environmental protection
and the protection of key industrial and
infrastructural assets. That authorisation
shall be for a limited period of time, while
the necessary conformity assessment
procedures are being carried out, and shall
terminate once those procedures have been
completed. The completion of those
procedures shall be undertaken without
undue delay.

Amendment 465
Proposal for a regulation
Article 47 – paragraph 2
Text proposed by the Commission
2.
The authorisation referred to in
paragraph 1 shall be issued only if the
market surveillance authority concludes
that the high-risk AI system complies with
the requirements of Chapter 2 of this Title.
The market surveillance authority shall
inform the Commission and the other
Member States of any authorisation issued
pursuant to paragraph 1.

Amendment 466
Proposal for a regulation
Article 47 – paragraph 3
Text proposed by the Commission
3.

Where, within 15 calendar days of

receipt of the information referred to in
paragraph 2, no objection has been raised
by either a Member State or the
Commission in respect of an authorisation
issued by a market surveillance authority
of a Member State in accordance with
paragraph 1, that authorisation shall be
deemed justified.

Amendment 467
Proposal for a regulation
Article 47 – paragraph 4
Text proposed by the Commission
4.
Where, within 15 calendar days of
receipt of the notification referred to in
paragraph 2, objections are raised by a
Member State against an authorisation
issued by a market surveillance authority
of another Member State, or where the
Commission considers the authorisation to
be contrary to Union law or the conclusion
of the Member States regarding the
compliance of the system as referred to in
paragraph 2 to be unfounded, the
Commission shall without delay enter into
consultation with the relevant Member
State; the operator(s) concerned shall be
consulted and have the possibility to
present their views. In view thereof, the
Commission shall decide whether the
authorisation is justified or not. The
Commission shall address its decision to
the Member State concerned and the
relevant operator or operators.

Amendment 468
Proposal for a regulation
Article 47 – paragraph 5
Text proposed by the Commission
5.
If the authorisation is considered
unjustified, this shall be withdrawn by the

market surveillance authority of the
Member State concerned.

Amendment 469
Proposal for a regulation
Article 48 – paragraph 1
Text proposed by the Commission
1.
The provider shall draw up a written
EU declaration of conformity for each AI
system and keep it at the disposal of the
national competent authorities for 10 years
after the AI system has been placed on the
market or put into service. The EU
declaration of conformity shall identify
the AI system for which it has been drawn
up. A copy of the EU declaration of
conformity shall be given to the relevant
national competent authorities upon
request.

Amendment 470
Proposal for a regulation
Article 48 – paragraph 2
Text proposed by the Commission
2.
The EU declaration of conformity
shall state that the high-risk AI system in
question meets the requirements set out in
Chapter 2 of this Title. The EU declaration
of conformity shall contain the information
set out in Annex V and shall be translated
into an official Union language or
languages required by the Member State(s)
in which the high-risk AI system is made
available.

Amendment 471
Proposal for a regulation
Article 48 – paragraph 3

Text proposed by the Commission
3.
Where high-risk AI systems are
subject to other Union harmonisation
legislation which also requires an EU
declaration of conformity, a single EU
declaration of conformity shall be drawn
up in respect of all Union legislations
applicable to the high-risk AI system. The
declaration shall contain all the information
required for identification of the Union
harmonisation legislation to which the
declaration relates.

Amendment 472
Proposal for a regulation
Article 48 – paragraph 5
Text proposed by the Commission
5.
The Commission shall be empowered
to adopt delegated acts in accordance with
Article 73 for the purpose of updating the
content of the EU declaration of
conformity set out in Annex V in order to
introduce elements that become necessary
in light of technical progress.

Amendment 473
Proposal for a regulation
Article 49 – paragraph 1
Text proposed by the Commission
1.
The CE marking shall be affixed
visibly, legibly and indelibly for high-risk
AI systems. Where that is not possible or
not warranted on account of the nature of
the high-risk AI system, it shall be affixed
to the packaging or to the accompanying
documentation, as appropriate.

Amendment 474
Proposal for a regulation
Article 49 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 475
Proposal for a regulation
Article 49 – paragraph 3
Text proposed by the Commission
3.
Where applicable, the CE marking
shall be followed by the identification
number of the notified body responsible for
the conformity assessment procedures set
out in Article 43. The identification
number shall also be indicated in any
promotional material which mentions that
the high-risk AI system fulfils the
requirements for CE marking.

Amendment 476
Proposal for a regulation
Article 49 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 477
Proposal for a regulation
Article 50 – paragraph 1 – introductory part
Text proposed by the Commission
The provider shall, for a period ending 10
years after the AI system has been placed
on the market or put into service, keep at
the disposal of the national competent
authorities:

Amendment 478
Proposal for a regulation
Article 51 – paragraph 1
Text proposed by the Commission
Before placing on the market or putting
into service a high-risk AI system referred
to in Article 6(2), the provider or, where
applicable, the authorised representative
shall register that system in the EU
database referred to in Article 60.

Amendment 479
Proposal for a regulation
Article 51 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 480
Proposal for a regulation
Article 51 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 481
Proposal for a regulation
Article 51 – paragraph 1 c (new)
Text proposed by the Commission

Amendment 482
Proposal for a regulation
Title IV
Text proposed by the Commission
TRANSPARENCY OBLIGATIONS FOR
CERTAIN AI SYSTEMS

Amendment 483

Proposal for a regulation
Article 52 – title
Text proposed by the Commission
Transparency obligations for certain AI
systems

Amendment 484
Proposal for a regulation
Article 52 – paragraph 1
Text proposed by the Commission
1.
Providers shall ensure that AI
systems intended to interact with natural
persons are designed and developed in
such a way that natural persons are
informed that they are interacting with an
AI system, unless this is obvious from the
circumstances and the context of use. This
obligation shall not apply to AI systems
authorised by law to detect, prevent,
investigate and prosecute criminal
offences, unless those systems are
available for the public to report a criminal
offence.

Amendment 485
Proposal for a regulation
Article 52 – paragraph 2
Text proposed by the Commission
2.
Users of an emotion recognition
system or a biometric categorisation
system shall inform of the operation of the
system the natural persons exposed thereto.
This obligation shall not apply to AI
systems used for biometric categorisation,
which are permitted by law to detect,
prevent and investigate criminal offences.

Amendment 486
Proposal for a regulation
Article 52 – paragraph 3 – subparagraph 1
Text proposed by the Commission
3.
Users of an AI system that generates
or manipulates image, audio or video
content that appreciably resembles
existing persons, objects, places or other
entities or events and would falsely appear
to a person to be authentic or truthful
(‘deep fake’), shall disclose that the content
has been artificially generated or
manipulated.

Amendment 487
Proposal for a regulation
Article 52 – paragraph 3 – subparagraph 2
Text proposed by the Commission
However, the first subparagraph shall not
apply where the use is authorised by law to
detect, prevent, investigate and prosecute
criminal offences or it is necessary for the
exercise of the right to freedom of
expression and the right to freedom of the
arts and sciences guaranteed in the Charter
of Fundamental Rights of the EU, and
subject to appropriate safeguards for the
rights and freedoms of third parties.

Amendment 488
Proposal for a regulation
Article 52 – paragraph 3 b (new)
Text proposed by the Commission

Amendment 489
Proposal for a regulation
Article 53 – paragraph 1
Text proposed by the Commission
1.
AI regulatory sandboxes established
by one or more Member States competent
authorities or the European Data
Protection Supervisor shall provide a
controlled environment that facilitates the
development, testing and validation of
innovative AI systems for a limited time
before their placement on the market or
putting into service pursuant to a specific
plan. This shall take place under the
direct supervision and guidance by the
competent authorities with a view to
ensuring compliance with the
requirements of this Regulation and,
where relevant, other Union and Member
States legislation supervised within the
sandbox.

Amendment 490
Proposal for a regulation
Article 53 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 491

Proposal for a regulation
Article 53 – paragraph 1 b (new)
Text proposed by the Commission

Amendment 492
Proposal for a regulation
Article 53 – paragraph 1 c (new)
Text proposed by the Commission

Amendment 493
Proposal for a regulation
Article 53 – paragraph 1 d (new)
Text proposed by the Commission

Amendment 494
Proposal for a regulation
Article 53 – paragraph 1 e (new)

Text proposed by the Commission

Amendment 495
Proposal for a regulation
Article 53 – paragraph 1 f (new)
Text proposed by the Commission

Amendment 496
Proposal for a regulation
Article 53 – paragraph 1 f (new)

Text proposed by the Commission

Amendment 497
Proposal for a regulation
Article 53 – paragraph 2
Text proposed by the Commission
2.
Member States shall ensure that to
the extent the innovative AI systems
involve the processing of personal data or
otherwise fall under the supervisory remit
of other national authorities or competent
authorities providing or supporting access
to data, the national data protection
authorities and those other national
authorities are associated to the operation
of the AI regulatory sandbox.

Amendment 498

Proposal for a regulation
Article 53 – paragraph 3
Text proposed by the Commission
3.
The AI regulatory sandboxes shall
not affect the supervisory and corrective
powers of the competent authorities. Any
significant risks to health and safety and
fundamental rights identified during the
development and testing of such systems
shall result in immediate mitigation and,
failing that, in the suspension of the
development and testing process until
such mitigation takes place.

Amendment 499
Proposal for a regulation
Article 53 – paragraph 4
Text proposed by the Commission
4.
Participants in the AI regulatory
sandbox shall remain liable under
applicable Union and Member States
liability legislation for any harm inflicted
on third parties as a result from the
experimentation taking place in the
sandbox.

Amendment 500

Proposal for a regulation
Article 53 – paragraph 5
Text proposed by the Commission
5.
Member States’ competent
authorities that have established AI
regulatory sandboxes shall coordinate
their activities and cooperate within the
framework of the European Artificial
Intelligence Board. They shall submit
annual reports to the Board and the
Commission on the results from the
implementation of those scheme,
including good practices, lessons learnt
and recommendations on their setup and,
where relevant, on the application of this
Regulation and other Union legislation
supervised within the sandbox.

Amendment 501
Proposal for a regulation
Article 53 – paragraph 5 a (new)
Text proposed by the Commission

Amendment 502
Proposal for a regulation
Article 53 – paragraph 5 b (new)
Text proposed by the Commission

Amendment 503
Proposal for a regulation
Article 53 – paragraph 6
Text proposed by the Commission
6.
The modalities and the conditions of
the operation of the AI regulatory
sandboxes, including the eligibility criteria
and the procedure for the application,
selection, participation and exiting from
the sandbox, and the rights and
obligations of the participants shall be set
out in implementing acts. Those
implementing acts shall be adopted in
accordance with the examination
procedure referred to in Article 74(2).

Amendment 504
Proposal for a regulation
Article 53 – paragraph 6 a (new)
Text proposed by the Commission

Amendment 505
Proposal for a regulation
Article 53 a (new)
Text proposed by the Commission

Amendment 506
Proposal for a regulation
Article 54 – title
Text proposed by the Commission
Further processing of personal data for
developing certain AI systems in the public
interest in the AI regulatory sandbox

Amendment 507
Proposal for a regulation
Article 54 – paragraph 1 – introductory part
Text proposed by the Commission
1.
In the AI regulatory sandbox
personal data lawfully collected for other
purposes shall be processed for the
purposes of developing and testing certain
innovative AI systems in the sandbox
under the following conditions:

Amendment 508

Proposal for a regulation
Article 54 – paragraph 1 – point a – introduc
Text proposed by the Commission
(a) the innovative AI systems shall be
developed for safeguarding substantial
public interest in one or more of the
following areas:

Amendment 509
Proposal for a regulation
Article 54 – paragraph 1 – point a – point i
Text proposed by the Commission
(i) the prevention, investigation,
detection or prosecution of criminal
offences or the execution of criminal
penalties, including the safeguarding
against and the prevention of threats to
public security, under the control and
responsibility of the competent
authorities. The processing shall be based
on Member State or Union law;

Amendment 510
Proposal for a regulation
Article 54 – paragraph 1 – point c
Text proposed by the Commission
(c) there are effective monitoring
mechanisms to identify if any high risks to

the fundamental rights of the data subjects
may arise during the sandbox
experimentation as well as response
mechanism to promptly mitigate those
risks and, where necessary, stop the
processing;

Amendment 511
Proposal for a regulation
Article 54 – paragraph 1 – point d
Text proposed by the Commission
(d) any personal data to be processed in
the context of the sandbox are in a
functionally separate, isolated and
protected data processing environment
under the control of the participants and
only authorised persons have access to that
data;

Amendment 512
Proposal for a regulation
Article 54 – paragraph 1 – point f
Text proposed by the Commission
(f) any processing of personal data in the
context of the sandbox do not lead to
measures or decisions affecting the data
subjects;

Amendment 513
Proposal for a regulation
Article 54 – paragraph 1 – point g
Text proposed by the Commission
(g) any personal data processed in the
context of the sandbox are deleted once the

participation in the sandbox has terminated
or the personal data has reached the end of
its retention period;

Amendment 514
Proposal for a regulation
Article 54 – paragraph 1 – point h
Text proposed by the Commission
(h) the logs of the processing of personal
data in the context of the sandbox are kept
for the duration of the participation in the
sandbox and 1 year after its termination,
solely for the purpose of and only as long
as necessary for fulfilling accountability
and documentation obligations under this
Article or other application Union or
Member States legislation;

Amendment 515
Proposal for a regulation
Article 54 – paragraph 1 – point j
Text proposed by the Commission
(j) a short summary of the AI project
developed in the sandbox, its objectives
and expected results published on the
website of the competent authorities.

Amendment 516
Proposal for a regulation
Article 54 a (new)
Text proposed by the Commission

Amendment 517
Proposal for a regulation
Article 55 – title
Text proposed by the Commission
Measures for small-scale providers and
users

Amendment 518
Proposal for a regulation
Article 55 – paragraph 1 – point a
Text proposed by the Commission
(a) provide small-scale providers and
start-ups with priority access to the AI
regulatory sandboxes to the extent that they
fulfil the eligibility conditions;

Amendment 519
Proposal for a regulation
Article 55 – paragraph 1 – point b
Text proposed by the Commission
(b) organise specific awareness raising
activities about the application of this
Regulation tailored to the needs of the
small-scale providers and users;

Amendment 520
Proposal for a regulation
Article 55 – paragraph 1 – point c
Text proposed by the Commission
(c) where appropriate, establish a
dedicated channel for communication with
small-scale providers and user and other
innovators to provide guidance and
respond to queries about the
implementation of this Regulation.

Amendment 521
Proposal for a regulation
Article 55 – paragraph 1 – point c a (new)

Text proposed by the Commission

Amendment 522
Proposal for a regulation
Article 55 – paragraph 2
Text proposed by the Commission
2.
The specific interests and needs of
the small-scale providers shall be taken
into account when setting the fees for
conformity assessment under Article 43,
reducing those fees proportionately to their
size and market size.

Amendment 523
Proposal for a regulation
Article 56 – SECTION 1 – Title
Text proposed by the Commission

Amendment 524

Proposal for a regulation
Article 56 – title
Text proposed by the Commission
Establishment of the European Artificial
Intelligence Board

Amendment 525
Proposal for a regulation
Article 56 – paragraph 1
Text proposed by the Commission
1.
A ‘European Artificial Intelligence
Board’ (the ‘Board’) is established.

Amendment 526
Proposal for a regulation
Article 56 – paragraph 2 – introductory part
Text proposed by the Commission
2.
The Board shall provide advice and
assistance to the Commission in order to:

Amendment 527
Proposal for a regulation
Article 56 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 528

Proposal for a regulation
Article 56 a (new)
Text proposed by the Commission

Amendment 529
Proposal for a regulation
Article 56 b (new)
Text proposed by the Commission

Amendment 530
Proposal for a regulation
Article 56 c (new)
Text proposed by the Commission

Amendment 531
Proposal for a regulation
Article - 57 a (new) – SECTION 2 – title
Text proposed by the Commission

Amendment 532
Proposal for a regulation
Article - 57 a (new)
Text proposed by the Commission

Amendment 533
Proposal for a regulation
Article - 57 b (new)
Text proposed by the Commission

Amendment 534
Proposal for a regulation
Article - 57 c (new)
Text proposed by the Commission

Amendment 535
Proposal for a regulation
Article 57 – SECTION 3 – title
Text proposed by the Commission
Structure of the Board

Amendment 536
Proposal for a regulation
Article 57 – paragraph 1
Text proposed by the Commission
1.
The Board shall be composed of the
national supervisory authorities, who shall
be represented by the head or equivalent
high-level official of that authority, and

the European Data Protection Supervisor.
Other national authorities may be invited
to the meetings, where the issues
discussed are of relevance for them.

Amendment 537
Proposal for a regulation
Article 57 – paragraph 2
Text proposed by the Commission
2.
The Board shall adopt its rules of
procedure by a simple majority of its
members, following the consent of the
Commission. The rules of procedure shall
also contain the operational aspects
related to the execution of the Board’s
tasks as listed in Article 58. The Board
may establish sub-groups as appropriate
for the purpose of examining specific
questions.

Amendment 538
Proposal for a regulation
Article 57 – paragraph 3
Text proposed by the Commission
3.
The Board shall be chaired by the
Commission. The Commission shall
convene the meetings and prepare the
agenda in accordance with the tasks of
the Board pursuant to this Regulation and
with its rules of procedure. The
Commission shall provide administrative
and analytical support for the activities of
the Board pursuant to this Regulation.

Amendment 539
Proposal for a regulation
Article 57 – paragraph 4

Text proposed by the Commission
4.
The Board may invite external
experts and observers to attend its
meetings and may hold exchanges with
interested third parties to inform its
activities to an appropriate extent. To that
end the Commission may facilitate
exchanges between the Board and other
Union bodies, offices, agencies and
advisory groups.

Amendment 540
Proposal for a regulation
Article 58 – SECTION 4 – title
Text proposed by the Commission
Tasks of the Board

Amendment 541
Proposal for a regulation
Article 58 – paragraph 1 – introductory part
Text proposed by the Commission
When providing advice and assistance to
the Commission in the context of Article
56(2), the Board shall in particular:

Amendment 542
Proposal for a regulation
Article 58 – paragraph 2 (new)
Text proposed by the Commission

Amendment 543
Proposal for a regulation
Article 58 – paragraph 3 (new)
Text proposed by the Commission

Amendment 544
Proposal for a regulation
Article 58 – paragraph 4 (new)
Text proposed by the Commission

Amendment 545

Proposal for a regulation
Article 58 – paragraph 5 (new)
Text proposed by the Commission

Amendment 546
Proposal for a regulation
Article 58 – paragraph 6 (new)
Text proposed by the Commission

Amendment 547
Proposal for a regulation
Article 58 – paragraph 7 (new)
Text proposed by the Commission

Amendment 548
Proposal for a regulation
Article 58 – paragraph 8 (new)

Text proposed by the Commission

Amendment 549
Proposal for a regulation
Article 58 – paragraph 9 (new)
Text proposed by the Commission

Amendment 550
Proposal for a regulation
Article 58 – paragraph 10 (new)
Text proposed by the Commission

Amendment 551
Proposal for a regulation
Article 58 a – SECTION 5 – title
Text proposed by the Commission

Amendment 552
Proposal for a regulation
Article 58 a (new)

Text proposed by the Commission

Amendment 553
Proposal for a regulation
Article 59 – title
Text proposed by the Commission
Designation of national competent
authorities

Amendment 554
Proposal for a regulation
Article 59 – paragraph 1
Text proposed by the Commission
1.
National competent authorities shall
be established or designated by each
Member State for the purpose of ensuring
the application and implementation of this
Regulation. National competent
authorities shall be organised so as to
safeguard the objectivity and impartiality
of their activities and tasks.

Amendment 555

Proposal for a regulation
Article 59 – paragraph 2
Text proposed by the Commission
2.
Each Member State shall designate
a national supervisory authority among the
national competent authorities. The
national supervisory authority shall act as
notifying authority and market
surveillance authority unless a Member
State has organisational and
administrative reasons to designate more
than one authority.

Amendment 556
Proposal for a regulation
Article 59 – paragraph 3
Text proposed by the Commission
3.
Member States shall inform the
Commission of their designation or
designations and, where applicable, the
reasons for designating more than one
authority.

Amendment 557
Proposal for a regulation
Article 59 – paragraph 4

Text proposed by the Commission
4.
Member States shall ensure that
national competent authorities are
provided with adequate financial and
human resources to fulfil their tasks under
this Regulation. In particular, national
competent authorities shall have a
sufficient number of personnel
permanently available whose competences
and expertise shall include an in-depth
understanding of artificial intelligence
technologies, data and data computing,
fundamental rights, health and safety risks
and knowledge of existing standards and
legal requirements.

Amendment 558
Proposal for a regulation
Article 59 – paragraph 4 a (new)
Text proposed by the Commission

Amendment 559
Proposal for a regulation
Article 59 – paragraph 4 b (new)

Text proposed by the Commission

Amendment 560
Proposal for a regulation
Article 59 – paragraph 4 c (new)
Text proposed by the Commission

Amendment 561
Proposal for a regulation
Article 59 – paragraph 5
Text proposed by the Commission
5.
Member States shall report to the
Commission on an annual basis on the
status of the financial and human resources
of the national competent authorities with
an assessment of their adequacy. The
Commission shall transmit that information
to the Board for discussion and possible
recommendations.

Amendment 562
Proposal for a regulation
Article 59 – paragraph 6
Text proposed by the Commission
6.
The Commission shall facilitate the
exchange of experience between national

competent authorities.

Amendment 563
Proposal for a regulation
Article 59 – paragraph 7
Text proposed by the Commission
7.
National competent authorities may
provide guidance and advice on the
implementation of this Regulation,
including to small-scale providers.
Whenever national competent authorities
intend to provide guidance and advice with
regard to an AI system in areas covered by
other Union legislation, the competent
national authorities under that Union
legislation shall be consulted, as
appropriate. Member States may also
establish one central contact point for
communication with operators.

Amendment 564
Proposal for a regulation
Article 59 – paragraph 8
Text proposed by the Commission
8.
When Union institutions, agencies
and bodies fall within the scope of this
Regulation, the European Data Protection
Supervisor shall act as the competent
authority for their supervision.

Amendment 565
Proposal for a regulation
Article 59 a (new)
Text proposed by the Commission

Amendment 566
Proposal for a regulation
Title VII
Text proposed by the Commission
VII EU DATABASE FOR STANDALONE HIGH-RISK AI SYSTEMS

Amendment 567
Proposal for a regulation
Article 60 – title
Text proposed by the Commission
EU database for stand-alone high-risk AI
systems

Amendment 568
Proposal for a regulation
Article 60 – paragraph 1

Text proposed by the Commission
1.
The Commission shall, in
collaboration with the Member States, set
up and maintain a EU database containing
information referred to in paragraph 2
concerning high-risk AI systems referred to
in Article 6(2) which are registered in
accordance with Article 51.

Amendment 569
Proposal for a regulation
Article 60 – paragraph 2
Text proposed by the Commission
2.
The data listed in Annex VIII shall
be entered into the EU database by the
providers. The Commission shall provide
them with technical and administrative
support.

Amendment 570
Proposal for a regulation
Article 60 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 571
Proposal for a regulation
Article 60 – paragraph 3

Text proposed by the Commission
3.
Information contained in the EU
database shall be accessible to the public.

Amendment 572
Proposal for a regulation
Article 60 – paragraph 4
Text proposed by the Commission
4.
The EU database shall contain
personal data only insofar as necessary for
collecting and processing information in
accordance with this Regulation. That
information shall include the names and
contact details of natural persons who are
responsible for registering the system and
have the legal authority to represent the
provider.

Amendment 573
Proposal for a regulation
Article 60 – paragraph 5
Text proposed by the Commission
5.
The Commission shall be the
controller of the EU database. It shall also
ensure to providers adequate technical and
administrative support.

Amendment 574
Proposal for a regulation
Article 61 – paragraph 2
Text proposed by the Commission
2.
The post-market monitoring system
shall actively and systematically collect,
document and analyse relevant data
provided by users or collected through
other sources on the performance of highrisk AI systems throughout their lifetime,
and allow the provider to evaluate the
continuous compliance of AI systems with
the requirements set out in Title III,
Chapter 2.

Amendment 575
Proposal for a regulation
Article 61 – paragraph 3
Text proposed by the Commission
3.
The post-market monitoring system
shall be based on a post-market monitoring
plan. The post-market monitoring plan
shall be part of the technical
documentation referred to in Annex IV.
The Commission shall adopt an
implementing act laying down detailed
provisions establishing a template for the
post-market monitoring plan and the list of
elements to be included in the plan.

Amendment 576

Proposal for a regulation
Article 62 – title
Text proposed by the Commission
Reporting of serious incidents and of
malfunctioning

Amendment 577
Proposal for a regulation
Article 62 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Providers of high-risk AI systems
placed on the Union market shall report
any serious incident or any
malfunctioning of those systems which
constitutes a breach of obligations under
Union law intended to protect fundamental
rights to the market surveillance
authorities of the Member States where
that incident or breach occurred.

Amendment 578
Proposal for a regulation
Article 62 – paragraph 1 – subparagraph 1
Text proposed by the Commission
Such notification shall be made
immediately after the provider has
established a causal link between the AI
system and the incident or malfunctioning
or the reasonable likelihood of such a link,
and, in any event, not later than 15 days
after the providers becomes aware of the
serious incident or of the malfunctioning.

Amendment 579
Proposal for a regulation
Article 62 – paragraph 1 a (new)

Text proposed by the Commission

Amendment 580
Proposal for a regulation
Article 62 – paragraph 2
Text proposed by the Commission
2.
Upon receiving a notification related
to a breach of obligations under Union law
intended to protect fundamental rights, the
market surveillance authority shall inform
the national public authorities or bodies
referred to in Article 64(3). The
Commission shall develop dedicated
guidance to facilitate compliance with the
obligations set out in paragraph 1. That
guidance shall be issued 12 months after
the entry into force of this Regulation, at
the latest.

Amendment 581
Proposal for a regulation
Article 62 – paragraph 2 a (new)
Text proposed by the Commission

Amendment 582
Proposal for a regulation
Article 62 – paragraph 3
Text proposed by the Commission
3.
For high-risk AI systems referred to
in point 5(b) of Annex III which are placed
on the market or put into service by
providers that are credit institutions
regulated by Directive 2013/36/EU and
for high-risk AI systems which are safety
components of devices, or are themselves
devices, covered by Regulation (EU)
2017/745 and Regulation (EU) 2017/746,
the notification of serious incidents or
malfunctioning shall be limited to those
that that constitute a breach of obligations
under Union law intended to protect
fundamental rights.

Amendment 583
Proposal for a regulation
Article 62 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 584
Proposal for a regulation
Article 63 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Regulation (EU) 2019/1020 shall
apply to AI systems covered by this
Regulation. However, for the purpose of
the effective enforcement of this
Regulation:

Amendment 585
Proposal for a regulation
Article 63 – paragraph 1 – point b a (new)
Text proposed by the Commission

Amendment 586
Proposal for a regulation
Article 63 – paragraph 2
Text proposed by the Commission
2.
The national supervisory authority
shall report to the Commission on a
regular basis the outcomes of relevant
market surveillance activities. The national
supervisory authority shall report, without
delay, to the Commission and relevant
national competition authorities any
information identified in the course of
market surveillance activities that may be
of potential interest for the application of
Union law on competition rules.

Amendment 587
Proposal for a regulation
Article 63 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 588
Proposal for a regulation
Article 63 – paragraph 5
Text proposed by the Commission
5.
For AI systems listed in point 1(a) in
so far as the systems are used for law
enforcement purposes, points 6 and 7 of
Annex III, Member States shall designate
as market surveillance authorities for the
purposes of this Regulation either the
competent data protection supervisory
authorities under Directive (EU) 2016/680,
or Regulation 2016/679 or the national
competent authorities supervising the
activities of the law enforcement,
immigration or asylum authorities putting
into service or using those systems.

Amendment 589
Proposal for a regulation
Article 63 – paragraph 7
Text proposed by the Commission
7.
Member States shall facilitate the
coordination between market surveillance
authorities designated under this
Regulation and other relevant national
authorities or bodies which supervise the
application of Union harmonisation
legislation listed in Annex II or other
Union legislation that might be relevant for
the high-risk AI systems referred to in
Annex III.

Amendment 590

Proposal for a regulation
Article 64 – paragraph 1
Text proposed by the Commission
1.
Access to data and documentation in
the context of their activities, the market
surveillance authorities shall be granted
full access to the training, validation and
testing datasets used by the provider,
including through application
programming interfaces (‘API’) or other
appropriate technical means and tools
enabling remote access.

Amendment 591
Proposal for a regulation
Article 64 – paragraph 2
Text proposed by the Commission
2.
Where necessary to assess the
conformity of the high-risk AI system with
the requirements set out in Title III,
Chapter 2 and upon a reasoned request, the
market surveillance authorities shall be
granted access to the source code of the AI
system.

Amendment 592
Proposal for a regulation
Article 64 – paragraph 2 a (new)

Text proposed by the Commission

Amendment 593
Proposal for a regulation
Article 64 – paragraph 3
Text proposed by the Commission
3.
National public authorities or bodies
which supervise or enforce the respect of
obligations under Union law protecting
fundamental rights in relation to the use of
high-risk AI systems referred to in Annex
III shall have the power to request and
access any documentation created or
maintained under this Regulation when
access to that documentation is necessary
for the fulfilment of the competences under
their mandate within the limits of their
jurisdiction. The relevant public authority
or body shall inform the market
surveillance authority of the Member State
concerned of any such request.

Amendment 594
Proposal for a regulation
Article 64 – paragraph 4
Text proposed by the Commission
4.
By 3 months after the entering into
force of this Regulation, each Member
State shall identify the public authorities or
bodies referred to in paragraph 3 and make
a list publicly available on the website of
the national supervisory authority. Member
States shall notify the list to the
Commission and all other Member States
and keep the list up to date.

Amendment 595
Proposal for a regulation
Article 64 – paragraph 5
Text proposed by the Commission
5.
Where the documentation referred to
in paragraph 3 is insufficient to ascertain
whether a breach of obligations under
Union law intended to protect fundamental
rights has occurred, the public authority or
body referred to paragraph 3 may make a
reasoned request to the market
surveillance authority to organise testing
of the high-risk AI system through
technical means. The market surveillance
authority shall organise the testing with the
close involvement of the requesting public
authority or body within reasonable time
following the request.

Amendment 596
Proposal for a regulation
Article 65 – paragraph 1
Text proposed by the Commission
1.
AI systems presenting a risk shall be
understood as a product presenting a risk
defined in Article 3, point 19 of
Regulation (EU) 2019/1020 insofar as
risks to the health or safety or to the
protection of fundamental rights of persons
are concerned.

Amendment 597
Proposal for a regulation
Article 65 – paragraph 2 – introductory part
Text proposed by the Commission
2.
Where the market surveillance
authority of a Member State has sufficient
reasons to consider that an AI system
presents a risk as referred to in paragraph
1, they shall carry out an evaluation of the
AI system concerned in respect of its
compliance with all the requirements and
obligations laid down in this Regulation.
When risks to the protection of
fundamental rights are present, the market
surveillance authority shall also inform the
relevant national public authorities or
bodies referred to in Article 64(3). The
relevant operators shall cooperate as
necessary with the market surveillance
authorities and the other national public
authorities or bodies referred to in Article
64(3).

Amendment 598
Proposal for a regulation
Article 65 – paragraph 2 – subparagraph 1
Text proposed by the Commission
Where, in the course of that evaluation, the

market surveillance authority finds that the
AI system does not comply with the
requirements and obligations laid down in
this Regulation, it shall without delay
require the relevant operator to take all
appropriate corrective actions to bring the
AI system into compliance, to withdraw
the AI system from the market, or to recall
it within a reasonable period,
commensurate with the nature of the risk,
as it may prescribe.

Amendment 599
Proposal for a regulation
Article 65 – paragraph 2 – subparagraph 2
Text proposed by the Commission
The market surveillance authority shall
inform the relevant notified body
accordingly. Article 18 of Regulation (EU)
2019/1020 shall apply to the measures
referred to in the second subparagraph.

Amendment 600
Proposal for a regulation
Article 65 – paragraph 3
Text proposed by the Commission
3.
Where the market surveillance
authority considers that non-compliance is
not restricted to its national territory, it
shall inform the Commission and the other
Member States of the results of the
evaluation and of the actions which it has
required the operator to take.

Amendment 601
Proposal for a regulation
Article 65 – paragraph 5
Text proposed by the Commission
5.
Where the operator of an AI system
does not take adequate corrective action
within the period referred to in paragraph
2, the market surveillance authority shall
take all appropriate provisional measures to
prohibit or restrict the AI system's being
made available on its national market, to
withdraw the product from that market or
to recall it. That authority shall inform the
Commission and the other Member States,
without delay, of those measures.

Amendment 602
Proposal for a regulation
Article 65 – paragraph 6 – introductory part
Text proposed by the Commission
6.
The information referred to in
paragraph 5 shall include all available
details, in particular the data necessary for
the identification of the non-compliant AI
system, the origin of the AI system, the
nature of the non-compliance alleged and
the risk involved, the nature and duration
of the national measures taken and the
arguments put forward by the relevant
operator. In particular, the market
surveillance authorities shall indicate
whether the non-compliance is due to one
or more of the following:

Amendment 603
Proposal for a regulation
Article 65 – paragraph 6 – point a

Text proposed by the Commission
(a) a failure of the AI system to meet
requirements set out in Title III, Chapter
2;

Amendment 604
Proposal for a regulation
Article 65 – paragraph 6 – point b a (new)
Text proposed by the Commission

Amendment 605
Proposal for a regulation
Article 65 – paragraph 6 – point b b (new)
Text proposed by the Commission

Amendment 606
Proposal for a regulation
Article 65 – paragraph 7
Text proposed by the Commission
7.
The market surveillance authorities
of the Member States other than the market
surveillance authority of the Member State
initiating the procedure shall without delay
inform the Commission and the other
Member States of any measures adopted
and of any additional information at their
disposal relating to the non-compliance of
the AI system concerned, and, in the event
of disagreement with the notified national
measure, of their objections.

Amendment 607
Proposal for a regulation
Article 65 – paragraph 8
Text proposed by the Commission
8.
Where, within three months of
receipt of the information referred to in
paragraph 5, no objection has been raised
by either a Member State or the
Commission in respect of a provisional
measure taken by a Member State, that
measure shall be deemed justified. This is
without prejudice to the procedural rights
of the concerned operator in accordance
with Article 18 of Regulation (EU)
2019/1020.

Amendment 608
Proposal for a regulation
Article 65 – paragraph 9
Text proposed by the Commission
9.
The market surveillance authorities
of all Member States shall ensure that
appropriate restrictive measures are taken
in respect of the product concerned, such
as withdrawal of the product from their
market, without delay.

Amendment 609
Proposal for a regulation
Article 65 – paragraph 9 a (new)

Text proposed by the Commission

Amendment 610
Proposal for a regulation
Article 66 – paragraph 1
Text proposed by the Commission
1.
Where, within three months of
receipt of the notification referred to in
Article 65(5), objections are raised by a
Member State against a measure taken by
another Member State, or where the
Commission considers the measure to be
contrary to Union law, the Commission
shall without delay enter into consultation
with the relevant Member State and
operator or operators and shall evaluate the
national measure. On the basis of the
results of that evaluation, the Commission
shall decide whether the national measure
is justified or not within 9 months from the
notification referred to in Article 65(5) and
notify such decision to the Member State
concerned.

Amendment 611

Proposal for a regulation
Article 66 – paragraph 2
Text proposed by the Commission
2.
If the national measure is considered
justified, all Member States shall take the
measures necessary to ensure that the noncompliant AI system is withdrawn from
their market, and shall inform the
Commission accordingly. If the national
measure is considered unjustified, the
Member State concerned shall withdraw
the measure.

Amendment 612
Proposal for a regulation
Article 66 a (new)
Text proposed by the Commission

Amendment 613
Proposal for a regulation
Article 67 – paragraph 1
Text proposed by the Commission
1.
Where, having performed an
evaluation under Article 65, the market
surveillance authority of a Member State
finds that although an AI system is in
compliance with this Regulation, it
presents a risk to the health or safety of
persons, to the compliance with obligations
under Union or national law intended to
protect fundamental rights or to other
aspects of public interest protection, it shall
require the relevant operator to take all
appropriate measures to ensure that the AI
system concerned, when placed on the
market or put into service, no longer
presents that risk, to withdraw the AI
system from the market or to recall it
within a reasonable period,
commensurate with the nature of the risk,
as it may prescribe.

Amendment 614
Proposal for a regulation
Article 67 – paragraph 2
Text proposed by the Commission
2.
The provider or other relevant
operators shall ensure that corrective action
is taken in respect of all the AI systems
concerned that they have made available
on the market throughout the Union within
the timeline prescribed by the market
surveillance authority of the Member State
referred to in paragraph 1.

Amendment 615
Proposal for a regulation
Article 67 – paragraph 2 a (new)

Text proposed by the Commission

Amendment 616
Proposal for a regulation
Article 67 – paragraph 3
Text proposed by the Commission
3.
The Member State shall immediately
inform the Commission and the other
Member States. That information shall
include all available details, in particular
the data necessary for the identification of
the AI system concerned, the origin and the
supply chain of the AI system, the nature
of the risk involved and the nature and
duration of the national measures taken.

Amendment 617
Proposal for a regulation
Article 67 – paragraph 4
Text proposed by the Commission
4.
The Commission shall without delay
enter into consultation with the Member
States and the relevant operator and shall
evaluate the national measures taken. On
the basis of the results of that evaluation,
the Commission shall decide whether the
measure is justified or not and, where
necessary, propose appropriate measures.

Amendment 618
Proposal for a regulation
Article 67 – paragraph 5
Text proposed by the Commission
5.
The Commission shall address its
decision to the Member States.

Amendment 619
Proposal for a regulation
Article 67 – paragraph 5 a (new)
Text proposed by the Commission

Amendment 620
Proposal for a regulation
Article 68 – paragraph 1 – introductory part
Text proposed by the Commission
1.
Where the market surveillance
authority of a Member State makes one of
the following findings, it shall require the
relevant provider to put an end to the noncompliance concerned:

Amendment 621
Proposal for a regulation
Article 68 – paragraph 1 – point a
Text proposed by the Commission
(a) the conformity marking has been
affixed in violation of Article 49;

Amendment 622
Proposal for a regulation
Article 68 – paragraph 1 – point b
Text proposed by the Commission
(b) the conformity marking has not been
affixed;

Amendment 623
Proposal for a regulation
Article 68 – paragraph 1 – point e a (new)
Text proposed by the Commission

Amendment 624
Proposal for a regulation
Article 68 – paragraph 1 – point e b (new)
Text proposed by the Commission

Amendment 625
Proposal for a regulation
Article 68 – paragraph 1 – point e c (new)

Text proposed by the Commission

Amendment 626
Proposal for a regulation
Article 68 – paragraph 2
Text proposed by the Commission
2.
Where the non-compliance referred
to in paragraph 1 persists, the Member
State concerned shall take all appropriate
measures to restrict or prohibit the highrisk AI system being made available on the
market or ensure that it is recalled or
withdrawn from the market.

Amendment 627
Proposal for a regulation
Article 68 – Chapter 3a (new)
Text proposed by the Commission

Amendment 628
Proposal for a regulation
Article 68 a (new)
Text proposed by the Commission

Amendment 629
Proposal for a regulation
Article 68 b (new)
Text proposed by the Commission

Amendment 630
Proposal for a regulation
Article 68 c (new)
Text proposed by the Commission

Amendment 631
Proposal for a regulation
Article 68 d (new)
Text proposed by the Commission

Amendment 632
Proposal for a regulation
Article 68 e (new)
Text proposed by the Commission

Amendment 633
Proposal for a regulation
Article 69 – paragraph 1
Text proposed by the Commission
1.
The Commission and the Member
States shall encourage and facilitate the
drawing up of codes of conduct intended to
foster the voluntary application to AI
systems other than high-risk AI systems of
the requirements set out in Title III,
Chapter 2 on the basis of technical
specifications and solutions that are
appropriate means of ensuring compliance
with such requirements in light of the
intended purpose of the systems.

Amendment 634
Proposal for a regulation
Article 69 – paragraph 2
Text proposed by the Commission
2.
The Commission and the Board
shall encourage and facilitate the drawing
up of codes of conduct intended to foster
the voluntary application to AI systems of
requirements related for example to
environmental sustainability, accessibility
for persons with a disability, stakeholders
participation in the design and
development of the AI systems and
diversity of development teams on the
basis of clear objectives and key
performance indicators to measure the
achievement of those objectives.

Amendment 635
Proposal for a regulation
Article 69 – paragraph 3
Text proposed by the Commission
3.

Codes of conduct may be drawn up

by individual providers of AI systems or by
organisations representing them or by both,
including with the involvement of users
and any interested stakeholders and their
representative organisations. Codes of
conduct may cover one or more AI systems
taking into account the similarity of the
intended purpose of the relevant systems.

Amendment 636
Proposal for a regulation
Article 69 – paragraph 4
Text proposed by the Commission
4.
The Commission and the Board shall
take into account the specific interests and
needs of the small-scale providers and
start-ups when encouraging and facilitating
the drawing up of codes of conduct.

Amendment 637
Proposal for a regulation
Article 70 – paragraph 1 – introductory part
Text proposed by the Commission
1.
National competent authorities and
notified bodies involved in the application
of this Regulation shall respect the
confidentiality of information and data
obtained in carrying out their tasks and
activities in such a manner as to protect, in
particular:

Amendment 638

Proposal for a regulation
Article 70 – paragraph 1 – point a
Text proposed by the Commission
(a) intellectual property rights, and
confidential business information or trade
secrets of a natural or legal person,
including source code, except the cases
referred to in Article 5 of Directive
2016/943 on the protection of undisclosed
know-how and business information (trade
secrets) against their unlawful acquisition,
use and disclosure apply.

Amendment 639
Proposal for a regulation
Article 70 – paragraph 1 – point b a (new)
Text proposed by the Commission

Amendment 640
Proposal for a regulation
Article 70 – paragraph 1 a (new)
Text proposed by the Commission

Amendment 641
Proposal for a regulation
Article 70 – paragraph 2 – introductory part
Text proposed by the Commission
2.
Without prejudice to paragraph 1,
information exchanged on a confidential
basis between the national competent
authorities and between national competent
authorities and the Commission shall not
be disclosed without the prior consultation
of the originating national competent
authority and the user when high-risk AI
systems referred to in points 1, 6 and 7 of
Annex III are used by law enforcement,
immigration or asylum authorities, when
such disclosure would jeopardise public
and national security interests.

Amendment 642
Proposal for a regulation
Article 70 – paragraph 3
Text proposed by the Commission
3.
Paragraphs 1 and 2 shall not affect
the rights and obligations of the
Commission, Member States and notified
bodies with regard to the exchange of
information and the dissemination of
warnings, nor the obligations of the parties
concerned to provide information under
criminal law of the Member States.

Amendment 643
Proposal for a regulation
Article 70 – paragraph 4
Text proposed by the Commission
4.

The Commission and Member States

may exchange, where necessary,
confidential information with regulatory
authorities of third countries with which
they have concluded bilateral or
multilateral confidentiality arrangements
guaranteeing an adequate level of
confidentiality.

Amendment 644
Proposal for a regulation
Article 71 – title
Text proposed by the Commission
Penalties and fines

Amendment 645
Proposal for a regulation
Article 71 – paragraph 1
Text proposed by the Commission
1.
In compliance with the terms and
conditions laid down in this Regulation,
Member States shall lay down the rules on
penalties, including administrative fines,
applicable to infringements of this
Regulation and shall take all measures
necessary to ensure that they are properly
and effectively implemented. The penalties
provided for shall be effective,
proportionate, and dissuasive. They shall
take into particular account the interests of
small-scale providers and start-up and
their economic viability.

Amendment 646
Proposal for a regulation
Article 71 – paragraph 2

Text proposed by the Commission
2.
The Member States shall notify the
Commission of those rules and of those
measures and shall notify it, without delay,
of any subsequent amendment affecting
them.

Amendment 647
Proposal for a regulation
Article 71 – paragraph 3 – introductory part
Text proposed by the Commission
3.
The following infringements shall be
subject to administrative fines of up to 30
000 000 EUR or, if the offender is
company, up to 6 % of its total worldwide
annual turnover for the preceding financial
year, whichever is higher:

Amendment 648
Proposal for a regulation
Article 71 – paragraph 3 – point a
Text proposed by the Commission
(a) non-compliance with the prohibition
of the artificial intelligence practices
referred to in Article 5;

Amendment 649
Proposal for a regulation
Article 71 – paragraph 3 – point b
Text proposed by the Commission
(b) non-compliance of the AI system
with the requirements laid down in Article

10.

Amendment 650
Proposal for a regulation
Article 71 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 651
Proposal for a regulation
Article 71 – paragraph 4
Text proposed by the Commission
4.
The non-compliance of the AI
system with any requirements or
obligations under this Regulation, other
than those laid down in Articles 5 and 10,
shall be subject to administrative fines of
up to 20 000 000 EUR or, if the offender is
a company, up to 4 % of its total
worldwide annual turnover for the
preceding financial year, whichever is
higher.

Amendment 652
Proposal for a regulation
Article 71 – paragraph 5
Text proposed by the Commission
5.
The supply of incorrect, incomplete
or misleading information to notified
bodies and national competent authorities
in reply to a request shall be subject to

administrative fines of up to 10 000 000
EUR or, if the offender is a company, up to
2 % of its total worldwide annual turnover
for the preceding financial year, whichever
is higher.

Amendment 653
Proposal for a regulation
Article 71 – paragraph 6 – introductory part
Text proposed by the Commission
6.
When deciding on the amount of the
administrative fine in each individual case,
all relevant circumstances of the specific
situation shall be taken into account and
due regard shall be given to the following:

Amendment 654
Proposal for a regulation
Article 71 – paragraph 6 – point a
Text proposed by the Commission
(a) the nature, gravity and duration of
the infringement and of its consequences;

Amendment 655
Proposal for a regulation
Article 71 – paragraph 6 – point b
Text proposed by the Commission
(b) whether administrative fines have
been already applied by other market
surveillance authorities to the same

operator for the same infringement.

Amendment 656
Proposal for a regulation
Article 71 – paragraph 6 – point c
Text proposed by the Commission
(c) the size and market share of the
operator committing the infringement;

Amendment 657
Proposal for a regulation
Article 71 – paragraph 6 – point c a (new)
Text proposed by the Commission

Amendment 658
Proposal for a regulation
Article 71 – paragraph 6 – point c b (new)
Text proposed by the Commission

Amendment 659
Proposal for a regulation
Article 71 – paragraph 6 – point c c (new)
Text proposed by the Commission

Amendment 660
Proposal for a regulation
Article 71 – paragraph 6 – point c d (new)
Text proposed by the Commission

Amendment 661
Proposal for a regulation
Article 71 – paragraph 6 – point c e (new)
Text proposed by the Commission

Amendment 662
Proposal for a regulation
Article 71 – paragraph 6 – point c f (new)
Text proposed by the Commission

Amendment 663
Proposal for a regulation
Article 71 – paragraph 6 – point c g (new)
Text proposed by the Commission

Amendment 664
Proposal for a regulation
Article 71 – paragraph 6 – point c h (new)
Text proposed by the Commission

Amendment 665
Proposal for a regulation
Article 71 – paragraph 7
Text proposed by the Commission
7.
Each Member State shall lay down
rules on whether and to what extent
administrative fines may be imposed on
public authorities and bodies established in
that Member State.

Amendment 666
Proposal for a regulation
Article 71 – paragraph 8 a (new)
Text proposed by the Commission

Amendment 667

Proposal for a regulation
Article 71 – paragraph 8 b (new)
Text proposed by the Commission

Amendment 668
Proposal for a regulation
Article 71 – paragraph 8 c (new)
Text proposed by the Commission

Amendment 669
Proposal for a regulation
Article 72 – paragraph 1 – point a
Text proposed by the Commission
(a) the nature, gravity and duration of
the infringement and of its consequences;

Amendment 670
Proposal for a regulation
Article 72 – paragraph 1 – point a a (new)

Text proposed by the Commission

Amendment 671
Proposal for a regulation
Article 72 – paragraph 1 – point a b (new)
Text proposed by the Commission

Amendment 672
Proposal for a regulation
Article 72 – paragraph 1 – point b
Text proposed by the Commission
(b) the cooperation with the European
Data Protection Supervisor in order to
remedy the infringement and mitigate the
possible adverse effects of the
infringement, including compliance with
any of the measures previously ordered by
the European Data Protection Supervisor
against the Union institution or agency or
body concerned with regard to the same
subject matter;

Amendment 673
Proposal for a regulation
Article 72 – paragraph 1 – point c a (new)
Text proposed by the Commission

Amendment 674
Proposal for a regulation
Article 72 – paragraph 1 – point c b (new)
Text proposed by the Commission

Amendment 675
Proposal for a regulation
Article 72 – paragraph 2 – introductory part
Text proposed by the Commission
2.
The following infringements shall be
subject to administrative fines of up to 500
000 EUR:

Amendment 676
Proposal for a regulation
Article 72 – paragraph 2 – point a
Text proposed by the Commission
(a) non-compliance with the prohibition
of the artificial intelligence practices
referred to in Article 5;

Amendment 677
Proposal for a regulation
Article 72 – paragraph 2 a (new)

Text proposed by the Commission

Amendment 678
Proposal for a regulation
Article 72 – paragraph 3
Text proposed by the Commission
3.
The non-compliance of the AI
system with any requirements or
obligations under this Regulation, other
than those laid down in Articles 5 and 10,
shall be subject to administrative fines of
up to 250 000 EUR.

Amendment 679
Proposal for a regulation
Article 72 – paragraph 6
Text proposed by the Commission
6.
Funds collected by imposition of
fines in this Article shall be the income of
the general budget of the Union.

Amendment 680
Proposal for a regulation
Article 72 – paragraph 6 a (new)
Text proposed by the Commission

Amendment 681
Proposal for a regulation
Article 73 – paragraph 2
Text proposed by the Commission
2.
The delegation of power referred to
in Article 4, Article 7(1), Article 11(3),
Article 43(5) and (6) and Article 48(5)
shall be conferred on the Commission for
an indeterminate period of time from
[entering into force of the Regulation].

Amendment 682
Proposal for a regulation
Article 73 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 683
Proposal for a regulation
Article 81 a (new)
Text proposed by the Commission

Amendment 684
Proposal for a regulation
Article 82 a (new)
Text proposed by the Commission

Amendment 685
Proposal for a regulation
Article 82 b (new)
Text proposed by the Commission

Amendment 686
Proposal for a regulation
Article 83 – paragraph 1 – introductory part
Text proposed by the Commission
1.
This Regulation shall not apply to
the AI systems which are components of
the large-scale IT systems established by
the legal acts listed in Annex IX that have
been placed on the market or put into
service before [12 months after the date of
application of this Regulation referred to
in Article 85(2)], unless the replacement
or amendment of those legal acts leads to
a significant change in the design or
intended purpose of the AI system or AI
systems concerned.

Amendment 687
Proposal for a regulation
Article 83 – paragraph 1 – subparagraph 1
Text proposed by the Commission
The requirements laid down in this
Regulation shall be taken into account,
where applicable, in the evaluation of each
large-scale IT systems established by the
legal acts listed in Annex IX to be
undertaken as provided for in those
respective acts.

Amendment 688
Proposal for a regulation
Article 83 – paragraph 2

Text proposed by the Commission
2.
This Regulation shall apply to the
high-risk AI systems, other than the ones
referred to in paragraph 1, that have been
placed on the market or put into service
before [date of application of this
Regulation referred to in Article 85(2)],
only if, from that date, those systems are
subject to significant changes in their
design or intended purpose.

Amendment 689
Proposal for a regulation
Article 84 – paragraph 1
Text proposed by the Commission
1.
The Commission shall assess the
need for amendment of the list in Annex III
once a year following the entry into force
of this Regulation.

Amendment 690
Proposal for a regulation
Article 84 – paragraph 2

Text proposed by the Commission
2.
By [three years after the date of
application of this Regulation referred to in
Article 85(2)] and every four years
thereafter, the Commission shall submit a
report on the evaluation and review of this
Regulation to the European Parliament and
to the Council. The reports shall be made
public.

Amendment 691
Proposal for a regulation
Article 84 – paragraph 3 – point a
Text proposed by the Commission
(a) the status of the financial and human
resources of the national competent
authorities in order to effectively perform
the tasks assigned to them under this
Regulation;

Amendment 692
Proposal for a regulation
Article 84 – paragraph 3 – point b a (new)
Text proposed by the Commission

Amendment 693
Proposal for a regulation
Article 84 – paragraph 3 – point b b (new)
Text proposed by the Commission

Amendment 694
Proposal for a regulation
Article 84 – paragraph 3 – point b c (new)
Text proposed by the Commission

Amendment 695
Proposal for a regulation
Article 84 – paragraph 3 – point b d (new)
Text proposed by the Commission

Amendment 696
Proposal for a regulation
Article 84 – paragraph 3 – point b e (new)
Text proposed by the Commission

Amendment 697
Proposal for a regulation
Article 84 – paragraph 3 – point b f (new)
Text proposed by the Commission

Amendment 698
Proposal for a regulation
Article 84 – paragraph 3 – point b g (new)
Text proposed by the Commission

Amendment 699
Proposal for a regulation
Article 84 – paragraph 3 – point b h (new)
Text proposed by the Commission

Amendment 700
Proposal for a regulation
Article 84 – paragraph 3 a (new)
Text proposed by the Commission

Amendment 701
Proposal for a regulation
Article 84 – paragraph 4
Text proposed by the Commission
4.
Within [three years after the date of
application of this Regulation referred to in
Article 85(2)] and every four years
thereafter, the Commission shall evaluate
the impact and effectiveness of codes of
conduct to foster the application of the
requirements set out in Title III, Chapter 2
and possibly other additional requirements
for AI systems other than high-risk AI
systems.

Amendment 702
Proposal for a regulation
Article 84 – paragraph 5
Text proposed by the Commission
5.
For the purpose of paragraphs 1 to 4
the Board, the Member States and national
competent authorities shall provide the
Commission with information on its
request.

Amendment 703
Proposal for a regulation
Article 84 – paragraph 6
Text proposed by the Commission
6.
In carrying out the evaluations and
reviews referred to in paragraphs 1 to 4 the
Commission shall take into account the
positions and findings of the Board, of the
European Parliament, of the Council, and
of other relevant bodies or sources.

Amendment 704
Proposal for a regulation
Article 84 – paragraph 7
Text proposed by the Commission
7.
The Commission shall, if necessary,
submit appropriate proposals to amend this
Regulation, in particular taking into
account developments in technology and in
the light of the state of progress in the
information society.

Amendment 705
Proposal for a regulation
Article 84 – paragraph 7 a (new)
Text proposed by the Commission

Amendment 706
Proposal for a regulation
Article 84 – paragraph 7 b (new)

Text proposed by the Commission

Amendment 707
Proposal for a regulation
Article 84 – paragraph 7 c (new)
Text proposed by the Commission

Amendment 708
Proposal for a regulation
Annex I
Text proposed by the Commission
ARTIFICIAL INTELLIGENCE
TECHNIQUES AND APPROACHES
referred to in Article 3, point 1

(a) Machine learning approaches,
including supervised, unsupervised and
reinforcement learning, using a wide
variety of methods including deep
learning;
(b) Logic- and knowledge-based
approaches, including knowledge
representation, inductive (logic)
programming, knowledge bases, inference
and deductive engines, (symbolic)
reasoning and expert systems;
(c) Statistical approaches, Bayesian
estimation, search and optimization
methods.

Amendment 709
Proposal for a regulation
Annex III – paragraph 1 – introductory part
Text proposed by the Commission
High-risk AI systems pursuant to Article
6(2) are the AI systems listed in any of the
following areas:

Amendment 710

Proposal for a regulation
Annex III – paragraph 1 – point 1 – introduc
Text proposed by the Commission
1.
Biometric identification and
categorisation of natural persons:

Amendment 711
Proposal for a regulation
Annex III – paragraph 1 – point 1 – point a

Text proposed by the Commission
(a) AI systems intended to be used for
the ‘real-time’ and ‘post’ remote biometric
identification of natural persons;

Amendment 712

Proposal for a regulation
Annex III – paragraph 1 – point 1 – point a a
Text proposed by the Commission

Amendment 713
Proposal for a regulation
Annex III – paragraph 1 – point 2 – point a
Text proposed by the Commission
(a) AI systems intended to be used as
safety components in the management and
operation of road traffic and the supply of
water, gas, heating and electricity.

Amendment 714

Proposal for a regulation
Annex III – paragraph 1 – point 2 – point a a

Text proposed by the Commission

Amendment 715
Proposal for a regulation
Annex III – paragraph 1 – point 3 – point a
Text proposed by the Commission
(a) AI systems intended to be used for
the purpose of determining access or
assigning natural persons to educational
and vocational training institutions;

Amendment 716
Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b
Text proposed by the Commission
(b) AI systems intended to be used for
the purpose of assessing students in
educational and vocational training
institutions and for assessing participants in
tests commonly required for admission to
educational institutions.

Amendment 717

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b a
Text proposed by the Commission

Amendment 718

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b b
Text proposed by the Commission

Amendment 719
Proposal for a regulation
Annex III – paragraph 1 – point 4 – point a
Text proposed by the Commission
(a) AI systems intended to be used for
recruitment or selection of natural persons,
notably for advertising vacancies,
screening or filtering applications,
evaluating candidates in the course of
interviews or tests;

Amendment 720
Proposal for a regulation
Annex III – paragraph 1 – point 4 – point b
Text proposed by the Commission
(b) AI intended to be used for making
decisions on promotion and termination of
work-related contractual relationships, for
task allocation and for monitoring and
evaluating performance and behavior of
persons in such relationships.

Amendment 721
Proposal for a regulation
Annex III – paragraph 1 – point 5 – point a
Text proposed by the Commission
(a) AI systems intended to be used by
public authorities or on behalf of public
authorities to evaluate the eligibility of
natural persons for public assistance
benefits and services, as well as to grant,
reduce, revoke, or reclaim such benefits
and services;

Amendment 722
Proposal for a regulation
Annex III – paragraph 1 – point 5 – point b
Text proposed by the Commission
(b) AI systems intended to be used to
evaluate the creditworthiness of natural
persons or establish their credit score, with
the exception of AI systems put into
service by small scale providers for their
own use;

Amendment 723

Proposal for a regulation
Annex III – paragraph 1 – point 5 – point b a
Text proposed by the Commission

Amendment 724
Proposal for a regulation
Annex III – paragraph 1 – point 5 – point c
Text proposed by the Commission
(c) AI systems intended to be used to
dispatch, or to establish priority in the
dispatching of emergency first response
services, including by firefighters and
medical aid.

Amendment 725
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point a
Text proposed by the Commission
(a) AI systems intended to be used by
law enforcement authorities for making
individual risk assessments of natural
persons in order to assess the risk of a
natural person for offending or
reoffending or the risk for potential
victims of criminal offences;

Amendment 726
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point b
Text proposed by the Commission
(b) AI systems intended to be used by
law enforcement authorities as polygraphs
and similar tools or to detect the emotional
state of a natural person;

Amendment 727
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point c
Text proposed by the Commission
(c) AI systems intended to be used by
law enforcement authorities to detect deep
fakes as referred to in article 52(3);

Amendment 728
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point d
Text proposed by the Commission
(d) AI systems intended to be used by
law enforcement authorities for evaluation
of the reliability of evidence in the course
of investigation or prosecution of criminal
offences;

Amendment 729
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point e
Text proposed by the Commission
(e) AI systems intended to be used by
law enforcement authorities for predicting
the occurrence or reoccurrence of an
actual or potential criminal offence based
on profiling of natural persons as referred
to in Article 3(4) of Directive (EU)
2016/680 or assessing personality traits
and characteristics or past criminal
behaviour of natural persons or groups;

Amendment 730

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point f
Text proposed by the Commission
(f) AI systems intended to be used by
law enforcement authorities for profiling of
natural persons as referred to in Article
3(4) of Directive (EU) 2016/680 in the
course of detection, investigation or
prosecution of criminal offences;

Amendment 731
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point g
Text proposed by the Commission
(g) AI systems intended to be used for
crime analytics regarding natural persons,
allowing law enforcement authorities to
search complex related and unrelated large
data sets available in different data sources
or in different data formats in order to
identify unknown patterns or discover
hidden relationships in the data.

Amendment 732
Proposal for a regulation
Annex III – paragraph 1 – point 7 – point a
Text proposed by the Commission
(a) AI systems intended to be used by
competent public authorities as polygraphs
and similar tools or to detect the emotional
state of a natural person;

Amendment 733
Proposal for a regulation
Annex III – paragraph 1 – point 7 – point b
Text proposed by the Commission
(b) AI systems intended to be used by
competent public authorities to assess a
risk, including a security risk, a risk of
irregular immigration, or a health risk,
posed by a natural person who intends to
enter or has entered into the territory of a
Member State;

Amendment 734
Proposal for a regulation
Annex III – paragraph 1 – point 7 – point c
Text proposed by the Commission
(c) AI systems intended to be used by
competent public authorities for the
verification of the authenticity of travel
documents and supporting documentation
of natural persons and detect non-authentic
documents by checking their security
features;

Amendment 735
Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d
Text proposed by the Commission
(d) AI systems intended to assist
competent public authorities for the
examination of applications for asylum,
visa and residence permits and associated
complaints with regard to the eligibility of

the natural persons applying for a status.

Amendment 736

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d a
Text proposed by the Commission

Amendment 737

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d b
Text proposed by the Commission

Amendment 738
Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a
Text proposed by the Commission
(a) AI systems intended to assist a
judicial authority in researching and
interpreting facts and the law and in

applying the law to a concrete set of facts.

Amendment 739

Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a a
Text proposed by the Commission

Amendment 740

Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a b
Text proposed by the Commission

Amendment 741
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point a

Text proposed by the Commission
(a) its intended purpose, the person/s
developing the system the date and the
version of the system;

Amendment 742

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point a a
Text proposed by the Commission

Amendment 743
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point b
Text proposed by the Commission
(b) how the AI system interacts or can
be used to interact with hardware or
software that is not part of the AI system
itself, where applicable;

Amendment 744
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point c
Text proposed by the Commission
(c) the versions of relevant software or
firmware and any requirement related to
version update;

Amendment 745
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point d
Text proposed by the Commission
(d) the description of all forms in which
the AI system is placed on the market or
put into service;

Amendment 746
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point f a
Text proposed by the Commission

Amendment 747
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g
Text proposed by the Commission
(g) instructions of use for the user and,
where applicable installation instructions;

Amendment 748

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g a
Text proposed by the Commission

Amendment 749

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g b
Text proposed by the Commission

Amendment 750
Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g c
Text proposed by the Commission

Amendment 751

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g d
Text proposed by the Commission

Amendment 752
Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point b
Text proposed by the Commission
(b) the design specifications of the
system, namely the general logic of the AI
system and of the algorithms; the key
design choices including the rationale and
assumptions made, also with regard to
persons or groups of persons on which the
system is intended to be used; the main
classification choices; what the system is

designed to optimise for and the relevance
of the different parameters; the decisions
about any possible trade-off made
regarding the technical solutions adopted to
comply with the requirements set out in
Title III, Chapter 2;

Amendment 753
Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point c
Text proposed by the Commission
(c) the description of the system
architecture explaining how software
components build on or feed into each
other and integrate into the overall
processing; the computational resources
used to develop, train, test and validate the
AI system;

Amendment 754
Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point e
Text proposed by the Commission
(e) assessment of the human oversight
measures needed in accordance with
Article 14, including an assessment of the
technical measures needed to facilitate the
interpretation of the outputs of AI systems
by the users, in accordance with Articles
13(3)(d);

Amendment 755
Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point g

Text proposed by the Commission
(g) the validation and testing procedures
used, including information about the
validation and testing data used and their
main characteristics; metrics used to
measure accuracy, robustness,
cybersecurity and compliance with other
relevant requirements set out in Title III,
Chapter 2 as well as potentially
discriminatory impacts; test logs and all
test reports dated and signed by the
responsible persons, including with regard
to pre-determined changes as referred to
under point (f).

Amendment 756

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point g a
Text proposed by the Commission

Amendment 757
Proposal for a regulation
Annex IV – paragraph 1 – point 3
Text proposed by the Commission
3.
Detailed information about the
monitoring, functioning and control of the
AI system, in particular with regard to: its
capabilities and limitations in performance,
including the degrees of accuracy for
specific persons or groups of persons on
which the system is intended to be used
and the overall expected level of accuracy
in relation to its intended purpose; the
foreseeable unintended outcomes and
sources of risks to health and safety,
fundamental rights and discrimination in
view of the intended purpose of the AI
system; the human oversight measures
needed in accordance with Article 14,

including the technical measures put in
place to facilitate the interpretation of the
outputs of AI systems by the users;
specifications on input data, as appropriate;

Amendment 758
Proposal for a regulation
Annex IV – paragraph 1 – point 3 a (new)
Text proposed by the Commission

Amendment 759
Proposal for a regulation
Annex IV – paragraph 1 – point 3 b (new)
Text proposed by the Commission

Amendment 760
Proposal for a regulation
Annex IV – paragraph 1 – point 5
Text proposed by the Commission
5.
A description of any change made to
the system through its lifecycle;

Amendment 761
Proposal for a regulation
Annex IV – paragraph 1 – point 6

Text proposed by the Commission
6.
A list of the harmonised standards
applied in full or in part the references of
which have been published in the Official
Journal of the European Union; where no
such harmonised standards have been
applied, a detailed description of the
solutions adopted to meet the requirements
set out in Title III, Chapter 2, including a
list of other relevant standards and
technical specifications applied;

Amendment 762
Proposal for a regulation
Annex V – paragraph 1 – point 4 a (new)
Text proposed by the Commission

Amendment 763
Proposal for a regulation
Annex V – paragraph 1 – point 7
Text proposed by the Commission
7.
Place and date of issue of the
declaration, name and function of the
person who signed it as well as an
indication for, and on behalf of whom, that
person signed, signature.

Amendment 764
Proposal for a regulation
Annex VII – point 4 – point 4.5

Text proposed by the Commission
4.5. Where necessary to assess the
conformity of the high-risk AI system with
the requirements set out in Title III,
Chapter 2 and upon a reasoned request, the
notified body shall also be granted access
to the source code of the AI system.

Amendment 765
Proposal for a regulation
Annex VIII – paragraph 1
Text proposed by the Commission
The following information shall be
provided and thereafter kept up to date
with regard to high-risk AI systems to be
registered in accordance with Article 51.

Amendment 766
Proposal for a regulation
Annex VIII – point 4 a (new)
Text proposed by the Commission

Amendment 767

Proposal for a regulation
Annex VIII – point 5
Text proposed by the Commission
5.
Description of the intended purpose
of the AI system;

Amendment 768
Proposal for a regulation
Annex VIII – point 5 a (new)
Text proposed by the Commission

Amendment 769
Proposal for a regulation
Annex VIII – point 11
Text proposed by the Commission
11. Electronic instructions for use; this
information shall not be provided for
high-risk AI systems in the areas of law
enforcement and migration, asylum and
border control management referred to in
Annex III, points 1, 6 and 7.

Amendment 770
Proposal for a regulation
ANNEX VIII – SECTION B (new)

Text proposed by the Commission

Amendment 771

Proposal for a regulation
Annex VIII – Section C (new)
Text proposed by the Commission

