European Parliament
2019-2024



                                     TEXTS ADOPTED



P9_TA(2023)0236
Artificial Intelligence Act
Amendments adopted by the European Parliament on 14 June 2023 on the proposal for
a regulation of the European Parliament and of the Council on laying down harmonised
rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union
legislative acts (COM(2021)0206 – C9-0146/2021 – 2021/0106(COD))1

(Ordinary legislative procedure: first reading)




1    The matter was referred back for interinstitutional negotiations to the committee
     responsible, pursuant to Rule 59(4), fourth subparagraph (A9-0188/2023).
Amendment 1

Proposal for a regulation
Citation 4 a (new)

     Text proposed by the Commission                           Amendment

                                               Having regard to the opinion of the
                                               European Central Bank,


Amendment 2

Proposal for a regulation
Citation 4 b (new)

     Text proposed by the Commission                           Amendment

                                               Having regard to the joint opinion of the
                                               European Data Protection Board and the
                                               European Data Protection Supervisor,


Amendment 3

Proposal for a regulation
Recital 1

     Text proposed by the Commission                           Amendment

(1) The purpose of this Regulation is to       (1) The purpose of this Regulation is to
improve the functioning of the internal        promote the uptake of human centric and
market by laying down a uniform legal          trustworthy artificial intelligence and to
framework in particular for the                ensure a high level of protection of
development, marketing and use of              health, safety, fundamental rights,
artificial intelligence in conformity with     democracy and rule of law and the
Union values. This Regulation pursues a        environment from harmful effects of
number of overriding reasons of public         artificial intelligence systems in the Union
interest, such as a high level of protection   while supporting innovation and
of health, safety and fundamental rights,      improving the functioning of the internal
and it ensures the free movement of AI-        market. This Regulation lays down a
based goods and services cross-border,         uniform legal framework in particular for
thus preventing Member States from             the development, the placing on the
imposing restrictions on the development,      market, the putting into service and the
marketing and use of AI systems, unless        use of artificial intelligence in conformity
explicitly authorised by this Regulation.      with Union values and ensures the free
                                               movement of AI-based goods and services
                                               cross-border, thus preventing Member
                                               States from imposing restrictions on the
                                               development, marketing and use of
                                               Artificial Intelligence systems (AI
                                               systems), unless explicitly authorised by
                                               this Regulation. Certain AI systems can
                                               also have an impact on democracy and
                                               rule of law and the environment. These
                                               concerns are specifically addressed in the
                                               critical sectors and use cases listed in the
                                               annexes to this Regulation.


Amendment 4

Proposal for a regulation
Recital 1 a (new)

    Text proposed by the Commission                            Amendment

                                               (1a) This Regulation should preserve the
                                               values of the Union facilitating the
                                               distribution of artificial intelligence
                                               benefits across society, protecting
                                               individuals, companies, democracy and
                                               rule of law and the environment from
                                               risks while boosting innovation and
                                               employment and making the Union a
                                               leader in the field.


Amendment 5

Proposal for a regulation
Recital 2

    Text proposed by the Commission                            Amendment

(2) Artificial intelligence systems (AI        (2) AI systems can be easily deployed in
systems) can be easily deployed in multiple    multiple sectors of the economy and
sectors of the economy and society,            society, including cross border, and
including cross border, and circulate          circulate throughout the Union. Certain
throughout the Union. Certain Member           Member States have already explored the
States have already explored the adoption      adoption of national rules to ensure that
of national rules to ensure that artificial    artificial intelligence is trustworthy and
intelligence is safe and is developed and      safe and is developed and used in
used in compliance with fundamental            compliance with fundamental rights
rights obligations. Differing national rules   obligations. Differing national rules may
may lead to fragmentation of the internal      lead to fragmentation of the internal market
market and decrease legal certainty for        and decrease legal certainty for operators
operators that develop or use AI systems.      that develop or use AI systems. A
A consistent and high level of protection      consistent and high level of protection
throughout the Union should therefore be       throughout the Union should therefore be
ensured, while divergences hampering the       ensured in order to achieve trustworthy
free circulation of AI systems and related     AI, while divergences hampering the free
products and services within the internal      circulation, innovation, deployment and
market should be prevented, by laying          uptake of AI systems and related products
down uniform obligations for operators and     and services within the internal market
guaranteeing the uniform protection of         should be prevented, by laying down
overriding reasons of public interest and of   uniform obligations for operators and
rights of persons throughout the internal      guaranteeing the uniform protection of
market based on Article 114 of the Treaty      overriding reasons of public interest and of
on the Functioning of the European Union       rights of persons throughout the internal
(TFEU). To the extent that this Regulation     market based on Article 114 of the Treaty
contains specific rules on the protection      on the Functioning of the European Union
of individuals with regard to the              (TFEU).
processing of personal data concerning
restrictions of the use of AI systems for
‘real-time’ remote biometric identification
in publicly accessible spaces for the
purpose of law enforcement, it is
appropriate to base this Regulation, in as
far as those specific rules are concerned,
on Article 16 of the TFEU. In light of
those specific rules and the recourse to
Article 16 TFEU, it is appropriate to
consult the European Data Protection
Board.


Amendment 6

Proposal for a regulation
Recital 2 a (new)

    Text proposed by the Commission                            Amendment

                                               (2a) As artificial intelligence often relies
                                               on the processing of large volumes of
                                               data, and many AI systems and
                                               applications on the processing of personal
                                               data, it is appropriate to base this
                                               Regulation on Article 16 TFEU, which
                                               enshrines the right to the protection of
                                               natural persons with regard to the
                                               processing of personal data and provides
                                               for the adoption of rules on the protection
                                               of individuals with regard to the
                                               processing of personal data.
Amendment 7

Proposal for a regulation
Recital 2 b (new)

    Text proposed by the Commission                   Amendment

                                      (2b) The fundamental right to the
                                      protection of personal data is safeguarded
                                      in particular by Regulations (EU)
                                      2016/679 and (EU) 2018/1725 and
                                      Directive 2016/680. Directive 2002/58/EC
                                      additionally protects private life and the
                                      confidentiality of communications,
                                      including providing conditions for any
                                      personal and non-personal data storing in
                                      and access from terminal equipment.
                                      Those legal acts provide the basis for
                                      sustainable and responsible data
                                      processing, including where datasets
                                      include a mix of personal and
                                      nonpersonal data. This Regulation does
                                      not seek to affect the application of
                                      existing Union law governing the
                                      processing of personal data, including the
                                      tasks and powers of the independent
                                      supervisory authorities competent to
                                      monitor compliance with those
                                      instruments. This Regulation does not
                                      affect the fundamental rights to private
                                      life and the protection of personal data as
                                      provided for by Union law on data
                                      protection and privacy and enshrined in
                                      the Charter of Fundamental Rights of the
                                      European Union (the ‘Charter’).


Amendment 8

Proposal for a regulation
Recital 2 c (new)

    Text proposed by the Commission                   Amendment

                                      (2c) Artificial intelligence systems in the
                                      Union are subject to relevant product
                                      safety legislation that provides a
                                      framework protecting consumers against
                                      dangerous products in general and such
                                      legislation should continue to apply. This
                                      Regulation is also without prejudice to the
                                      rules laid down by other Union legal acts
                                      related to consumer protection and
                                      product safety, including including
                                      Regulation (EU) 2017/2394, Regulation
                                      (EU) 2019/1020 and Directive
                                      2001/95/EC on general product safety and
                                      Directive 2013/11/EU.


Amendment 9

Proposal for a regulation
Recital 2 d (new)

    Text proposed by the Commission                   Amendment

                                      (2d) In accordance with Article 114(2)
                                      TFEU, this Regulation complements and
                                      should not undermine the rights and
                                      interests of employed persons. This
                                      Regulation should therefore not affect
                                      Union law on social policy and national
                                      labour law and practice, that is any legal
                                      and contractual provision concerning
                                      employment conditions, working
                                      conditions, including health and safety at
                                      work and the relationship between
                                      employers and workers, including
                                      information, consultation and
                                      participation. This Regulation should not
                                      affect the exercise of fundamental rights
                                      as recognised in the Member States and at
                                      Union level, including the right or
                                      freedom to strike or to take other action
                                      covered by the specific industrial relations
                                      systems in Member States, in accordance
                                      with national law and/or practice. Nor
                                      should it affect concertation practices, the
                                      right to negotiate, to conclude and enforce
                                      collective agreement or to take collective
                                      action in accordance with national law
                                      and/or practice. It should in any event not
                                      prevent the Commission from proposing
                                      specific legislation on the rights and
                                      freedoms of workers affected by AI
                                      systems.


Amendment 10
Proposal for a regulation
Recital 2 e (new)

    Text proposed by the Commission                            Amendment

                                               (2e) This Regulation should not affect
                                               the provisions aiming to improve working
                                               conditions in platform work set out in
                                               Directive ... [COD 2021/414/EC].


Amendment 11

Proposal for a regulation
Recital 2 f (new)

    Text proposed by the Commission                            Amendment

                                               (2f) This Regulation should help in
                                               supporting research and innovation and
                                               should not undermine research and
                                               development activity and respect freedom
                                               of scientific research. It is therefore
                                               necessary to exclude from its scope AI
                                               systems specifically developed for the sole
                                               purpose of scientific research and
                                               development and to ensure that the
                                               Regulation does not otherwise affect
                                               scientific research and development
                                               activity on AI systems. Under all
                                               circumstances, any research and
                                               development activity should be carried out
                                               in accordance with the Charter, Union
                                               law as well as the national law;


Amendment 12

Proposal for a regulation
Recital 3

    Text proposed by the Commission                            Amendment

(3) Artificial intelligence is a fast          (3) Artificial intelligence is a fast
evolving family of technologies that can       evolving family of technologies that can
contribute to a wide array of economic and     and already contributes to a wide array of
societal benefits across the entire spectrum   economic, environmental and societal
of industries and social activities. By        benefits across the entire spectrum of
improving prediction, optimising               industries and social activities if developed
operations and resource allocation, and         in accordance with relevant general
personalising digital solutions available for   principles in line with the Charter and the
individuals and organisations, the use of       values on which the Union is founded. By
artificial intelligence can provide key         improving prediction, optimising
competitive advantages to companies and         operations and resource allocation, and
support socially and environmentally            personalising digital solutions available for
beneficial outcomes, for example in             individuals and organisations, the use of
healthcare, farming, education and training,    artificial intelligence can provide key
infrastructure management, energy,              competitive advantages to companies and
transport and logistics, public services,       support socially and environmentally
security, justice, resource and energy          beneficial outcomes, for example in
efficiency, and climate change mitigation       healthcare, farming, food safety, education
and adaptation.                                 and training, media, sports, culture,
                                                infrastructure management, energy,
                                                transport and logistics, crisis management,
                                                public services, security, justice, resource
                                                and energy efficiency, environmental
                                                monitoring, the conservation and
                                                restoration of biodiversity and ecosystems
                                                and climate change mitigation and
                                                adaptation.


Amendment 13

Proposal for a regulation
Recital 3 a (new)

     Text proposed by the Commission                            Amendment

                                                (3a) To contribute to reaching the
                                                carbon neutrality targets, European
                                                companies should seek to utilise all
                                                available technological advancements that
                                                can assist in realising this goal. Artificial
                                                Intelligence is a technology that has the
                                                potential of being used to process the
                                                ever-growing amount of data created
                                                during industrial, environmental, health
                                                and other processes. To facilitate
                                                investments in AI-based analysis and
                                                optimisation tools, this Regulation should
                                                provide a predictable and proportionate
                                                environment for low-risk industrial
                                                solutions.


Amendment 14
Proposal for a regulation
Recital 4

     Text proposed by the Commission                           Amendment

(4) At the same time, depending on the         (4) At the same time, depending on the
circumstances regarding its specific           circumstances regarding its specific
application and use, artificial intelligence   application and use, as well as the level of
may generate risks and cause harm to           technological development, artificial
public interests and rights that are           intelligence may generate risks and cause
protected by Union law. Such harm might        harm to public or private interests and
be material or immaterial.                     fundamental rights of natural persons that
                                               are protected by Union law. Such harm
                                               might be material or immaterial, including
                                               physical, psychological, societal or
                                               economic harm.


Amendment 15

Proposal for a regulation
Recital 4 a (new)

     Text proposed by the Commission                           Amendment

                                               (4a) Given the major impact that
                                               artificial intelligence can have on society
                                               and the need to build trust, it is vital for
                                               artificial intelligence and its regulatory
                                               framework to be developed according to
                                               Union values enshrined in Article 2 TEU,
                                               the fundamental rights and freedoms
                                               enshrined in the Treaties, the Charter,
                                               and international human rights law. As a
                                               pre-requisite, artificial intelligence should
                                               be a human-centric technology. It should
                                               not substitute human autonomy or
                                               assume the loss of individual freedom and
                                               should primarily serve the needs of the
                                               society and the common good. Safeguards
                                               should be provided to ensure the
                                               development and use of ethically
                                               embedded artificial intelligence that
                                               respects Union values and the Charter.


Amendment 16

Proposal for a regulation
Recital 5
     Text proposed by the Commission                             Amendment

(5) A Union legal framework laying               (5) A Union legal framework laying
down harmonised rules on artificial              down harmonised rules on artificial
intelligence is therefore needed to foster       intelligence is therefore needed to foster
the development, use and uptake of               the development, use and uptake of
artificial intelligence in the internal market   artificial intelligence in the internal market
that at the same time meets a high level of      that at the same time meets a high level of
protection of public interests, such as          protection of public interests, such as
health and safety and the protection of          health and safety, protection of
fundamental rights, as recognised and            fundamental rights, democracy and rule of
protected by Union law. To achieve that          law and the environment, as recognised
objective, rules regulating the placing on       and protected by Union law. To achieve
the market and putting into service of           that objective, rules regulating the placing
certain AI systems should be laid down,          on the market, the putting into service and
thus ensuring the smooth functioning of the      the use of certain AI systems should be
internal market and allowing those systems       laid down, thus ensuring the smooth
to benefit from the principle of free            functioning of the internal market and
movement of goods and services. By               allowing those systems to benefit from the
laying down those rules, this Regulation         principle of free movement of goods and
supports the objective of the Union of           services. These rules should be clear and
being a global leader in the development of      robust in protecting fundamental rights,
secure, trustworthy and ethical artificial       supportive of new innovative solutions,
intelligence, as stated by the European          and enabling to a European ecosystem of
Council33 , and it ensures the protection of     public and private actors creating AI
ethical principles, as specifically requested    systems in line with Union values. By
by the European Parliament34 .                   laying down those rules as well as
                                                 measures in support of innovation with a
                                                 particular focus on SMEs and start-ups,
                                                 this Regulation supports the objective of
                                                 promoting the AI made in Europe, of the
                                                 Union of being a global leader in the
                                                 development of secure, trustworthy and
                                                 ethical artificial intelligence, as stated by
                                                 the European Council33, and it ensures the
                                                 protection of ethical principles, as
                                                 specifically requested by the European
                                                 Parliament34.
__________________                               __________________
33 European Council, Special meeting of          33 European Council, Special meeting of

the European Council (1 and 2 October            the European Council (1 and 2 October
2020) – Conclusions, EUCO 13/20, 2020,           2020) – Conclusions, EUCO 13/20, 2020,
p. 6.                                            p. 6.
34 European Parliament resolution of 20          34 European Parliament resolution of 20

October 2020 with recommendations to the         October 2020 with recommendations to the
Commission on a framework of ethical             Commission on a framework of ethical
aspects of artificial intelligence, robotics     aspects of artificial intelligence, robotics
and related technologies, 2020/2012(INL).        and related technologies, 2020/2012(INL).
Amendment 17

Proposal for a regulation
Recital 5 a (new)

    Text proposed by the Commission                            Amendment

                                              (5a) Furthermore, in order to foster the
                                              development of AI systems in line with
                                              Union values, the Union needs to address
                                              the main gaps and barriers blocking the
                                              potential of the digital transformation
                                              including the shortage of digitally skilled
                                              workers, cybersecurity concerns, lack of
                                              investment and access to investment, and
                                              existing and potential gaps between large
                                              companies, SME’s and start-ups. Special
                                              attention should be paid to ensuring that
                                              the benefits of AI and innovation in new
                                              technologies are felt across all regions of
                                              the Union and that sufficient investment
                                              and resources are provided especially to
                                              those regions that may be lagging behind
                                              in some digital indicators.


Amendment 18

Proposal for a regulation
Recital 6

    Text proposed by the Commission                            Amendment

(6) The notion of AI system should be         (6) The notion of AI system in this
clearly defined to ensure legal certainty,    Regulation should be clearly defined and
while providing the flexibility to            closely aligned with the work of
accommodate future technological              international organisations working on
developments. The definition should be        artificial intelligence to ensure legal
based on the key functional characteristics   certainty, harmonization and wide
of the software, in particular the ability,   acceptance, while providing the flexibility
for a given set of human-defined              to accommodate the rapid technological
objectives, to generate outputs such as       developments in this field. Moreover, it
content, predictions, recommendations, or     should be based on key characteristics of
decisions which influence the                 artificial intelligence, such as its learning,
environment with which the system             reasoning or modelling capabilities, so as
interacts, be it in a physical or digital     to distinguish it from simpler software
dimension. AI systems can be designed to      systems or programming approaches. AI
operate with varying levels of autonomy       systems are designed to operate with
and be used on a stand-alone basis or as a   varying levels of autonomy, meaning that
component of a product, irrespective of      they have at least some degree of
whether the system is physically             independence of actions from human
integrated into the product (embedded) or    controls and of capabilities to operate
serve the functionality of the product       without human intervention. The term
without being integrated therein (non-       “machine-based” refers to the fact that AI
embedded). The definition of AI system       systems run on machines. The reference
should be complemented by a list of          to explicit or implicit objectives
specific techniques and approaches used      underscores that AI systems can operate
for its development, which should be kept    according to explicit human-defined
up-to–date in the light of market and        objectives or to implicit objectives. The
technological developments through the       objectives of the AI system may be
adoption of delegated acts by the            different from the intended purpose of the
Commission to amend that list.               AI system in a specific context. The
                                             reference to predictions includes content,
                                             which is considered in this Regulation a
                                             form of prediction as one of the possible
                                             outputs produced by an AI system. For
                                             the purposes of this Regulation,
                                             environments should be understood as the
                                             contexts in which the AI systems operate,
                                             whereas outputs generated by the AI
                                             system, meaning predictions,
                                             recommendations or decisions, respond to
                                             the objectives of the system, on the basis
                                             of inputs from said environment. Such
                                             output further influences said
                                             environment, even by merely introducing
                                             new information to it.


Amendment 19

Proposal for a regulation
Recital 6 a (new)

    Text proposed by the Commission                         Amendment

                                             (6a) AI systems often have machine
                                             learning capacities that allow them to
                                             adapt and perform new tasks
                                             autonomously. Machine learning refers to
                                             the computational process of optimizing
                                             the parameters of a model from data,
                                             which is a mathematical construct
                                             generating an output based on input data.
                                             Machine learning approaches include, for
                                             instance, supervised, unsupervised and
                                             reinforcement learning, using a variety of
                                             methods including deep learning with
                                      neural networks. This Regulation is
                                      aimed at addressing new potential risks
                                      that may arise by delegating control to AI
                                      systems, in particular to those AI systems
                                      that can evolve after deployment. The
                                      function and outputs of many of these AI
                                      systems are based on abstract
                                      mathematical relationships that are
                                      difficult for humans to understand,
                                      monitor and trace back to specific inputs.
                                      These complex and opaque characteristics
                                      (black box element) impact accountability
                                      and explainability. Comparably simpler
                                      techniques such as knowledge-based
                                      approaches, Bayesian estimation or
                                      decision-trees may also lead to legal gaps
                                      that need to be addressed by this
                                      Regulation, in particular when they are
                                      used in combination with machine
                                      learning approaches in hybrid systems.


Amendment 20

Proposal for a regulation
Recital 6 b (new)

    Text proposed by the Commission                  Amendment

                                      (6b) AI systems can be used as stand-
                                      alone software system, integrated into a
                                      physical product (embedded), used to
                                      serve the functionality of a physical
                                      product without being integrated therein
                                      (non-embedded) or used as an AI
                                      component of a larger system. If this
                                      larger system would not function without
                                      the AI component in question, then the
                                      entire larger system should be considered
                                      as one single AI system under this
                                      Regulation.


Amendment 21

Proposal for a regulation
Recital 7
    Text proposed by the Commission                          Amendment

(7) The notion of biometric data used in      (7) The notion of biometric data used in
this Regulation is in line with and should    this Regulation is in line with and should
be interpreted consistently with the notion   be interpreted consistently with the notion
of biometric data as defined in Article       of biometric data as defined in Article
4(14) of Regulation (EU) 2016/679 of the      4(14) of Regulation (EU) 2016/679 of the
European Parliament and of the Council35 ,    European Parliament and of the Council35.
Article 3(18) of Regulation (EU)              Biometrics-based data are additional data
2018/1725 of the European Parliament          resulting from specific technical
and of the Council36 and Article 3(13) of     processing relating to physical,
Directive (EU) 2016/680 of the European       physiological or behavioural signals of a
Parliament and of the Council37 .             natural person, such as facial
                                              expressions, movements, pulse frequency,
                                              voice, key strikes or gait, which may or
                                              may not allow or confirm the unique
                                              identification of a natural person.
__________________                            __________________
35 Regulation (EU) 2016/679 of the            35 Regulation (EU) 2016/679 of the

European Parliament and of the Council of     European Parliament and of the Council of
27 April 2016 on the protection of natural    27 April 2016 on the protection of natural
persons with regard to the processing of      persons with regard to the processing of
personal data and on the free movement of     personal data and on the free movement of
such data, and repealing Directive            such data, and repealing Directive
95/46/EC (General Data Protection             95/46/EC (General Data Protection
Regulation) (OJ L 119, 4.5.2016, p. 1).       Regulation) (OJ L 119, 4.5.2016, p. 1).
36 Regulation (EU) 2018/1725 of the

European Parliament and of the Council
of 23 October 2018 on the protection of
natural persons with regard to the
processing of personal data by the Union
institutions, bodies, offices and agencies
and on the free movement of such data,
and repealing Regulation (EC) No
45/2001 and Decision No 1247/2002/EC
(OJ L 295, 21.11.2018, p. 39)
37 Directive (EU) 2016/680 of the

European Parliament and of the Council
of 27 April 2016 on the protection of
natural persons with regard to the
processing of personal data by competent
authorities for the purposes of the
prevention, investigation, detection or
prosecution of criminal offences or the
execution of criminal penalties, and on
the free movement of such data, and
repealing Council Framework Decision
2008/977/JHA (Law Enforcement
Directive) (OJ L 119, 4.5.2016, p. 89).


Amendment 22

Proposal for a regulation
Recital 7 a (new)

    Text proposed by the Commission                       Amendment

                                          (7a) The notion of biometric
                                          identification as used in this Regulation
                                          should be defined as the automated
                                          recognition of physical, physiological,
                                          behavioural, and psychological human
                                          features such as the face, eye movement,
                                          facial expressions, body shape, voice,
                                          speech, gait, posture, heart rate, blood
                                          pressure, odour, keystrokes, psychological
                                          reactions (anger, distress, grief, etc.) for
                                          the purpose of establishing an
                                          individual’s identity by comparing
                                          biometric data of that individual to stored
                                          biometric data of individuals in a
                                          database (one-to-many identification),
                                          irrespective of whether the individual has
                                          given its consent or not.


Amendment 23

Proposal for a regulation
Recital 7 b (new)

    Text proposed by the Commission                       Amendment

                                          (7b) The notion of biometric
                                          categorisation as used in this Regulation
                                          should be defined as assigning natural
                                          persons to specific categories or inferring
                                          their characteristics and attributes such as
                                          gender, sex, age, hair colour, eye colour,
                                          tattoos, ethnic or social origin, health,
                                          mental or physical ability, behavioural or
                                          personality, traits language, religion, or
                                          membership of a national minority or
                                          sexual or political orientation on the basis
                                          of their biometric or biometric-based data,
                                          or which can be inferred from such data.
Amendment 24

Proposal for a regulation
Recital 8

     Text proposed by the Commission                            Amendment

(8) The notion of remote biometric              (8) The notion of remote biometric
identification system as used in this           identification system as used in this
Regulation should be defined functionally,      Regulation should be defined functionally,
as an AI system intended for the                as an AI system intended for the
identification of natural persons at a          identification of natural persons at a
distance through the comparison of a            distance through the comparison of a
person’s biometric data with the biometric      person’s biometric data with the biometric
data contained in a reference database, and     data contained in a reference database, and
without prior knowledge whether the             without prior knowledge whether the
targeted person will be present and can be      targeted person will be present and can be
identified, irrespectively of the particular    identified, irrespectively of the particular
technology, processes or types of biometric     technology, processes or types of biometric
data used. Considering their different          data used, exlcuding verification systems
characteristics and manners in which they       which merely compare the biometric data
are used, as well as the different risks        of an individual to their previously
involved, a distinction should be made          provided biometric data (one-to-one).
between ‘real-time’ and ‘post’ remote           Considering their different characteristics
biometric identification systems. In the        and manners in which they are used, as
case of ‘real-time’ systems, the capturing      well as the different risks involved, a
of the biometric data, the comparison and       distinction should be made between ‘real-
the identification occur all instantaneously,   time’ and ‘post’ remote biometric
near-instantaneously or in any event            identification systems. In the case of ‘real-
without a significant delay. In this regard,    time’ systems, the capturing of the
there should be no scope for circumventing      biometric data, the comparison and the
the rules of this Regulation on the ‘real-      identification occur all instantaneously,
time’ use of the AI systems in question by      near-instantaneously or in any event
providing for minor delays. ‘Real-time’         without a significant delay. In this regard,
systems involve the use of ‘live’ or ‘near-     there should be no scope for circumventing
‘live’ material, such as video footage,         the rules of this Regulation on the ‘real-
generated by a camera or other device with      time’ use of the AI systems in question by
similar functionality. In the case of ‘post’    providing for minor delays. ‘Real-time’
systems, in contrast, the biometric data        systems involve the use of ‘live’ or ‘near-
have already been captured and the              ‘live’ material, such as video footage,
comparison and identification occur only        generated by a camera or other device with
after a significant delay. This involves        similar functionality. In the case of ‘post’
material, such as pictures or video footage     systems, in contrast, the biometric data
generated by closed circuit television          have already been captured and the
cameras or private devices, which has been      comparison and identification occur only
generated before the use of the system in       after a significant delay. This involves
respect of the natural persons concerned.       material, such as pictures or video footage
                                                generated by closed circuit television
                                                cameras or private devices, which has been
                                                 generated before the use of the system in
                                                 respect of the natural persons concerned.
                                                 Given that the notion of biometric
                                                 identification is independent from the
                                                 individual’s consent, this definition
                                                 applies even when warning notices are
                                                 placed in the location that is under
                                                 surveillance of the remote biometric
                                                 identification system, and is not de facto
                                                 annulled by pre-enrolment.


Amendment 25

Proposal for a regulation
Recital 8 a (new)

     Text proposed by the Commission                             Amendment

                                                 (8a) The identification of natural
                                                 persons at a distance is understood to
                                                 distinguish remote biometric
                                                 identification systems from close
                                                 proximity individual verification systems
                                                 using biometric identification means,
                                                 whose sole purpose is to confirm whether
                                                 or not a specific natural person
                                                 presenting themselves for identification is
                                                 permitted, such as in order to gain access
                                                 to a service, a device, or premises.


Amendment 26

Proposal for a regulation
Recital 9

     Text proposed by the Commission                             Amendment

(9) For the purposes of this Regulation          (9) For the purposes of this Regulation
the notion of publicly accessible space          the notion of publicly accessible space
should be understood as referring to any         should be understood as referring to any
physical place that is accessible to the         physical place that is accessible to the
public, irrespective of whether the place in     public, irrespective of whether the place in
question is privately or publicly owned.         question is privately or publicly owned and
Therefore, the notion does not cover places      regardless of the potential capacity
that are private in nature and normally not      restrictions. Therefore, the notion does not
freely accessible for third parties, including   cover places that are private in nature and
law enforcement authorities, unless those        normally not freely accessible for third
parties have been specifically invited or        parties, including law enforcement
authorised, such as homes, private clubs,       authorities, unless those parties have been
offices, warehouses and factories. Online       specifically invited or authorised, such as
spaces are not covered either, as they are      homes, private clubs, offices, warehouses
not physical spaces. However, the mere          and factories. Online spaces are not
fact that certain conditions for accessing a    covered either, as they are not physical
particular space may apply, such as             spaces. However, the mere fact that certain
admission tickets or age restrictions, does     conditions for accessing a particular space
not mean that the space is not publicly         may apply, such as admission tickets or
accessible within the meaning of this           age restrictions, does not mean that the
Regulation. Consequently, in addition to        space is not publicly accessible within the
public spaces such as streets, relevant parts   meaning of this Regulation. Consequently,
of government buildings and most                in addition to public spaces such as streets,
transport infrastructure, spaces such as        relevant parts of government buildings and
cinemas, theatres, shops and shopping           most transport infrastructure, spaces such
centres are normally also publicly              as cinemas, theatres, sports grounds,
accessible. Whether a given space is            schools, universities, relevant parts of
accessible to the public should however be      hospitals and banks, amusement parks,
determined on a case-by-case basis, having      festivals, shops and shopping centres are
regard to the specificities of the individual   normally also publicly accessible. Whether
situation at hand.                              a given space is accessible to the public
                                                should however be determined on a case-
                                                by-case basis, having regard to the
                                                specificities of the individual situation at
                                                hand.


Amendment 27

Proposal for a regulation
Recital 9 a (new)

     Text proposed by the Commission                            Amendment

                                                (9a) It is important to note that AI
                                                systems should make best efforts to
                                                respect general principles establishing a
                                                high-level framework that promotes a
                                                coherent human-centric approach to
                                                ethical and trustworthy AI in line with the
                                                Charter of Fundamental Rights of the
                                                European Union and the values on which
                                                the Union is founded, including the
                                                protection of fundamental rights, human
                                                agency and oversight, technical
                                                robustness and safety, privacy and data
                                                governance, transparency, non-
                                                discrimination and fairness and societal
                                                and environmental wellbeing.
Amendment 28

Proposal for a regulation
Recital 9 b (new)

    Text proposed by the Commission                           Amendment

                                               (9b) ‘AI literacy’ refers to skills,
                                               knowledge and understanding that allows
                                               providers, users and affected persons,
                                               taking into account their respective rights
                                               and obligations in the context of this
                                               Regulation, to make an informed
                                               deployment of AI systems, as well as to
                                               gain awareness about the opportunities
                                               and risks of AI and possible harm it can
                                               cause and thereby promote its democratic
                                               control. AI literacy should not be limited
                                               to learning about tools and technologies,
                                               but should also aim to equip providers
                                               and users with the notions and skills
                                               required to ensure compliance with and
                                               enforcement of this Regulation. It is
                                               therefore necessary that the Commission,
                                               the Member States as well as providers
                                               and users of AI systems, in cooperation
                                               with all relevant stakeholders, promote
                                               the development of a sufficient level of AI
                                               literacy, in all sectors of society, for
                                               people of all ages, including women and
                                               girls, and that progress in that regard is
                                               closely followed.


Amendment 29

Proposal for a regulation
Recital 10

    Text proposed by the Commission                           Amendment

(10) In order to ensure a level playing        (10) In order to ensure a level playing
field and an effective protection of rights    field and an effective protection of rights
and freedoms of individuals across the         and freedoms of individuals across the
Union, the rules established by this           Union and on international level, the rules
Regulation should apply to providers of AI     established by this Regulation should apply
systems in a non-discriminatory manner,        to providers of AI systems in a non-
irrespective of whether they are established   discriminatory manner, irrespective of
within the Union or in a third country, and    whether they are established within the
to users of AI systems established within      Union or in a third country, and to
the Union.                                       deployers of AI systems established within
                                                 the Union. In order for the Union to be
                                                 true to its fundamental values, AI systems
                                                 intended to be used for practices that are
                                                 considered unacceptable by this
                                                 Regulation, should equally be deemed to
                                                 be unacceptable outside the Union
                                                 because of their particularly harmful
                                                 effect to fundamental rights as enshrined
                                                 in the Charter. Therefore it is appropriate
                                                 to prohibit the export of such AI systems
                                                 to third countries by providers residing in
                                                 the Union.


Amendment 30

Proposal for a regulation
Recital 11

     Text proposed by the Commission                             Amendment

(11) In light of their digital nature, certain   (11) In light of their digital nature, certain
AI systems should fall within the scope of       AI systems should fall within the scope of
this Regulation even when they are neither       this Regulation even when they are neither
placed on the market, nor put into service,      placed on the market, nor put into service,
nor used in the Union. This is the case for      nor used in the Union. This is the case for
example of an operator established in the        example of an operator established in the
Union that contracts certain services to an      Union that contracts certain services to an
operator established outside the Union in        operator established outside the Union in
relation to an activity to be performed by       relation to an activity to be performed by
an AI system that would qualify as high-         an AI system that would qualify as high-
risk and whose effects impact natural            risk and whose effects impact natural
persons located in the Union. In those           persons located in the Union. In those
circumstances, the AI system used by the         circumstances, the AI system used by the
operator outside the Union could process         operator outside the Union could process
data lawfully collected in and transferred       data lawfully collected in and transferred
from the Union, and provide to the               from the Union, and provide to the
contracting operator in the Union the            contracting operator in the Union the
output of that AI system resulting from that     output of that AI system resulting from that
processing, without that AI system being         processing, without that AI system being
placed on the market, put into service or        placed on the market, put into service or
used in the Union. To prevent the                used in the Union. To prevent the
circumvention of this Regulation and to          circumvention of this Regulation and to
ensure an effective protection of natural        ensure an effective protection of natural
persons located in the Union, this               persons located in the Union, this
Regulation should also apply to providers        Regulation should also apply to providers
and users of AI systems that are established     and users deployers of AI systems that are
in a third country, to the extent the output     established in a third country, to the extent
produced by those systems is used in the         the output produced by those systems is
Union. Nonetheless, to take into account      intended to be used in the Union.
existing arrangements and special needs for   Nonetheless, to take into account existing
cooperation with foreign partners with        arrangements and special needs for
whom information and evidence is              cooperation with foreign partners with
exchanged, this Regulation should not         whom information and evidence is
apply to public authorities of a third        exchanged, this Regulation should not
country and international organisations       apply to public authorities of a third
when acting in the framework of               country and international organisations
international agreements concluded at         when acting in the framework of
national or European level for law            international agreements concluded at
enforcement and judicial cooperation with     national or European level for law
the Union or with its Member States. Such     enforcement and judicial cooperation with
agreements have been concluded                the Union or with its Member States. Such
bilaterally between Member States and         agreements have been concluded
third countries or between the European       bilaterally between Member States and
Union, Europol and other EU agencies and      third countries or between the European
third countries and international             Union, Europol and other EU agencies and
organisations.                                third countries and international
                                              organisations. This exception should
                                              nevertheless be limited to trusted
                                              countries and international organisation
                                              that share Union values.


Amendment 31

Proposal for a regulation
Recital 12

    Text proposed by the Commission                          Amendment

(12) This Regulation should also apply to     (12) This Regulation should also apply to
Union institutions, offices, bodies and       Union institutions, offices, bodies and
agencies when acting as a provider or user    agencies when acting as a provider or
of an AI system. AI systems exclusively       deployer of an AI system. AI systems
developed or used for military purposes       exclusively developed or used for military
should be excluded from the scope of this     purposes should be excluded from the
Regulation where that use falls under the     scope of this Regulation where that use
exclusive remit of the Common Foreign         falls under the exclusive remit of the
and Security Policy regulated under Title V   Common Foreign and Security Policy
of the Treaty on the European Union           regulated under Title V of the Treaty on
(TEU). This Regulation should be without      the European Union (TEU). This
prejudice to the provisions regarding the     Regulation should be without prejudice to
liability of intermediary service providers   the provisions regarding the liability of
set out in Directive 2000/31/EC of the        intermediary service providers set out in
European Parliament and of the Council        Directive 2000/31/EC of the European
[as amended by the Digital Services Act].     Parliament and of the Council [as amended
                                              by the Digital Services Act].
Amendment 32

Proposal for a regulation
Recital 12 a (new)

    Text proposed by the Commission                   Amendment

                                      (12a) Software and data that are openly
                                      shared and where users can freely access,
                                      use, modify and redistribute them or
                                      modified versions thereof, can contribute
                                      to research and innovation in the market.
                                      Research by the Commission also shows
                                      that free and open-source software can
                                      contribute between EUR 65 billion to
                                      EUR 95 billion to the European Union’s
                                      GDP and that it can provide significant
                                      growth opportunities for the European
                                      economy. Users are allowed to run, copy,
                                      distribute, study, change and improve
                                      software and data, including models by
                                      way of free and open-source licences. To
                                      foster the development and deployment of
                                      AI, especially by SMEs, start-ups,
                                      academic research but also by individuals,
                                      this Regulation should not apply to such
                                      free and open-source AI components
                                      except to the extent that they are placed
                                      on the market or put into service by a
                                      provider as part of a high-risk AI system
                                      or of an AI system that falls under Title II
                                      or IV of this Regulation.


Amendment 33

Proposal for a regulation
Recital 12 b (new)

    Text proposed by the Commission                   Amendment

                                      (12b) Neither the collaborative
                                      development of free and open-source AI
                                      components nor making them available
                                      on open repositories should constitute a
                                      placing on the market or putting into
                                      service. A commercial activity, within the
                                      understanding of making available on the
                                      market, might however be characterised
                                      by charging a price, with the exception of
                                               transactions between micro enterprises,
                                               for a free and open-source AI component
                                               but also by charging a price for technical
                                               support services, by providing a software
                                               platform through which the provider
                                               monetises other services, or by the use of
                                               personal data for reasons other than
                                               exclusively for improving the security,
                                               compatibility or interoperability of the
                                               software.


Amendment 34

Proposal for a regulation
Recital 12 c (new)

    Text proposed by the Commission                            Amendment

                                               (12c) The developers of free and open-
                                               source AI components should not be
                                               mandated under this Regulation to
                                               comply with requirements targeting the AI
                                               value chain and, in particular, not
                                               towards the provider that has used that
                                               free and open-source AI component.
                                               Developers of free and open-source AI
                                               components should however be
                                               encouraged to implement widely adopted
                                               documentation practices, such as model
                                               and data cards, as a way to accelerate
                                               information sharing along the AI value
                                               chain, allowing the promotion of
                                               trustworthy AI systems in the Union.


Amendment 35

Proposal for a regulation
Recital 13

    Text proposed by the Commission                            Amendment

(13) In order to ensure a consistent and       (13) In order to ensure a consistent and
high level of protection of public interests   high level of protection of public interests
as regards health, safety and fundamental      as regards health, safety and fundamental
rights, common normative standards for all     rights as well as democracy and rule of
high-risk AI systems should be established.    law and the environment, common
Those standards should be consistent with      normative standards for all high-risk AI
the Charter of fundamental rights of the       systems should be established. Those
European Union (the Charter) and should          standards should be consistent with the
be non-discriminatory and in line with the       Charter, the European Green Deal, the
Union’s international trade commitments.         Joint Declaration on Digital Rights of the
                                                 Union and the Ethics Guidelines for
                                                 Trustworthy Artificial Intelligence (AI) of
                                                 the High-Level Expert Group on Artificial
                                                 Intelligence, and should be non-
                                                 discriminatory and in line with the Union’s
                                                 international trade commitments.


Amendment 36

Proposal for a regulation
Recital 14

     Text proposed by the Commission                             Amendment

(14) In order to introduce a proportionate       (14) In order to introduce a proportionate
and effective set of binding rules for AI        and effective set of binding rules for AI
systems, a clearly defined risk-based            systems, a clearly defined risk-based
approach should be followed. That                approach should be followed. That
approach should tailor the type and content      approach should tailor the type and content
of such rules to the intensity and scope of      of such rules to the intensity and scope of
the risks that AI systems can generate. It is    the risks that AI systems can generate. It is
therefore necessary to prohibit certain          therefore necessary to prohibit certain
artificial intelligence practices, to lay down   unacceptable artificial intelligence
requirements for high-risk AI systems and        practices, to lay down requirements for
obligations for the relevant operators, and      high-risk AI systems and obligations for
to lay down transparency obligations for         the relevant operators, and to lay down
certain AI systems.                              transparency obligations for certain AI
                                                 systems


Amendment 37

Proposal for a regulation
Recital 15

     Text proposed by the Commission                             Amendment

(15) Aside from the many beneficial uses         (15) Aside from the many beneficial uses
of artificial intelligence, that technology      of artificial intelligence, that technology
can also be misused and provide novel and        can also be misused and provide novel and
powerful tools for manipulative,                 powerful tools for manipulative,
exploitative and social control practices.       exploitative and social control practices.
Such practices are particularly harmful and      Such practices are particularly harmful and
should be prohibited because they                abusive and should be prohibited because
contradict Union values of respect for           they contradict Union values of respect for
human dignity, freedom, equality,                human dignity, freedom, equality,
democracy and the rule of law and Union       democracy and the rule of law and Union
fundamental rights, including the right to    fundamental rights, including the right to
non-discrimination, data protection and       non-discrimination, data protection and
privacy and the rights of the child.          privacy and the rights of the child.


Amendment 38

Proposal for a regulation
Recital 16

    Text proposed by the Commission                           Amendment

(16) The placing on the market, putting       (16) The placing on the market, putting
into service or use of certain AI systems     into service or use of certain AI systems
intended to distort human behaviour,          with the objective to or the effect of
whereby physical or psychological harms       materially distorting human behaviour,
are likely to occur, should be forbidden.     whereby physical or psychological harms
Such AI systems deploy subliminal             are likely to occur, should be forbidden.
components individuals cannot perceive or     This limitation should be understood to
exploit vulnerabilities of children and       include neuro-technologies assisted by AI
people due to their age, physical or mental   systems that are used to monitor, use, or
incapacities. They do so with the intention   influence neural data gathered through
to materially distort the behaviour of a      brain-computer interfaces insofar as they
person and in a manner that causes or is      are materially distorting the behaviour of
likely to cause harm to that or another       a natural person in a manner that causes
person. The intention may not be presumed     or is likely to cause that person or another
if the distortion of human behaviour          person significant harm. Such AI systems
results from factors external to the AI       deploy subliminal components individuals
system which are outside of the control of    cannot perceive or exploit vulnerabilities of
the provider or the user. Research for        individuals and specific groups of persons
legitimate purposes in relation to such AI    due to their known or predicted
systems should not be stifled by the          personality traits, age, physical or mental
prohibition, if such research does not        incapacities, social or economic situation.
amount to use of the AI system in human-      They do so with the intention to or the
machine relations that exposes natural        effect of materially distorting the
persons to harm and such research is          behaviour of a person and in a manner that
carried out in accordance with recognised     causes or is likely to cause significant
ethical standards for scientific research.    harm to that or another person or groups of
                                              persons, including harms that may be
                                              accumulated over time. The intention to
                                              distort the behaviour may not be presumed
                                              if the distortion results from factors
                                              external to the AI system which are outside
                                              of the control of the provider or the user,
                                              such as factors that may not be
                                              reasonably foreseen and mitigated by the
                                              provider or the deployer of the AI system.
                                              In any case, it is not necessary for the
                                              provider or the deployer to have the
                                      intention to cause the significant harm, as
                                      long as such harm results from the
                                      manipulative or exploitative AI-enabled
                                      practices. The prohibitions for such AI
                                      practices is complementary to the
                                      provisions contained in Directive
                                      2005/29/EC, according to which unfair
                                      commercial practices are prohibited,
                                      irrespective of whether they carried out
                                      having recourse to AI systems or
                                      otherwise. In such setting, lawful
                                      commercial practices, for example in the
                                      field of advertising, that are in compliance
                                      with Union law should not in themselves
                                      be regarded as violating prohibition.
                                      Research for legitimate purposes in relation
                                      to such AI systems should not be stifled by
                                      the prohibition, if such research does not
                                      amount to use of the AI system in human-
                                      machine relations that exposes natural
                                      persons to harm and such research is
                                      carried out in accordance with recognised
                                      ethical standards for scientific research and
                                      on the basis of specific informed consent
                                      of the individuals that are exposed to them
                                      or, where applicable, of their legal
                                      guardian.


Amendment 39

Proposal for a regulation
Recital 16 a (new)

    Text proposed by the Commission                   Amendment

                                      (16a) AI systems that categorise natural
                                      persons by assigning them to specific
                                      categories, according to known or
                                      inferred sensitive or protected
                                      characteristics are particularly intrusive,
                                      violate human dignity and hold great risk
                                      of discrimination. Such characteristics
                                      include gender, gender identity, race,
                                      ethnic origin, migration or citizenship
                                      status, political orientation, sexual
                                      orientation, religion, disability or any
                                      other grounds on which discrimination is
                                      prohibited under Article 21 of the Charter
                                      of Fundamental Rights of the European
                                                Union, as well as under Article 9 of
                                                Regulation (EU)2016/769. Such systems
                                                should therefore be prohibited.


Amendment 40

Proposal for a regulation
Recital 17

     Text proposed by the Commission                            Amendment

(17) AI systems providing social scoring        (17) AI systems providing social scoring
of natural persons for general purpose by       of natural persons for general purpose may
public authorities or on their behalf may       lead to discriminatory outcomes and the
lead to discriminatory outcomes and the         exclusion of certain groups. They violate
exclusion of certain groups. They may           the right to dignity and non-discrimination
violate the right to dignity and non-           and the values of equality and justice. Such
discrimination and the values of equality       AI systems evaluate or classify natural
and justice. Such AI systems evaluate or        persons or groups based on multiple data
classify the trustworthiness of natural         points and time occurrences related to
persons based on their social behaviour in      their social behaviour in multiple contexts
multiple contexts or known or predicted         or known, inferred or predicted personal or
personal or personality characteristics. The    personality characteristics. The social score
social score obtained from such AI systems      obtained from such AI systems may lead to
may lead to the detrimental or                  the detrimental or unfavourable treatment
unfavourable treatment of natural persons       of natural persons or whole groups thereof
or whole groups thereof in social contexts,     in social contexts, which are unrelated to
which are unrelated to the context in which     the context in which the data was originally
the data was originally generated or            generated or collected or to a detrimental
collected or to a detrimental treatment that    treatment that is disproportionate or
is disproportionate or unjustified to the       unjustified to the gravity of their social
gravity of their social behaviour. Such AI      behaviour. Such AI systems should be
systems should be therefore prohibited.         therefore prohibited.


Amendment 41

Proposal for a regulation
Recital 18

     Text proposed by the Commission                            Amendment

(18) The use of AI systems for ‘real-time’      (18) The use of AI systems for ‘real-time’
remote biometric identification of natural      remote biometric identification of natural
persons in publicly accessible spaces for       persons in publicly accessible spaces is
the purpose of law enforcement is               particularly intrusive to the rights and
considered particularly intrusive in the        freedoms of the concerned persons, and
rights and freedoms of the concerned            can ultimately affect the private life of a
persons, to the extent that it may affect the   large part of the population, evoke a
private life of a large part of the          feeling of constant surveillance, give
population, evoke a feeling of constant      parties deploying biometric identification
surveillance and indirectly dissuade the     in publicly accessible spaces a position of
exercise of the freedom of assembly and      uncontrollable power and indirectly
other fundamental rights. In addition, the   dissuade the exercise of the freedom of
immediacy of the impact and the limited      assembly and other fundamental rights at
opportunities for further checks or          the core to the Rule of Law. Technical
corrections in relation to the use of such   inaccuracies of AI systems intended for
systems operating in ‘real-time’ carry       the remote biometric identification of
heightened risks for the rights and          natural persons can lead to biased results
freedoms of the persons that are concerned   and entail discriminatory effects. This is
by law enforcement activities.               particularly relevant when it comes to age,
                                             ethnicity, sex or disabilities. In addition,
                                             the immediacy of the impact and the
                                             limited opportunities for further checks or
                                             corrections in relation to the use of such
                                             systems operating in ‘real-time’ carry
                                             heightened risks for the rights and
                                             freedoms of the persons that are concerned
                                             by law enforcement activities. The use of
                                             those systems in publicly accessible places
                                             should therefore be prohibited. Similarly,
                                             AI systems used for the analysis of
                                             recorded footage of publicly accessible
                                             spaces through ‘post’ remote biometric
                                             identification systems should also be
                                             prohibited, unless there is pre-judicial
                                             authorisation for use in the context of law
                                             enforcement, when strictly necessary for
                                             the targeted search connected to a specific
                                             serious criminal offense that already took
                                             place, and only subject to a pre-judicial
                                             authorisation.


Amendment 42

Proposal for a regulation
Recital 19

    Text proposed by the Commission                          Amendment

(19) The use of those systems for the        deleted
purpose of law enforcement should
therefore be prohibited, except in three
exhaustively listed and narrowly defined
situations, where the use is strictly
necessary to achieve a substantial public
interest, the importance of which
outweighs the risks. Those situations
involve the search for potential victims of
crime, including missing children; certain
threats to the life or physical safety of
natural persons or of a terrorist attack;
and the detection, localisation,
identification or prosecution of
perpetrators or suspects of the criminal
offences referred to in Council
Framework Decision 2002/584/JHA38 if
those criminal offences are punishable in
the Member State concerned by a
custodial sentence or a detention order for
a maximum period of at least three years
and as they are defined in the law of that
Member State. Such threshold for the
custodial sentence or detention order in
accordance with national law contributes
to ensure that the offence should be
serious enough to potentially justify the
use of ‘real-time’ remote biometric
identification systems. Moreover, of the 32
criminal offences listed in the Council
Framework Decision 2002/584/JHA,
some are in practice likely to be more
relevant than others, in that the recourse
to ‘real-time’ remote biometric
identification will foreseeably be
necessary and proportionate to highly
varying degrees for the practical pursuit
of the detection, localisation,
identification or prosecution of a
perpetrator or suspect of the different
criminal offences listed and having regard
to the likely differences in the seriousness,
probability and scale of the harm or
possible negative consequences.
__________________
38 Council Framework Decision

2002/584/JHA of 13 June 2002 on the
European arrest warrant and the
surrender procedures between Member
States (OJ L 190, 18.7.2002, p. 1).


Amendment 43

Proposal for a regulation
Recital 20
    Text proposed by the Commission                      Amendment

(20) In order to ensure that those systems     deleted
are used in a responsible and
proportionate manner, it is also important
to establish that, in each of those three
exhaustively listed and narrowly defined
situations, certain elements should be
taken into account, in particular as
regards the nature of the situation giving
rise to the request and the consequences
of the use for the rights and freedoms of
all persons concerned and the safeguards
and conditions provided for with the use.
In addition, the use of ‘real-time’ remote
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement should be subject to
appropriate limits in time and space,
having regard in particular to the
evidence or indications regarding the
threats, the victims or perpetrator. The
reference database of persons should be
appropriate for each use case in each of
the three situations mentioned above.


Amendment 44

Proposal for a regulation
Recital 21

    Text proposed by the Commission                      Amendment

(21) Each use of a ‘real-time’ remote          deleted
biometric identification system in publicly
accessible spaces for the purpose of law
enforcement should be subject to an
express and specific authorisation by a
judicial authority or by an independent
administrative authority of a Member
State. Such authorisation should in
principle be obtained prior to the use,
except in duly justified situations of
urgency, that is, situations where the need
to use the systems in question is such as to
make it effectively and objectively
impossible to obtain an authorisation
before commencing the use. In such
situations of urgency, the use should be
restricted to the absolute minimum
necessary and be subject to appropriate
safeguards and conditions, as determined
in national law and specified in the
context of each individual urgent use case
by the law enforcement authority itself. In
addition, the law enforcement authority
should in such situations seek to obtain
an authorisation as soon as possible,
whilst providing the reasons for not
having been able to request it earlier.


Amendment 45

Proposal for a regulation
Recital 22

     Text proposed by the Commission                     Amendment

(22) Furthermore, it is appropriate to         deleted
provide, within the exhaustive framework
set by this Regulation that such use in the
territory of a Member State in accordance
with this Regulation should only be
possible where and in as far as the
Member State in question has decided to
expressly provide for the possibility to
authorise such use in its detailed rules of
national law. Consequently, Member
States remain free under this Regulation
not to provide for such a possibility at all
or to only provide for such a possibility in
respect of some of the objectives capable
of justifying authorised use identified in
this Regulation.


Amendment 46

Proposal for a regulation
Recital 23

     Text proposed by the Commission                     Amendment

(23) The use of AI systems for ‘real-time’     deleted
remote biometric identification of natural
persons in publicly accessible spaces for
the purpose of law enforcement
necessarily involves the processing of
biometric data. The rules of this
Regulation that prohibit, subject to
certain exceptions, such use, which are
based on Article 16 TFEU, should apply
as lex specialis in respect of the rules on
the processing of biometric data contained
in Article 10 of Directive (EU) 2016/680,
thus regulating such use and the
processing of biometric data involved in
an exhaustive manner. Therefore, such
use and processing should only be
possible in as far as it is compatible with
the framework set by this Regulation,
without there being scope, outside that
framework, for the competent authorities,
where they act for purpose of law
enforcement, to use such systems and
process such data in connection thereto
on the grounds listed in Article 10 of
Directive (EU) 2016/680. In this context,
this Regulation is not intended to provide
the legal basis for the processing of
personal data under Article 8 of Directive
2016/680. However, the use of ‘real-time’
remote biometric identification systems in
publicly accessible spaces for purposes
other than law enforcement, including by
competent authorities, should not be
covered by the specific framework
regarding such use for the purpose of law
enforcement set by this Regulation. Such
use for purposes other than law
enforcement should therefore not be
subject to the requirement of an
authorisation under this Regulation and
the applicable detailed rules of national
law that may give effect to it.


Amendment 47

Proposal for a regulation
Recital 24

    Text proposed by the Commission                          Amendment

(24) Any processing of biometric data and     (24) Any processing of biometric data and
other personal data involved in the use of    other personal data involved in the use of
AI systems for biometric identification,      AI systems for biometric identification,
other than in connection to the use of ‘real-     other than in connection to the use of ‘real-
time’ remote biometric identification             time’ remote biometric identification
systems in publicly accessible spaces for         systems in publicly accessible spaces as
the purpose of law enforcement as                 regulated by this Regulation should
regulated by this Regulation, including           continue to comply with all requirements
where those systems are used by                   resulting from Article 9(1) of Regulation
competent authorities in publicly                 (EU) 2016/679, Article 10(1) of Regulation
accessible spaces for other purposes than         (EU) 2018/1725 and Article 10 of
law enforcement, should continue to               Directive (EU) 2016/680, as applicable.
comply with all requirements resulting
from Article 9(1) of Regulation (EU)
2016/679, Article 10(1) of Regulation (EU)
2018/1725 and Article 10 of Directive
(EU) 2016/680, as applicable.


Amendment 48

Proposal for a regulation
Recital 25

     Text proposed by the Commission                              Amendment

(25) In accordance with Article 6a of             (25) In accordance with Article 6a of
Protocol No 21 on the position of the             Protocol No 21 on the position of the
United Kingdom and Ireland in respect of          United Kingdom and Ireland in respect of
the area of freedom, security and justice, as     the area of freedom, security and justice, as
annexed to the TEU and to the TFEU,               annexed to the TEU and to the TFEU,
Ireland is not bound by the rules laid down       Ireland is not bound by the rules laid down
in Article 5(1), point (d), (2) and (3) of this   in Article 5(1), point (d), of this Regulation
Regulation adopted on the basis of Article        adopted on the basis of Article 16 of the
16 of the TFEU which relate to the                TFEU which relate to the processing of
processing of personal data by the Member         personal data by the Member States when
States when carrying out activities falling       carrying out activities falling within the
within the scope of Chapter 4 or Chapter 5        scope of Chapter 4 or Chapter 5 of Title V
of Title V of Part Three of the TFEU,             of Part Three of the TFEU, where Ireland
where Ireland is not bound by the rules           is not bound by the rules governing the
governing the forms of judicial cooperation       forms of judicial cooperation in criminal
in criminal matters or police cooperation         matters or police cooperation which require
which require compliance with the                 compliance with the provisions laid down
provisions laid down on the basis of Article      on the basis of Article 16 of the TFEU.
16 of the TFEU.


Amendment 49

Proposal for a regulation
Recital 26
     Text proposed by the Commission                              Amendment

(26) In accordance with Articles 2 and 2a         (26) In accordance with Articles 2 and 2a
of Protocol No 22 on the position of              of Protocol No 22 on the position of
Denmark, annexed to the TEU and TFEU,             Denmark, annexed to the TEU and TFEU,
Denmark is not bound by rules laid down           Denmark is not bound by rules laid down
in Article 5(1), point (d), (2) and (3) of this   in Article 5(1), point (d) of this Regulation
Regulation adopted on the basis of Article        adopted on the basis of Article 16 of the
16 of the TFEU, or subject to their               TFEU, or subject to their application,
application, which relate to the processing       which relate to the processing of personal
of personal data by the Member States             data by the Member States when carrying
when carrying out activities falling within       out activities falling within the scope of
the scope of Chapter 4 or Chapter 5 of Title      Chapter 4 or Chapter 5 of Title V of Part
V of Part Three of the TFEU.                      Three of the TFEU.


Amendment 50

Proposal for a regulation
Recital 26 a (new)

     Text proposed by the Commission                              Amendment

                                                  (26a) AI systems used by law enforcement
                                                  authorities or on their behalf to make
                                                  predictions, profiles or risk assessments
                                                  based on profiling of natural persons or
                                                  data analysis based on personality traits
                                                  and characteristics, including the
                                                  person’s location, or past criminal
                                                  behaviour of natural persons or groups of
                                                  persons for the purpose of predicting the
                                                  occurrence or reoccurrence of an actual
                                                  or potential criminal offence(s) or other
                                                  criminalised social behaviour or
                                                  administrative offences, including fraud-
                                                  predicition systems, hold a particular risk
                                                  of discrimination against certain persons
                                                  or groups of persons, as they violate
                                                  human dignity as well as the key legal
                                                  principle of presumption of innocence.
                                                  Such AI systems should therefore be
                                                  prohibited.


Amendment 51

Proposal for a regulation
Recital 26 b (new)
    Text proposed by the Commission                   Amendment

                                      (26b) The indiscriminate and untargeted
                                      scraping of biometric data from social
                                      media or CCTV footage to create or
                                      expand facial recognition databases add
                                      to the feeling of mass surveillance and
                                      can lead to gross violations of
                                      fundamental rights, including the right to
                                      privacy. The use of AI systems with this
                                      intended purpose should therefore be
                                      prohibited.


Amendment 52

Proposal for a regulation
Recital 26 c (new)

    Text proposed by the Commission                   Amendment

                                      (26c) There are serious concerns about
                                      the scientific basis of AI systems aiming to
                                      detect emotions, physical or physiological
                                      features such as facial expressions,
                                      movements, pulse frequency or voice.
                                      Emotions or expressions of emotions and
                                      perceptions thereof vary considerably
                                      across cultures and situations, and even
                                      within a single individual. Among the key
                                      shortcomings of such technologies, are
                                      the limited reliability (emotion categories
                                      are neither reliably expressed through,
                                      nor unequivocally associated with, a
                                      common set of physical or physiological
                                      movements), the lack of specificity
                                      (physical or physiological expressions do
                                      not perfectly match emotion categories)
                                      and the limited generalisability (the
                                      effects of context and culture are not
                                      sufficiently considered). Reliability issues
                                      and consequently, major risks for abuse,
                                      may especially arise when deploying the
                                      system in real-life situations related to law
                                      enforcement, border management,
                                      workplace and education institutions.
                                      Therefore, the placing on the market,
                                      putting into service, or use of AI systems
                                      intended to be used in these contexts to
                                               detect the emotional state of individuals
                                               should be prohibited.


Amendment 53

Proposal for a regulation
Recital 26 d (new)

    Text proposed by the Commission                            Amendment

                                               (26d) Practices that are prohibited by
                                               Union legislation, including data
                                               protection law, non-discrimination law,
                                               consumer protection law, and competition
                                               law, should not be affected by this
                                               Regulation


Amendment 54

Proposal for a regulation
Recital 27

    Text proposed by the Commission                            Amendment

(27) High-risk AI systems should only be       (27) High-risk AI systems should only be
placed on the Union market or put into         placed on the Union market, put into
service if they comply with certain            service or used if they comply with certain
mandatory requirements. Those                  mandatory requirements. Those
requirements should ensure that high-risk      requirements should ensure that high-risk
AI systems available in the Union or whose     AI systems available in the Union or whose
output is otherwise used in the Union do       output is otherwise used in the Union do
not pose unacceptable risks to important       not pose unacceptable risks to important
Union public interests as recognised and       Union public interests as recognised and
protected by Union law. AI systems             protected by Union law, including
identified as high-risk should be limited to   fundamental rights, democracy, the rule
those that have a significant harmful          or law or the environment. In order to
impact on the health, safety and               ensure alignment with sectoral legislation
fundamental rights of persons in the Union     and avoid duplications, requirements for
and such limitation minimises any potential    high-risk AI systems should take into
restriction to international trade, if any.    account sectoral legislation laying down
                                               requirements for high-risk AI systems
                                               included in the scope of this Regulation,
                                               such as Regulation (EU) 2017/745 on
                                               Medical Devices and Regulation (EU)
                                               2017/746 on In Vitro Diagnostic Devices
                                               or Directive 2006/42/EC on Machinery.
                                               AI systems identified as high-risk should
                                               be limited to those that have a significant
                                                harmful impact on the health, safety and
                                                fundamental rights of persons in the Union
                                                and such limitation minimises any potential
                                                restriction to international trade, if any.
                                                Given the rapid pace of technological
                                                development, as well as the potential
                                                changes in the use of AI systems, the list
                                                of high-risk areas and use-cases in Annex
                                                III should nonetheless be subject to
                                                permanent review through the exercise of
                                                regular assessment.


Amendment 55

Proposal for a regulation
Recital 28

     Text proposed by the Commission                            Amendment

(28) AI systems could produce adverse           (28) AI systems could have an adverse
outcomes to health and safety of persons,       impact to health and safety of persons, in
in particular when such systems operate as      particular when such systems operate as
components of products. Consistently with       safety components of products.
the objectives of Union harmonisation           Consistently with the objectives of Union
legislation to facilitate the free movement     harmonisation legislation to facilitate the
of products in the internal market and to       free movement of products in the internal
ensure that only safe and otherwise             market and to ensure that only safe and
compliant products find their way into the      otherwise compliant products find their
market, it is important that the safety risks   way into the market, it is important that the
that may be generated by a product as a         safety risks that may be generated by a
whole due to its digital components,            product as a whole due to its digital
including AI systems, are duly prevented        components, including AI systems, are
and mitigated. For instance, increasingly       duly prevented and mitigated. For instance,
autonomous robots, whether in the context       increasingly autonomous robots, whether
of manufacturing or personal assistance         in the context of manufacturing or personal
and care should be able to safely operate       assistance and care should be able to safely
and performs their functions in complex         operate and performs their functions in
environments. Similarly, in the health          complex environments. Similarly, in the
sector where the stakes for life and health     health sector where the stakes for life and
are particularly high, increasingly             health are particularly high, increasingly
sophisticated diagnostics systems and           sophisticated diagnostics systems and
systems supporting human decisions              systems supporting human decisions
should be reliable and accurate. The extent     should be reliable and accurate.
of the adverse impact caused by the AI
system on the fundamental rights
protected by the Charter is of particular
relevance when classifying an AI system
as high-risk. Those rights include the
right to human dignity, respect for private
and family life, protection of personal
data, freedom of expression and
information, freedom of assembly and of
association, and non-discrimination,
consumer protection, workers’ rights,
rights of persons with disabilities, right to
an effective remedy and to a fair trial,
right of defence and the presumption of
innocence, right to good administration.
In addition to those rights, it is important
to highlight that children have specific
rights as enshrined in Article 24 of the
EU Charter and in the United Nations
Convention on the Rights of the Child
(further elaborated in the UNCRC
General Comment No. 25 as regards the
digital environment), both of which
require consideration of the children’s
vulnerabilities and provision of such
protection and care as necessary for their
well-being. The fundamental right to a
high level of environmental protection
enshrined in the Charter and
implemented in Union policies should
also be considered when assessing the
severity of the harm that an AI system can
cause, including in relation to the health
and safety of persons.


Amendment 56

Proposal for a regulation
Recital 28 a (new)

     Text proposed by the Commission                            Amendment

                                                (28a) The extent of the adverse impact
                                                caused by the AI system on the
                                                fundamental rights protected by the
                                                Charter is of particular relevance when
                                                classifying an AI system as high-risk.
                                                Those rights include the right to human
                                                dignity, respect for private and family life,
                                                protection of personal data, freedom of
                                                expression and information, freedom of
                                                assembly and of association, and non-
                                                discrimination, right to education
                                                consumer protection, workers’ rights,
                                                rights of persons with disabilities, gender
                                              equality, intellectual property rights, right
                                              to an effective remedy and to a fair trial,
                                              right of defence and the presumption of
                                              innocence, right to good administration.
                                              In addition to those rights, it is important
                                              to highlight that children have specific
                                              rights as enshrined in Article 24 of the
                                              EU Charter and in the United Nations
                                              Convention on the Rights of the Child
                                              (further elaborated in the UNCRC
                                              General Comment No. 25 as regards the
                                              digital environment), both of which
                                              require consideration of the children’s
                                              vulnerabilities and provision of such
                                              protection and care as necessary for their
                                              well-being. The fundamental right to a
                                              high level of environmental protection
                                              enshrined in the Charter and
                                              implemented in Union policies should
                                              also be considered when assessing the
                                              severity of the harm that an AI system can
                                              cause, including in relation to the health
                                              and safety of persons or to the
                                              environment.


Amendment 57

Proposal for a regulation
Recital 29

    Text proposed by the Commission                           Amendment

(29) As regards high-risk AI systems that     (29) As regards high-risk AI systems that
are safety components of products or          are safety components of products or
systems, or which are themselves products     systems, or which are themselves products
or systems falling within the scope of        or systems falling within the scope of
Regulation (EC) No 300/2008 of the            Regulation (EC) No 300/2008 of the
European Parliament and of the Council39 ,    European Parliament and of the Council39 ,
Regulation (EU) No 167/2013 of the            Regulation (EU) No 167/2013 of the
European Parliament and of the Council40 ,    European Parliament and of the Council40 ,
Regulation (EU) No 168/2013 of the            Regulation (EU) No 168/2013 of the
European Parliament and of the Council41 ,    European Parliament and of the Council41 ,
Directive 2014/90/EU of the European          Directive 2014/90/EU of the European
Parliament and of the Council42 , Directive   Parliament and of the Council42 , Directive
(EU) 2016/797 of the European Parliament      (EU) 2016/797 of the European Parliament
and of the Council43 , Regulation (EU)        and of the Council43 , Regulation (EU)
2018/858 of the European Parliament and       2018/858 of the European Parliament and
of the Council44 , Regulation (EU)            of the Council44 , Regulation (EU)
2018/1139 of the European Parliament and      2018/1139 of the European Parliament and
of the Council45 , and Regulation (EU)          of the Council45 , and Regulation (EU)
2019/2144 of the European Parliament and        2019/2144 of the European Parliament and
of the Council46 , it is appropriate to amend   of the Council46 , it is appropriate to amend
those acts to ensure that the Commission        those acts to ensure that the Commission
takes into account, on the basis of the         takes into account, on the basis of the
technical and regulatory specificities of       technical and regulatory specificities of
each sector, and without interfering with       each sector, and without interfering with
existing governance, conformity                 existing governance, conformity
assessment and enforcement mechanisms           assessment, market surveillance and
and authorities established therein, the        enforcement mechanisms and authorities
mandatory requirements for high-risk AI         established therein, the mandatory
systems laid down in this Regulation when       requirements for high-risk AI systems laid
adopting any relevant future delegated or       down in this Regulation when adopting any
implementing acts on the basis of those         relevant future delegated or implementing
acts.                                           acts on the basis of those acts.
__________________                              __________________
39 Regulation (EC) No 300/2008 of the           39 Regulation (EC) No 300/2008 of the

European Parliament and of the Council of       European Parliament and of the Council of
11 March 2008 on common rules in the            11 March 2008 on common rules in the
field of civil aviation security and            field of civil aviation security and
repealing Regulation (EC) No 2320/2002          repealing Regulation (EC) No 2320/2002
(OJ L 97, 9.4.2008, p. 72).                     (OJ L 97, 9.4.2008, p. 72).
40 Regulation (EU) No 167/2013 of the           40 Regulation (EU) No 167/2013 of the

European Parliament and of the Council of       European Parliament and of the Council of
5 February 2013 on the approval and             5 February 2013 on the approval and
market surveillance of agricultural and         market surveillance of agricultural and
forestry vehicles (OJ L 60, 2.3.2013, p. 1).    forestry vehicles (OJ L 60, 2.3.2013, p. 1).
41 Regulation (EU) No 168/2013 of the           41 Regulation (EU) No 168/2013 of the

European Parliament and of the Council of       European Parliament and of the Council of
15 January 2013 on the approval and             15 January 2013 on the approval and
market surveillance of two- or three-wheel      market surveillance of two- or three-wheel
vehicles and quadricycles (OJ L 60,             vehicles and quadricycles (OJ L 60,
2.3.2013, p. 52).                               2.3.2013, p. 52).
42 Directive 2014/90/EU of the European         42 Directive 2014/90/EU of the European

Parliament and of the Council of 23 July        Parliament and of the Council of 23 July
2014 on marine equipment and repealing          2014 on marine equipment and repealing
Council Directive 96/98/EC (OJ L 257,           Council Directive 96/98/EC (OJ L 257,
28.8.2014, p. 146).                             28.8.2014, p. 146).
43 Directive (EU) 2016/797 of the               43 Directive (EU) 2016/797 of the

European Parliament and of the Council of       European Parliament and of the Council of
11 May 2016 on the interoperability of the      11 May 2016 on the interoperability of the
rail system within the European Union (OJ       rail system within the European Union (OJ
L 138, 26.5.2016, p. 44).                       L 138, 26.5.2016, p. 44).
44 Regulation (EU) 2018/858 of the              44 Regulation (EU) 2018/858 of the

European Parliament and of the Council of       European Parliament and of the Council of
30 May 2018 on the approval and market          30 May 2018 on the approval and market
surveillance of motor vehicles and their        surveillance of motor vehicles and their
trailers, and of systems, components and        trailers, and of systems, components and
separate technical units intended for such      separate technical units intended for such
vehicles, amending Regulations (EC) No          vehicles, amending Regulations (EC) No
715/2007 and (EC) No 595/2009 and               715/2007 and (EC) No 595/2009 and
repealing Directive 2007/46/EC (OJ L 151,       repealing Directive 2007/46/EC (OJ L 151,
14.6.2018, p. 1).                               14.6.2018, p. 1).
45 Regulation (EU) 2018/1139 of the             45 Regulation (EU) 2018/1139 of the

European Parliament and of the Council of       European Parliament and of the Council of
4 July 2018 on common rules in the field        4 July 2018 on common rules in the field
of civil aviation and establishing a            of civil aviation and establishing a
European Union Aviation Safety Agency,          European Union Aviation Safety Agency,
and amending Regulations (EC) No                and amending Regulations (EC) No
2111/2005, (EC) No 1008/2008, (EU) No           2111/2005, (EC) No 1008/2008, (EU) No
996/2010, (EU) No 376/2014 and                  996/2010, (EU) No 376/2014 and
Directives 2014/30/EU and 2014/53/EU of         Directives 2014/30/EU and 2014/53/EU of
the European Parliament and of the              the European Parliament and of the
Council, and repealing Regulations (EC)         Council, and repealing Regulations (EC)
No 552/2004 and (EC) No 216/2008 of the         No 552/2004 and (EC) No 216/2008 of the
European Parliament and of the Council          European Parliament and of the Council
and Council Regulation (EEC) No 3922/91         and Council Regulation (EEC) No 3922/91
(OJ L 212, 22.8.2018, p. 1).                    (OJ L 212, 22.8.2018, p. 1).
46 Regulation (EU) 2019/2144 of the             46 Regulation (EU) 2019/2144 of the

European Parliament and of the Council of       European Parliament and of the Council of
27 November 2019 on type-approval               27 November 2019 on type-approval
requirements for motor vehicles and their       requirements for motor vehicles and their
trailers, and systems, components and           trailers, and systems, components and
separate technical units intended for such      separate technical units intended for such
vehicles, as regards their general safety and   vehicles, as regards their general safety and
the protection of vehicle occupants and         the protection of vehicle occupants and
vulnerable road users, amending                 vulnerable road users, amending
Regulation (EU) 2018/858 of the European        Regulation (EU) 2018/858 of the European
Parliament and of the Council and               Parliament and of the Council and
repealing Regulations (EC) No 78/2009,          repealing Regulations (EC) No 78/2009,
(EC) No 79/2009 and (EC) No 661/2009 of         (EC) No 79/2009 and (EC) No 661/2009 of
the European Parliament and of the              the European Parliament and of the
Council and Commission Regulations (EC)         Council and Commission Regulations (EC)
No 631/2009, (EU) No 406/2010, (EU) No          No 631/2009, (EU) No 406/2010, (EU) No
672/2010, (EU) No 1003/2010, (EU) No            672/2010, (EU) No 1003/2010, (EU) No
1005/2010, (EU) No 1008/2010, (EU) No           1005/2010, (EU) No 1008/2010, (EU) No
1009/2010, (EU) No 19/2011, (EU) No             1009/2010, (EU) No 19/2011, (EU) No
109/2011, (EU) No 458/2011, (EU) No             109/2011, (EU) No 458/2011, (EU) No
65/2012, (EU) No 130/2012, (EU) No              65/2012, (EU) No 130/2012, (EU) No
347/2012, (EU) No 351/2012, (EU) No             347/2012, (EU) No 351/2012, (EU) No
1230/2012 and (EU) 2015/166 (OJ L 325,          1230/2012 and (EU) 2015/166 (OJ L 325,
16.12.2019, p. 1).                              16.12.2019, p. 1).


Amendment 58
Proposal for a regulation
Recital 30

    Text proposed by the Commission                            Amendment

(30) As regards AI systems that are safety     (30) As regards AI systems that are safety
components of products, or which are           components of products, or which are
themselves products, falling within the        themselves products, falling within the
scope of certain Union harmonisation           scope of certain Union harmonisation law
legislation, it is appropriate to classify     listed in Annex II, it is appropriate to
them as high-risk under this Regulation if     classify them as high-risk under this
the product in question undergoes the          Regulation if the product in question
conformity assessment procedure with a         undergoes the conformity assessment
third-party conformity assessment body         procedure in order to ensure compliance
pursuant to that relevant Union                with essential safety requirements with a
harmonisation legislation. In particular,      third-party conformity assessment body
such products are machinery, toys, lifts,      pursuant to that relevant Union
equipment and protective systems intended      harmonisation law. In particular, such
for use in potentially explosive               products are machinery, toys, lifts,
atmospheres, radio equipment, pressure         equipment and protective systems intended
equipment, recreational craft equipment,       for use in potentially explosive
cableway installations, appliances burning     atmospheres, radio equipment, pressure
gaseous fuels, medical devices, and in vitro   equipment, recreational craft equipment,
diagnostic medical devices.                    cableway installations, appliances burning
                                               gaseous fuels, medical devices, and in vitro
                                               diagnostic medical devices.


Amendment 59

Proposal for a regulation
Recital 31

    Text proposed by the Commission                            Amendment

(31) The classification of an AI system as     (31) The classification of an AI system as
high-risk pursuant to this Regulation          high-risk pursuant to this Regulation
should not necessarily mean that the           should not mean that the product whose
product whose safety component is the AI       safety component is the AI system, or the
system, or the AI system itself as a           AI system itself as a product, is considered
product, is considered ‘high-risk’ under the   ‘high-risk’ under the criteria established in
criteria established in the relevant Union     the relevant Union harmonisation law that
harmonisation legislation that applies to      applies to the product. This is notably the
the product. This is notably the case for      case for Regulation (EU) 2017/745 of the
Regulation (EU) 2017/745 of the European       European Parliament and of the Council47
Parliament and of the Council47 and            and Regulation (EU) 2017/746 of the
Regulation (EU) 2017/746 of the European       European Parliament and of the Council48 ,
Parliament and of the Council48 , where a      where a third-party conformity assessment
third-party conformity assessment is           is provided for medium-risk and high-risk
provided for medium-risk and high-risk         products.
products.
__________________                                __________________
47 Regulation (EU) 2017/745 of the                47 Regulation (EU) 2017/745 of the

European Parliament and of the Council of         European Parliament and of the Council of
5 April 2017 on medical devices, amending         5 April 2017 on medical devices, amending
Directive 2001/83/EC, Regulation (EC) No          Directive 2001/83/EC, Regulation (EC) No
178/2002 and Regulation (EC) No                   178/2002 and Regulation (EC) No
1223/2009 and repealing Council                   1223/2009 and repealing Council
Directives 90/385/EEC and 93/42/EEC (OJ           Directives 90/385/EEC and 93/42/EEC (OJ
L 117, 5.5.2017, p. 1).                           L 117, 5.5.2017, p. 1).
48 Regulation (EU) 2017/746 of the                48 Regulation (EU) 2017/746 of the

European Parliament and of the Council of         European Parliament and of the Council of
5 April 2017 on in vitro diagnostic medical       5 April 2017 on in vitro diagnostic medical
devices and repealing Directive 98/79/EC          devices and repealing Directive 98/79/EC
and Commission Decision 2010/227/EU               and Commission Decision 2010/227/EU
(OJ L 117, 5.5.2017, p. 176).                     (OJ L 117, 5.5.2017, p. 176).


Amendment 60

Proposal for a regulation
Recital 32

     Text proposed by the Commission                              Amendment

(32) As regards stand-alone AI systems,           (32) As regards stand-alone AI systems,
meaning high-risk AI systems other than           meaning high-risk AI systems other than
those that are safety components of               those that are safety components of
products, or which are themselves                 products, or which are themselves products
products, it is appropriate to classify them      and that are listed in one of the areas and
as high-risk if, in the light of their intended   use cases in Annex III, it is appropriate to
purpose, they pose a high risk of harm to         classify them as high-risk if, in the light of
the health and safety or the fundamental          their intended purpose, they pose a
rights of persons, taking into account both       significant risk of harm to the health and
the severity of the possible harm and its         safety or the fundamental rights of persons
probability of occurrence and they are            and, where the AI system is used as a
used in a number of specifically pre-             safety component of a critical
defined areas specified in the Regulation.        infrastructure, to the environment . Such
The identification of those systems is based      significant risk of harm should be
on the same methodology and criteria              identified by assessing on the one hand
envisaged also for any future amendments          the effect of such risk with respect to its
of the list of high-risk AI systems.              level of severity, intensity, probability of
                                                  occurrence and duration combined
                                                  altogether and on the other hand whether
                                                  the risk can affect an individual, a
                                                  plurality of persons or a particular group
                                                  of persons. Such combination could for
                                                  instance result in a high severity but low
                                                  probability to affect a natural person, or a
                                      high probability to affect a group of
                                      persons with a low intensity over a long
                                      period of time, depending on the context.
                                      The identification of those systems is based
                                      on the same methodology and criteria
                                      envisaged also for any future amendments
                                      of the list of high-risk AI systems.


Amendment 61

Proposal for a regulation
Recital 32 a (new)

    Text proposed by the Commission                   Amendment

                                      (32a) Providers whose AI systems fall
                                      under one of the areas and use cases
                                      listed in Annex III that consider their
                                      system does not pose a significant risk of
                                      harm to the health, safety, fundamental
                                      rights or the environment should inform
                                      the national supervisory authorities by
                                      submitting a reasoned notification. This
                                      could take the form of a one-page
                                      summary of the relevant information on
                                      the AI system in question, including its
                                      intended purpose and why it would not
                                      pose a significant risk of harm to the
                                      health, safety, fundamental rights or the
                                      environment. The Commission should
                                      specify criteria to enable companies to
                                      assess whether their system would pose
                                      such risks, as well as develop an easy to
                                      use and standardised template for the
                                      notification. Providers should submit the
                                      notification as early as possible and in
                                      any case prior to the placing of the AI
                                      system on the market or its putting into
                                      service, ideally at the development stage,
                                      and they should be free to place it on the
                                      market at any given time after the
                                      notification. However, if the authority
                                      estimates the AI system in question was
                                      misclassified, it should object to the
                                      notification within a period of three
                                      months. The objection should be
                                      substantiated and duly explain why the AI
                                      system has been misclassified. The
                                      provider should retain the right to appeal
                                              by providing further arguments. If after
                                              the three months there has been no
                                              objection to the notification, national
                                              supervisory authorities could still
                                              intervene if the AI system presents a risk
                                              at national level, as for any other AI
                                              system on the market. National
                                              supervisory authorities should submit
                                              annual reports to the AI Office detailing
                                              the notifications received and the
                                              decisions taken.


Amendment 62

Proposal for a regulation
Recital 33

    Text proposed by the Commission                           Amendment

(33) Technical inaccuracies of AI             deleted
systems intended for the remote biometric
identification of natural persons can lead
to biased results and entail discriminatory
effects. This is particularly relevant when
it comes to age, ethnicity, sex or
disabilities. Therefore, ‘real-time’ and
‘post’ remote biometric identification
systems should be classified as high-risk.
In view of the risks that they pose, both
types of remote biometric identification
systems should be subject to specific
requirements on logging capabilities and
human oversight.


Amendment 63

Proposal for a regulation
Recital 33 a (new)

    Text proposed by the Commission                           Amendment

                                              (33a) As biometric data constitute a
                                              special category of sensitive personal data
                                              in accordance with Regulation 2016/679,
                                              it is appropriate to classify as high-risk
                                              several critical use-cases of biometric and
                                              biometrics-based systems. AI systems
                                              intended to be used for biometric
                                               identification of natural persons and AI
                                               systems intended to be used to make
                                               inferences about personal characteristics
                                               of natural persons on the basis of
                                               biometric or biometrics-based data,
                                               including emotion recognition systems,
                                               with the exception of those which are
                                               prohibited under this Regulation should
                                               therefore be classified as high-risk. This
                                               should not include AI systems intended to
                                               be used for biometric verification, which
                                               includes authentication, whose sole
                                               purpose is to confirm that a specific
                                               natural person is the person he or she
                                               claims to be and to confirm the identity of
                                               a natural person for the sole purpose of
                                               having access to a service, a device or
                                               premises (one-to-one verification).
                                               Biometric and biometrics-based systems
                                               which are provided for under Union law
                                               to enable cybersecurity and personal data
                                               protection measures should not be
                                               considered as posing a significant risk of
                                               harm to the health, safety and
                                               fundamental rights.


Amendment 64

Proposal for a regulation
Recital 34

     Text proposed by the Commission                           Amendment

(34) As regards the management and             (34) As regards the management and
operation of critical infrastructure, it is    operation of critical infrastructure, it is
appropriate to classify as high-risk the AI    appropriate to classify as high-risk the AI
systems intended to be used as safety          systems intended to be used as safety
components in the management and               components in the management and
operation of road traffic and the supply of    operation of the supply of water, gas,
water, gas, heating and electricity, since     heating electricity and critical digital
their failure or malfunctioning may put at     infrastructure, since their failure or
risk the life and health of persons at large   malfunctioning may infringe the security
scale and lead to appreciable disruptions in   and integrity of such critical
the ordinary conduct of social and             infrastructure or put at risk the life and
economic activities.                           health of persons at large scale and lead to
                                               appreciable disruptions in the ordinary
                                               conduct of social and economic activities.
                                               Safety components of critical
                                               infrastructure, including critical digital
                                                infrastructure, are systems used to directly
                                                protect the physical integrity of critical
                                                infrastructure or health and safety of
                                                persons and property. Failure or
                                                malfunctioning of such components
                                                might directly lead to risks to the physical
                                                integrity of critical infrastructure and
                                                thus to risks to the health and safety of
                                                persons and property. Components
                                                intended to be used solely for
                                                cybersecurity purposes should not qualify
                                                as safety components. Examples of such
                                                safety components may include systems
                                                for monitoring water pressure or fire
                                                alarm controlling systems in cloud
                                                computing centres.


Amendment 65

Proposal for a regulation
Recital 35

     Text proposed by the Commission                            Amendment

(35) AI systems used in education or            (35) Deployment of AI systems in
vocational training, notably for                education is important in order to help
determining access or assigning persons to      modernise entire education systems, to
educational and vocational training             increase educational quality, both offline
institutions or to evaluate persons on tests    and online and to accelerate digital
as part of or as a precondition for their       education, thus also making it available to
education should be considered high-risk,       a broader audience . AI systems used in
since they may determine the educational        education or vocational training, notably
and professional course of a person’s life      for determining access or materially
and therefore affect their ability to secure    influence decisions on admission or
their livelihood. When improperly               assigning persons to educational and
designed and used, such systems may             vocational training institutions or to
violate the right to education and training     evaluate persons on tests as part of or as a
as well as the right not to be discriminated    precondition for their education or to
against and perpetuate historical patterns of   assess the appropriate level of education
discrimination.                                 for an individual and materially influence
                                                the level of education and training that
                                                individuals will receive or be able to
                                                access or to monitor and detect prohibited
                                                behaviour of students during tests should
                                                be classified as high-risk AI systems, since
                                                they may determine the educational and
                                                professional course of a person’s life and
                                                therefore affect their ability to secure their
                                                livelihood. When improperly designed and
                                                used, such systems can be particularly
                                                intrusive and may violate the right to
                                                education and training as well as the right
                                                not to be discriminated against and
                                                perpetuate historical patterns of
                                                discrimination, for example against
                                                women, certain age groups, persons with
                                                disabilities, or persons of certain racial or
                                                ethnic origins or sexual orientation.


Amendment 66

Proposal for a regulation
Recital 36

     Text proposed by the Commission                            Amendment

(36) AI systems used in employment,             (36) AI systems used in employment,
workers management and access to self-          workers management and access to self-
employment, notably for the recruitment         employment, notably for the recruitment
and selection of persons, for making            and selection of persons, for making
decisions on promotion and termination          decisions or materially influence decisions
and for task allocation, monitoring or          on initiation, promotion and termination
evaluation of persons in work-related           and for personalised task allocation based
contractual relationships, should also be       on individual behaviour, personal traits or
classified as high-risk, since those systems    biometric data, monitoring or evaluation of
may appreciably impact future career            persons in work-related contractual
prospects and livelihoods of these persons.     relationships, should also be classified as
Relevant work-related contractual               high-risk, since those systems may
relationships should involve employees          appreciably impact future career prospects,
and persons providing services through          livelihoods of these persons and workers’
platforms as referred to in the Commission      rights. Relevant work-related contractual
Work Programme 2021. Such persons               relationships should meaningfully involve
should in principle not be considered           employees and persons providing services
users within the meaning of this                through platforms as referred to in the
Regulation. Throughout the recruitment          Commission Work Programme 2021.
process and in the evaluation, promotion,       Throughout the recruitment process and in
or retention of persons in work-related         the evaluation, promotion, or retention of
contractual relationships, such systems         persons in work-related contractual
may perpetuate historical patterns of           relationships, such systems may perpetuate
discrimination, for example against             historical patterns of discrimination, for
women, certain age groups, persons with         example against women, certain age
disabilities, or persons of certain racial or   groups, persons with disabilities, or
ethnic origins or sexual orientation. AI        persons of certain racial or ethnic origins or
systems used to monitor the performance         sexual orientation. AI systems used to
and behaviour of these persons may also         monitor the performance and behaviour of
impact their rights to data protection and      these persons may also undermine the
privacy.                                        essence of their fundamental rights to data
                                                protection and privacy. This Regulation
                                                applies without prejudice to Union and
                                                Member State competences to provide for
                                                more specific rules for the use of AI-
                                                systems in the employment context.


Amendment 67

Proposal for a regulation
Recital 37

     Text proposed by the Commission                            Amendment

(37) Another area in which the use of AI        (37) Another area in which the use of AI
systems deserves special consideration is       systems deserves special consideration is
the access to and enjoyment of certain          the access to and enjoyment of certain
essential private and public services and       essential private and public services,
benefits necessary for people to fully          including healthcare services, and
participate in society or to improve one’s      essential services, including but not
standard of living. In particular, AI systems   limited to housing, electricity,
used to evaluate the credit score or            heating/cooling and internet, and benefits
creditworthiness of natural persons should      necessary for people to fully participate in
be classified as high-risk AI systems, since    society or to improve one’s standard of
they determine those persons’ access to         living. In particular, AI systems used to
financial resources or essential services       evaluate the credit score or
such as housing, electricity, and               creditworthiness of natural persons should
telecommunication services. AI systems          be classified as high-risk AI systems, since
used for this purpose may lead to               they determine those persons’ access to
discrimination of persons or groups and         financial resources or essential services
perpetuate historical patterns of               such as housing, electricity, and
discrimination, for example based on racial     telecommunication services. AI systems
or ethnic origins, disabilities, age, sexual    used for this purpose may lead to
orientation, or create new forms of             discrimination of persons or groups and
discriminatory impacts. Considering the         perpetuate historical patterns of
very limited scale of the impact and the        discrimination, for example based on racial
available alternatives on the market, it is     or ethnic origins, gender, disabilities, age,
appropriate to exempt AI systems for the        sexual orientation, or create new forms of
purpose of creditworthiness assessment          discriminatory impacts. However, AI
and credit scoring when put into service        systems provided for by Union law for the
by small-scale providers for their own use.     purpose of detecting fraud in the offering
Natural persons applying for or receiving       of financial services should not be
public assistance benefits and services         considered as high-risk under this
from public authorities are typically           Regulation. Natural persons applying for
dependent on those benefits and services        or receiving public assistance benefits and
and in a vulnerable position in relation to     services from public authorities, including
the responsible authorities. If AI systems      healthcare services and essential services,
are used for determining whether such           including but not limited to housing,
benefits and services should be denied,         electricity, heating/cooling and internet,
reduced, revoked or reclaimed by                are typically dependent on those benefits
authorities, they may have a significant        and services and in a vulnerable position in
impact on persons’ livelihood and may            relation to the responsible authorities. If AI
infringe their fundamental rights, such as       systems are used for determining whether
the right to social protection, non-             such benefits and services should be
discrimination, human dignity or an              denied, reduced, revoked or reclaimed by
effective remedy. Those systems should           authorities, they may have a significant
therefore be classified as high-risk.            impact on persons’ livelihood and may
Nonetheless, this Regulation should not          infringe their fundamental rights, such as
hamper the development and use of                the right to social protection, non-
innovative approaches in the public              discrimination, human dignity or an
administration, which would stand to             effective remedy. Similarly, AI systems
benefit from a wider use of compliant and        intended to be used to make decisions or
safe AI systems, provided that those             materially influence decisions on the
systems do not entail a high risk to legal       eligibility of natural persons for health
and natural persons. Finally, AI systems         and life insurance may also have a
used to dispatch or establish priority in the    significant impact on persons’ livelihood
dispatching of emergency first response          and may infringe their fundamental rights
services should also be classified as high-      such as by limiting access to healthcare or
risk since they make decisions in very           by perpetuating discrimination based on
critical situations for the life and health of   personal characteristics. Those systems
persons and their property.                      should therefore be classified as high-risk.
                                                 Nonetheless, this Regulation should not
                                                 hamper the development and use of
                                                 innovative approaches in the public
                                                 administration, which would stand to
                                                 benefit from a wider use of compliant and
                                                 safe AI systems, provided that those
                                                 systems do not entail a high risk to legal
                                                 and natural persons. Finally, AI systems
                                                 used to evaluate and classify emergency
                                                 calls by natural persons or to dispatch or
                                                 establish priority in the dispatching of
                                                 emergency first response services should
                                                 also be classified as high-risk since they
                                                 make decisions in very critical situations
                                                 for the life and health of persons and their
                                                 property.


Amendment 68

Proposal for a regulation
Recital 37 a (new)

     Text proposed by the Commission                             Amendment

                                                 (37a) Given the role and responsibility of
                                                 police and judicial authorities, and the
                                                 impact of decisions they take for the
                                                 purposes of the prevention, investigation,
                                                 detection or prosecution of criminal
                                               offences or the execution of criminal
                                               penalties, some specific use-cases of AI
                                               applications in law enforcement has to be
                                               classified as high-risk, in particular in
                                               instances where there is the potential to
                                               significantly affect the lives or the
                                               fundamental rights of individuals.


Amendment 69

Proposal for a regulation
Recital 38

    Text proposed by the Commission                            Amendment

(38) Actions by law enforcement                (38) Actions by law enforcement
authorities involving certain uses of AI       authorities involving certain uses of AI
systems are characterised by a significant     systems are characterised by a significant
degree of power imbalance and may lead to      degree of power imbalance and may lead to
surveillance, arrest or deprivation of a       surveillance, arrest or deprivation of a
natural person’s liberty as well as other      natural person’s liberty as well as other
adverse impacts on fundamental rights          adverse impacts on fundamental rights
guaranteed in the Charter. In particular, if   guaranteed in the Charter. In particular, if
the AI system is not trained with high         the AI system is not trained with high
quality data, does not meet adequate           quality data, does not meet adequate
requirements in terms of its accuracy or       requirements in terms of its performance,
robustness, or is not properly designed and    its accuracy or robustness, or is not
tested before being put on the market or       properly designed and tested before being
otherwise put into service, it may single      put on the market or otherwise put into
out people in a discriminatory or otherwise    service, it may single out people in a
incorrect or unjust manner. Furthermore,       discriminatory or otherwise incorrect or
the exercise of important procedural           unjust manner. Furthermore, the exercise
fundamental rights, such as the right to an    of important procedural fundamental
effective remedy and to a fair trial as well   rights, such as the right to an effective
as the right of defence and the presumption    remedy and to a fair trial as well as the
of innocence, could be hampered, in            right of defence and the presumption of
particular, where such AI systems are not      innocence, could be hampered, in
sufficiently transparent, explainable and      particular, where such AI systems are not
documented. It is therefore appropriate to     sufficiently transparent, explainable and
classify as high-risk a number of AI           documented. It is therefore appropriate to
systems intended to be used in the law         classify as high-risk a number of AI
enforcement context where accuracy,            systems intended to be used in the law
reliability and transparency is particularly   enforcement context where accuracy,
important to avoid adverse impacts, retain     reliability and transparency is particularly
public trust and ensure accountability and     important to avoid adverse impacts, retain
effective redress. In view of the nature of    public trust and ensure accountability and
the activities in question and the risks       effective redress. In view of the nature of
relating thereto, those high-risk AI systems   the activities in question and the risks
should include in particular AI systems        relating thereto, those high-risk AI systems
intended to be used by law enforcement         should include in particular AI systems
authorities for individual risk assessments,   intended to be used by or on behalf of law
polygraphs and similar tools or to detect      enforcement authorities or by Union
the emotional state of natural person, to      agencies, offices or bodies in support of
detect ‘deep fakes’, for the evaluation of     law enforcement authorities, as
the reliability of evidence in criminal        polygraphs and similar tools insofar as
proceedings, for predicting the occurrence     their use is permitted under relevant
or reoccurrence of an actual or potential      Union and national law, for the evaluation
criminal offence based on profiling of         of the reliability of evidence in criminal
natural persons, or assessing personality      proceedings, for profiling in the course of
traits and characteristics or past criminal    detection, investigation or prosecution of
behaviour of natural persons or groups,        criminal offences, as well as for crime
for profiling in the course of detection,      analytics regarding natural persons. AI
investigation or prosecution of criminal       systems specifically intended to be used for
offences, as well as for crime analytics       administrative proceedings by tax and
regarding natural persons. AI systems          customs authorities should not be classified
specifically intended to be used for           as high-risk AI systems used by law
administrative proceedings by tax and          enforcement authorities for the purposes of
customs authorities should not be              prevention, detection, investigation and
considered high-risk AI systems used by        prosecution of criminal offences. The use
law enforcement authorities for the            of AI tools by law enforcement and
purposes of prevention, detection,             judicial authorities should not become a
investigation and prosecution of criminal      factor of inequality, social fracture or
offences.                                      exclusion. The impact of the use of AI
                                               tools on the defence rights of suspects
                                               should not be ignored, notably the
                                               difficulty in obtaining meaningful
                                               information on their functioning and the
                                               consequent difficulty in challenging their
                                               results in court, in particular by
                                               individuals under investigation.


Amendment 70

Proposal for a regulation
Recital 39

    Text proposed by the Commission                            Amendment

(39) AI systems used in migration, asylum      (39) AI systems used in migration, asylum
and border control management affect           and border control management affect
people who are often in particularly           people who are often in particularly
vulnerable position and who are dependent      vulnerable position and who are dependent
on the outcome of the actions of the           on the outcome of the actions of the
competent public authorities. The              competent public authorities. The
accuracy, non-discriminatory nature and        accuracy, non-discriminatory nature and
transparency of the AI systems used in         transparency of the AI systems used in
those contexts are therefore particularly      those contexts are therefore particularly
important to guarantee the respect of the      important to guarantee the respect of the
fundamental rights of the affected persons,    fundamental rights of the affected persons,
notably their rights to free movement, non-    notably their rights to free movement, non-
discrimination, protection of private life     discrimination, protection of private life
and personal data, international protection    and personal data, international protection
and good administration. It is therefore       and good administration. It is therefore
appropriate to classify as high-risk AI        appropriate to classify as high-risk AI
systems intended to be used by the             systems intended to be used by or on
competent public authorities charged with      behalf of competent public authorities or
tasks in the fields of migration, asylum and   by Union agencies, offices or bodies
border control management as polygraphs        charged with tasks in the fields of
and similar tools or to detect the emotional   migration, asylum and border control
state of a natural person; for assessing       management as polygraphs and similar
certain risks posed by natural persons         tools insofar as their use is permitted
entering the territory of a Member State or    under relevant Union and national law,
applying for visa or asylum; for verifying     for assessing certain risks posed by natural
the authenticity of the relevant documents     persons entering the territory of a Member
of natural persons; for assisting competent    State or applying for visa or asylum; for
public authorities for the examination of      verifying the authenticity of the relevant
applications for asylum, visa and residence    documents of natural persons; for assisting
permits and associated complaints with         competent public authorities for the
regard to the objective to establish the       examination and assessment of the
eligibility of the natural persons applying    veracity of evidence in relation to
for a status. AI systems in the area of        applications for asylum, visa and residence
migration, asylum and border control           permits and associated complaints with
management covered by this Regulation          regard to the objective to establish the
should comply with the relevant procedural     eligibility of the natural persons applying
requirements set by the Directive              for a status; for monitoring, surveilling or
2013/32/EU of the European Parliament          processing personal data in the context of
and of the Council49 , the Regulation (EC)     border management activities, for the
No 810/2009 of the European Parliament         purpose of detecting, recognising or
and of the Council50 and other relevant        identifying natural persons; for the
legislation.                                   forecasting or prediction of trends related
                                               to migration movements and border
                                               crossings. AI systems in the area of
                                               migration, asylum and border control
                                               management covered by this Regulation
                                               should comply with the relevant procedural
                                               requirements set by the Directive
                                               2013/32/EU of the European Parliament
                                               and of the Council49 , the Regulation (EC)
                                               No 810/2009 of the European Parliament
                                               and of the Council50 and other relevant
                                               legislation. The use of AI systems in
                                               migration, asylum and border control
                                               management should in no circumstances
                                               be used by Member States or Union
                                               institutions, agencies or bodies as a means
                                               to circumvent their international
                                               obligations under the Convention of 28
                                               July 1951 relating to the Status of
                                                Refugees as amended by the Protocol of
                                                31 January 1967, nor should they be used
                                                to in any way infringe on the principle of
                                                non-refoulement, or or deny safe and
                                                effective legal avenues into the territory of
                                                the Union, including the right to
                                                international protection.
__________________                              __________________
49 Directive 2013/32/EU of the European         49 Directive 2013/32/EU of the European

Parliament and of the Council of 26 June        Parliament and of the Council of 26 June
2013 on common procedures for granting          2013 on common procedures for granting
and withdrawing international protection        and withdrawing international protection
(OJ L 180, 29.6.2013, p. 60).                   (OJ L 180, 29.6.2013, p. 60).
50 Regulation (EC) No 810/2009 of the           50 Regulation (EC) No 810/2009 of the

European Parliament and of the Council of       European Parliament and of the Council of
13 July 2009 establishing a Community           13 July 2009 establishing a Community
Code on Visas (Visa Code) (OJ L 243,            Code on Visas (Visa Code) (OJ L 243,
15.9.2009, p. 1).                               15.9.2009, p. 1).


Amendment 71

Proposal for a regulation
Recital 40

     Text proposed by the Commission                            Amendment

(40) Certain AI systems intended for the        (40) Certain AI systems intended for the
administration of justice and democratic        administration of justice and democratic
processes should be classified as high-risk,    processes should be classified as high-risk,
considering their potentially significant       considering their potentially significant
impact on democracy, rule of law,               impact on democracy, rule of law,
individual freedoms as well as the right to     individual freedoms as well as the right to
an effective remedy and to a fair trial. In     an effective remedy and to a fair trial. In
particular, to address the risks of potential   particular, to address the risks of potential
biases, errors and opacity, it is appropriate   biases, errors and opacity, it is appropriate
to qualify as high-risk AI systems intended     to qualify as high-risk AI systems intended
to assist judicial authorities in researching   to be used by a judicial authority or
and interpreting facts and the law and in       administrative body or on their behalf to
applying the law to a concrete set of facts.    assist judicial authorities or administrative
Such qualification should not extend,           bodies in researching and interpreting facts
however, to AI systems intended for purely      and the law and in applying the law to a
ancillary administrative activities that do     concrete set of facts or used in a similar
not affect the actual administration of         way in alternative dispute resolution. The
justice in individual cases, such as            use of artificial intelligence tools can
anonymisation or pseudonymisation of            support, but should not replace the
judicial decisions, documents or data,          decision-making power of judges or
communication between personnel,                judicial independence, as the final
administrative tasks or allocation of           decision-making must remain a human-
resources.                            driven activity and decision. Such
                                      qualification should not extend, however,
                                      to AI systems intended for purely ancillary
                                      administrative activities that do not affect
                                      the actual administration of justice in
                                      individual cases, such as anonymisation or
                                      pseudonymisation of judicial decisions,
                                      documents or data, communication
                                      between personnel, administrative tasks or
                                      allocation of resources.


Amendment 72

Proposal for a regulation
Recital 40 a (new)

    Text proposed by the Commission                   Amendment

                                      (40a) In order to address the risks of
                                      undue external interference to the right to
                                      vote enshrined in Article 39 of the
                                      Charter, and of disproportionate effects
                                      on democratic processes, democracy, and
                                      the rule of law, AI systems intended to be
                                      used to influence the outcome of an
                                      election or referendum or the voting
                                      behaviour of natural persons in the
                                      exercise of their vote in elections or
                                      referenda should be classified as high-risk
                                      AI systems. with the exception of AI
                                      systems whose output natural persons are
                                      not directly exposed to, such as tools used
                                      to organise, optimise and structure
                                      political campaigns from an
                                      administrative and logistical point of view.


Amendment 73

Proposal for a regulation
Recital 40 b (new)

    Text proposed by the Commission                   Amendment

                                      (40b) Considering the scale of natural
                                      persons using the services provided by
                                      social media platforms designated as very
                                      large online platforms, such online
                                      platforms can be used in a way that
                                             strongly influences safety online, the
                                             shaping of public opinion and discourse,
                                             election and democratic processes and
                                             societal concerns. It is therefore
                                             appropriate that AI systems used by those
                                             online platforms in their recommender
                                             systems are subject to this Regulation so
                                             as to ensure that the AI systems comply
                                             with the requirements laid down under
                                             this Regulation, including the technical
                                             requirements on data governance,
                                             technical documentation and traceability,
                                             transparency, human oversight, accuracy
                                             and robustness. Compliance with this
                                             Regulation should enable such very large
                                             online platforms to comply with their
                                             broader risk assessment and risk-
                                             mitigation obligations in Article 34 and 35
                                             of Regulation EU 2022/2065. The
                                             obligations in this Regulation are without
                                             prejudice to Regulation (EU) 2022/2065
                                             and should complement the obligations
                                             required under the Regulation (EU)
                                             2022/2065 when the social media platform
                                             has been designated as a very large online
                                             platform. Given the European-wide
                                             impact of social media platforms
                                             designated as very large online platforms,
                                             the authorities designated under
                                             Regulation (EU) 2022/2065 should act as
                                             enforcement authorities for the purposes
                                             of enforcing this provision.


Amendment 74

Proposal for a regulation
Recital 41

    Text proposed by the Commission                          Amendment

(41) The fact that an AI system is           (41) The fact that an AI system is
classified as high risk under this           classified as a high risk AI system under
Regulation should not be interpreted as      this Regulation should not be interpreted as
indicating that the use of the system is     indicating that the use of the system is
necessarily lawful under other acts of       necessarily lawful or unlawful under other
Union law or under national law              acts of Union law or under national law
compatible with Union law, such as on the    compatible with Union law, such as on the
protection of personal data, on the use of   protection of personal data, Any such use
polygraphs and similar tools or other        should continue to occur solely in
systems to detect the emotional state of      accordance with the applicable
natural persons. Any such use should          requirements resulting from the Charter
continue to occur solely in accordance with   and from the applicable acts of secondary
the applicable requirements resulting from    Union law and national law.
the Charter and from the applicable acts of
secondary Union law and national law.
This Regulation should not be understood
as providing for the legal ground for
processing of personal data, including
special categories of personal data, where
relevant.


Amendment 75

Proposal for a regulation
Recital 41 a (new)

    Text proposed by the Commission                          Amendment

                                              (41a) A number of legally binding rules at
                                              European, national and international
                                              level already apply or are relevant to AI
                                              systems today, including but not limited to
                                              EU primary law (the Treaties of the
                                              European Union and its Charter of
                                              Fundamental Rights), EU secondary law
                                              (such as the General Data Protection
                                              Regulation, the Product Liability
                                              Directive, the Regulation on the Free
                                              Flow of Non-Personal Data, anti-
                                              discrimination Directives, consumer law
                                              and Safety and Health at Work
                                              Directives), the UN Human Rights
                                              treaties and the Council of Europe
                                              conventions (such as the European
                                              Convention on Human Rights), and
                                              national law. Besides horizontally
                                              applicable rules, various domain-specific
                                              rules exist that apply to particular AI
                                              applications (such as for instance the
                                              Medical Device Regulation in the
                                              healthcare sector).


Amendment 76

Proposal for a regulation
Recital 42
     Text proposed by the Commission                         Amendment

(42) To mitigate the risks from high-risk     (42) To mitigate the risks from high-risk
AI systems placed or otherwise put into       AI systems placed or otherwise put into
service on the Union market for users and     service on the Union market for deployers
affected persons, certain mandatory           and affected persons, certain mandatory
requirements should apply, taking into        requirements should apply, taking into
account the intended purpose of the use of    account the intended purpose, the
the system and according to the risk          reasonably foreseeable misuse of the
management system to be established by        system and according to the risk
the provider.                                 management system to be established by
                                              the provider. These requirements should
                                              be objective-driven, fit for purpose,
                                              reasonable and effective, without adding
                                              undue regulatory burdens or costs on
                                              operators.


Amendment 77

Proposal for a regulation
Recital 43

     Text proposed by the Commission                         Amendment

(43) Requirements should apply to high-       (43) Requirements should apply to high-
risk AI systems as regards the quality of     risk AI systems as regards the quality and
data sets used, technical documentation       relevance of data sets used, technical
and record-keeping, transparency and the      documentation and record-keeping,
provision of information to users, human      transparency and the provision of
oversight, and robustness, accuracy and       information to deployers, human oversight,
cybersecurity. Those requirements are         and robustness, accuracy and
necessary to effectively mitigate the risks   cybersecurity. Those requirements are
for health, safety and fundamental rights,    necessary to effectively mitigate the risks
as applicable in the light of the intended    for health, safety and fundamental rights,
purpose of the system, and no other less      as well as the environment, democracy
trade restrictive measures are reasonably     and rule of law, as applicable in the light
available, thus avoiding unjustified          of the intended purpose or reasonably
restrictions to trade.                        foreseeable misuse of the system, and no
                                              other less trade restrictive measures are
                                              reasonably available, thus avoiding
                                              unjustified restrictions to trade.


Amendment 78

Proposal for a regulation
Recital 44
     Text proposed by the Commission                            Amendment

(44) High data quality is essential for the     (44) Access to data of high quality plays a
performance of many AI systems,                 vital role in providing structure and in
especially when techniques involving the        ensuring the performance of many AI
training of models are used, with a view to     systems, especially when techniques
ensure that the high-risk AI system             involving the training of models are used,
performs as intended and safely and it does     with a view to ensure that the high-risk AI
not become the source of discrimination         system performs as intended and safely and
prohibited by Union law. High quality           it does not become a source of
training, validation and testing data sets      discrimination prohibited by Union law.
require the implementation of appropriate       High quality training, validation and
data governance and management                  testing data sets require the implementation
practices. Training, validation and testing     of appropriate data governance and
data sets should be sufficiently relevant,      management practices. Training, and
representative and free of errors and           where applicable, validation and testing
complete in view of the intended purpose        data sets, including the labels, should be
of the system. They should also have the        sufficiently relevant, representative,
appropriate statistical properties, including   appropriately vetted for errors and as
as regards the persons or groups of persons     complete as possible in view of the
on which the high-risk AI system is             intended purpose of the system. They
intended to be used. In particular, training,   should also have the appropriate statistical
validation and testing data sets should take    properties, including as regards the persons
into account, to the extent required in the     or groups of persons in relation to whom
light of their intended purpose, the            the high-risk AI system is intended to be
features, characteristics or elements that      used, with specific attention to the
are particular to the specific geographical,    mitigation of possible biases in the
behavioural or functional setting or context    datasets, that might lead to risks to
within which the AI system is intended to       fundamental rights or discriminatory
be used. In order to protect the right of       outcomes for the persons affected by the
others from the discrimination that might       high-risk AI system. Biases can for
result from the bias in AI systems, the         example be inherent in underlying
providers shouldbe able to process also         datasets, especially when historical data is
special categories of personal data, as a       being used, introduced by the developers
matter of substantial public interest, in       of the algorithms, or generated when the
order to ensure the bias monitoring,            systems are implemented in real world
detection and correction in relation to high-   settings. Results provided by AI systems
risk AI systems.                                are influenced by such inherent biases
                                                that are inclined to gradually increase
                                                and thereby perpetuate and amplify
                                                existing discrimination, in particular for
                                                persons belonging to certain vulnerable or
                                                ethnic groups, or racialised communities.
                                                In particular, training, validation and
                                                testing data sets should take into account,
                                                to the extent required in the light of their
                                                intended purpose, the features,
                                                characteristics or elements that are
                                                particular to the specific geographical,
                                                 contextal, behavioural or functional setting
                                                 or context within which the AI system is
                                                 intended to be used. In order to protect the
                                                 right of others from the discrimination that
                                                 might result from the bias in AI systems,
                                                 the providers should, exceptionally and
                                                 following the application of all applicable
                                                 conditions laid down under this
                                                 Regulation and in Regulation (EU)
                                                 2016/679, Directive (EU) 2016/680 and
                                                 Regulation (EU) 2018/1725, be able to
                                                 process also special categories of personal
                                                 data, as a matter of substantial public
                                                 interest, in order to ensure the negative bias
                                                 detection and correction in relation to high-
                                                 risk AI systems. Negative bias should be
                                                 understood as bias that create direct or
                                                 indirect discriminatory effect against a
                                                 natural person The requirements related
                                                 to data governance can be complied with
                                                 by having recourse to third-parties that
                                                 offer certified compliance services
                                                 including verification of data governance,
                                                 data set integrity, and data training,
                                                 validation and testing practices.


Amendment 79

Proposal for a regulation
Recital 45

     Text proposed by the Commission                             Amendment

(45) For the development of high-risk AI         (45) For the development and assessment
systems, certain actors, such as providers,      of high-risk AI systems, certain actors,
notified bodies and other relevant entities,     such as providers, notified bodies and other
such as digital innovation hubs, testing         relevant entities, such as digital innovation
experimentation facilities and researchers,      hubs, testing experimentation facilities and
should be able to access and use high            researchers, should be able to access and
quality datasets within their respective         use high quality datasets within their
fields of activities which are related to this   respective fields of activities which are
Regulation. European common data spaces          related to this Regulation. European
established by the Commission and the            common data spaces established by the
facilitation of data sharing between             Commission and the facilitation of data
businesses and with government in the            sharing between businesses and with
public interest will be instrumental to          government in the public interest will be
provide trustful, accountable and non-           instrumental to provide trustful,
discriminatory access to high quality data       accountable and non-discriminatory access
for the training, validation and testing of      to high quality data for the training,
AI systems. For example, in health, the       validation and testing of AI systems. For
European health data space will facilitate    example, in health, the European health
non-discriminatory access to health data      data space will facilitate non-
and the training of artificial intelligence   discriminatory access to health data and the
algorithms on those datasets, in a privacy-   training of artificial intelligence algorithms
preserving, secure, timely, transparent and   on those datasets, in a privacy-preserving,
trustworthy manner, and with an               secure, timely, transparent and trustworthy
appropriate institutional governance.         manner, and with an appropriate
Relevant competent authorities, including     institutional governance. Relevant
sectoral ones, providing or supporting the    competent authorities, including sectoral
access to data may also support the           ones, providing or supporting the access to
provision of high-quality data for the        data may also support the provision of
training, validation and testing of AI        high-quality data for the training,
systems.                                      validation and testing of AI systems.


Amendment 80

Proposal for a regulation
Recital 45 a (new)

    Text proposed by the Commission                           Amendment

                                              (45a) The right to privacy and to
                                              protection of personal data must be
                                              guaranteed throughout the entire lifecycle
                                              of the AI system. In this regard, the
                                              principles of data minimisation and data
                                              protection by design and by default, as set
                                              out in Union data protection law, are
                                              essential when the processing of data
                                              involves significant risks to the
                                              fundamental rights of individuals.
                                              Providers and users of AI systems should
                                              implement state-of-the-art technical and
                                              organisational measures in order to
                                              protect those rights. Such measures
                                              should include not only anonymisation
                                              and encryption, but also the use of
                                              increasingly available technology that
                                              permits algorithms to be brought to the
                                              data and allows valuable insights to be
                                              derived without the transmission between
                                              parties or unnecessary copying of the raw
                                              or structured data themselves.


Amendment 81
Proposal for a regulation
Recital 46

     Text proposed by the Commission                            Amendment

(46) Having information on how high-risk        (46) Having comprehensible information
AI systems have been developed and how          on how high-risk AI systems have been
they perform throughout their lifecycle is      developed and how they perform
essential to verify compliance with the         throughout their lifetime is essential to
requirements under this Regulation. This        verify compliance with the requirements
requires keeping records and the                under this Regulation. This requires
availability of a technical documentation,      keeping records and the availability of a
containing information which is necessary       technical documentation, containing
to assess the compliance of the AI system       information which is necessary to assess
with the relevant requirements. Such            the compliance of the AI system with the
information should include the general          relevant requirements. Such information
characteristics, capabilities and limitations   should include the general characteristics,
of the system, algorithms, data, training,      capabilities and limitations of the system,
testing and validation processes used as        algorithms, data, training, testing and
well as documentation on the relevant risk      validation processes used as well as
management system. The technical                documentation on the relevant risk
documentation should be kept up to date.        management system. The technical
                                                documentation should be kept up to date
                                                appropriately throughout the lifecycle of
                                                the AI system. AI systems can have a
                                                large important environmental impact
                                                and high energy consumption during
                                                their lifecyle. In order to better apprehend
                                                the impact of AI systems on the
                                                environment, the technical documentation
                                                drafted by providers should include
                                                information on the energy consumption of
                                                the AI system, including the consumption
                                                during development and expected
                                                consumption during use. Such
                                                information should take into account the
                                                relevant Union and national legislation.
                                                This reported information should be
                                                comprehensible, comparable and
                                                verifiable and to that end, the Commission
                                                should develop guidelines on a
                                                harmonised metholodogy for calculation
                                                and reporting of this information. To
                                                ensure that a single documentation is
                                                possible, terms and definitions related to
                                                the required documentation and any
                                                required documentation in the relevant
                                                Union legislation should be aligned as
                                                much as possible.
Amendment 82

Proposal for a regulation
Recital 46 a (new)

    Text proposed by the Commission                  Amendment

                                      (46a) AI systems should take into account
                                      state-of-the art methods and relevant
                                      applicable standards to reduce the energy
                                      use, resource use and waste, as well as to
                                      increase their energy efficiency and the
                                      overall efficiency of the system. The
                                      environmental aspects of AI systems that
                                      are significant for the purposes of this
                                      Regulation are the energy consumption of
                                      the AI system in the development, training
                                      and deployment phase as well as the
                                      recording and reporting and storing of
                                      this data. The design of AI systems should
                                      enable the measurement and logging of
                                      the consumption of energy and resources
                                      at each stage of development, training and
                                      deployment. The monitoring and
                                      reporting of the emissions of AI systems
                                      must be robust, transparent, consistent
                                      and accurate. In order to ensure the
                                      uniform application of this Regulation
                                      and stable legal ecosystem for providers
                                      and deployers in the Single Market, the
                                      Commission should develop a common
                                      specification for the methodology to fulfil
                                      the reporting and documentation
                                      requirement on the consumption of
                                      energy and resources during development,
                                      training and deployment. Such common
                                      specifications on measurement
                                      methodology can develop a baseline upon
                                      which the Commission can better decide if
                                      future regulatory interventions are
                                      needed, upon conducting an impact
                                      assessment that takes into account
                                      existing law.


Amendment 83

Proposal for a regulation
Recital 46 b (new)
    Text proposed by the Commission                   Amendment

                                      (46b) In order to achieve the objectives of
                                      this Regulation, and contribute to the
                                      Union’s environmental objectives while
                                      ensuring the smooth functioning of the
                                      internal market, it may be necessary to
                                      establish recommendations and guidelines
                                      and, eventually, targets for sustainability.
                                      For that purpose the Commission is
                                      entitled to develop a methodology to
                                      contribute towards having Key
                                      Performance Indicators (KPIs) and a
                                      reference for the Sustainable
                                      Development Goals (SDGs). The goal
                                      should be in the first instance to enable
                                      fair comparison between AI
                                      implementation choices providing
                                      incentives to promote using more efficient
                                      AI technologies addressing energy and
                                      resource concerns. To meet this objective
                                      this Regulation should provide the means
                                      to establish a baseline collection of data
                                      reported on the emissions from
                                      development and training and for
                                      deployment.


Amendment 84

Proposal for a regulation
Recital 47 a (new)

    Text proposed by the Commission                   Amendment

                                      (47a) Such requirements on transparency
                                      and on the explicability of AI decision-
                                      making should also help to counter the
                                      deterrent effects of digital asymmetry and
                                      so-called ‘dark patterns’ targeting
                                      individuals and their informed consent.



Amendment 85

Proposal for a regulation
Recital 49
     Text proposed by the Commission                             Amendment

(49) High-risk AI systems should perform         (49) High-risk AI systems should perform
consistently throughout their lifecycle and      consistently throughout their lifecycle and
meet an appropriate level of accuracy,           meet an appropriate level of accuracy,
robustness and cybersecurity in accordance       robustness and cybersecurity in accordance
with the generally acknowledged state of         with the generally acknowledged state of
the art. The level of accuracy and               the art. Performance metrics and their
accuracy metrics should be communicated          expected level should be defined with the
to the users.                                    primary objective to mitigate risks and
                                                 negative impact of the AI system. The
                                                 expected level of performance metrics
                                                 should be communicated in a clear,
                                                 transparent, easily understandable and
                                                 intelligible way to the deployers. The
                                                 declaration of performance metrics
                                                 cannot be considered proof of future
                                                 levels, but relevant methods need to be
                                                 applied to ensure consistent levels during
                                                 use While standardisation organisations
                                                 exist to establish standards, coordination
                                                 on benchmarking is needed to establish
                                                 how these standardised requirements and
                                                 characteristics of AI systems should be
                                                 measured. The European Artificial
                                                 Intelligence Office should bring together
                                                 national and international metrology and
                                                 benchmarking authorities and provide
                                                 non-binding guidance to address the
                                                 technical aspects of how to measure the
                                                 appropriate levels of performance and
                                                 robustness.


Amendment 86

Proposal for a regulation
Recital 50

     Text proposed by the Commission                             Amendment

(50) The technical robustness is a key           (50) The technical robustness is a key
requirement for high-risk AI systems. They       requirement for high-risk AI systems. They
should be resilient against risks connected      should be resilient against risks connected
to the limitations of the system (e.g. errors,   to the limitations of the system (e.g. errors,
faults, inconsistencies, unexpected              faults, inconsistencies, unexpected
situations) as well as against malicious         situations) as well as against malicious
actions that may compromise the security         actions that may compromise the security
of the AI system and result in harmful or        of the AI system and result in harmful or
otherwise undesirable behaviour. Failure to    otherwise undesirable behaviour. Failure to
protect against these risks could lead to      protect against these risks could lead to
safety impacts or negatively affect the        safety impacts or negatively affect the
fundamental rights, for example due to         fundamental rights, for example due to
erroneous decisions or wrong or biased         erroneous decisions or wrong or biased
outputs generated by the AI system.            outputs generated by the AI system. Users
                                               of the AI system should take steps to
                                               ensure that the possible trade-off between
                                               robustness and accuracy does not lead to
                                               discriminatory or negative outcomes for
                                               minority subgroups.


Amendment 87

Proposal for a regulation
Recital 51

     Text proposed by the Commission                           Amendment

(51) Cybersecurity plays a crucial role in     (51) Cybersecurity plays a crucial role in
ensuring that AI systems are resilient         ensuring that AI systems are resilient
against attempts to alter their use,           against attempts to alter their use,
behaviour, performance or compromise           behaviour, performance or compromise
their security properties by malicious third   their security properties by malicious third
parties exploiting the system’s                parties exploiting the system’s
vulnerabilities. Cyberattacks against AI       vulnerabilities. Cyberattacks against AI
systems can leverage AI specific assets,       systems can leverage AI specific assets,
such as training data sets (e.g. data          such as training data sets (e.g. data
poisoning) or trained models (e.g.             poisoning) or trained models (e.g.
adversarial attacks), or exploit               adversarial attacks or confidentiality
vulnerabilities in the AI system’s digital     attacks), or exploit vulnerabilities in the AI
assets or the underlying ICT infrastructure.   system’s digital assets or the underlying
To ensure a level of cybersecurity             ICT infrastructure. To ensure a level of
appropriate to the risks, suitable measures    cybersecurity appropriate to the risks,
should therefore be taken by the providers     suitable measures should therefore be taken
of high-risk AI systems, also taking into      by the providers of high-risk AI systems,
account as appropriate the underlying ICT      as well as the notified bodies, competent
infrastructure.                                national authorities and market
                                               surveillance authorities, also taking into
                                               account as appropriate the underlying ICT
                                               infrastructure. High-risk AI should be
                                               accompanied by security solutions and
                                               patches for the lifetime of the product, or
                                               in case of the absence of dependence on a
                                               specific product, for a time that needs to
                                               be stated by the manufacturer.


Amendment 88
Proposal for a regulation
Recital 53 a (new)

    Text proposed by the Commission                         Amendment

                                             (53a) As signatories to the United Nations
                                             Convention on the Rights of Persons with
                                             Disabilities (UNCRPD), the Union and
                                             the Member States are legally obliged to
                                             protect persons with disabilities from
                                             discrilmination and promote their
                                             equality, to ensure that persons with
                                             disabilities have access, on an equal basis
                                             wirh others, to information and
                                             communications technologies and
                                             systems, and to ensure respect for privacy
                                             for persons with disabilities. Given the
                                             growing importance and use of AI
                                             systems, the application of universal
                                             design principles to all new technologies
                                             and services should ensure full, equal,
                                             and unrestricted access for everyone
                                             potentially affected by or using AI
                                             technologies, including persons with
                                             disabilities, in a way that takes full
                                             account of their inherent dignity and
                                             diversity. It is therefore essential that
                                             Providers ensure full compliance with
                                             accessibility requirements, including
                                             Directive (EU) 2016/2102 and Directive
                                             (EU) 2019/882. Providers should ensure
                                             compliance with these requirements by
                                             design. Therefore, the necessary measures
                                             should be integrated as much as possible
                                             into the design of the high-risk AI system.


Amendment 89

Proposal for a regulation
Recital 54

    Text proposed by the Commission                         Amendment

(54) The provider should establish a         (54) The provider should establish a
sound quality management system, ensure      sound quality management system, ensure
the accomplishment of the required           the accomplishment of the required
conformity assessment procedure, draw up     conformity assessment procedure, draw up
the relevant documentation and establish a   the relevant documentation and establish a
robust post-market monitoring system.          robust post-market monitoring system. For
Public authorities which put into service      providers that have already in place
high-risk AI systems for their own use may     quality management systems based on
adopt and implement the rules for the          standards such as ISO 9001 or other
quality management system as part of the       relevant standards, no duplicative quality
quality management system adopted at a         management system in full should be
national or regional level, as appropriate,    expected but rather an adaptation of their
taking into account the specificities of the   existing systems to certain aspects linked
sector and the competences and                 to compliance with specific requirements
organisation of the public authority in        of this Regulation. This should also be
question.                                      reflected in future standardization
                                               activities or guidance adopted by the
                                               Commission in this respect. Public
                                               authorities which put into service high-risk
                                               AI systems for their own use may adopt
                                               and implement the rules for the quality
                                               management system as part of the quality
                                               management system adopted at a national
                                               or regional level, as appropriate, taking
                                               into account the specificities of the sector
                                               and the competences and organisation of
                                               the public authority in question.


Amendment 90

Proposal for a regulation
Recital 56

    Text proposed by the Commission                            Amendment

(56) To enable enforcement of this             (56) To enable enforcement of this
Regulation and create a level-playing field    Regulation and create a level-playing field
for operators, and taking into account the     for operators, and taking into account the
different forms of making available of         different forms of making available of
digital products, it is important to ensure    digital products, it is important to ensure
that, under all circumstances, a person        that, under all circumstances, a person
established in the Union can provide           established in the Union can provide
authorities with all the necessary             authorities with all the necessary
information on the compliance of an AI         information on the compliance of an AI
system. Therefore, prior to making their AI    system. Therefore, prior to making their AI
systems available in the Union, where an       systems available in the Union, providers
importer cannot be identified, providers       established outside the Union shall, by
established outside the Union shall, by        written mandate, appoint an authorised
written mandate, appoint an authorised         representative established in the Union.
representative established in the Union.


Amendment 91
Proposal for a regulation
Recital 58

    Text proposed by the Commission                            Amendment

(58) Given the nature of AI systems and        (58) Given the nature of AI systems and
the risks to safety and fundamental rights     the risks to safety and fundamental rights
possibly associated with their use,            possibly associated with their use,
including as regard the need to ensure         including as regards the need to ensure
proper monitoring of the performance of an     proper monitoring of the performance of an
AI system in a real-life setting, it is        AI system in a real-life setting, it is
appropriate to set specific responsibilities   appropriate to set specific responsibilities
for users. Users should in particular use      for deployers. Deployers should in
high-risk AI systems in accordance with        particular use high-risk AI systems in
the instructions of use and certain other      accordance with the instructions of use and
obligations should be provided for with        certain other obligations should be
regard to monitoring of the functioning of     provided for with regard to monitoring of
the AI systems and with regard to record-      the functioning of the AI systems and with
keeping, as appropriate.                       regard to record-keeping, as appropriate.


Amendment 92

Proposal for a regulation
Recital 58 a (new)

    Text proposed by the Commission                            Amendment

                                               (58a) Whilst risks related to AI systems
                                               can result from the way such systems are
                                               designed, risks can as well stem from how
                                               such AI systems are used. Deployers of
                                               high-risk AI system therefore play a
                                               critical role in ensuring that fundamental
                                               rights are protected, complementing the
                                               obligations of the provider when
                                               developing the AI system. Deployers are
                                               best placed to understand how the high-
                                               risk AI system will be used concretely and
                                               can therefore identify potential significant
                                               risks that were not foreseen in the
                                               development phase, due to a more precise
                                               knowledge of the context of use, the
                                               people or groups of people likely to be
                                               affected, including marginalised and
                                               vulnerable groups. Deployers should
                                               identify appropriate governance
                                               structures in that specific context of use,
                                               such as arrangements for human
                                               oversight, complaint-handling procedures
               and redress procedures, because choices
               in the governance structures can be
               instrumental in mitigating risks to
               fundamental rights in concrete use-cases.
               In order to efficiently ensure that
               fundamental rights are protected, the
               deployer of high-risk AI systems should
               therefore carry out a fundamental rights
               impact assessment prior to putting it into
               use. The impact assessment should be
               accompanied by a detailed plan describing
               the measures or tools that will help
               mitigating the risks to fundamental rights
               identified at the latest from the time of
               putting it into use. If such plan cannot be
               identified, the deployer should refrain
               from putting the system into use. When
               performing this impact assessment, the
               deployer should notify the national
               supervisory authority and, to the best
               extent possible relevant stakeholders as
               well as representatives of groups of
               persons likely to be affected by the AI
               system in order to collect relevant
               information which is deemed necessary to
               perform the impact assessment and are
               encouraged to make the summary of their
               fundamental rights impact assessment
               publicly available on their online website.
               This obligations should not apply to
               SMEs which, given the lack of resrouces,
               might find it difficult to perform such
               consultation. Nevertheless, they should
               also strive to invole such representatives
               when carrying out their fundamental
               rights impact assessment.In addition,
               given the potential impact and the need
               for democratic oversight and scrutiny,
               deployers of high-risk AI systems that are
               public authorities or Union institutions,
               bodies, offices and agencies, as well
               deployers who are undertakings
               designated as a gatekeeper under
               Regulation (EU) 2022/1925 should be
               required to register the use of any high-
               risk AI system in a public database. Other
               deployers may voluntarily register.


Amendment 93
Proposal for a regulation
Recital 59

     Text proposed by the Commission                            Amendment

(59) It is appropriate to envisage that the     (59) It is appropriate to envisage that the
user of the AI system should be the natural     deployer of the AI system should be the
or legal person, public authority, agency or    natural or legal person, public authority,
other body under whose authority the AI         agency or other body under whose
system is operated except where the use is      authority the AI system is operated except
made in the course of a personal non-           where the use is made in the course of a
professional activity.                          personal non-professional activity.


Amendment 94

Proposal for a regulation
Recital 60

     Text proposed by the Commission                            Amendment

(60) In the light of the complexity of the      (60) Within the AI value chain multiple
artificial intelligence value chain, relevant   entities often supply tools and services but
third parties, notably the ones involved in     also components or processes that are
the sale and the supply of software,            then incorporated by the provider into the
software tools and components, pre-trained      AI system, including in relation to data
models and data, or providers of network        collection and pre-processing, model
services, should cooperate, as appropriate,     training, model retraining, model testing
with providers and users to enable their        and evaluation, integration into software,
compliance with the obligations under this      or other aspects of model development.
Regulation and with competent                   The involved entities may make their
authorities established under this              offering commercially available directly
Regulation.                                     or indirectly, through interfaces, such as
                                                Application Programming Interfaces
                                                (API), and distributed under free and
                                                open source licenses but also more and
                                                more by AI workforce platforms, trained
                                                parameters resale, DIY kits to build
                                                models or the offering of paying access to
                                                a model serving architecture to develop
                                                and train models. In the light of this
                                                complexity of the AI value chain, all
                                                relevant third parties, in particular those
                                                that are involved in the development, sale
                                                and the commercial supply of software
                                                tools, components, pre-trained models or
                                                data incorporated into the AI system, or
                                                providers of network services, should
                                                without compromising their own
                                      intellectual property rights or trade
                                      secrets, make available the required
                                      information, training or expertise and
                                      cooperate, as appropriate, with providers to
                                      enable their control over all compliance
                                      relevant aspects of the AI system that falls
                                      under this Regulation. To allow a cost-
                                      effective AI value chain governance, the
                                      level of control shall be explicitly
                                      disclosed by each third party that supplies
                                      the provider with a tool, service,
                                      component or process that is later
                                      incorporated by the provider into the AI
                                      system.


Amendment 95

Proposal for a regulation
Recital 60 a (new)

    Text proposed by the Commission                   Amendment

                                      (60a) Where one party is in a stronger
                                      bargaining position, there is a risk that
                                      that party could leverage such position to
                                      the detriment of the other contracting
                                      party when negotiating the supply of tools,
                                      services, components or processes that are
                                      used or integrated in a high risk AI
                                      system or the remedies for the breach or
                                      the termination of related obligations.
                                      Such contractual imbalances particularly
                                      harm micro, small and medium-sized
                                      enterprises as well as start-ups, unless
                                      they are owned or sub-contracted by an
                                      enterprise which is able to compensate the
                                      sub-contractor appropriately, as they are
                                      without a meaningful ability to negotiate
                                      the conditions of the contractual
                                      agreement, and may have no other choice
                                      than to accept ‘take-it-or-leave-it’
                                      contractual terms. Therefore, unfair
                                      contract terms regulating the supply of
                                      tools, services, components or processes
                                      that are used or integrated in a high risk
                                      AI system or the remedies for the breach
                                      or the termination of related obligations
                                      should not be binding to such micro,
                                      small or medium-sized enterprises and
                                      start-ups when they have been unilaterally
                                      imposed on them.


Amendment 96

Proposal for a regulation
Recital 60 b (new)

    Text proposed by the Commission                  Amendment

                                      (60b) Rules on contractual terms should
                                      take into account the principle of
                                      contractual freedom as an essential
                                      concept in business-to-business
                                      relationships. Therefore, not all
                                      contractual terms should be subject to an
                                      unfairness test, but only to those terms
                                      that are unilaterally imposed on micro,
                                      small and medium-sized enterprises and
                                      start-ups. This concerns ‘take-it-or-leave-
                                      it’ situations where one party supplies a
                                      certain contractual term and the micro,
                                      small or medium-sized enterprise and
                                      start-up cannot influence the content of
                                      that term despite an attempt to negotiate
                                      it. A contractual term that is simply
                                      provided by one party and accepted by the
                                      micro, small, medium-sized enterprise or
                                      a start-up or a term that is negotiated and
                                      subsequently agreed in an amended way
                                      between contracting parties should not be
                                      considered as unilaterally imposed.


Amendment 97

Proposal for a regulation
Recital 60 c (new)

    Text proposed by the Commission                  Amendment

                                      (60c) Furthermore, the rules on unfair
                                      contractual terms should only apply to
                                      those elements of a contract that are
                                      related to supply of tools, services,
                                      components or processes that are used or
                                      integrated in a high risk AI system or the
                                      remedies for the breach or the
                                      termination of related obligations. Other
                                      parts of the same contract, unrelated to
                                      these elements, should not be subject to
                                      the unfairness test laid down in this
                                      Regulation.


Amendment 98

Proposal for a regulation
Recital 60 d (new)

    Text proposed by the Commission                   Amendment

                                      (60d) Criteria to identify unfair
                                      contractual terms should be applied only
                                      to excessive contractual terms, where a
                                      stronger bargaining position is abused.
                                      The vast majority of contractual terms
                                      that are commercially more favourable to
                                      one party than to the other, including
                                      those that are normal in business-to-
                                      business contracts, are a normal
                                      expression of the principle of contractual
                                      freedom and continue to apply. If a
                                      contractual term is not included in the list
                                      of terms that are always considered
                                      unfair, the general unfairness provision
                                      applies. In this regard, the terms listed as
                                      unfair terms should serve as a yardstick to
                                      interpret the general unfairness provision.


Amendment 99

Proposal for a regulation
Recital 60 e (new)

    Text proposed by the Commission                   Amendment

                                      (60e) Foundation models are a recent
                                      development, in which AI models are
                                      developed from algorithms designed to
                                      optimize for generality and versatility of
                                      output. Those models are often trained on
                                      a broad range of data sources and large
                                      amounts of data to accomplish a wide
                                      range of downstream tasks, including
                                      some for which they were not specifically
                                      developed and trained. The foundation
                                      model can be unimodal or multimodal,
                                      trained through various methods such as
                                      supervised learning or reinforced
                                      learning. AI systems with specific
                                      intended purpose or general purpose AI
                                      systems can be an implementation of a
                                      foundation model, which means that each
                                      foundation model can be reused in
                                      countless downstream AI or general
                                      purpose AI systems. These models hold
                                      growing importance to many downstream
                                      applications and systems.


Amendment 100

Proposal for a regulation
Recital 60 f (new)

    Text proposed by the Commission                    Amendment

                                      (60f) In the case of foundation models
                                      provided as a service such as through API
                                      access, the cooperation with downstream
                                      providers should extend throughout the
                                      time during which that service is provided
                                      and supported, in order to enable
                                      appropriate risk mitigation, unless the
                                      provider of the foundation model
                                      transfers the training model as well as
                                      extensive and appropriate information on
                                      the datasets and the development process
                                      of the system or restricts the service, such
                                      as the API access, in such a way that the
                                      downstream provider is able to fully
                                      comply with this Regulation without
                                      further support from the original provider
                                      of the foundation model.


Amendment 101

Proposal for a regulation
Recital 60 g (new)

    Text proposed by the Commission                    Amendment

                                      (60g) In light of the nature and
                                      complexity of the value chain for AI
                                      system, it is essential to clarify the role of
                                      actors contributing to the development of
AI systems. There is significant
uncertainty as to the way foundation
models will evolve, both in terms of
typology of models and in terms of self-
governance. Therefore, it is essential to
clarify the legal situation of providers of
foundation models. Combined with their
complexity and unexpected impact, the
downstream AI provider’s lack of control
over the foundation model’s development
and the consequent power imbalance and
in order to ensure a fair sharing of
responsibilities along the AI value chain,
such models should be subject to
proportionate and more specific
requirements and obligations under this
Regulation, namely foundation models
should assess and mitigate possible risks
and harms through appropriate design,
testing and analysis, should implement
data governance measures, including
assessment of biases, and should comply
with technical design requirements to
ensure appropriate levels of performance,
predictability, interpretability,
corrigibility, safety and cybersecurity and
should comply with environmental
standards. These obligations should be
accompanied by standards. Also,
foundation models should have
information obligations and prepare all
necessary technical documentation for
potential downstream providers to be able
to comply with their obligations under this
Regulation. Generative foundation
models should ensure transparency about
the fact the content is generated by an AI
system, not by humans. These specific
requirements and obligations do not
amount to considering foundation models
as high risk AI systems, but should
guarantee that the objectives of this
Regulation to ensure a high level of
protection of fundamental rights, health
and safety, environment, democracy and
rule of law are achieved. Pre-trained
models developed for a narrower, less
general, more limited set of applications
that cannot be adapted for a wide range of
tasks such as simple multi-purpose AI
                                      systems should not be considered
                                      foundation models for the purposes of this
                                      Regulation, because of their greater
                                      interpretability which makes their
                                      behaviour less unpredictable.


Amendment 102

Proposal for a regulation
Recital 60 h (new)

    Text proposed by the Commission                   Amendment

                                      (60h) Given the nature of foundation
                                      models, expertise in conformity
                                      assessment is lacking and third-party
                                      auditing methods are still under
                                      development . The sector itself is therefore
                                      developing new ways to assess
                                      fundamental models that fulfil in part the
                                      objective of auditing (such as model
                                      evaluation, red-teaming or machine
                                      learning verification and validation
                                      techniques). Those internal assessments
                                      for foundation models should be should
                                      be broadly applicable (e.g. independent of
                                      distribution channels, modality,
                                      development methods), to address risks
                                      specific to such models taking into
                                      account industry state-of-the-art practices
                                      and focus on developing sufficient
                                      technical understanding and control over
                                      the model, the management of reasonably
                                      foreseeable risks, and extensive analysis
                                      and testing of the model through
                                      appropriate measures, such as by the
                                      involvement of independent evaluators. As
                                      foundation models are a new and fast-
                                      evolving development in the field of
                                      artificial intelligence, it is appropriate for
                                      the Commission and the AI Office to
                                      monitor and periodically asses the
                                      legislative and governance framework of
                                      such models and in particular of
                                      generative AI systems based on such
                                      models, which raise significant questions
                                      related to the generation of content in
                                      breach of Union law, copyright rules, and
                                      potential misuse. It should be clarified
                                             that this Regulation should be without
                                             prejudice to Union law on copyright and
                                             related rights, including Directives
                                             2001/29/EC, 2004/48/ECR and (EU)
                                             2019/790 of the European Parliament and
                                             of the Council.


Amendment 103

Proposal for a regulation
Recital 61

    Text proposed by the Commission                          Amendment

(61) Standardisation should play a key       (61) Standardisation should play a key
role to provide technical solutions to       role to provide technical solutions to
providers to ensure compliance with this     providers to ensure compliance with this
Regulation. Compliance with harmonised       Regulation. Compliance with harmonised
standards as defined in Regulation (EU)      standards as defined in Regulation (EU)
No 1025/2012 of the European Parliament      No 1025/2012 of the European Parliament
and of the Council54 should be a means for   and of the Council[1] should be a means
providers to demonstrate conformity with     for providers to demonstrate conformity
the requirements of this Regulation.         with the requirements of this Regulation.
However, the Commission could adopt          To ensure the effectiveness of standards
common technical specifications in areas     as policy tool for the Union and
where no harmonised standards exist or       considering the importance of standards
where they are insufficient.                 for ensuring conformity with the
                                             requirements of this Regulation and for
                                             the competitiveness of undertakings, it is
                                             necessary to ensure a balanced
                                             representation of interests by involving all
                                             relevant stakeholders in the development
                                             of standards. The standardisation process
                                             should be transparent in terms of legal
                                             and natural persons participating in the
                                             standardisation activities.
__________________                           __________________
54 Regulation (EU) No 1025/2012 of the       54 Regulation (EU) No 1025/2012 of the

European Parliament and of the Council of    European Parliament and of the Council of
25 October 2012 on European                  25 October 2012 on European
standardisation, amending Council            standardisation, amending Council
Directives 89/686/EEC and 93/15/EEC and      Directives 89/686/EEC and 93/15/EEC and
Directives 94/9/EC, 94/25/EC, 95/16/EC,      Directives 94/9/EC, 94/25/EC, 95/16/EC,
97/23/EC, 98/34/EC, 2004/22/EC,              97/23/EC, 98/34/EC, 2004/22/EC,
2007/23/EC, 2009/23/EC and 2009/105/EC       2007/23/EC, 2009/23/EC and 2009/105/EC
of the European Parliament and of the        of the European Parliament and of the
Council and repealing Council Decision       Council and repealing Council Decision
87/95/EEC and Decision No                    87/95/EEC and Decision No
1673/2006/EC of the European Parliament     1673/2006/EC of the European Parliament
and of the Council (OJ L 316, 14.11.2012,   and of the Council (OJ L 316, 14.11.2012,
p. 12).                                     p. 12).


Amendment 104

Proposal for a regulation
Recital 61 a (new)

    Text proposed by the Commission                         Amendment

                                            (61a) In order to facilitate compliance, the
                                            first standardisation requests should be
                                            issued by the Commission two months
                                            after the entry into force of this
                                            Regulation at the latest. This should serve
                                            to improve legal certainty, thereby
                                            promoting investment and innovation in
                                            AI, as well as competitiveness and growth
                                            of the Union market, while enhancing
                                            multistakeholder governance representing
                                            all relevant European stakeholders such
                                            as the AI Office, European
                                            standardisation organisations and bodies
                                            or experts groups established under
                                            relevant sectorial Union law as well as
                                            industry, SMEs, start-ups, civil society,
                                            researchers and social partners, and
                                            should ultimately facilitate global
                                            cooperation on standardisation in the
                                            field of AI in a manner consistent with
                                            Union values. When preparing the
                                            standardisation request, the Commission
                                            should consult the AI Office and the AI
                                            advisory Forum in order to collect
                                            relevant expertise.


Amendment 105

Proposal for a regulation
Recital 61 b (new)

    Text proposed by the Commission                         Amendment

                                            (61b) When AI systems are intended to be
                                            used at the workplace, harmonised
                                            standards should be limited to technical
                                      specifications and procedures.


Amendment 106

Proposal for a regulation
Recital 61 c (new)

    Text proposed by the Commission                  Amendment

                                      (61c) The Commission should be able to
                                      adopt common specifications under
                                      certain conditions, when no relevant
                                      harmonised standard exists or to address
                                      specific fundamental rights concerns.
                                      Through the whole drafting process, the
                                      Commission should regularly consult the
                                      AI Office and its advisory forum, the
                                      European standardisation organisations
                                      and bodies or expert groups established
                                      under relevant sectorial Union law as well
                                      as relevant stakeholders, such as industry,
                                      SMEs, start-ups, civil society, researchers
                                      and social partners.


Amendment 107

Proposal for a regulation
Recital 61 d (new)

    Text proposed by the Commission                  Amendment

                                      (61d) When adopting common
                                      specifications, the Commission should
                                      strive for regulatory alignment of AI with
                                      likeminded global partners, which is key
                                      to fostering innovation and cross-border
                                      partnerships within the field of AI, as
                                      coordination with likeminded partners in
                                      international standardisation bodies is of
                                      great importance.


Amendment 108

Proposal for a regulation
Recital 62
     Text proposed by the Commission                             Amendment

(62) In order to ensure a high level of          (62) In order to ensure a high level of
trustworthiness of high-risk AI systems,         trustworthiness of high-risk AI systems,
those systems should be subject to a             those systems should be subject to a
conformity assessment prior to their             conformity assessment prior to their
placing on the market or putting into            placing on the market or putting into
service.                                         service. To increase the trust in the value
                                                 chain and to give certainty to businesses
                                                 about the performance of their systems,
                                                 third-parties that supply AI components
                                                 may voluntarily apply for a third-party
                                                 conformity assessment.


Amendment 109

Proposal for a regulation
Recital 64

     Text proposed by the Commission                             Amendment

(64) Given the more extensive experience         (64) Given the complexity of high-risk AI
of professional pre-market certifiers in the     systems and the risks that are associated
field of product safety and the different        to them, it is essential to develop a more
nature of risks involved, it is appropriate to   adequate capacity for the application of
limit, at least in an initial phase of           third party conformity assessment for
application of this Regulation, the scope of     high-risk AI systems. However, given the
application of third-party conformity            current experience of professional pre-
assessment for high-risk AI systems other        market certifiers in the field of product
than those related to products. Therefore,       safety and the different nature of risks
the conformity assessment of such systems        involved, it is appropriate to limit, at least
should be carried out as a general rule by       in an initial phase of application of this
the provider under its own responsibility,       Regulation, the scope of application of
with the only exception of AI systems            third-party conformity assessment for high-
intended to be used for the remote               risk AI systems other than those related to
biometric identification of persons, for         products. Therefore, the conformity
which the involvement of a notified body         assessment of such systems should be
in the conformity assessment should be           carried out as a general rule by the provider
foreseen, to the extent they are not             under its own responsibility, with the only
prohibited.                                      exception of AI systems intended to be
                                                 used for the remote biometric identification
                                                 of persons, or AI systems intended to be
                                                 used to make inferences about personal
                                                 characteristics of natural persons on the
                                                 basis of biometric or biometrics-based
                                                 data, including emotion recognition
                                                 systems for which the involvement of a
                                                 notified body in the conformity assessment
                                             should be foreseen, to the extent they are
                                             not prohibited


Amendment 110

Proposal for a regulation
Recital 65

    Text proposed by the Commission                          Amendment

(65) In order to carry out third-party       (65) In order to carry out third-party
conformity assessment for AI systems         conformity assessments when so required,
intended to be used for the remote           notified bodies should be designated under
biometric identification of persons,         this Regulation by the national competent
notified bodies should be designated under   authorities, provided they are compliant
this Regulation by the national competent    with a set of requirements, notably on
authorities, provided they are compliant     independence, competence, absence of
with a set of requirements, notably on       conflicts of interests and minimum
independence, competence and absence of      cybersecurity requirements. Member
conflicts of interests.                      States should encourage the designation
                                             of a sufficient number of conformity
                                             assessment bodies, in order to make the
                                             certification feasible in a timely manner.
                                             The procedures of assessment,
                                             designation, notification and monitoring
                                             of conformity assessment bodies should be
                                             implemented as uniformly as possible in
                                             Member States, with a view to removing
                                             administrative border barriers and
                                             ensuring that the potential of the internal
                                             market is realised.


Amendment 111

Proposal for a regulation
Recital 65 a (new)

    Text proposed by the Commission                          Amendment

                                             (65a) In line with Union commitments
                                             under the World Trade Organization
                                             Agreement on Technical Barriers to
                                             Trade, it is adequate to maximise the
                                             acceptance of test results produced by
                                             competent conformity assessment bodies,
                                             independent of the territory in which they
                                             are established, where necessary to
                                             demonstrate conformity with the
                                               applicable requirements of the
                                               Regulation. The Commission should
                                               actively explore possible international
                                               instruments for that purpose and in
                                               particular pursue the possible
                                               establishment of mutual recognition
                                               agreements with countries which are on a
                                               comparable level of technical
                                               development, and have compatible
                                               approach concerning AI and conformity
                                               assessment.


Amendment 112

Proposal for a regulation
Recital 66

    Text proposed by the Commission                            Amendment

(66) In line with the commonly                 (66) In line with the commonly
established notion of substantial              established notion of substantial
modification for products regulated by         modification for products regulated by
Union harmonisation legislation, it is         Union harmonisation legislation, it is
appropriate that an AI system undergoes a      appropriate that an high-risk AI system
new conformity assessment whenever a           undergoes a new conformity assessment
change occurs which may affect the             whenever an unplanned change occurs
compliance of the system with this             which goes beyond controlled or
Regulation or when the intended purpose        predetermined changes by the provider
of the system changes. In addition, as         including continuous learning and which
regards AI systems which continue to           may create a new unacceptable risk and
‘learn’ after being placed on the market or    significantly affect the compliance of the
put into service (i.e. they automatically      high-risk AI system with this Regulation
adapt how functions are carried out), it is    or when the intended purpose of the system
necessary to provide rules establishing that   changes. In addition, as regards AI systems
changes to the algorithm and its               which continue to ‘learn’ after being
performance that have been pre-determined      placed on the market or put into service
by the provider and assessed at the moment     (i.e. they automatically adapt how
of the conformity assessment should not        functions are carried out), it is necessary to
constitute a substantial modification.         provide rules establishing that changes to
                                               the algorithm and its performance that have
                                               been pre-determined by the provider and
                                               assessed at the moment of the conformity
                                               assessment should not constitute a
                                               substantial modification. The same should
                                               apply to updates of the AI system for
                                               security reasons in general and to protect
                                               against evolving threats of manipulation
                                               of the system, provided that they do not
                                               amount to a substantial modification
Amendment 113

Proposal for a regulation
Recital 67

    Text proposed by the Commission                            Amendment

(67) High-risk AI systems should bear the      (67) High-risk AI systems should bear the
CE marking to indicate their conformity        CE marking to indicate their conformity
with this Regulation so that they can move     with this Regulation so that they can move
freely within the internal market. Member      freely within the internal market. For
States should not create unjustified           physical high-risk AI systems, a physical
obstacles to the placing on the market or      CE marking should be affixed, and may
putting into service of high-risk AI systems   be complemented by a digital CE
that comply with the requirements laid         marking. For digital only high-risk AI
down in this Regulation and bear the CE        systems, a digital CE marking should be
marking.                                       used. Member States should not create
                                               unjustified obstacles to the placing on the
                                               market or putting into service of high-risk
                                               AI systems that comply with the
                                               requirements laid down in this Regulation
                                               and bear the CE marking.


Amendment 114

Proposal for a regulation
Recital 68

    Text proposed by the Commission                            Amendment

(68) Under certain conditions, rapid           (68) Under certain conditions, rapid
availability of innovative technologies may    availability of innovative technologies may
be crucial for health and safety of persons    be crucial for health and safety of persons,
and for society as a whole. It is thus         the environment and climate change and
appropriate that under exceptional reasons     for society as a whole. It is thus appropriate
of public security or protection of life and   that under exceptional reasons of
health of natural persons and the protection   protection of life and health of natural
of industrial and commercial property,         persons, environmental protection and the
Member States could authorise the placing      protection of critical infrastructure,
on the market or putting into service of AI    Member States could authorise the placing
systems which have not undergone a             on the market or putting into service of AI
conformity assessment.                         systems which have not undergone a
                                               conformity assessment.


Amendment 115
Proposal for a regulation
Recital 69

    Text proposed by the Commission                            Amendment

(69) In order to facilitate the work of the    (69) In order to facilitate the work of the
Commission and the Member States in the        Commission and the Member States in the
artificial intelligence field as well as to    artificial intelligence field as well as to
increase the transparency towards the          increase the transparency towards the
public, providers of high-risk AI systems      public, providers of high-risk AI systems
other than those related to products falling   other than those related to products falling
within the scope of relevant existing Union    within the scope of relevant existing Union
harmonisation legislation, should be           harmonisation legislation, should be
required to register their high-risk AI        required to register their high-risk AI
system in a EU database, to be established     system and foundation models in a EU
and managed by the Commission. The             database, to be established and managed by
Commission should be the controller of         the Commission. This database should be
that database, in accordance with              freely and publicly accessible, easily
Regulation (EU) 2018/1725 of the               understandable and machine-readable.
European Parliament and of the Council55 .     The database should also be user-friendly
In order to ensure the full functionality of   and easily navigable, with search
the database, when deployed, the procedure     functionalities at minimum allowing the
for setting the database should include the    general public to search the database for
elaboration of functional specifications by    specific high-risk systems, locations,
the Commission and an independent audit        categories of risk under Annex IV and
report.                                        keywords. Deployers who are public
                                               authorities or Union institutions, bodies,
                                               offices and agencies or deployers acting
                                               on their behalf and deployers who are
                                               undertakings designated as a gatekeeper
                                               under Regulation (EU)2022/1925 should
                                               also register in the EU database before
                                               putting into service or using a high-risk
                                               AI system for the first time and following
                                               each substantial modification. Other
                                               deployers should be entitled to do so
                                               voluntarily. Any substantial modification
                                               of high-risk AI systems shall also be
                                               registered in the EU database. The
                                               Commission should be the controller of
                                               that database, in accordance with
                                               Regulation (EU) 2018/1725 of the
                                               European Parliament and of the Council55.
                                               In order to ensure the full functionality of
                                               the database, when deployed, the procedure
                                               for setting the database should include the
                                               elaboration of functional specifications by
                                               the Commission and an independent audit
                                               report. The Commission should take into
                                               account cybersecurity and hazard-related
                                               risks when carrying out its tasks as data
                                               controller on the EU database. In order to
                                               maximise the availability and use of the
                                               database by the public, the database,
                                               including the information made available
                                               through it, should comply with
                                               requirements under the Directive
                                               2019/882.
__________________                             __________________
55 Regulation (EU) 2016/679 of the             55 Regulation (EU) 2016/679 of the

European Parliament and of the Council of      European Parliament and of the Council of
27 April 2016 on the protection of natural     27 April 2016 on the protection of natural
persons with regard to the processing of       persons with regard to the processing of
personal data and on the free movement of      personal data and on the free movement of
such data, and repealing Directive             such data, and repealing Directive
95/46/EC (General Data Protection              95/46/EC (General Data Protection
Regulation) (OJ L 119, 4.5.2016, p. 1).        Regulation) (OJ L 119, 4.5.2016, p. 1).


Amendment 116

Proposal for a regulation
Recital 71

    Text proposed by the Commission                           Amendment

(71) Artificial intelligence is a rapidly      (71) Artificial intelligence is a rapidly
developing family of technologies that         developing family of technologies that
requires novel forms of regulatory             requires regulatory oversight and a safe
oversight and a safe space for                 and controlled space for experimentation,
experimentation, while ensuring                while ensuring responsible innovation and
responsible innovation and integration of      integration of appropriate safeguards and
appropriate safeguards and risk mitigation     risk mitigation measures. To ensure a legal
measures. To ensure a legal framework that     framework that promotes innovation, is
is innovation-friendly, future-proof and       future-proof, and resilient to disruption,
resilient to disruption, national competent    Member States should establish at least
authorities from one or more Member            one artificial intelligence regulatory
States should be encouraged to establish       sandbox to facilitate the development and
artificial intelligence regulatory sandboxes   testing of innovative AI systems under
to facilitate the development and testing of   strict regulatory oversight before these
innovative AI systems under strict             systems are placed on the market or
regulatory oversight before these systems      otherwise put into service. It is indeed
are placed on the market or otherwise put      desirable for the establishment of
into service.                                  regulatory sandboxes, whose
                                               establishment is currently left at the
                                               discretion of Member States, as a next
                                               step to be made mandatory with
                                               established criteria. That mandatory
                                               sandbox could also be established jointly
                                              with one or several other Member States,
                                              as long as that sandbox would cover the
                                              respective national level of the involved
                                              Member States. Additional sandboxes may
                                              also be established at different levels,
                                              including cross Member States, in order
                                              to facilitate cross-border cooperation and
                                              synergies. With the exception of the
                                              mandatory sandbox at national level,
                                              Member States should also be able to
                                              establish virtual or hybrid sandboxes. All
                                              regulatory sandboxes should be able to
                                              accommodate both physical and virtual
                                              products. Establishing authorities should
                                              also ensure that the regulatory sandboxes
                                              have the adequate financial and human
                                              resources for their functioning.


Amendment 117

Proposal for a regulation
Recital 72

    Text proposed by the Commission                          Amendment

(72) The objectives of the regulatory         (72) The objectives of the regulatory
sandboxes should be to foster AI              sandboxes should be: for the establishing
innovation by establishing a controlled       authorities to increase their
experimentation and testing environment       understanding of technical developments,
in the development and pre-marketing          improve supervisory methods and provide
phase with a view to ensuring compliance      guidance to AI systems developers and
of the innovative AI systems with this        providers to achieve regulatory
Regulation and other relevant Union and       compliance with this Regulation or where
Member States legislation; to enhance legal   relevant, other applicable Union and
certainty for innovators and the competent    Member States legislation, as well as with
authorities’ oversight and understanding      the Charter of Fundamental Rights ; for
of the opportunities, emerging risks and      the prospective providers to allow and
the impacts of AI use, and to accelerate      facilitate the testing and development of
access to markets, including by removing      innovative solutions related to AI systems
barriers for small and medium enterprises     in the pre-marketing phase to enhance
(SMEs) and start-ups. To ensure uniform       legal certainty, to allow for more
implementation across the Union and           regulatory learning by establishing
economies of scale, it is appropriate to      authorities in a controlled environment to
establish common rules for the regulatory     develop better guidance and to identify
sandboxes’ implementation and a               possible future improvements of the legal
framework for cooperation between the         framework through the ordinary
relevant authorities involved in the          legislative procedure. Any significant
supervision of the sandboxes. This            risks identified during the development
Regulation should provide the legal basis     and testing of such AI systems should
for the use of personal data collected for    result in immediate mitigation and, failing
other purposes for developing certain AI      that, in the suspension of the development
systems in the public interest within the     and testing process until such mitigation
AI regulatory sandbox, in line with Article   takes place. To ensure uniform
6(4) of Regulation (EU) 2016/679, and         implementation across the Union and
Article 6 of Regulation (EU) 2018/1725,       economies of scale, it is appropriate to
and without prejudice to Article 4(2) of      establish common rules for the regulatory
Directive (EU) 2016/680. Participants in      sandboxes’ implementation and a
the sandbox should ensure appropriate         framework for cooperation between the
safeguards and cooperate with the             relevant authorities involved in the
competent authorities, including by           supervision of the sandboxes. Member
following their guidance and acting           States should ensure that regulatory
expeditiously and in good faith to mitigate   sandboxes are widely available
any high-risks to safety and fundamental      throughout the Union, while the
rights that may arise during the              participation should remain voluntary. It
development and experimentation in the        is especially important to ensure that
sandbox. The conduct of the participants      SMEs and startups can easily access these
in the sandbox should be taken into           sandboxes, are actively involved and
account when competent authorities            participate in the development and testing
decide whether to impose an                   of innovative AI systems, in order to be
administrative fine under Article 83(2) of    able to contribute with their knowhow and
Regulation 2016/679 and Article 57 of         experience.
Directive 2016/680.


Amendment 118

Proposal for a regulation
Recital 72 a (new)

    Text proposed by the Commission                          Amendment

                                              (72a) This Regulation should provide the
                                              legal basis for the use of personal data
                                              collected for other purposes for
                                              developing certain AI systems in the
                                              public interest within the AI regulatory
                                              sandbox only under specified conditions
                                              in line with Article 6(4) of Regulation
                                              (EU) 2016/679, and Article 6 of
                                              Regulation (EU) 2018/1725, and without
                                              prejudice to Article 4(2) of Directive (EU)
                                              2016/680. Prospective providers in the
                                              sandbox should ensure appropriate
                                              safeguards and cooperate with the
                                              competent authorities, including by
                                              following their guidance and acting
                                              expeditiously and in good faith to mitigate
                                              any high-risks to safety, health and the
                                              environment and fundamental rights that
                                                 may arise during the development and
                                                 experimentation in the sandbox. The
                                                 conduct of the prospective providers in the
                                                 sandbox should be taken into account
                                                 when competent authorities decide over
                                                 the temporary or permanent suspension of
                                                 their participation in the sandbox whether
                                                 to impose an administrative fine under
                                                 Article 83(2) of Regulation 2016/679 and
                                                 Article 57 of Directive 2016/680.


Amendment 119

Proposal for a regulation
Recital 72 b (new)

     Text proposed by the Commission                              Amendment

                                                 (72b) To ensure that Artificial Intelligence
                                                 leads to socially and environmentally
                                                 beneficial outcomes, Member States
                                                 should support and promote research and
                                                 development of AI in support of socially
                                                 and environmentally beneficial outcomes
                                                 by allocating sufficient resources,
                                                 including public and Union funding, and
                                                 giving priority access to regulatory
                                                 sandboxes to projects led by civil society.
                                                 Such projects should be based on the
                                                 principle of interdisciplinary cooperation
                                                 between AI developers, experts on
                                                 inequality and non-discrimination,
                                                 accessibility, consumer, environmental,
                                                 and digital rights, as well as academics


Amendment 120

Proposal for a regulation
Recital 73

     Text proposed by the Commission                              Amendment

(73) In order to promote and protect             (73) In order to promote and protect
innovation, it is important that the interests   innovation, it is important that the interests
of small-scale providers and users of AI         of small-scale providers and users of AI
systems are taken into particular account.       systems are taken into particular account.
To this objective, Member States should          To this objective, Member States should
develop initiatives, which are targeted at       develop initiatives, which are targeted at
those operators, including on awareness        those operators, including on AI literacy,
raising and information communication.         awareness raising and information
Moreover, the specific interests and needs     communication. Member States shall
of small-scale providers shall be taken into   utilise existing channels and where
account when Notified Bodies set               appropriate, establish new dedicated
conformity assessment fees. Translation        channels for communication with SMEs,
costs related to mandatory documentation       start-ups, user and other innovators to
and communication with authorities may         provide guidance and respond to queries
constitute a significant cost for providers    about the implementation of this
and other operators, notably those of a        Regulation. Such existing channels could
smaller scale. Member States should            include but are not limited to ENISA’s
possibly ensure that one of the languages      Computer Security Incident Response
determined and accepted by them for            Teams, National Data Protection
relevant providers’ documentation and for      Agencies, the AI-on demand platform, the
communication with operators is one            European Digital Innovation Hubs and
which is broadly understood by the largest     other relevant instruments funded by EU
possible number of cross-border users.         programmes as well as the Testing and
                                               Experimentation Facilities established by
                                               the Commission and the Member States at
                                               national or Union level. Where
                                               appropriate, these channels shall work
                                               together to create synergies and ensure
                                               homogeneity in their guidance to start-
                                               ups, SMEs and users. Moreover, the
                                               specific interests and needs of small-scale
                                               providers shall be taken into account when
                                               Notified Bodies set conformity assessment
                                               fees. The Commission shall regularly
                                               assess the certification and compliance
                                               costs for SMEs and start-ups, including
                                               through transparent consultations with
                                               SMEs, start-ups and users and shall work
                                               with Member States to lower such costs.
                                               For example, translation costs related to
                                               mandatory documentation and
                                               communication with authorities may
                                               constitute a significant cost for providers
                                               and other operators, notably those of a
                                               smaller scale. Member States should
                                               possibly ensure that one of the languages
                                               determined and accepted by them for
                                               relevant providers’ documentation and for
                                               communication with operators is one
                                               which is broadly understood by the largest
                                               possible number of cross-border users.
                                               Medium-sized enterprises which recently
                                               changed from the small to medium-size
                                               category within the meaning of the Annex
                                               to Recommendation 2003/361/EC (Article
                                               16) shall have access to these initiatives
                                               and guidance for a period of time deemed
                                               appropriate by the Member States, as
                                               these new medium-sized enterprises may
                                               sometimes lack the legal resources and
                                               training necessary to ensure proper
                                               understanding and compliance with
                                               provisions.



Amendment 121

Proposal for a regulation
Recital 74

    Text proposed by the Commission                            Amendment

(74) In order to minimise the risks to         (74) In order to minimise the risks to
implementation resulting from lack of          implementation resulting from lack of
knowledge and expertise in the market as       knowledge and expertise in the market as
well as to facilitate compliance of            well as to facilitate compliance of
providers and notified bodies with their       providers and notified bodies with their
obligations under this Regulation, the AI-     obligations under this Regulation, the AI-
on demand platform, the European Digital       on demand platform, the European Digital
Innovation Hubs and the Testing and            Innovation Hubs and the Testing and
Experimentation Facilities established by      Experimentation Facilities established by
the Commission and the Member States at        the Commission and the Member States at
national or EU level should possibly           national or EU level should contribute to
contribute to the implementation of this       the implementation of this Regulation.
Regulation. Within their respective mission    Within their respective mission and fields
and fields of competence, they may             of competence, they may provide in
provide in particular technical and            particular technical and scientific support
scientific support to providers and notified   to providers and notified bodies.
bodies.


Amendment 122

Proposal for a regulation
Recital 76

    Text proposed by the Commission                            Amendment

(76) In order to facilitate a smooth,          (76) In order to avoid fragmentation, to
effective and harmonised implementation        ensure the optimal functioning of the
of this Regulation a European Artificial       Single market, to ensure effective and
Intelligence Board should be established.      harmonised implementation of this
The Board should be responsible for a          Regulation, to achieve a high level of
number of advisory tasks, including issuing    trustworthiness and of protection of
opinions, recommendations, advice or           health and safety, fundamental rights, the
guidance on matters related to the              environment, democracy and the rule of
implementation of this Regulation,              law across the Union with regards to AI
including on technical specifications or        systems, to actively support national
existing standards regarding the                supervisory authorities, Union
requirements established in this                institutions, bodies, offices and agencies
Regulation and providing advice to and          in matters pertaining to this Regulation,
assisting the Commission on specific            and to increase the uptake of artificial
questions related to artificial intelligence.   intelligence throughout the Union, an
                                                European Union Artificial Intelligence
                                                Office should be established. The AI
                                                Office should have legal personality,
                                                should act in full independence, should be
                                                responsible for a number of advisory and
                                                coordination tasks, including issuing
                                                opinions, recommendations, advice or
                                                guidance on matters related to the
                                                implementation of this Regulation and
                                                should be adequately funded and staffed.
                                                Member States should provide the
                                                strategic direction and control of the AI
                                                Office through the management board of
                                                the AI Office, alongside the Commission,
                                                the EDPS, the FRA, and ENISA. An
                                                executive director should be responsible
                                                for managing the activities of the
                                                secretariat of the AI office and for
                                                representing the AI office. Stakeholders
                                                should formally participate in the work of
                                                the AI Office through an advisory forum
                                                that should ensure varied and balanced
                                                stakeholder representation and should
                                                advise the AI Office on matters pertaining
                                                to this Regulation. In case the
                                                establishment of the AI Office prove not
                                                to be sufficient to ensure a fully consistent
                                                application of this Regulation at Union
                                                level as well as efficient cross-border
                                                enforcement measures, the creation of an
                                                AI agency should be considered.


Amendment 123

Proposal for a regulation
Recital 77

     Text proposed by the Commission                            Amendment

(77) Member States hold a key role in the       (77) Each Member State should designate
application and enforcement of this             a national supervisory authority for the
Regulation. In this respect, each Member       purpose of supervising the application and
State should designate one or more             implementation of this Regulation. It
national competent authorities for the         should also represent its Member State at
purpose of supervising the application and     the management board of the AI Office.
implementation of this Regulation. In order    In order to increase organisation efficiency
to increase organisation efficiency on the     on the side of Member States and to set an
side of Member States and to set an official   official point of contact vis-à-vis the public
point of contact vis-à-vis the public and      and other counterparts at Member State
other counterparts at Member State and         and Union levels. Each national
Union levels, in each Member State one         supervisory authority should act with
national authority should be designated as     complete independence in performing its
national supervisory authority.                tasks and exercising its powers in
                                               accordance with this Regulation.


Amendment 124

Proposal for a regulation
Recital 77 a (new)

    Text proposed by the Commission                            Amendment

                                               (77a) The national supervisory authorities
                                               should monitor the application of the
                                               provisions pursuant to this Regulation
                                               and contribute to its consistent application
                                               throughout the Union. For that purpose,
                                               the national supervisory authorities
                                               should cooperate with each other, with the
                                               relevant national competent authorities,
                                               the Commission, and with the AI Office.


Amendment 125

Proposal for a regulation
Recital 77 b (new)

    Text proposed by the Commission                            Amendment

                                               (77b) The member or the staff of each
                                               national supervisory authority should, in
                                               accordance with Union or national law,
                                               be subject to a duty of professional
                                               secrecy both during and after their term
                                               of office, with regard to any confidential
                                               information which has come to their
                                               knowledge in the course of the
                                               performance of their tasks or exercise of
                                               their powers. During their term of office,
                                               that duty of professional secrecy should in
                                               particular apply to trade secrets and to
                                               reporting by natural persons of
                                               infringements of this Regulation


Amendment 126

Proposal for a regulation
Recital 78

    Text proposed by the Commission                            Amendment

(78) In order to ensure that providers of      (78) In order to ensure that providers of
high-risk AI systems can take into account     high-risk AI systems can take into account
the experience on the use of high-risk AI      the experience on the use of high-risk AI
systems for improving their systems and        systems for improving their systems and
the design and development process or can      the design and development process or can
take any possible corrective action in a       take any possible corrective action in a
timely manner, all providers should have a     timely manner, all providers should have a
post-market monitoring system in place.        post-market monitoring system in place.
This system is also key to ensure that the     This system is also key to ensure that the
possible risks emerging from AI systems        possible risks emerging from AI systems
which continue to ‘learn’ after being          which continue to ‘learn’ or evolve after
placed on the market or put into service       being placed on the market or put into
can be more efficiently and timely             service can be more efficiently and timely
addressed. In this context, providers should   addressed. In this context, providers should
also be required to have a system in place     also be required to have a system in place
to report to the relevant authorities any      to report to the relevant authorities any
serious incidents or any breaches to           serious incidents or any breaches to
national and Union law protecting              national and Union law, including those
fundamental rights resulting from the use      protecting fundamental rights and
of their AI systems.                           consumer rights resulting from the use of
                                               their AI systems and take appropriate
                                               corrective actions. Deployers should also
                                               report to the relevant authorities, any
                                               serious incidents or breaches to national
                                               and Union law resulting from the use of
                                               their AI system when they become aware
                                               of such serious incidents or breaches.


Amendment 127

Proposal for a regulation
Recital 79

    Text proposed by the Commission                            Amendment

(79) In order to ensure an appropriate and     (79) In order to ensure an appropriate and
effective enforcement of the requirements     effective enforcement of the requirements
and obligations set out by this Regulation,   and obligations set out by this Regulation,
which is Union harmonisation legislation,     which is Union harmonisation legislation,
the system of market surveillance and         the system of market surveillance and
compliance of products established by         compliance of products established by
Regulation (EU) 2019/1020 should apply        Regulation (EU) 2019/1020 should apply
in its entirety. Where necessary for their    in its entirety. For the purpose of this
mandate, national public authorities or       Regulation, national supervisory
bodies, which supervise the application of    authorities should act as market
Union law protecting fundamental rights,      surveillance authorities for AI systems
including equality bodies, should also have   covered by this Regulation except for AI
access to any documentation created under     systems covered by Annex II of this
this Regulation.                              Regulation. For AI systems covered by
                                              legal acts listed in the Annex II, the
                                              competent authorites under those legal
                                              acts should remain the lead authority.
                                              National supervisory authorities and
                                              competent authorities in the legal acts
                                              listed in Annex II should work together
                                              whenever necessary. When appropriate,
                                              the competent authorities in the legal acts
                                              listed in Annex II should send competent
                                              staff to the national supervisory authority
                                              in order to assist in the performance of its
                                              tasks. For the purpose of this Regulation,
                                              national supervisory authorities should
                                              have the same powers and obligations as
                                              market surveillance authorities under
                                              Regulation (EU) 2019/1020. Where
                                              necessary for their mandate, national
                                              public authorities or bodies, which
                                              supervise the application of Union law
                                              protecting fundamental rights, including
                                              equality bodies, should also have access to
                                              any documentation created under this
                                              Regulation. After having exhausted all
                                              other reasonable ways to assess/verify the
                                              conformity and upon a reasoned request,
                                              the national supervisory authority should
                                              be granted access to the training,
                                              validation and testing datasets, the trained
                                              and training model of the high-risk AI
                                              system, including its relevant model
                                              parameters and their execution /run
                                              environment. In cases of simpler software
                                              systems falling under this Regulation that
                                              are not based on trained models, and
                                              where all other ways to verify conformity
                                              have been exhausted, the national
                                              supervisory authority may exceptionally
                                                have access to the source code, upon a
                                                reasoned request. Where the national
                                                supervisory authority has been granted
                                                access to the training, validation and
                                                testing datasets in accordance with this
                                                Regulation, such access should be
                                                achieved through appropriate technical
                                                means and tools, including on site access
                                                and in exceptional circumstances, remote
                                                access. The national supervisory authority
                                                should treat any information, including
                                                source code, software, and data as
                                                applicable, obtained as confidential
                                                information and respect relevant Union
                                                law on the protection of intellectual
                                                property and trade secrets. The national
                                                supervisory authority should delete any
                                                information obtained upon the completion
                                                of the investigation.


Amendment 128

Proposal for a regulation
Recital 80

     Text proposed by the Commission                            Amendment

(80) Union legislation on financial             (80) Union law on financial services
services includes internal governance and       includes internal governance and risk
risk management rules and requirements          management rules and requirements which
which are applicable to regulated financial     are applicable to regulated financial
institutions in the course of provision of      institutions in the course of provision of
those services, including when they make        those services, including when they make
use of AI systems. In order to ensure           use of AI systems. In order to ensure
coherent application and enforcement of         coherent application and enforcement of
the obligations under this Regulation and       the obligations under this Regulation and
relevant rules and requirements of the          relevant rules and requirements of the
Union financial services legislation, the       Union financial services law, the
authorities responsible for the supervision     competent authorities responsible for the
and enforcement of the financial services       supervision and enforcement of the
legislation, including where applicable the     financial services law, including where
European Central Bank, should be                applicable the European Central Bank,
designated as competent authorities for the     should be designated as competent
purpose of supervising the implementation       authorities for the purpose of supervising
of this Regulation, including for market        the implementation of this Regulation,
surveillance activities, as regards AI          including for market surveillance activities,
systems provided or used by regulated and       as regards AI systems provided or used by
supervised financial institutions. To further   regulated and supervised financial
enhance the consistency between this            institutions. To further enhance the
Regulation and the rules applicable to          consistency between this Regulation and
credit institutions regulated under Directive   the rules applicable to credit institutions
2013/36/EU of the European Parliament           regulated under Directive 2013/36/EU of
and of the Council56 , it is also appropriate   the European Parliament and of the
to integrate the conformity assessment          Council56 , it is also appropriate to
procedure and some of the providers’            integrate the conformity assessment
procedural obligations in relation to risk      procedure and some of the providers’
management, post marketing monitoring           procedural obligations in relation to risk
and documentation into the existing             management, post marketing monitoring
obligations and procedures under Directive      and documentation into the existing
2013/36/EU. In order to avoid overlaps,         obligations and procedures under Directive
limited derogations should also be              2013/36/EU. In order to avoid overlaps,
envisaged in relation to the quality            limited derogations should also be
management system of providers and the          envisaged in relation to the quality
monitoring obligation placed on users of        management system of providers and the
high-risk AI systems to the extent that         monitoring obligation placed on deployers
these apply to credit institutions regulated    of high-risk AI systems to the extent that
by Directive 2013/36/EU.                        these apply to credit institutions regulated
                                                by Directive 2013/36/EU.
__________________                              __________________
56 Directive 2013/36/EU of the European         56 Directive 2013/36/EU of the European

Parliament and of the Council of 26 June        Parliament and of the Council of 26 June
2013 on access to the activity of credit        2013 on access to the activity of credit
institutions and the prudential supervision     institutions and the prudential supervision
of credit institutions and investment firms,    of credit institutions and investment firms,
amending Directive 2002/87/EC and               amending Directive 2002/87/EC and
repealing Directives 2006/48/EC and             repealing Directives 2006/48/EC and
2006/49/EC (OJ L 176, 27.6.2013, p. 338).       2006/49/EC (OJ L 176, 27.6.2013, p. 338).


Amendment 129

Proposal for a regulation
Recital 80 a (new)

     Text proposed by the Commission                            Amendment

                                                (80a) Given the objectives of this
                                                Regulation, namely to ensure an
                                                equivalent level of protection of health,
                                                safety and fundamental rights of natural
                                                persons, to ensure the protection of the
                                                rule of law and democracy, and taking
                                                into account that the mitigation of the
                                                risks of AI system against such rights may
                                                not be sufficiently achieved at national
                                                level or may be subject to diverging
                                                interpretation which could ultimately lead
                                                to an uneven level of protection of natural
                                               persons and create market fragmentation,
                                               the national supervisory authorities
                                               should be empowered to conduct joint
                                               investigations or rely on the union
                                               safeguard procedure provided for in this
                                               Regulation for effective enforcement.
                                               Joint investigations should be initiated
                                               where the national supervisory authority
                                               have sufficient reasons to believe that an
                                               infringement of this Regulation amount to
                                               a widespread infringement or a
                                               widespread infringement with a Union
                                               dimension, or where the AI system or
                                               foundation model presents a risk which
                                               affects or is likely to affect at least 45
                                               million individuals in more than one
                                               Member State.


Amendment 130

Proposal for a regulation
Recital 82

    Text proposed by the Commission                            Amendment

(82) It is important that AI systems related   (82) It is important that AI systems related
to products that are not high-risk in          to products that are not high-risk in
accordance with this Regulation and thus       accordance with this Regulation and thus
are not required to comply with the            are not required to comply with the
requirements set out herein are                requirements set out for high-risk AI
nevertheless safe when placed on the           systems are nevertheless safe when placed
market or put into service. To contribute to   on the market or put into service. To
this objective, the Directive 2001/95/EC of    contribute to this objective, the Directive
the European Parliament and of the             2001/95/EC of the European Parliament
Council57 would apply as a safety net.         and of the Council57 would apply as a
                                               safety net.
__________________                             __________________
57 Directive 2001/95/EC of the European        57 Directive 2001/95/EC of the European

Parliament and of the Council of 3             Parliament and of the Council of 3
December 2001 on general product safety        December 2001 on general product safety
(OJ L 11, 15.1.2002, p. 4).                    (OJ L 11, 15.1.2002, p. 4).


Amendment 131

Proposal for a regulation
Recital 83
     Text proposed by the Commission                            Amendment

(83) In order to ensure trustful and            (83) In order to ensure trustful and
constructive cooperation of competent           constructive cooperation of competent
authorities on Union and national level, all    authorities on Union and national level, all
parties involved in the application of this     parties involved in the application of this
Regulation should respect the                   Regulation should aim for transparency
confidentiality of information and data         and openness while respecting the
obtained in carrying out their tasks.           confidentiality of information and data
                                                obtained in carrying out their tasks by
                                                putting in place technical and
                                                organisational measures to protect the
                                                security and confidentiality of the
                                                information obtained carrying out their
                                                activities including for intellectual
                                                property rights and public and national
                                                security interests. Where the activities of
                                                the Commission, national competent
                                                authorities and notified bodies pursuant
                                                to this Regulation results in a breach of
                                                intellectual property rights, Member
                                                States should provide for adequate
                                                measures and remedies to ensure the
                                                enforcement of intellectual property rights
                                                in application of Directive 2004/48/EC.


Amendment 132

Proposal for a regulation
Recital 84

     Text proposed by the Commission                            Amendment

(84) Member States should take all              (84) Compliance with this Regulation
necessary measures to ensure that the           should be enforceable by means of the
provisions of this Regulation are               imposition of fines by the national
implemented, including by laying down           supervisory authority when carrying out
effective, proportionate and dissuasive         proceedings under the procedure laid
penalties for their infringement. For certain   down in this Regulation. Member States
specific infringements, Member States           should take all necessary measures to
should take into account the margins and        ensure that the provisions of this
criteria set out in this Regulation. The        Regulation are implemented, including by
European Data Protection Supervisor             laying down effective, proportionate and
should have the power to impose fines on        dissuasive penalties for their infringement.
Union institutions, agencies and bodies         In order to strengthen and harmonise
falling within the scope of this Regulation.    administrative penalties for infringement
                                                of this Regulation, the upper limits for
                                                setting the administrative fines for certain
                                      specific infringements should be laid
                                      down;. When assessing the amount of the
                                      fines, national competent authorities
                                      should, in each individual case, take into
                                      account all relevant circumstances of the
                                      specific situation, with due regard in
                                      particular to the nature, gravity and
                                      duration of the infringement and of its
                                      consequences and to the provider’s size,
                                      in particular if the provider is a SME or a
                                      start-up. The European Data Protection
                                      Supervisor should have the power to
                                      impose fines on Union institutions,
                                      agencies and bodies falling within the
                                      scope of this Regulation. The penalties
                                      and litigation costs under this Regulation
                                      should not be subject to contractual
                                      clauses or any other arrangements.


Amendment 133

Proposal for a regulation
Recital 84 a (new)

    Text proposed by the Commission                  Amendment

                                      (84a) As the rights and freedoms of
                                      natural and legal persons and groups of
                                      natural persons can be seriously
                                      undermined by AI systems, it is essential
                                      that natural and legal persons or groups
                                      of natural persons have meaningful
                                      access to reporting and redress
                                      mechanisms and to be entitled to access
                                      proportionate and effective remedies.
                                      They should be able to report
                                      infringments of this Regulation to their
                                      national supervisory authority and have
                                      the right to lodge a complaint against the
                                      providers or deployers of AI systems.
                                      Where applicable, deployers should
                                      provide internal complaints mechanisms
                                      to be used by natural and legal persons or
                                      groups of natural persons. Without
                                      prejudice to any other administrative or
                                      non-judicial remedy, natural and legal
                                      persons and groups of natural persons
                                      should also have the right to an effective
                                      judicial remedy with regard to a legally
                                      binding decision of a national supervisory
                                      authority concerning them or, where the
                                      national supervisory authority does not
                                      handle a complaint, does not inform the
                                      complainant of the progress or
                                      preliminary outcome of the complaint
                                      lodged or does not comply with its
                                      obligation to reach a final decision, with
                                      regard to the complaint.


Amendment 134

Proposal for a regulation
Recital 84 b (new)

    Text proposed by the Commission                  Amendment

                                      (84b) Affected persons should always be
                                      informed that they are subject to the use
                                      of a high-risk AI system, when deployers
                                      use a high-risk AI system to assist in
                                      decision-making or make decisions
                                      related to natural persons. This
                                      information can provide a basis for
                                      affected persons to exercise their right to
                                      an explanation under this
                                      Regulation.When deployers provide an
                                      explanation to affected persons under this
                                      Regulation, they should take into account
                                      the level of expertise and knowledge of the
                                      average consumer or individual.


Amendment 135

Proposal for a regulation
Recital 84 c (new)

    Text proposed by the Commission                  Amendment

                                      (84c) Union law on the protection of
                                      whistleblowers (Directive (EU)
                                      2019/1937) has full application to
                                      academics, designers, developers, project
                                      contributors, auditors, product managers,
                                      engineers and economic operators
                                      acquiring information on breaches of
                                      Union law by a provider of AI system or
                                               its AI system.


Amendment 136

Proposal for a regulation
Recital 85

    Text proposed by the Commission                             Amendment

(85) In order to ensure that the regulatory    (85) In order to ensure that the regulatory
framework can be adapted where                 framework can be adapted where
necessary, the power to adopt acts in          necessary, the power to adopt acts in
accordance with Article 290 TFEU should        accordance with Article 290 TFEU should
be delegated to the Commission to amend        be delegated to the Commission to amend
the techniques and approaches referred to      the Union harmonisation legislation listed
in Annex I to define AI systems, the Union     in Annex II, the high-risk AI systems listed
harmonisation legislation listed in Annex      in Annex III, the provisions regarding
II, the high-risk AI systems listed in Annex   technical documentation listed in Annex
III, the provisions regarding technical        IV, the content of the EU declaration of
documentation listed in Annex IV, the          conformity in Annex V, the provisions
content of the EU declaration of               regarding the conformity assessment
conformity in Annex V, the provisions          procedures in Annex VI and VII and the
regarding the conformity assessment            provisions establishing the high-risk AI
procedures in Annex VI and VII and the         systems to which the conformity
provisions establishing the high-risk AI       assessment procedure based on assessment
systems to which the conformity                of the quality management system and
assessment procedure based on assessment       assessment of the technical documentation
of the quality management system and           should apply. It is of particular importance
assessment of the technical documentation      that the Commission carry out appropriate
should apply. It is of particular importance   consultations during its preparatory work,
that the Commission carry out appropriate      including at expert level, and that those
consultations during its preparatory work,     consultations be conducted in accordance
including at expert level, and that those      with the principles laid down in the
consultations be conducted in accordance       Interinstitutional Agreement of 13 April
with the principles laid down in the           2016 on Better Law-Making58. These
Interinstitutional Agreement of 13 April       consultations should involve the
2016 on Better Law-Making58 . In               participation of a balanced selection of
particular, to ensure equal participation in   stakeholders, including consumer
the preparation of delegated acts, the         organisations, civil society, associations
European Parliament and the Council            representing affected persons, businesses
receive all documents at the same time as      representatives from different sectors and
Member States’ experts, and their experts      sizes, as well as researchers and scientists.
systematically have access to meetings of      In particular, to ensure equal participation
Commission expert groups dealing with the      in the preparation of delegated acts, the
preparation of delegated acts.                 European Parliament and the Council
                                               receive all documents at the same time as
                                               Member States’ experts, and their experts
                                               systematically have access to meetings of
                                               Commission expert groups dealing with the
                                       preparation of delegated acts.
__________________                     __________________
58 OJ L 123, 12.5.2016, p. 1.          58 OJ L 123, 12.5.2016, p. 1.




Amendment 137

Proposal for a regulation
Recital 85 a (new)

     Text proposed by the Commission                   Amendment

                                       (85a) Given the rapid technological
                                       developments and the required technical
                                       expertise in conducting the assessment of
                                       high-risk AI systems, the Commission
                                       should regularly review the
                                       implementation of this Regulation, in
                                       particular the prohibited AI systems, the
                                       transparency obligations and the list of
                                       high-risk areas and use cases, at least
                                       every year, while consulting the AI office
                                       and the relevant stakeholders.


Amendment 138

Proposal for a regulation
Recital 87 a (new)

     Text proposed by the Commission                   Amendment

                                       (87a) As reliable information on the
                                       resource and energy use, waste
                                       production and other environmental
                                       impact of AI systems and related ICT
                                       technology, including software, hardware
                                       and in particular data centres, is limited,
                                       the Commission should introduce of an
                                       adequate methodology to measure the
                                       environmental impact and effectiveness of
                                       this Regulation in light of the Union
                                       environmental and climate objectives.


Amendment 139

Proposal for a regulation
Recital 89
    Text proposed by the Commission                         Amendment

(89) The European Data Protection           (89) The European Data Protection
Supervisor and the European Data            Supervisor and the European Data
Protection Board were consulted in          Protection Board were consulted in
accordance with Article 42(2) of            accordance with Article 42(2) of
Regulation (EU) 2018/1725 and delivered     Regulation (EU) 2018/1725 and delivered
an opinion on […]”.                         an opinion on 18 June 2021.


Amendment 140

Proposal for a regulation
Article 1 – paragraph 1 (new)

    Text proposed by the Commission                         Amendment

                                            1.     The purpose of this Regulation is to
                                            promote the uptake of human-centric and
                                            trustworthy artificial intelligence and to
                                            ensure a high level of protection of
                                            health, safety, fundamental rights,
                                            democracy and the rule of law, and the
                                            environment from harmful effects of
                                            artificial intelligence systems in the Union
                                            while supporting innovation;


Amendment 141

Proposal for a regulation
Article 1 – paragraph 1 – point d

    Text proposed by the Commission                         Amendment

(d) harmonised transparency rules for AI    (d) harmonised transparency rules for
systems intended to interact with natural   certain AI systems;
persons, emotion recognition systems and
biometric categorisation systems, and AI
systems used to generate or manipulate
image, audio or video content;


Amendment 142
Proposal for a regulation
Article 1 – paragraph 1 – point e

    Text proposed by the Commission                         Amendment
(e) rules on market monitoring and          (e) rules on market monitoring, market
surveillance.                               surveillance governance and enforcement;


Amendment 143

Proposal for a regulation
Article 1 – paragraph 1 – point e a (new)

    Text proposed by the Commission                        Amendment

                                            (ea) measures to support innovation,
                                            with a particular focus on SMEs and
                                            start-ups, including on setting up
                                            regulatory sandboxes and targeted
                                            measures to reduce the regulatory burden
                                            on SMEs’s and start-ups;


Amendment 144

Proposal for a regulation
Article 1 – paragraph 1 – point e b (new)

    Text proposed by the Commission                        Amendment

                                            (eb) rules for the establishment and
                                            functioning of the Union’s Artificial
                                            Intelligence Office (AI Office).


Amendment 145

Proposal for a regulation
Article 2 – paragraph 1 – point b

    Text proposed by the Commission                        Amendment

(b) users of AI systems located within      (b) deployers of AI systems that have
the Union;                                  their place of establishment or who are
                                            located within the Union;


Amendment 146

Proposal for a regulation
Article 2 – paragraph 1 – point c
    Text proposed by the Commission                         Amendment

(c) providers and users of AI systems        (c) providers and deployers of AI
that are located in a third country, where   systems that have their place of
the output produced by the system is used    establishment or who are located in a third
in the Union;                                country, where either Member State law
                                             applies by virtue of a public international
                                             law or the output produced by the system
                                             is intended to be used in the Union;


Amendment 147

Proposal for a regulation
Article 2 – paragraph 1 – point c a (new)

    Text proposed by the Commission                         Amendment

                                             (ca) providers placing on the market or
                                             putting into service AI systems referred to
                                             in Article 5 outside the Union where the
                                             provider or distributor of such systems is
                                             located within the Union;


Amendment 148

Proposal for a regulation
Article 2 – paragraph 1 – point c b (new)

    Text proposed by the Commission                         Amendment

                                             (cb) importers and distributors of AI
                                             systems as well as authorised
                                             representatives of providers of AI systems,
                                             where such importers, distributors or
                                             authorised representatives have their
                                             establishment or are located in the Union;


Amendment 149

Proposal for a regulation
Article 2 – paragraph 1 – point c c (new)

    Text proposed by the Commission                         Amendment

                                             (cc) affected persons as defined in
                                             Article 3(8a) that are located in the Union
                                              and whose health, safety or fundamental
                                              rights are adversely impacted by the use of
                                              an AI system that is placed on the market
                                              or put into service within the Union.


Amendment 150

Proposal for a regulation
Article 2 – paragraph 2 – introductory part

      Text proposed by the Commission                        Amendment

2.    For high-risk AI systems that are       2.    For high-risk AI systems that are
safety components of products or systems,     safety components of products or systems,
or which are themselves products or           or which are themselves products or
systems, falling within the scope of the      systems and that fall, within the scope of
following acts, only Article 84 of this       harmonisation legislation listed in Annex
Regulation shall apply:                       II - Section B, only Article 84 of this
                                              Regulation shall apply;


Amendment 151

Proposal for a regulation
Article 2 – paragraph 2 – point a

      Text proposed by the Commission                        Amendment

(a)   Regulation (EC) 300/2008;               deleted


Amendment 152

Proposal for a regulation
Article 2 – paragraph 2 – point b

      Text proposed by the Commission                        Amendment

(b)   Regulation (EU) No 167/2013;            deleted


Amendment 153

Proposal for a regulation
Article 2 – paragraph 2 – point c
      Text proposed by the Commission             Amendment

(c)   Regulation (EU) No 168/2013;      deleted


Amendment 154

Proposal for a regulation
Article 2 – paragraph 2 – point d

      Text proposed by the Commission             Amendment

(d)   Directive 2014/90/EU;             deleted


Amendment 155

Proposal for a regulation
Article 2 – paragraph 2 – point e

      Text proposed by the Commission             Amendment

(e)   Directive (EU) 2016/797;          deleted


Amendment 156

Proposal for a regulation
Article 2 – paragraph 2 – point f

      Text proposed by the Commission             Amendment

(f)   Regulation (EU) 2018/858;         deleted


Amendment 157

Proposal for a regulation
Article 2 – paragraph 2 – point g

      Text proposed by the Commission             Amendment

(g)   Regulation (EU) 2018/1139;        deleted


Amendment 158
Proposal for a regulation
Article 2 – paragraph 2 – point h

      Text proposed by the Commission                          Amendment

(h)   Regulation (EU) 2019/2144.               deleted


Amendment 159

Proposal for a regulation
Article 2 – paragraph 4

      Text proposed by the Commission                          Amendment

4.    This Regulation shall not apply to       4.    This Regulation shall not apply to
public authorities in a third country nor to   public authorities in a third country nor to
international organisations falling within     international organisations falling within
the scope of this Regulation pursuant to       the scope of this Regulation pursuant to
paragraph 1, where those authorities or        paragraph 1, where those authorities or
organisations use AI systems in the            organisations use AI systems in the
framework of international agreements for      framework of international cooperation or
law enforcement and judicial cooperation       agreements for law enforcement and
with the Union or with one or more             judicial cooperation with the Union or with
Member States.                                 one or more Member States and are
                                               subject of a decision of the Commission
                                               adopted in accordance with Article 36 of
                                               Directive (EU)2016/680 or Article 45 of
                                               Regulation 2016/679 (adequacy decision)
                                               or are part of an international agreement
                                               concluded between the Union and that
                                               third country or international
                                               organisation pursuant to Article 218
                                               TFUE providing adequate safeguards
                                               with respect to the protection of privacy
                                               and fundamental rights and freedoms of
                                               individuals;


Amendment 160

Proposal for a regulation
Article 2 – paragraph 5 a (new)

      Text proposed by the Commission                          Amendment

                                               5a. Union law on the protection of
                                               personal data, privacy and the
                                               confidentiality of communications applies
                                               to personal data processes in connection
                                      with the rights and obligations laid down
                                      in this Regulation. This Regulation shall
                                      not affect Regulations (EU) 2016/679 and
                                      (EU) 2018/1725 and Directives
                                      2002/58/EC and (EU) 2016/680, without
                                      prejudice to arrangements provided for in
                                      Article 10(5) and Article 54 of this
                                      Regulation.;


Amendment 161

Proposal for a regulation
Article 2 – paragraph 5 b (new)

    Text proposed by the Commission                   Amendment

                                      5b. This Regulation is without prejudice
                                      to the rules laid down by other Union
                                      legal acts related to consumer protection
                                      and product safety;


Amendment 162

Proposal for a regulation
Article 2 – paragraph 5 c (new)

    Text proposed by the Commission                   Amendment

                                      5c. This regulation shall not preclude
                                      Member States or the Union from
                                      maintaining or introducing laws,
                                      regulations or administrative provisions
                                      which are more favourable to workers in
                                      terms of protecting their rights in respect
                                      of the use of AI systems by employers, or
                                      to encourage or allow the application of
                                      collective agreements which are more
                                      favourable to workers.


Amendment 163

Proposal for a regulation
Article 2 – paragraph 5 d (new)
    Text proposed by the Commission                   Amendment

                                      5d. This Regulation shall not apply to
                                      research, testing and development
                                      activities regarding an AI system prior to
                                      this system being placed on the market or
                                      put into service, provided that these
                                      activities are conducted respecting
                                      fundamental rights and the applicable
                                      Union law. The testing in real world
                                      conditions shall not be covered by this
                                      exemption.The Commission is empowered
                                      to may adopt delegated acts in accordance
                                      with Article 73 that clarify the application
                                      of this paragraph to specify this
                                      exemption to prevent its existing and
                                      potential abuse. The AI Office shall
                                      provide guidance on the governance of
                                      research and development pursuant to
                                      Article 56, also aiming to coordinate its
                                      application by the national supervisory
                                      authorities;


Amendment 164

Proposal for a regulation
Article 2 – paragraph 5 e (new)

    Text proposed by the Commission                   Amendment

                                      5e. This Regulation shall not apply to
                                      AI components provided under free and
                                      open-source licences except to the extent
                                      they are placed on the market or put into
                                      service by a provider as part of a high-risk
                                      AI system or of an AI system that falls
                                      under Title II or IV. This exemption shall
                                      not apply to foundation models as defined
                                      in Art 3.


Amendment 165

Proposal for a regulation
Article 3 – paragraph 1 – point 1
    Text proposed by the Commission                          Amendment

(1) ‘artificial intelligence system’ (AI     (1) ‘‘artificial intelligence system’ (AI
system) means software that is developed     system) means a machine-based system
with one or more of the techniques and       that is designed to operate with varying
approaches listed in Annex I and can, for    levels of autonomy and that can, for
a given set of human-defined objectives,     explicit or implicit objectives, generate
generate outputs such as content,            outputs such as predictions,
predictions, recommendations, or decisions   recommendations, or decisions, that
influencing the environments they interact   influence physical or virtual
with;                                        environments;


Amendment 166

Proposal for a regulation
Article 3 – paragraph 1 – point 1 a (new)

    Text proposed by the Commission                          Amendment

                                             (1a) ‘risk’ means the combination of the
                                             probability of an occurrence of harm and
                                             the severity of that harm;


Amendment 167

Proposal for a regulation
Article 3 – paragraph 1 – point 1 b (new)

    Text proposed by the Commission                          Amendment

                                             (1b) ‘significant risk’ means a risk that is
                                             significant as a result of the combination
                                             of its severity, intensity, probability of
                                             occurrence, and duration of its effects,
                                             and its the ability to affect an individual, a
                                             plurality of persons or to affect a
                                             particular group of persons;


Amendment 168

Proposal for a regulation
Article 3 – paragraph 1 – point 1 c (new)
    Text proposed by the Commission                        Amendment

                                            (1c) ‘foundation model’ means an AI
                                            system model that is trained on broad data
                                            at scale, is designed for generality of
                                            output, and can be adapted to a wide
                                            range of distinctive tasks;


Amendment 169

Proposal for a regulation
Article 3 – paragraph 1 – point 1 d (new)

    Text proposed by the Commission                        Amendment

                                            (1d) ‘general purpose AI system’ means
                                            an AI system that can be used in and
                                            adapted to a wide range of applications
                                            for which it was not intentionally and
                                            specifically designed;


Amendment 170

Proposal for a regulation
Article 3 – paragraph 1 – point 1 e (new)

    Text proposed by the Commission                        Amendment

                                            (1e) ‘large training runs’ means the
                                            production process of a powerful AI
                                            model that require computing resources
                                            above a very high threshold;


Amendment 171

Proposal for a regulation
Article 3 – paragraph 1 – point 3

    Text proposed by the Commission                        Amendment

(3) ‘small-scale provider’ means a          deleted
provider that is a micro or small
enterprise within the meaning of
Commission Recommendation
2003/361/EC61 ;
__________________
61 Commission Recommendation of 6 May

2003 concerning the definition of micro,
small and medium-sized enterprises (OJ L
124, 20.5.2003, p. 36).


Amendment 172

Proposal for a regulation
Article 3 – paragraph 1 – point 4

    Text proposed by the Commission                         Amendment

(4) ‘user’ means any natural or legal       (4) ‘deployer means any natural or legal
person, public authority, agency or other   person, public authority, agency or other
body using an AI system under its           body using an AI system under its
authority, except where the AI system is    authority except where the AI system is
used in the course of a personal non-       used in the course of a personal non-
professional activity;                      professional activity;


Amendment 173

Proposal for a regulation
Article 3 – paragraph 1 – point 8

    Text proposed by the Commission                         Amendment

(8) ‘operator’ means the provider, the      (8) ‘operator’ means the provider, the
user, the authorised representative, the    deployer, the authorised representative, the
importer and the distributor;               importer and the distributor;


Amendment 174

Proposal for a regulation
Article 3 – paragraph 1 – point 8 a (new)

    Text proposed by the Commission                         Amendment

                                            (8a) ‘affected person’ means any natural
                                            person or group of persons who are
                                            subject to or otherwise affected by an AI
                                            system;


Amendment 175
Proposal for a regulation
Article 3 – paragraph 1 – point 11

     Text proposed by the Commission                            Amendment

(11) ‘putting into service’ means the           (11) ‘putting into service’ means the
supply of an AI system for first use directly   supply of an AI system for first use directly
to the user or for own use on the Union         to the deployer or for own use on the
market for its intended purpose;                Union market for its intended purpose;


Amendment 176

Proposal for a regulation
Article 3 – paragraph 1 – point 13

     Text proposed by the Commission                            Amendment

(13) ‘reasonably foreseeable misuse’            (13) ‘reasonably foreseeable misuse’
means the use of an AI system in a way          means the use of an AI system in a way
that is not in accordance with its intended     that is not in accordance with its intended
purpose, but which may result from              purpose as indicated in instructions for
reasonably foreseeable human behaviour or       use established by the provider, but which
interaction with other systems;                 may result from reasonably foreseeable
                                                human behaviour or interaction with other
                                                systems, including other AI systems;


Amendment 177

Proposal for a regulation
Article 3 – paragraph 1 – point 14

     Text proposed by the Commission                            Amendment

(14) ‘safety component of a product or          (14) ‘safety component of a product or
system’ means a component of a product or       system’ means, in line with Union
of a system which fulfils a safety function     harmonisation law listed in Annex II, a
for that product or system or the failure or    component of a product or of a system
malfunctioning of which endangers the           which fulfils a safety function for that
health and safety of persons or property;       product or system, or the failure or
                                                malfunctioning of which endangers the
                                                health and safety of persons;


Amendment 178

Proposal for a regulation
Article 3 – paragraph 1 – point 15
     Text proposed by the Commission                           Amendment

(15) ‘instructions for use’ means the          (15) ‘instructions for use’ means the
information provided by the provider to        information provided by the provider to
inform the user of in particular an AI         inform the deployer of in particular an AI
system’s intended purpose and proper use,      system’s intended purpose and proper use,
inclusive of the specific geographical,        as well as information on any precautions
behavioural or functional setting within       to be taken; inclusive of the specific
which the high-risk AI system is intended      geographical, behavioural or functional
to be used;                                    setting within which the high-risk AI
                                               system is intended to be used;


Amendment 179

Proposal for a regulation
Article 3 – paragraph 1 – point 16

     Text proposed by the Commission                           Amendment

(16) ‘recall of an AI system’ means any        (16) ‘recall of an AI system’ means any
measure aimed at achieving the return to       measure aimed at achieving the return to
the provider of an AI system made              the provider of an AI system that has been
available to users;                            made available to deployers;


Amendment 180

Proposal for a regulation
Article 3 – paragraph 1 – point 20

     Text proposed by the Commission                           Amendment

(20) ‘conformity assessment’ means the         (20) ‘conformity assessment’ means the
process of verifying whether the               process of demonstrating whether the
requirements set out in Title III, Chapter 2   requirements set out in Title III, Chapter 2
of this Regulation relating to an AI system    of this Regulation relating to an AI system
have been fulfilled;                           have been fulfilled;


Amendment 181

Proposal for a regulation
Article 3 – paragraph 1 – point 22

     Text proposed by the Commission                           Amendment

(22) ‘notified body’ means a conformity        (22) ‘notified body’ means a conformity
assessment body designated in accordance       assessment body notified in accordance
with this Regulation and other relevant       with this Regulation and other relevant
Union harmonisation legislation;              Union harmonisation legislation;


Amendment 182

Proposal for a regulation
Article 3 – paragraph 1 – point 23

    Text proposed by the Commission                          Amendment

(23) ‘substantial modification’ means a       (23) ‘substantial modification’ means a
change to the AI system following its         modification or a series of modifications
placing on the market or putting into         of the AI system after its placing on the
service which affects the compliance of the   market or putting into service which is not
AI system with the requirements set out in    foreseen or planned in the initial risk
Title III, Chapter 2 of this Regulation or    assessment by the provider and as a result
results in a modification to the intended     of which the compliance of the AI system
purpose for which the AI system has been      with the requirements set out in Title III,
assessed;                                     Chapter 2 of this Regulation is affected or
                                              results in a modification to the intended
                                              purpose for which the AI system has been
                                              assessed;


Amendment 183

Proposal for a regulation
Article 3 – paragraph 1 – point 24

    Text proposed by the Commission                          Amendment

(24) ‘CE marking of conformity’ (CE           (24) ‘CE marking of conformity’ (CE
marking) means a marking by which a           marking) means a physical or digital
provider indicates that an AI system is in    marking by which a provider indicates that
conformity with the requirements set out in   an AI system or a product with an
Title III, Chapter 2 of this Regulation and   embedded AI system is in conformity with
other applicable Union legislation            the requirements set out in Title III,
harmonising the conditions for the            Chapter 2 of this Regulation and other
marketing of products (‘Union                 applicable Union legislation harmonising
harmonisation legislation’) providing for     the conditions for the marketing of
its affixing;                                 products (‘Union harmonisation
                                              legislation’) providing for its affixing;


Amendment 184

Proposal for a regulation
Article 3 – paragraph 1 – point 29
     Text proposed by the Commission                              Amendment

(29) ‘training data’ means data used for         (29) ‘training data’ means data used for
training an AI system through fitting its        training an AI system through fitting its
learnable parameters, including the              learnable parameters;
weights of a neural network;


Amendment 185

Proposal for a regulation
Article 3 – paragraph 1 – point 30

     Text proposed by the Commission                              Amendment

(30) ‘validation data’ means data used for       (30) ‘validation data’ means data used for
providing an evaluation of the trained AI        providing an evaluation of the trained AI
system and for tuning its non-learnable          system and for tuning its non-learnable
parameters and its learning process, among       parameters and its learning process, among
other things, in order to prevent overfitting;   other things, in order to prevent
whereas the validation dataset can be a          underfitting or overfitting; whereas the
separate dataset or part of the training         validation dataset is a separate dataset or
dataset, either as a fixed or variable split;    part of the training dataset, either as a fixed
                                                 or variable split;


Amendment 186

Proposal for a regulation
Article 3 – paragraph 1 – point 33

     Text proposed by the Commission                              Amendment

(33) ‘biometric data’ means personal data        (33) ‘biometric data’ means biometric
resulting from specific technical                data as defined in Article 4, point (14) of
processing relating to the physical,             Regulation (EU) 2016/679;
physiological or behavioural
characteristics of a natural person, which
allow or confirm the unique identification
of that natural person, such as facial
images or dactyloscopic data;


Amendment 187

Proposal for a regulation
Article 3 – paragraph 1 – point 33 a (new)
    Text proposed by the Commission                          Amendment

                                             (33a) ‘biometric-based data’ means data
                                             resulting from specific technical
                                             processing relating to physical,
                                             physiological or behavioural signals of a
                                             natural person;


Amendment 188

Proposal for a regulation
Article 3 – paragraph 1 – point 33 b (new)

    Text proposed by the Commission                          Amendment

                                             (33b) ‘biometric identification’ means the
                                             automated recognition of physical,
                                             physiological, behavioural, and
                                             psychological human features for the
                                             purpose of establishing an individual’s
                                             identity by comparing biometric data of
                                             that individual to stored biometric data of
                                             individuals in a database (one-to-many
                                             identification);


Amendment 189

Proposal for a regulation
Article 3 – paragraph 1 – point 33 c (new)

    Text proposed by the Commission                          Amendment

                                             (33c) ‘biometric verification’ means the
                                             automated verification of the identity of
                                             natural persons by comparing biometric
                                             data of an individual to previously
                                             provided biometric data (one-to-one
                                             verification, including authentication);


Amendment 190

Proposal for a regulation
Article 3 – paragraph 1 – point 33 d (new)
     Text proposed by the Commission                           Amendment

                                               (33d) ‘special categories of personal data’
                                               means the categories of personal data
                                               referred to in Article 9(1) of Regulation
                                               (EU)2016/679;


Amendment 191

Proposal for a regulation
Article 3 – paragraph 1 – point 34

     Text proposed by the Commission                           Amendment

(34) ‘emotion recognition system’ means        (34) ‘emotion recognition system’ means
an AI system for the purpose of identifying    an AI system for the purpose of identifying
or inferring emotions or intentions of         or inferring emotions, thoughts, states of
natural persons on the basis of their          mind or intentions of individuals or
biometric data;                                groups on the basis of their biometric and
                                               biometric-based data;


Amendment 192

Proposal for a regulation
Article 3 – paragraph 1 – point 35

     Text proposed by the Commission                           Amendment

(35) ‘biometric categorisation system’         (35) ‘biometric categorisation means
means an AI system for the purpose of          assigning natural persons to specific
assigning natural persons to specific          categories, or inferring their
categories, such as sex, age, hair colour,     characteristics and attributes on the basis
eye colour, tattoos, ethnic origin or sexual   of their biometric or biometric-based data,
or political orientation, on the basis of      or which can be inferred from such data;
their biometric data;


Amendment 193

Proposal for a regulation
Article 3 – paragraph 1 – point 36

     Text proposed by the Commission                           Amendment

(36) ‘remote biometric identification          (36) ‘remote biometric identification
system’ means an AI system for the             system’ means an AI system for the
purpose of identifying natural persons at a    purpose of identifying natural persons at a
distance through the comparison of a           distance through the comparison of a
person’s biometric data with the biometric     person’s biometric data with the biometric
data contained in a reference database, and    data contained in a reference database, and
without prior knowledge of the user of the     without prior knowledge of the deployer of
AI system whether the person will be           the AI system whether the person will be
present and can be identified ;                present and can be identified, excluding
                                               verification systems;


Amendment 194

Proposal for a regulation
Article 3 – paragraph 1 – point 37

    Text proposed by the Commission                            Amendment

(37) ‘‘real-time’ remote biometric             (37) ‘‘real-time’ remote biometric
identification system’ means a remote          identification system’ means a remote
biometric identification system whereby        biometric identification system whereby
the capturing of biometric data, the           the capturing of biometric data, the
comparison and the identification all occur    comparison and the identification all occur
without a significant delay. This comprises    without a significant delay. This comprises
not only instant identification, but also      not only instant identification, but also
limited short delays in order to avoid         limited delays in order to avoid
circumvention.                                 circumvention;


Amendment 195

Proposal for a regulation
Article 3 – paragraph 1 – point 39

    Text proposed by the Commission                            Amendment

(39) ‘publicly accessible space’ means         (39) ‘publicly accessible space’ means
any physical place accessible to the public,   any publicly or privately owned physical
regardless of whether certain conditions for   place accessible to the public, regardless of
access may apply;                              whether certain conditions for access may
                                               apply, and regardless of the potential
                                               capacity restrictions;


Amendment 196
Proposal for a regulation
Article 3 – paragraph 1 – point 41

    Text proposed by the Commission                            Amendment

(41) ‘law enforcement’ means activities        (41) ‘law enforcement’ means activities
carried out by law enforcement authorities     carried out by law enforcement authorities
for the prevention, investigation, detection    or on their behalf for the prevention,
or prosecution of criminal offences or the      investigation, detection or prosecution of
execution of criminal penalties, including      criminal offences or the execution of
the safeguarding against and the prevention     criminal penalties, including the
of threats to public security;                  safeguarding against and the prevention of
                                                threats to public security;


Amendment 197

Proposal for a regulation
Article 3 – paragraph 1 – point 42

     Text proposed by the Commission                            Amendment

(42) ‘national supervisory authority’           (42) ‘national supervisory authority’
means the authority to which a Member           means a public (AM 69) authority to which
State assigns the responsibility for the        a Member State assigns the responsibility
implementation and application of this          for the implementation and application of
Regulation, for coordinating the activities     this Regulation, for coordinating the
entrusted to that Member State, for acting      activities entrusted to that Member State,
as the single contact point for the             for acting as the single contact point for the
Commission, and for representing the            Commission, and for representing the
Member State at the European Artificial         Member State in the management Board
Intelligence Board;                             of the AI Office;


Amendment 198

Proposal for a regulation
Article 3 – paragraph 1 – point 43

     Text proposed by the Commission                            Amendment

(43) ‘national competent authority’ means       (43) ‘national competent authority’ means
the national supervisory authority, the         any of the national authorities which are
notifying authority and the market              responsible for the enforcement of this
surveillance authority;                         Regulation;


Amendment 199

Proposal for a regulation
Article 3 – paragraph 1 – point 44 – introductory part

     Text proposed by the Commission                            Amendment

(44) ‘serious incident’ means any incident      (44) ‘serious incident’ means any incident
that directly or indirectly leads, might have   or malfunctioning of an AI system that
                                                directly or indirectly leads, might have led
led or might lead to any of the following:    or might lead to any of the following:
(a) the death of a person or serious          (a) the death of a person or serious
damage to a person’s health, to property or   damage to a person’s health,
the environment,
(b) a serious disruption of the               (b) a serious disruption of the
management and operation of critical          management and operation of critical
infrastructure.                               infrastructure,
                                              (ba) a breach of fundamental rights
                                              protected under Union law,
                                              (bb) serious damage to property or the
                                              environment.


Amendment 200

Proposal for a regulation
Article 3 – paragraph 1 – point 44 a (new)

     Text proposed by the Commission                          Amendment

                                              (44a) 'personal data' means personal data
                                              as defined in Article 4, point (1) of
                                              Regulation (EU)2016/679;


Amendment 201

Proposal for a regulation
Article 3 – paragraph 1 – point 44 b (new)

     Text proposed by the Commission                          Amendment

                                              (44b) ‘non-personal data’ means data
                                              other than personal data;


Amendment 202

Proposal for a regulation
Article 3 – paragraph 1 – point 44 c (new)

     Text proposed by the Commission                          Amendment

                                              (44c) ‘profiling’ means any form of
                                              automated processing of personal data as
                                              defined in point (4) of Article 4 of
                                              Regulation (EU) 2016/679; or in the case
                                              of law enforcement authorities – in point
                                             4 of Article 3 of Directive (EU) 2016/680
                                             or, in the case of Union institutions,
                                             bodies, offices or agencies, in point 5
                                             Article 3 of Regulation (EU) 2018/1725;


Amendment 203

Proposal for a regulation
Article 3 – paragraph 1 – point 44 d (new)

    Text proposed by the Commission                          Amendment

                                             (44d) "deep fake" means manipulated or
                                             synthetic audio, image or video content
                                             that would falsely appear to be authentic
                                             or truthful, and which features depictions
                                             of persons appearing to say or do things
                                             they did not say or do, produced using AI
                                             techniques, including machine learning
                                             and deep learning;


Amendment 204

Proposal for a regulation
Article 3 – paragraph 1 – point 44 e (new)

    Text proposed by the Commission                          Amendment

                                             (44e) ‘widespread infringement’ means
                                             any act or omission contrary to Union law
                                             that protects the interest of individuals:
                                             (a) which has harmed or is likely to harm
                                             the collective interests of individuals
                                             residing in at least two Member States
                                             other than the Member State, in which:
                                             (i) the act or omission originated or took
                                             place;
                                             (ii) the provider concerned, or, where
                                             applicable, its authorised representative is
                                             established; or,
                                             (iii) the deployer is established, when the
                                             infringement is committed by the
                                             deployer;
                                             (b) which protects the interests of
                                             individuals, that have caused, cause or
                                             are likely to cause harm to the collective
                                             interests of individuals and that have
                                             common features, including the same
                                             unlawful practice, the same interest being
                                             infringed and that are occurring
                                             concurrently, committed by the same
                                             operator, in at least three Member States;


Amendment 205

Proposal for a regulation
Article 3 – paragraph 1 – point 44 f (new)

    Text proposed by the Commission                          Amendment

                                             (44f) ‘widespread infringement with a
                                             Union dimension’ means a widespread
                                             infringement that has harmed or is likely
                                             to harm the collective interests of
                                             individuals in at least two-thirds of the
                                             Member States, accounting, together, for
                                             at least two-thirds of the population of the
                                             Union;


Amendment 206

Proposal for a regulation
Article 3 – paragraph 1 – point 44 g (new)

    Text proposed by the Commission                          Amendment

                                             (44g) ‘regulatory sandbox’ means a
                                             controlled environment established by a
                                             public authority that facilitates the safe
                                             development, testing and validation of
                                             innovative AI systems for a limited time
                                             before their placement on the market or
                                             putting into service pursuant to a specific
                                             plan under regulatory supervision;


Amendment 207

Proposal for a regulation
Article 3 – paragraph 1 – point 44 h (new)
    Text proposed by the Commission                          Amendment

                                             (44h) ‘critical infrastructure’ means an
                                             asset, a facility, equipment, a network or a
                                             system, or a part of an asset, a facility,
                                             equipment, a network or a system, which
                                             is necessary for the provision of an
                                             essential service within the meaning of
                                             Article 2(4) of Directive (EU) 2022/2557;


Amendment 208

Proposal for a regulation
Article 3 – paragraph 1 – point 44 k (new)

    Text proposed by the Commission                          Amendment

                                             (44k) ‘social scoring’ means evaluating or
                                             classifying natural persons based on their
                                             social behaviour, socio-economic status or
                                             known or predicted personal or
                                             personality characteristics;


Amendment 209

Proposal for a regulation
Article 3 – paragraph 1 – point 44 l (new)

    Text proposed by the Commission                          Amendment

                                             (44l) ‘social behaviour’ means the way a
                                             natural person interacts with and
                                             influences other natural persons or
                                             society;


Amendment 210

Proposal for a regulation
Article 3 – paragraph 1 – point 44 m (new)

    Text proposed by the Commission                          Amendment

                                             (44m)      ‘state of the art’ means the
                                             developed stage of technical capability at
                                             a given time as regards products,
                                             processes and services, based on the
                                             relevant consolidated findings of science,
                                             technology and experience;


Amendment 211

Proposal for a regulation
Article 3 – paragraph 1 – point 44 n (new)

    Text proposed by the Commission                          Amendment

                                             (44n) ‘testing in real world conditions’
                                             means the temporary testing of an AI
                                             system for its intended purpose in real
                                             world conditions outside of a laboratory
                                             or otherwise simulated environment;


Amendment 212

Proposal for a regulation
Article 4

    Text proposed by the Commission                          Amendment

                 Article 4                   deleted
         Amendments to Annex I
The Commission is empowered to adopt
delegated acts in accordance with Article
73 to amend the list of techniques and
approaches listed in Annex I, in order to
update that list to market and
technological developments on the basis
of characteristics that are similar to the
techniques and approaches listed therein.


Amendment 213

Proposal for a regulation
Article 4 a (new)

    Text proposed by the Commission                          Amendment

                                                             Article 4 a
                                               General principles applicable to all AI
                                                              systems
                                             1. All operators falling under this
Regulation shall make their best efforts to
develop and use AI systems or foundation
models in accordance with the following
general principles establishing a high-
level framework that promotes a coherent
human-centric European approach to
ethical and trustworthy Artificial
Intelligence, which is fully in line with the
Charter as well as the values on which the
Union is founded:
a) ‘human agency and oversight’ means
that AI systems shall be developed and
used as a tool that serves people, respects
human dignity and personal autonomy,
and that is functioning in a way that can
be appropriately controlled and overseen
by humans;
b) ‘technical robustness and safety’
means that AI systems shall be developed
and used in a way to minimize unintended
and unexpected harm as well as being
robust in case of unintended problems
and being resilient against attempts to
alter the use or performance of the AI
system so as to allow unlawful use by
malicious third parties;
c) ‘privacy and data governance’ means
that AI systems shall be developed and
used in compliance with existing privacy
and data protection rules, while
processing data that meets high standards
in terms of quality and integrity;
d) ‘transparency’ means that AI systems
shall be developed and used in a way that
allows appropriate traceability and
explainability, while making humans
aware that they communicate or interact
with an AI system as well as duly
informing users of the capabilities and
limitations of that AI system and affected
persons about their rights;.
e) ‘diversity, non-discrimination and
fairness’ means that AI systems shall be
developed and used in a way that includes
diverse actors and promotes equal access,
gender equality and cultural diversity,
while avoiding discriminatory impacts
and unfair biases that are prohibited by
                Union or national law;
                f) ‘social and environmental well-being’
                means that AI systems shall be developed
                and used in a sustainable and
                environmentally friendly manner as well
                as in a way to benefit all human beings,
                while monitoring and assessing the long-
                term impacts on the individual, society
                and democracy.
                2. Paragraph 1 is without prejudice to
                obligations set up by existing Union and
                national law. For high-risk AI systems,
                the general principles are translated into
                and complied with by providers or
                deployers by means of the requirements
                set out in Articles 8 to 15, and the relevant
                obligations laid down in Chapter 3 of Title
                III of this Regulation. For foundation
                models, the general principles are
                translated into and complied with by
                providers by means of the requirements
                set out in Articles 28 to 28b. For all AI
                systems, the application of the principles
                referred to in paragraph 1 can be
                achieved, as applicable, through the
                provisions of Article 28, Article 52, or the
                application of harmonised standards,
                technical specifications, and codes of
                conduct as referred to in Article
                69,without creating new obligations under
                this Regulation.
                3. The Commission and the AI Office
                shall incorporate these guiding principles
                in standardisation requests as well as
                recommendations consisting in technical
                guidance to assist providers and deployers
                on how to develop and use AI systems.
                European Standardisation Organisations
                shall take the general principles referred
                to in paragraph 1of this Article into
                account as outcome-based objectives
                when developing the appropriate
                harmonised standards for high risk AI
                systems as referred to in Article 40(2b).


Amendment 214
Proposal for a regulation
Article 4 b (new)

    Text proposed by the Commission                   Amendment

                                                       Article 4 b
                                                       AI literacy
                                      1. When implementing this Regulation,
                                      the Union and the Member States shall
                                      promote measures for the development of
                                      a sufficient level of AI literacy, across
                                      sectors and taking into account the
                                      different needs of groups of providers,
                                      deployers and affected persons concerned,
                                      including through education and training,
                                      skilling and reskilling programmes and
                                      while ensuring proper gender and age
                                      balance, in view of allowing a democratic
                                      control of AI systems
                                      2. Providers and deployers of AI systems
                                      shall take measures to ensure a sufficient
                                      level of AI literacy of their staff and other
                                      persons dealing with the operation and
                                      use of AI systems on their behalf, taking
                                      into account their technical knowledge,
                                      experience, education and training and
                                      the context the AI systems are to be used
                                      in, and considering the persons or groups
                                      of persons on which the AI systems are to
                                      be used.
                                      3. Such literacy measures shall consist, in
                                      particular, of the teaching of basic
                                      notions and skills about AI systems and
                                      their functioning, including the different
                                      types of products and uses, their risks and
                                      benefits.
                                      4. A sufficient level of AI literacy is one
                                      that contributes, as necessary, to the
                                      ability of providers and deployers to
                                      ensure compliance and enforcement of
                                      this Regulation.


Amendment 215

Proposal for a regulation
Article 5 – paragraph 1 – point a
     Text proposed by the Commission                            Amendment

(a) the placing on the market, putting          (a) the placing on the market, putting
into service or use of an AI system that        into service or use of an AI system that
deploys subliminal techniques beyond a          deploys subliminal techniques beyond a
person’s consciousness in order to              person’s consciousness or purposefully
materially distort a person’s behaviour in a    manipulative or deceptive techniques,
manner that causes or is likely to cause that   with the objective to or the effect of
person or another person physical or            materially distorting a person’s or a group
psychological harm;                             of persons’ behaviour by appreciably
                                                impairing the person’s ability to make an
                                                informed decision, thereby causing the
                                                person to take a decision that that person
                                                would not have otherwise taken in a
                                                manner that causes or is likely to cause that
                                                person, another person or group of persons
                                                significant harm;
                                                The prohibition of AI system that deploys
                                                subliminal techniques referred to in the
                                                first sub-paragraph shall not apply to AI
                                                systems intended to be used for approved
                                                therapeutical purposes on the basis of
                                                specific informed consent of the
                                                individuals that are exposed to them or,
                                                where applicable, of their legal guardian;


Amendment 216

Proposal for a regulation
Article 5 – paragraph 1 – point b

     Text proposed by the Commission                            Amendment

(b) the placing on the market, putting          (b) the placing on the market, putting
into service or use of an AI system that        into service or use of an AI system that
exploits any of the vulnerabilities of a        exploits any of the vulnerabilities of a
specific group of persons due to their age,     person or a specific group of persons,
physical or mental disability, in order to      including characteristics of such person’s
materially distort the behaviour of a person    or a such group’s known or predicted
pertaining to that group in a manner that       personality traits or social or economic
causes or is likely to cause that person or     situation age, physical or mental ability
another person physical or psychological        with the objective or to the effect of
harm;                                           materially distorting the behaviour of that
                                                person or a person pertaining to that group
                                                in a manner that causes or is likely to cause
                                                that person or another person significant
                                                harm;;
Amendment 217

Proposal for a regulation
Article 5 – paragraph 1 – point b a (new)

     Text proposed by the Commission                            Amendment

                                                (b a) the placing on the market, putting
                                                into service or use of biometric
                                                categorisation systems that categorise
                                                natural persons according to sensitive or
                                                protected attributes or characteristics or
                                                based on the inference of those attributes
                                                or characteristics. This prohibition shall
                                                not apply to AI systems intended to be
                                                used for approved therapeutical purposes
                                                on the basis of specific informed consent
                                                of the individuals that are exposed to them
                                                or, where applicable, of their legal
                                                guardian.


Amendment 218

Proposal for a regulation
Article 5 – paragraph 1 – point c – introductory part

     Text proposed by the Commission                            Amendment

(c) the placing on the market, putting          (c) the placing on the market, putting
into service or use of AI systems by public     into service or use of AI systems for the
authorities or on their behalf for the          social scoring evaluation or classification
evaluation or classification of the             of natural persons or groups thereof over a
trustworthiness of natural persons over a       certain period of time based on their social
certain period of time based on their social    behaviour or known, inferred or predicted
behaviour or known or predicted personal        personal or personality characteristics, with
or personality characteristics, with the        the social score leading to either or both of
social score leading to either or both of the   the following:
following:


Amendment 219

Proposal for a regulation
Article 5 – paragraph 1 – point c – point i
    Text proposed by the Commission                            Amendment

(i) detrimental or unfavourable                (i) detrimental or unfavourable
treatment of certain natural persons or        treatment of certain natural persons or
whole groups thereof in social contexts        whole groups thereof in social contexts
which are unrelated to the contexts in         that are unrelated to the contexts in which
which the data was originally generated or     the data was originally generated or
collected;                                     collected;


Amendment 220

Proposal for a regulation
Article 5 – paragraph 1 – point d – introductory part

    Text proposed by the Commission                            Amendment

(d) the use of ‘real-time’ remote              (d) the use of ‘real-time’ remote
biometric identification systems in publicly   biometric identification systems in publicly
accessible spaces for the purpose of law       accessible spaces;
enforcement, unless and in as far as such
use is strictly necessary for one of the
following objectives:


Amendment 221

Proposal for a regulation
Article 5 – paragraph 1 – point d – point i

    Text proposed by the Commission                            Amendment

(i) the targeted search for specific           deleted
potential victims of crime, including
missing children;


Amendment 222

Proposal for a regulation
Article 5 – paragraph 1 – point d – point ii

    Text proposed by the Commission                            Amendment

(ii) the prevention of a specific,             deleted
substantial and imminent threat to the life
or physical safety of natural persons or of
a terrorist attack;
Amendment 223

Proposal for a regulation
Article 5 – paragraph 1 – point d – point iii

    Text proposed by the Commission                            Amendment

(iii) the detection, localisation,              deleted
identification or prosecution of a
perpetrator or suspect of a criminal
offence referred to in Article 2(2) of
Council Framework Decision
2002/584/JHA62 and punishable in the
Member State concerned by a custodial
sentence or a detention order for a
maximum period of at least three years, as
determined by the law of that Member
State.
__________________
62 Council Framework Decision

2002/584/JHA of 13 June 2002 on the
European arrest warrant and the
surrender procedures between Member
States (OJ L 190, 18.7.2002, p. 1).


Amendment 224

Proposal for a regulation
Article 5 – paragraph 1 – point d a (new)

    Text proposed by the Commission                            Amendment

                                                (d a) the placing on the market, putting
                                                into service or use of an AI system for
                                                making risk assessments of natural
                                                persons or groups thereof in order to
                                                assess the risk of a natural person for
                                                offending or reoffending or for predicting
                                                the occurrence or reoccurrence of an
                                                actual or potential criminal or
                                                administrative offence based on profiling
                                                of a natural person or on assessing
                                                personality traits and characteristics,
                                                including the person’s location, or past
                                                criminal behaviour of natural persons or
                                                groups of natural persons;
Amendment 225

Proposal for a regulation
Article 5 – paragraph 1 – point d b (new)

    Text proposed by the Commission                         Amendment

                                            (d b) The placing on the market, putting
                                            into service or use of AI systems that
                                            create or expand facial recognition
                                            databases through the untargeted
                                            scraping of facial images from the
                                            internet or CCTV footage;


Amendment 226

Proposal for a regulation
Article 5 – paragraph 1 – point d c (new)

    Text proposed by the Commission                         Amendment

                                            dc) the placing on the market, putting into
                                            service or use of AI systems to infer
                                            emotions of a natural person in the areas
                                            of law enforcement, border management,
                                            in workplace and education institutions.


Amendment 227

Proposal for a regulation
Article 5 – paragraph 1 – point d d (new)

    Text proposed by the Commission                         Amendment

                                            (d d) the putting into service or use of AI
                                            systems for the analysis of recorded
                                            footage of publicly accessible spaces
                                            through ‘post’ remote biometric
                                            identification systems, unless they are
                                            subject to a pre-judicial authorisation in
                                            accordance with Union law and strictly
                                            necessary for the targeted search
                                            connected to a specific serious criminal
                                            offense as defined in Article 83(1) of
                                            TFEU that already took place for the
                                            purpose of law enforcement.
Amendment 228

Proposal for a regulation
Article 5 – paragraph 1 a (new)

     Text proposed by the Commission                         Amendment

                                              1 a. This Article shall not affect the
                                              prohibitions that apply where an artificial
                                              intelligence practice infringes another
                                              Union law, including Union law on data
                                              protection, non discrimination, consumer
                                              protection or competition;


Amendment 229

Proposal for a regulation
Article 5 – paragraph 2

     Text proposed by the Commission                         Amendment

2.    The use of ‘real-time’ remote           deleted
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement for any of the
objectives referred to in paragraph 1 point
d) shall take into account the following
elements:
(a) the nature of the situation giving
rise to the possible use, in particular the
seriousness, probability and scale of the
harm caused in the absence of the use of
the system;
(b) the consequences of the use of the
system for the rights and freedoms of all
persons concerned, in particular the
seriousness, probability and scale of those
consequences.
In addition, the use of ‘real-time’ remote
biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement for any of the
objectives referred to in paragraph 1 point
d) shall comply with necessary and
proportionate safeguards and conditions
in relation to the use, in particular as
regards the temporal, geographic and
personal limitations.


Amendment 230

Proposal for a regulation
Article 5 – paragraph 3

    Text proposed by the Commission                     Amendment

3.    As regards paragraphs 1, point (d)      deleted
and 2, each individual use for the purpose
of law enforcement of a ‘real-time’
remote biometric identification system in
publicly accessible spaces shall be subject
to a prior authorisation granted by a
judicial authority or by an independent
administrative authority of the Member
State in which the use is to take place,
issued upon a reasoned request and in
accordance with the detailed rules of
national law referred to in paragraph 4.
However, in a duly justified situation of
urgency, the use of the system may be
commenced without an authorisation and
the authorisation may be requested only
during or after the use.
The competent judicial or administrative
authority shall only grant the
authorisation where it is satisfied, based
on objective evidence or clear indications
presented to it, that the use of the ‘real-
time’ remote biometric identification
system at issue is necessary for and
proportionate to achieving one of the
objectives specified in paragraph 1, point
(d), as identified in the request. In
deciding on the request, the competent
judicial or administrative authority shall
take into account the elements referred to
in paragraph 2.


Amendment 231

Proposal for a regulation
Article 5 – paragraph 4
     Text proposed by the Commission                          Amendment

4.     A Member State may decide to            deleted
provide for the possibility to fully or
partially authorise the use of ‘real-time’
remote biometric identification systems in
publicly accessible spaces for the purpose
of law enforcement within the limits and
under the conditions listed in paragraphs
1, point (d), 2 and 3. That Member State
shall lay down in its national law the
necessary detailed rules for the request,
issuance and exercise of, as well as
supervision relating to, the authorisations
referred to in paragraph 3. Those rules
shall also specify in respect of which of
the objectives listed in paragraph 1, point
(d), including which of the criminal
offences referred to in point (iii) thereof,
the competent authorities may be
authorised to use those systems for the
purpose of law enforcement.


Amendment 232

Proposal for a regulation
Article 6 – paragraph 1 – point a

     Text proposed by the Commission                          Amendment

(a) the AI system is intended to be used       (a) the AI system is intended to be used
as a safety component of a product, or is      as a safety component of a product, or the
itself a product, covered by the Union         AI system is itself a product, covered by
harmonisation legislation listed in Annex      the Union harmonisation law listed in
II;                                            Annex II;


Amendment 233

Proposal for a regulation
Article 6 – paragraph 1 – point b

     Text proposed by the Commission                          Amendment

(b) the product whose safety component         (b) the product whose safety component
is the AI system, or the AI system itself as   pursuant to point (a) is the AI system, or
a product, is required to undergo a third-     the AI system itself as a product, is
party conformity assessment with a view to     required to undergo a third-party
the placing on the market or putting into     conformity assessment related to risks for
service of that product pursuant to the       health and safety, with a view to the
Union harmonisation legislation listed in     placing on the market or putting into
Annex II.                                     service of that product pursuant to the
                                              Union harmonisation law listed in Annex
                                              II;


Amendment 234

Proposal for a regulation
Article 6 – paragraph 2

     Text proposed by the Commission                         Amendment

2.   In addition to the high-risk AI          2.     In addition to the high-risk AI
systems referred to in paragraph 1, AI        systems referred to in paragraph 1, AI
systems referred to in Annex III shall also   systems falling under one or more of the
be considered high-risk.                      critical areas and use cases referred to in
                                              Annex III shall be considered high-risk if
                                              they pose a significant risk of harm to the
                                              health, safety or fundamental rights of
                                              natural persons. Where an AI system falls
                                              under Annex III point 2, it shall be
                                              considered to be high-risk if it poses a
                                              significant risk of harm to the
                                              environment.
                                              The Commission shall, six months prior
                                              to the entry into force of this Regulation,
                                              after consulting the AI Office and
                                              relevant stakeholders, provide guidelines
                                              clearly specifying the circumstances
                                              where the output of AI systems referred to
                                              in Annex III would pose a significant risk
                                              of harm to the health, safety or
                                              fundamental rights of natural persons or
                                              cases in which it would not.


Amendment 235

Proposal for a regulation
Article 6 – paragraph 2 a (new)

     Text proposed by the Commission                         Amendment

                                              2 a. Where providers falling under one
                                              or more of the critical areas and use cases
                                              referred to in Annex III consider that
                                      their AI system does not pose a significant
                                      risk as described in paragraph 2, they
                                      shall submit a reasoned notification to the
                                      national supervisory authority that they
                                      are not subject to the requirements of
                                      Title III Chapter 2 of this Regulation.
                                      Where the AI system is intended to be
                                      used in two or more Member States, that
                                      notification shall be addressed to the AI
                                      Office. Without prejudice to Article 65,
                                      the national supervisory authority shall
                                      review and reply to the notification,
                                      directly or via the AI Office, within three
                                      months if they deem the AI system to be
                                      misclassified.


Amendment 236

Proposal for a regulation
Article 6 – paragraph 2 a (new)

    Text proposed by the Commission                   Amendment

                                      2 b. Providers that misclassify their AI
                                      system as not subject to the requirements
                                      of Title III Chapter 2 of this Regulation
                                      and place it on the market before the
                                      deadline for objection by national
                                      supervisory authorities shall be subject to
                                      fines pursuant to Article 71.


Amendment 237

Proposal for a regulation
Article 6 – paragraph 2 b (new)

    Text proposed by the Commission                   Amendment

                                      2 c. National supervisory authorities
                                      shall submit a yearly report to the AI
                                      Office detailing the number of
                                      notifications received, the related high-
                                      risk areas at stake and the decisions taken
                                      concerning received notifications


Amendment 238
Proposal for a regulation
Article 7 – paragraph 1 – introductory part

     Text proposed by the Commission                          Amendment

1.    The Commission is empowered to          1.    The Commission is empowered to
adopt delegated acts in accordance with       adopt delegated acts in accordance with
Article 73 to update the list in Annex III    Article 73 to amend Annex III by adding
by adding high-risk AI systems where both     or modifying areas or use-cases of high-
of the following conditions are fulfilled:    risk AI systems where these pose a
                                              significant risk of harm to health and
                                              safety, or an adverse impact on
                                              fundamental rights, to the environment,
                                              or to democracy and the rule of law, and
                                              that risk is, in respect of its severity and
                                              probability of occurrence, equivalent to or
                                              greater than the risk of harm or of
                                              adverse impact posed by the high-risk AI
                                              systems already referred to in Annex III.


Amendment 239

Proposal for a regulation
Article 7 – paragraph 1 – point a

     Text proposed by the Commission                          Amendment

(a) the AI systems are intended to be         deleted
used in any of the areas listed in points 1
to 8 of Annex III;


Amendment 240

Proposal for a regulation
Article 7 – paragraph 1 – point b

     Text proposed by the Commission                          Amendment

(b) the AI systems pose a risk of harm        deleted
to the health and safety, or a risk of
adverse impact on fundamental rights,
that is, in respect of its severity and
probability of occurrence, equivalent to or
greater than the risk of harm or of
adverse impact posed by the high-risk AI
systems already referred to in Annex III.
Amendment 241

Proposal for a regulation
Article 7 – paragraph 1 a (new)

     Text proposed by the Commission                          Amendment

                                               1 a. The Commission is also empowered
                                               to adopt delegated acts in accordance with
                                               Article 73 to remove use-cases of high-
                                               risk AI systems from the list in Annex III
                                               if the conditions referred to in paragraph
                                               1 no longer apply;


Amendment 242

Proposal for a regulation
Article 7 – paragraph 2 – introductory part

     Text proposed by the Commission                          Amendment

2.    When assessing for the purposes of       2.    When assessing an AI system for the
paragraph 1 whether an AI system poses a       purposes of paragraph 1 and 1a the
risk of harm to the health and safety or a     Commission shall take into account the
risk of adverse impact on fundamental          following criteria:
rights that is equivalent to or greater than
the risk of harm posed by the high-risk AI
systems already referred to in Annex III,
the Commission shall take into account the
following criteria:


Amendment 243

Proposal for a regulation
Article 7 – paragraph 2 – point a a (new)

     Text proposed by the Commission                          Amendment

                                               (a a) the general capabilities and
                                               functionalities of the AI system
                                               independent of its intended purpose;


Amendment 244

Proposal for a regulation
Article 7 – paragraph 2 – point b a (new)
    Text proposed by the Commission                           Amendment

                                              (b a) the nature and amount of the data
                                              processed and used by the AI system;


Amendment 245

Proposal for a regulation
Article 7 – paragraph 2 – point b b (new)

    Text proposed by the Commission                           Amendment

                                              (b b) the extent to which the AI system
                                              acts autonomously;


Amendment 246

Proposal for a regulation
Article 7 – paragraph 2 – point c

    Text proposed by the Commission                           Amendment

(c) the extent to which the use of an AI      (c) the extent to which the use of an AI
system has already caused harm to the         system has already caused harm to health
health and safety or adverse impact on the    and safety, has had an adverse impact on
fundamental rights or has given rise to       fundamental rights, the environment,
significant concerns in relation to the       democracy and the rule of law or has
materialisation of such harm or adverse       given rise to significant concerns in
impact, as demonstrated by reports or         relation to the likelihood of such harm or
documented allegations submitted to           adverse impact, as demonstrated for
national competent authorities;               example by reports or documented
                                              allegations submitted to national
                                              supervisory authorities, to the
                                              Commission, to the AI Office, to the
                                              EDPS, or to the European Union Agency
                                              for Fundamental Rights;


Amendment 247

Proposal for a regulation
Article 7 – paragraph 2 – point d

    Text proposed by the Commission                           Amendment

(d) the potential extent of such harm or      (d) the potential extent of such harm or
such adverse impact, in particular in terms   such adverse impact, in particular in terms
of its intensity and its ability to affect a   of its intensity and its ability to affect a
plurality of persons;                          plurality of persons or to
                                               disproportionately affect a particular
                                               group of persons;


Amendment 248

Proposal for a regulation
Article 7 – paragraph 2 – point e

     Text proposed by the Commission                            Amendment

(e) the extent to which potentially            (e) the extent to which potentially
harmed or adversely impacted persons are       harmed or adversely impacted persons are
dependent on the outcome produced with         dependent on the output produced
an AI system, in particular because for        involving an AI system, and that output is
practical or legal reasons it is not           purely accessory in respect of the relevant
reasonably possible to opt-out from that       action or decision to be taken, in particular
outcome;                                       because for practical or legal reasons it is
                                               not reasonably possible to opt-out from
                                               that output;


Amendment 249

Proposal for a regulation
Article 7 – paragraph 2 – point e a (new)

     Text proposed by the Commission                            Amendment

                                               (e a) the potential misuse and malicious
                                               use of the AI system and of the technology
                                               underpinning it;


Amendment 250

Proposal for a regulation
Article 7 – paragraph 2 – point f

     Text proposed by the Commission                            Amendment

(f) the extent to which potentially            (f) the extent to which there is an
harmed or adversely impacted persons are       imbalance of power, or the potentially
in a vulnerable position in relation to the    harmed or adversely impacted persons are
user of an AI system, in particular due to     in a vulnerable position in relation to the
an imbalance of power, knowledge,              user of an AI system, in particular due to
economic or social circumstances, or age;      status, authority, knowledge, economic or
                                                social circumstances, or age;


Amendment 251

Proposal for a regulation
Article 7 – paragraph 2 – point g

     Text proposed by the Commission                            Amendment

(g) the extent to which the outcome             (g) the extent to which the outcome
produced with an AI system is easily            produced involving an AI system is easily
reversible, whereby outcomes having an          reversible or remedied, whereby outcomes
impact on the health or safety of persons       having an adverse impact on health, safety,
shall not be considered as easily reversible;   fundamental rights of persons, the
                                                environment, or on democracy and rule of
                                                law shall not be considered as easily
                                                reversible;


Amendment 252

Proposal for a regulation
Article 7 – paragraph 2 – point g a (new)

     Text proposed by the Commission                            Amendment

                                                (g a) the extent of the availability and use
                                                of effective technical solutions and
                                                mechanisms for the control, reliability
                                                and corrigibility of the AI system;


Amendment 253

Proposal for a regulation
Article 7 – paragraph 2 – point g b (new)

     Text proposed by the Commission                            Amendment

                                                (g b) the magnitude and likelihood of
                                                benefit of the deployment of the AI system
                                                for individuals, groups, or society at large,
                                                including possible improvements in
                                                product safety;


Amendment 254
Proposal for a regulation
Article 7 – paragraph 2 – point g c (new)

    Text proposed by the Commission                           Amendment

                                               (g c) the extent of human oversight and
                                               the possibility for a human to intercede in
                                               order to override a decision or
                                               recommendations that may lead to
                                               potential harm;


Amendment 255

Proposal for a regulation
Article 7 – paragraph 2 – point h –

    Text proposed by the Commission                           Amendment

(i) effective measures of redress in           (h) the extent to which existing Union
relation to the risks posed by an AI system,   law provides for:
with the exclusion of claims for damages;
                                               (i) effective measures of redress in
                                               relation to the damage caused by an AI
                                               system, with the exclusion of claims for
                                               direct or indirect damages;
                                               (ii) effective measures to prevent or
                                               substantially minimise those risks.


Amendment 256

Proposal for a regulation
Article 7 – paragraph 2 a (new)

    Text proposed by the Commission                           Amendment

                                               2 a. When assessing an AI system for the
                                               purposes of paragraphs 1 or 1a the
                                               Commission shall consult the AI Office
                                               and, where relevant, representatives of
                                               groups on which an AI system has an
                                               impact, industry, independent experts, the
                                               social partners, and civil society
                                               organisations. The Commission shall also
                                               organise public consultations in this
                                               regard and shall make the results of those
                                               consultations and of the final assessment
                                               publicly available;
Amendment 257

Proposal for a regulation
Article 7 – paragraph 2 b (new)

    Text proposed by the Commission                            Amendment

                                               2 b. The AI Office, national supervisory
                                               authorities or the European Parliament
                                               may request the Commission to reassess
                                               and recategorise the risk categorisation of
                                               an AI systemin accordance with
                                               paragraphs 1 and 1a. The Commission
                                               shall give reasons for its decision and
                                               make them public.


Amendment 258

Proposal for a regulation
Article 8 – paragraph 1 a (new)

    Text proposed by the Commission                            Amendment

                                               1 a. In complying with the requirement
                                               established in this Chapter, due account
                                               shall be taken of guidelines developed as
                                               referred to in Article 82b, the generally
                                               acknowledged state of the art, including
                                               as reflected in the relevant harmonised
                                               standards and common specifications as
                                               referred to in articles 40 and 41 or those
                                               already set out in Union harmonisation
                                               law;.


Amendment 259

Proposal for a regulation
Article 8 – paragraph 2

    Text proposed by the Commission                            Amendment

2.    The intended purpose of the high-risk    2.    The intended purpose of the high-risk
AI system and the risk management system       AI system, the reasonably foreseeable
referred to in Article 9 shall be taken into   misuses and the risk management system
account when ensuring compliance with          referred to in Article 9 shall be taken into
those requirements.                            account when ensuring compliance with
                                           those requirements.


Amendment 260

Proposal for a regulation
Article 8 – paragraph 2 a (new)

    Text proposed by the Commission                        Amendment

                                           2 a. As long as the requirements of Title
                                           III, Chapters 2 and 3 or Title VIII,
                                           Chapters 1, 2 and 3 for high-risk AI
                                           systems are addressed by Union
                                           harmonisation law listed in Annex II,
                                           Section A, the requirements or obligations
                                           of those Chapters of this Regulation shall
                                           be deemed to be fulfilled, as long as they
                                           include the AI component. Requirements
                                           of Chapters 2 and 3 of Title III or Title
                                           VIII, Chapters 1, 2 and 3 for high-risk AI
                                           systems not addressed by Union
                                           harmonisation law listed in Annex II
                                           Section A, shall be incorporated into that
                                           Union harmonisation law, where
                                           applicable. The relevant conformity
                                           assessment shall be carried out as part of
                                           the procedures laid out under Union
                                           harmonisation law listed in Annex II,
                                           Section A.


Amendment 261

Proposal for a regulation
Article 9 – paragraph 1

    Text proposed by the Commission                        Amendment

1.    A risk management system shall be    1.    A risk management system shall be
established, implemented, documented and   established, implemented, documented and
maintained in relation to high-risk AI     maintained in relation to high-risk AI
systems.                                   systems, throughout the entire lifecycle of
                                           the AI system. The risk management
                                           system can be integrated into, or a part of,
                                           already existing risk management
                                           procedures relating to the relevant Union
                                           sectoral law insofar as it fulfils the
                                           requirements of this article.
Amendment 262

Proposal for a regulation
Article 9 – paragraph 2 – introductory part

    Text proposed by the Commission                          Amendment

2.    The risk management system shall        2.     The risk management system shall
consist of a continuous iterative process     consist of a continuous iterative process
run throughout the entire lifecycle of a      run throughout the entire lifecycle of a
high-risk AI system, requiring regular        high-risk AI system, requiring regular
systematic updating. It shall comprise the    review and updating of the risk
following steps:                              management process, to ensure its
                                              continuing effectiveness, and
                                              documentation of any significant
                                              decisions and actions taken subject to this
                                              Article. It shall comprise the following
                                              steps:


Amendment 263

Proposal for a regulation
Article 9 – paragraph 2 – point a

    Text proposed by the Commission                          Amendment

(a) identification and analysis of the        (a) identification, estimation and
known and foreseeable risks associated        evaluation of the known and the
with each high-risk AI system;                reasonably foreseeable risks that the high-
                                              risk AI system can pose to the health or
                                              safety of natural persons, their
                                              fundamental rights including equal
                                              access and opportunities, democracy and
                                              rule of law or the environement when the
                                              high-risk AI system is used in accordance
                                              with its intended purpose and under
                                              conditions of reasonably foreseeable
                                              misuse;


Amendment 264

Proposal for a regulation
Article 9 – paragraph 2 – point b
     Text proposed by the Commission                           Amendment

(b) estimation and evaluation of the           deleted
risks that may emerge when the high-risk
AI system is used in accordance with its
intended purpose and under conditions of
reasonably foreseeable misuse;


Amendment 265

Proposal for a regulation
Article 9 – paragraph 2 – point c

     Text proposed by the Commission                           Amendment

(c) evaluation of other possibly arising       (c) evaluation of emerging significant
risks based on the analysis of data gathered   risks as described in point (a) and
from the post-market monitoring system         identified based on the analysis of data
referred to in Article 61;                     gathered from the post-market monitoring
                                               system referred to in Article 61;


Amendment 266

Proposal for a regulation
Article 9 – paragraph 2 – point d

     Text proposed by the Commission                           Amendment

(d) adoption of suitable risk                  (d) adoption of appropriate and targeted
management measures in accordance with         risk management measures designed to
the provisions of the following paragraphs.    address the risks identified pursuant to
                                               points a and b of this paragraph in
                                               accordance with the provisions of the
                                               following paragraphs


Amendment 267

Proposal for a regulation
Article 9 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    The risk management measures             3.    The risk management measures
referred to in paragraph 2, point (d) shall    referred to in paragraph 2, point (d) shall
give due consideration to the effects and      give due consideration to the effects and
possible interactions resulting from the       possible interactions resulting from the
combined application of the requirements       combined application of the requirements
set out in this Chapter 2. They shall take     set out in this Chapter 2, with a view to
into account the generally acknowledged        mitigate risks effectively while ensuring
state of the art, including as reflected in    an appropriate and proportionate
relevant harmonised standards or               implementation of the requirements.
common specifications.


Amendment 268

Proposal for a regulation
Article 9 – paragraph 4 – introductory part

     Text proposed by the Commission                           Amendment

4.     The risk management measures            4.    The risk management measures
referred to in paragraph 2, point (d) shall    referred to in paragraph 2, point (d) shall
be such that any residual risk associated      be such that relevant residual risk
with each hazard as well as the overall        associated with each hazard as well as the
residual risk of the high-risk AI systems is   overall residual risk of the high-risk AI
judged acceptable, provided that the high-     systems is reasonably judged to be
risk AI system is used in accordance with      acceptable, provided that the high-risk AI
its intended purpose or under conditions of    system is used in accordance with its
reasonably foreseeable misuse. Those           intended purpose or under conditions of
residual risks shall be communicated to the    reasonably foreseeable misuse. Those
user.                                          residual risks and the reasoned
                                               judgements made shall be communicated
                                               to the deployer.
                                               In identifying the most appropriate risk
                                               management measures, the following
                                               shall be ensured:


Amendment 269

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – point a

     Text proposed by the Commission                           Amendment

(a) elimination or reduction of risks as       (a) elimination or reduction of identified
far as possible through adequate design and    risks as far as technically feasible through
development;                                   adequate design and development of the
                                               high-risk AI system, involving when
                                               relevant, experts and external
                                               stakeholders;


Amendment 270
Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – point b

     Text proposed by the Commission                          Amendment

(b) where appropriate, implementation of      (b) where appropriate, implementation of
adequate mitigation and control measures      adequate mitigation and control measures
in relation to risks that cannot be           addressing significant risks that cannot be
eliminated;                                   eliminated;


Amendment 271

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 1 – point c

     Text proposed by the Commission                          Amendment

(c) provision of adequate information         (c) provision of the required information
pursuant to Article 13, in particular as      pursuant to Article 13, and, where
regards the risks referred to in paragraph    appropriate, training to deployers.
2, point (b) of this Article, and, where
appropriate, training to users.


Amendment 272

Proposal for a regulation
Article 9 – paragraph 4 – subparagraph 2

     Text proposed by the Commission                          Amendment

In eliminating or reducing risks related to   In eliminating or reducing risks related to
the use of the high-risk AI system, due       the use of the high-risk AI system,
consideration shall be given to the           providers shall take into due consideration
technical knowledge, experience,              the technical knowledge, experience,
education, training to be expected by the     education and training the deployer may
user and the environment in which the         need, including in relation to the
system is intended to be used.                presumable context of use.


Amendment 273

Proposal for a regulation
Article 9 – paragraph 5

     Text proposed by the Commission                          Amendment

5.    High-risk AI systems shall be tested    5.     High-risk AI systems shall be tested
for the purposes of identifying the most        for the purposes of identifying the most
appropriate risk management measures.           appropriate and targeted risk management
Testing shall ensure that high-risk AI          measures and weighing any such
systems perform consistently for their          measures against the potential benefits
intended purpose and they are in                and intended goals of the system. Testing
compliance with the requirements set out        shall ensure that high-risk AI systems
in this Chapter.                                perform consistently for their intended
                                                purpose and they are in compliance with
                                                the requirements set out in this Chapter.


Amendment 274

Proposal for a regulation
Article 9 – paragraph 6

     Text proposed by the Commission                            Amendment

6.    Testing procedures shall be suitable      6.    Testing procedures shall be suitable
to achieve the intended purpose of the AI       to achieve the intended purpose of the AI
system and do not need to go beyond what        system.
is necessary to achieve that purpose.


Amendment 275

Proposal for a regulation
Article 9 – paragraph 7

     Text proposed by the Commission                            Amendment

7.    The testing of the high-risk AI           7.    The testing of the high-risk AI
systems shall be performed, as                  systems shall be performed, prior to the
appropriate, at any point in time               placing on the market or the putting into
throughout the development process, and,        service. Testing shall be made against prior
in any event, prior to the placing on the       defined metrics, and probabilistic
market or the putting into service. Testing     thresholds that are appropriate to the
shall be made against preliminarily defined     intended purpose or reasonably
metrics and probabilistic thresholds that are   foreseeable misuse of the high-risk AI
appropriate to the intended purpose of the      system.
high-risk AI system.


Amendment 276

Proposal for a regulation
Article 9 – paragraph 8
     Text proposed by the Commission                               Amendment

8.    When implementing the risk                  8.    When implementing the risk
management system described in                    management system described in
paragraphs 1 to 7, specific consideration         paragraphs 1 to 7, providers shall give
shall be given to whether the high-risk AI        specific consideration to whether the high-
system is likely to be accessed by or have        risk AI system is likely to adversely impact
an impact on children.                            vulnerable groups of people or children.


Amendment 277

Proposal for a regulation
Article 9 – paragraph 9

     Text proposed by the Commission                               Amendment

9.    For credit institutions regulated by        9.    For providers and AI systems
Directive 2013/36/EU, the aspects                 already covered by Union law that require
described in paragraphs 1 to 8 shall be part      them to establish a specific risk
of the risk management procedures                 management, including credit institutions
established by those institutions pursuant        regulated by Directive 2013/36/EU, the
to Article 74 of that Directive.                  aspects described in paragraphs 1 to 8 shall
                                                  be part of or combined with the risk
                                                  management procedures established by
                                                  that Union law.


Amendment 278

Proposal for a regulation
Article 10 – paragraph 1

     Text proposed by the Commission                               Amendment

1.     High-risk AI systems which make            1.     High-risk AI systems which make
use of techniques involving the training of       use of techniques involving the training of
models with data shall be developed on the        models with data shall be developed on the
basis of training, validation and testing data    basis of training, validation and testing data
sets that meet the quality criteria referred to   sets that meet the quality criteria referred to
in paragraphs 2 to 5.                             in paragraphs 2 to 5 as far as this is
                                                  technically feasible according to the
                                                  specific market segment or scope of
                                                  application.
                                                  Techniques that do not require labelled
                                                  input data such as unsupervised learning
                                                  and reinforcement learning shall be
                                                  developed on the basis of data sets such as
                                                  for testing and verification that meet the
                                               quality criteria referred to in paragraphs
                                               2 to 5.


Amendment 279

Proposal for a regulation
Article 10 – paragraph 2 – introductory part

      Text proposed by the Commission                          Amendment

2.    Training, validation and testing data    2.    Training, validation and testing data
sets shall be subject to appropriate data      sets shall be subject to data governance
governance and management practices.           appropriate for the context of use as well
Those practices shall concern in particular,   as the intended purpose of the AI system.
                                               Those measures shall concern in
                                               particular,


Amendment 280

Proposal for a regulation
Article 10 – paragraph 2 – point a a (new)

      Text proposed by the Commission                          Amendment

                                               (a a) transparency as regards the original
                                               purpose of data collection;


Amendment 281

Proposal for a regulation
Article 10 – paragraph 2 – point b

      Text proposed by the Commission                          Amendment

(b)   data collection;                         (b)   data collection processes;


Amendment 282

Proposal for a regulation
Article 10 – paragraph 2 – point c

      Text proposed by the Commission                          Amendment

(c) relevant data preparation processing       (c) data preparation processing
operations, such as annotation, labelling,     operations, such as annotation, labelling,
                                               cleaning, updating enrichment and
cleaning, enrichment and aggregation;            aggregation;


Amendment 283

Proposal for a regulation
Article 10 – paragraph 2 – point d

     Text proposed by the Commission                              Amendment

(d) the formulation of relevant                  (d) the formulation of assumptions,
assumptions, notably with respect to the         notably with respect to the information that
information that the data are supposed to        the data are supposed to measure and
measure and represent;                           represent;


Amendment 284

Proposal for a regulation
Article 10 – paragraph 2 – point e

     Text proposed by the Commission                              Amendment

(e) a prior assessment of the availability,      (e) an assessment of the availability,
quantity and suitability of the data sets that   quantity and suitability of the data sets that
are needed;                                      are needed;


Amendment 285

Proposal for a regulation
Article 10 – paragraph 2 – point f

     Text proposed by the Commission                              Amendment

(f) examination in view of possible              (f) examination in view of possible
biases;                                          biases that are likely to affect the health
                                                 and safety of persons, negatively impact
                                                 fundamental rights or lead to
                                                 discrimination prohibited under Union
                                                 law, especially where data outputs
                                                 influence inputs for future operations
                                                 (‘feedback loops’) and appropriate
                                                 measures to detect, prevent and mitigate
                                                 possible biases;


Amendment 286
Proposal for a regulation
Article 10 – paragraph 2 – point f a (new)

     Text proposed by the Commission                             Amendment

                                                 (f a) appropriate measures to detect,
                                                 prevent and mitigate possible biases


Amendment 287

Proposal for a regulation
Article 10 – paragraph 2 – point g

     Text proposed by the Commission                             Amendment

(g) the identification of any possible data      (g) the identification of relevant data
gaps or shortcomings, and how those gaps         gaps or shortcomings that prevent
and shortcomings can be addressed.               compliance with this Regulation, and how
                                                 those gaps and shortcomings can be
                                                 addressed;


Amendment 288

Proposal for a regulation
Article 10 – paragraph 3

     Text proposed by the Commission                             Amendment

3.     Training, validation and testing data     3.     Training datasets, and where they
sets shall be relevant, representative, free     are used, validation and testing datasets,
of errors and complete. They shall have the      including the labels, shall be relevant,
appropriate statistical properties, including,   sufficiently representative, appropriately
where applicable, as regards the persons or      vetted for errors and be as complete as
groups of persons on which the high-risk         possible in view of the intended purpose.
AI system is intended to be used. These          They shall have the appropriate statistical
characteristics of the data sets may be met      properties, including, where applicable, as
at the level of individual data sets or a        regards the persons or groups of persons in
combination thereof.                             relation to whom the high-risk AI system
                                                 is intended to be used. These
                                                 characteristics of the datasets shall be met
                                                 at the level of individual datasets or a
                                                 combination thereof.


Amendment 289

Proposal for a regulation
Article 10 – paragraph 4
     Text proposed by the Commission                           Amendment

4.    Training, validation and testing data    4.     Datasets shall take into account, to
sets shall take into account, to the extent    the extent required by the intended purpose
required by the intended purpose, the          or reasonably foreseeable misuses of the
characteristics or elements that are           AI system, the characteristics or elements
particular to the specific geographical,       that are particular to the specific
behavioural or functional setting within       geographical, contextual behavioural or
which the high-risk AI system is intended      functional setting within which the high-
to be used.                                    risk AI system is intended to be used.


Amendment 290

Proposal for a regulation
Article 10 – paragraph 5

     Text proposed by the Commission                           Amendment

5.     To the extent that it is strictly       5.     To the extent that it is strictly
necessary for the purposes of ensuring bias    necessary for the purposes of ensuring
monitoring, detection and correction in        negative bias detection and correction in
relation to the high-risk AI systems, the      relation to the high-risk AI systems, the
providers of such systems may process          providers of such systems may
special categories of personal data referred   exceptionally process special categories of
to in Article 9(1) of Regulation (EU)          personal data referred to in Article 9(1) of
2016/679, Article 10 of Directive (EU)         Regulation (EU) 2016/679, Article 10 of
2016/680 and Article 10(1) of Regulation       Directive (EU) 2016/680 and Article 10(1)
(EU) 2018/1725, subject to appropriate         of Regulation (EU) 2018/1725, subject to
safeguards for the fundamental rights and      appropriate safeguards for the fundamental
freedoms of natural persons, including         rights and freedoms of natural persons,
technical limitations on the re-use and use    including technical limitations on the re-
of state-of-the-art security and privacy-      use and use of state-of-the-art security and
preserving measures, such as                   privacy-preserving. In particular, all the
pseudonymisation, or encryption where          following conditions shall apply in order
anonymisation may significantly affect         for this processing to occur: (a) the bias
the purpose pursued.                           detection and correction cannot be
                                               effectively fulfilled by processing synthetic
                                               or anonymised data;
                                               (b) the data are pseudonymised;
                                               (c) the provider takes appropriate
                                               technical and organisational measures to
                                               ensure that the data processed for the
                                               purpose of this paragraph are secured,
                                               protected, subject to suitable safeguards
                                               and only authorised persons have access
                                               to those data with appropriate
                                               confidentiality obligations;
                                      (d) the data processed for the purpose of
                                      this paragraph are not to be transmitted,
                                      transferred or otherwise accessed by other
                                      parties;
                                      (e) the data processed for the purpose of
                                      this paragraph are protected by means of
                                      appropriate technical and organisational
                                      measures and deleted once the bias has
                                      been corrected or the personal data has
                                      reached the end of its retention period;
                                      (f) effective and appropriate measures are
                                      in place to ensure availability, security
                                      and resilience of processing systems and
                                      services against technical or physical
                                      incidents;
                                      (g) effective and appropriate measures are
                                      in place to ensure physical security of
                                      locations where the data are stored and
                                      processed, internal IT and IT security
                                      governance and management,
                                      certification of processes and products;
                                      Providers having recourse to this
                                      provision shall draw up documentation
                                      explaining why the processing of special
                                      categories of personal data was necessary
                                      to detect and correct biases.


Amendment 291

Proposal for a regulation
Article 10 – paragraph 6 a (new)

    Text proposed by the Commission                  Amendment

                                      6 a. Where the provider cannot comply
                                      with the obligations laid down in this
                                      Article because that provider does not
                                      have access to the data and the data is
                                      held exclusively by the deployer, the
                                      deployer may, on the basis of a contract,
                                      be made responsible for any infringement
                                      of this Article.


Amendment 292
Proposal for a regulation
Article 11 – paragraph 1 – subparagraph 1

     Text proposed by the Commission                           Amendment

The technical documentation shall be           The technical documentation shall be
drawn up in such a way to demonstrate that     drawn up in such a way to demonstrate that
the high-risk AI system complies with the      the high-risk AI system complies with the
requirements set out in this Chapter and       requirements set out in this Chapter and
provide national competent authorities and     provide national supervisory authorities
notified bodies with all the necessary         and notified bodies with the necessary
information to assess the compliance of the    information to assess the compliance of the
AI system with those requirements. It shall    AI system with those requirements. It shall
contain, at a minimum, the elements set out    contain, at a minimum, the elements set out
in Annex IV.                                   in Annex IV or, in the case of SMEs and
                                               start-ups, any equivalent documentation
                                               meeting the same objectives, subject to
                                               approval of the competent national
                                               authority.


Amendment 293

Proposal for a regulation
Article 11 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    Where a high-risk AI system related      2.    Where a high-risk AI system related
to a product, to which the legal acts listed   to a product, to which the legal acts listed
in Annex II, section A apply, is placed on     in Annex II, section A apply, is placed on
the market or put into service one single      the market or put into service one single
technical documentation shall be drawn up      technical documentation shall be drawn up
containing all the information set out in      containing all the information set out in
Annex IV as well as the information            paragraph 1 as well as the information
required under those legal acts.               required under those legal acts.


Amendment 294

Proposal for a regulation
Article 11 – paragraph 3 a (new)

     Text proposed by the Commission                           Amendment

                                               3 a. Providers that are credit institutions
                                               regulated by Directive 2013/36/EU shall
                                               maintain the technical documentation as
                                               part of the documentation concerning
                                               internal governance, arrangements,
                                               processes and mechanisms pursuant to
                                               Article 74 of that Directive.


Amendment 295

Proposal for a regulation
Article 12 – paragraph 1

    Text proposed by the Commission                            Amendment

1.    High-risk AI systems shall be            1.    High-risk AI systems shall be
designed and developed with capabilities       designed and developed with capabilities
enabling the automatic recording of events     enabling the automatic recording of events
(‘logs’) while the high-risk AI systems is     (‘logs’) while the high-risk AI systems is
operating. Those logging capabilities shall    operating. Those logging capabilities shall
conform to recognised standards or             conform to the state of the art and
common specifications.                         recognised standards or common
                                               specifications.


Amendment 296

Proposal for a regulation
Article 12 – paragraph 2

    Text proposed by the Commission                            Amendment

2.    The logging capabilities shall ensure    2.     In order to ensure a level of
a level of traceability of the AI system’s     traceability of the AI system’s functioning
functioning throughout its lifecycle that is   throughout its entire lifetime that is
appropriate to the intended purpose of the     appropriate to the intended purpose of the
system.                                        system, the logging capabilities shall
                                               facilitate the monitoring of operations as
                                               referred to in Article 29(4) as well as the
                                               post market monitoring referred to in
                                               Article 61. In particular, they shall enable
                                               the recording of events relevant for the
                                               identification of situations that may:
                                               (a) result in the AI system presenting a
                                               risk within the meaning of Article65(1);
                                               or
                                               (b) lead to a substantial modification of
                                               the AI system.


Amendment 297
Proposal for a regulation
Article 12 – paragraph 2 a (new)

    Text proposed by the Commission                        Amendment

                                            2 a. High-risk AI systems shall be
                                            designed and developed with, the logging
                                            capabilities enabling the recording of
                                            energy consumption, the measurement or
                                            calculation of resource use and
                                            environmental impact of the high-risk AI
                                            system during all phases of the system’s
                                            lifecycle.


Amendment 298

Proposal for a regulation
Article 12 – paragraph 3

    Text proposed by the Commission                        Amendment

3.    In particular, logging capabilities   deleted
shall enable the monitoring of the
operation of the high-risk AI system with
respect to the occurrence of situations
that may result in the AI system
presenting a risk within the meaning of
Article 65(1) or lead to a substantial
modification, and facilitate the post-
market monitoring referred to in Article
61.


Amendment 299

Proposal for a regulation
Article 13 – title

    Text proposed by the Commission                        Amendment

Transparency and provision of information   Transparency and provision of information
to users


Amendment 300

Proposal for a regulation
Article 13 – paragraph 1
     Text proposed by the Commission                           Amendment

1.    High-risk AI systems shall be            1.    High-risk AI systems shall be
designed and developed in such a way to        designed and developed in such a way to
ensure that their operation is sufficiently    ensure that their operation is sufficiently
transparent to enable users to interpret the   transparent to enable providers and users
system’s output and use it appropriately.      to reasonably understand the system’s
An appropriate type and degree of              functioning. Appropriate transparency
transparency shall be ensured, with a view     shall be ensured in accordance with the
to achieving compliance with the relevant      intended purpose of the AI system, with a
obligations of the user and of the provider    view to achieving compliance with the
set out in Chapter 3 of this Title.            relevant obligations of the provider and
                                               user set out in Chapter 3 of this Title.
                                               Transparency shall thereby mean that, at
                                               the time the high-risk AI system is placed
                                               on the market, all technical means
                                               available in accordance with the generally
                                               acknowledged state of art are used to
                                               ensure that the AI system’s output is
                                               interpretable by the provider and the user.
                                               The user shall be enabled to understand
                                               and use the AI system appropriately by
                                               generally knowing how the AI system
                                               works and what data it processes,
                                               allowing the user to explain the decisions
                                               taken by the AI system to the affected
                                               person pursuant to Article 68(c).


Amendment 301

Proposal for a regulation
Article 13 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    High-risk AI systems shall be            2.    High-risk AI systems shall be
accompanied by instructions for use in an      accompanied by intelligible instructions
appropriate digital format or otherwise that   for use in an appropriate digital format or
include concise, complete, correct and         made otherwise available in a durable
clear information that is relevant,            medium that include concise, correct, clear
accessible and comprehensible to users.        and to the extent possible complete
                                               information that helps operating and
                                               maintaining the AI system as well as
                                               supporting informed decision-making by
                                               users and is reasonably relevant,
                                               accessible and comprehensible to users .
Amendment 302

Proposal for a regulation
Article 13 – paragraph 3 – introductory part

    Text proposed by the Commission                            Amendment

3.   The information referred to in            3.    To achieve the outcomes referred to
paragraph 2 shall specify:                     in paragraph 1, information referred to in
                                               paragraph 2 shall specify:


Amendment 303

Proposal for a regulation
Article 13 – paragraph 3 – point a

    Text proposed by the Commission                            Amendment

(a) the identity and the contact details of    (a) the identity and the contact details of
the provider and, where applicable, of its     the provider and, where applicable, of its
authorised representative;                     authorised representatives;


Amendment 304

Proposal for a regulation
Article 13 – paragraph 3 – point a a (new)

    Text proposed by the Commission                            Amendment

                                               (aa) where it is not the same as the
                                               provider, the identity and the contact
                                               details of the entity that carried out the
                                               conformity assessment and, where
                                               applicable, of its authorised
                                               representative;


Amendment 305

Proposal for a regulation
Article 13 – paragraph 3 – point b – introductory part

    Text proposed by the Commission                            Amendment

(b) the characteristics, capabilities and      (b) the characteristics, capabilities and
limitations of performance of the high-risk    limitations of performance of the high-risk
AI system, including:                          AI system, including, where appropriate:
Amendment 306

Proposal for a regulation
Article 13 – paragraph 3 – point b – point ii

    Text proposed by the Commission                             Amendment

(ii) the level of accuracy, robustness and       (ii) the level of accuracy, robustness and
cybersecurity referred to in Article 15          cybersecurity referred to in Article 15
against which the high-risk AI system has        against which the high-risk AI system has
been tested and validated and which can be       been tested and validated and which can be
expected, and any known and foreseeable          expected, and any clearly known and
circumstances that may have an impact on         foreseeable circumstances that may have
that expected level of accuracy, robustness      an impact on that expected level of
and cybersecurity;                               accuracy, robustness and cybersecurity;


Amendment 307

Proposal for a regulation
Article 13 – paragraph 3 – point b – point iii

    Text proposed by the Commission                             Amendment

(iii) any known or foreseeable                   (iii) any clearly known or foreseeable
circumstance, related to the use of the          circumstance, related to the use of the
high-risk AI system in accordance with its       high-risk AI system in accordance with its
intended purpose or under conditions of          intended purpose or under conditions of
reasonably foreseeable misuse, which may         reasonably foreseeable misuse, which may
lead to risks to the health and safety or        lead to risks to the health and safety,
fundamental rights;                              fundamental rights or the environment,
                                                 including, where appropriate, illustrative
                                                 examples of such limitations and of
                                                 scenarios for which the system should not
                                                 be used;


Amendment 308

Proposal for a regulation
Article 13 – paragraph 3 – point b – point iii a (new)

    Text proposed by the Commission                             Amendment

                                                 (iiia) the degree to which the AI system
                                                 can provide an explanation for decisions
                                                 it takes;
Amendment 309

Proposal for a regulation
Article 13 – paragraph 3 – point b – point v

     Text proposed by the Commission                            Amendment

(v) when appropriate, specifications for        (v) relevant information about user
the input data, or any other relevant           actions that may influence system
information in terms of the training,           performance, including type or quality of
validation and testing data sets used, taking   input data, or any other relevant
into account the intended purpose of the AI     information in terms of the training,
system.                                         validation and testing data sets used, taking
                                                into account the intended purpose of the AI
                                                system.


Amendment 310

Proposal for a regulation
Article 13 – paragraph 3 – point e

     Text proposed by the Commission                            Amendment

(e) the expected lifetime of the high-risk      (e) any necessary maintenance and care
AI system and any necessary maintenance         measures to ensure the proper functioning
and care measures to ensure the proper          of that AI system, including as regards
functioning of that AI system, including as     software updates, through its expected
regards software updates.                       lifetime.


Amendment 311

Proposal for a regulation
Article 13 – paragraph 3 – point e a (new)

     Text proposed by the Commission                            Amendment

                                                (ea) a description of the mechanisms
                                                included within the AI system that allows
                                                users to properly collect, store and
                                                interpret the logs in accordance with
                                                Article 12(1).


Amendment 312

Proposal for a regulation
Article 13 – paragraph 3 – point e b (new)
     Text proposed by the Commission                            Amendment

                                                (eb) The information shall be provided at
                                                least in the language of the country where
                                                the AI system is used.


Amendment 313

Proposal for a regulation
Article 13 – paragraph 3 a (new)

     Text proposed by the Commission                            Amendment

                                                3a. In order to comply with the
                                                obligations laid down in this Article,
                                                providers and users shall ensure a
                                                sufficient level of AI literacy in line with
                                                Article 4b.


Amendment 314

Proposal for a regulation
Article 14 – paragraph 1

     Text proposed by the Commission                            Amendment

1.    High-risk AI systems shall be             1.    High-risk AI systems shall be
designed and developed in such a way,           designed and developed in such a way,
including with appropriate human-machine        including with appropriate human-machine
interface tools, that they can be effectively   interface tools, that they be effectively
overseen by natural persons during the          overseen by natural persons as
period in which the AI system is in use.        proportionate to the risks associated with
                                                those systems. Natural persons in charge
                                                of ensuring human oversight shall have
                                                sufficient level of AI literacy in
                                                accordance with Article 4b and the
                                                necessary support and authority to
                                                exercise that function, during the period in
                                                which the AI system is in use and to allow
                                                for thorough investigation after an
                                                incident.


Amendment 315

Proposal for a regulation
Article 14 – paragraph 2
     Text proposed by the Commission                          Amendment

2.    Human oversight shall aim at             2.    Human oversight shall aim at
preventing or minimising the risks to          preventing or minimising the risks to
health, safety or fundamental rights that      health, safety, fundamental rights or
may emerge when a high-risk AI system is       environment that may emerge when a
used in accordance with its intended           high-risk AI system is used in accordance
purpose or under conditions of reasonably      with its intended purpose or under
foreseeable misuse, in particular when such    conditions of reasonably foreseeable
risks persist notwithstanding the              misuse, in particular when such risks
application of other requirements set out in   persist notwithstanding the application of
this Chapter.                                  other requirements set out in this Chapter
                                               and where decisions based solely on
                                               automated processing by AI systems
                                               produce legal or otherwise significant
                                               effects on the persons or groups of
                                               persons on which the system is to be used.


Amendment 316

Proposal for a regulation
Article 14 – paragraph 3 – introductory part

     Text proposed by the Commission                          Amendment

3.    Human oversight shall be ensured         3.     Human oversight shall take into
through either one or all of the following     account the specific risks, the level of
measures:                                      automation, and context of the AI system
                                               and shall be ensured through either one or
                                               all of the following types of measures:


Amendment 317

Proposal for a regulation
Article 14 – paragraph 4 – introductory part

     Text proposed by the Commission                          Amendment

4.    The measures referred to in              4.    For the purpose of implementing
paragraph 3 shall enable the individuals       paragraphs 1 to 3, the high-risk AI system
to whom human oversight is assigned to do      shall be provided to the user in such a way
the following, as appropriate to the           that natural persons to whom human
circumstances:                                 oversight is assigned are enabled, as
                                               appropriate and proportionate to the
                                               circumstances:
Amendment 318

Proposal for a regulation
Article 14 – paragraph 4 – point a

     Text proposed by the Commission                            Amendment

(a) fully understand the capacities and         (a) be aware of and sufficiently
limitations of the high-risk AI system and      understand the relevant capacities and
be able to duly monitor its operation, so       limitations of the high-risk AI system and
that signs of anomalies, dysfunctions and       be able to duly monitor its operation, so
unexpected performance can be detected          that signs of anomalies, dysfunctions and
and addressed as soon as possible;              unexpected performance can be detected
                                                and addressed as soon as possible;


Amendment 319

Proposal for a regulation
Article 14 – paragraph 4 – point e

     Text proposed by the Commission                            Amendment

(e) be able to intervene on the operation       (e) be able to intervene on the operation
of the high-risk AI system or interrupt the     of the high-risk AI system or interrupt, the
system through a “stop” button or a similar     system through a “stop” button or a similar
procedure.                                      procedure that allows the system to come
                                                to a halt in a safe state, except if the
                                                human interference increases the risks or
                                                would negatively impact the performance
                                                in consideration of generally
                                                acknowledged state-of-the-art.


Amendment 320

Proposal for a regulation
Article 14 – paragraph 5

     Text proposed by the Commission                            Amendment

5.     For high-risk AI systems referred to     5.     For high-risk AI systems referred to
in point 1(a) of Annex III, the measures        in point1(a) of Annex III, the measures
referred to in paragraph 3 shall be such as     referred to in paragraph 3 shall be such as
to ensure that, in addition, no action or       to ensure that, in addition, no action or
decision is taken by the user on the basis of   decision is taken by the user on the basis of
the identification resulting from the system    the identification resulting from the system
unless this has been verified and confirmed     unless this has been verified and confirmed
by at least two natural persons.                by at least two natural persons with the
                                                necessary competence, training and
                                               authority.


Amendment 321

Proposal for a regulation
Article 15 – paragraph 1

    Text proposed by the Commission                            Amendment

1.     High-risk AI systems shall be           1.     High-risk AI systems shall be
designed and developed in such a way that      designed and developed following the
they achieve, in the light of their intended   principle of security by design and by
purpose, an appropriate level of accuracy,     default. In the light of their intended
robustness and cybersecurity, and perform      purpose, they should achieve an
consistently in those respects throughout      appropriate level of accuracy, robustness,
their lifecycle.                               safety, and cybersecurity, and perform
                                               consistently in those respects throughout
                                               their lifecycle. Compliance with these
                                               requirements shall include
                                               implementation of state-of-the-art
                                               measures, according to the specific
                                               market segment or scope of application.



Amendment 322

Proposal for a regulation
Article 15 – paragraph 1 a (new)

    Text proposed by the Commission                            Amendment

                                               1 a. To address the technical aspects of
                                               how to measure the appropriate levels of
                                               accuracy and robustness set out in
                                               paragraph 1 of this Article, the AI Office
                                               shall bring together national and
                                               international metrology and
                                               benchmarking authorities and provide
                                               non-binding guidance on the matter as set
                                               out in Article 56, paragraph 2, point (a).


Amendment 323

Proposal for a regulation
Article 15 – paragraph 1 b (new)
    Text proposed by the Commission                           Amendment

                                              1b. To address any emerging issues
                                              across the internal market with regard to
                                              cybersecurity, the European Union
                                              Agency for Cybersecurity (ENISA) shall
                                              be involved alongside the European
                                              Artificial Intelligence Board as set out
                                              Article 56, paragraph 2, point (b).


Amendment 324

Proposal for a regulation
Article 15 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    The levels of accuracy and the          2.    The levels of accuracy and the
relevant accuracy metrics of high-risk AI     relevant accuracy metrics of high-risk AI
systems shall be declared in the              systems shall be declared in the
accompanying instructions of use.             accompanying instructions of use. The
                                              language used shall be clear, free of
                                              misunderstandings or misleading
                                              statements.


Amendment 325

Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 1

    Text proposed by the Commission                           Amendment

High-risk AI systems shall be resilient as    Technical and organisational measures
regards errors, faults or inconsistencies     shall be taken to ensure that high-risk AI
that may occur within the system or the       systems shall be as resilient as possible
environment in which the system operates,     regarding errors, faults or inconsistencies
in particular due to their interaction with   that may occur within the system or the
natural persons or other systems.             environment in which the system operates,
                                              in particular due to their interaction with
                                              natural persons or other systems.


Amendment 326

Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 2
     Text proposed by the Commission                           Amendment

The robustness of high-risk AI systems         The robustness of high-risk AI systems
may be achieved through technical              may be achieved by the appropriate
redundancy solutions, which may include        provider with input from the user, where
backup or fail-safe plans.                     necessary, through technical redundancy
                                               solutions, which may include backup or
                                               fail-safe plans.


Amendment 327

Proposal for a regulation
Article 15 – paragraph 3 – subparagraph 3

     Text proposed by the Commission                           Amendment

High-risk AI systems that continue to learn    High-risk AI systems that continue to learn
after being placed on the market or put into   after being placed on the market or put into
service shall be developed in such a way to    service shall be developed in such a way to
ensure that possibly biased outputs due to     ensure that possibly biased outputs
outputs used as an input for future            influencing input for future operations
operations (‘feedback loops’) are duly         (‘feedback loops’) and malicious
addressed with appropriate mitigation          manipulation of inputs used in learning
measures.                                      during operation are duly addressed with
                                               appropriate mitigation measures.


Amendment 328

Proposal for a regulation
Article 15 – paragraph 4 – subparagraph 1

     Text proposed by the Commission                           Amendment

High-risk AI systems shall be resilient as     High-risk AI systems shall be resilient as
regards attempts by unauthorised third         regards to attempts by unauthorised third
parties to alter their use or performance by   parties to alter their use, behaviour,
exploiting the system vulnerabilities.         outputs or performance by exploiting the
                                               system vulnerabilities.


Amendment 329

Proposal for a regulation
Article 15 – paragraph 4 – subparagraph 3
     Text proposed by the Commission                            Amendment

The technical solutions to address AI           The technical solutions to address AI
specific vulnerabilities shall include, where   specific vulnerabilities shall include, where
appropriate, measures to prevent and            appropriate, measures to prevent, detect,
control for attacks trying to manipulate the    respond to, resolve and control for attacks
training dataset (‘data poisoning’), inputs     trying to manipulate the training dataset
designed to cause the model to make a           (‘data poisoning’), or pre-trained
mistake (‘adversarial examples’), or model      components used in training (‘model
flaws.                                          poisoning’) , inputs designed to cause the
                                                model to make a mistake (‘adversarial
                                                examples’ or ‘model evasion’),
                                                confidentiality attacks or model flaws,
                                                which could lead to harmful decision-
                                                making.


Amendment 330

Proposal for a regulation
Title III – Chapter 3 – title

     Text proposed by the Commission                            Amendment

OBLIGATIONS OF PROVIDERS AND                    OBLIGATIONS OF PROVIDERS AND
USERS OF HIGH-RISK AI SYSTEMS                   DEPLOYERS OF HIGH-RISK AI
and other parties                               SYSTEMS AND OTHER PARTIES


Amendment 331

Proposal for a regulation
Article 16 – title

     Text proposed by the Commission                            Amendment

Obligations of providers of high-risk AI        Obligations of providers and deployers of
systems                                         high-risk AI systems and other parties


Amendment 332

Proposal for a regulation
Article 16 – paragraph 1 – point a

     Text proposed by the Commission                            Amendment

(a) ensure that their high-risk AI systems      (a) ensure that their high-risk AI systems
are compliant with the requirements set out     are compliant with the requirements set out
in Chapter 2 of this Title;                  in Chapter 2 of this Title before placing
                                             them on the market or putting them into
                                             service;


Amendment 333

Proposal for a regulation
Article 16 – paragraph 1 – point a a (new)

     Text proposed by the Commission                        Amendment

                                             (a a) indicate their name, registered trade
                                             name or registered trade mark, and their
                                             address and contact information on the
                                             high-risk AI system or, where that is not
                                             possible, on its accompanying
                                             documentation, as appropriate;


Amendment 334

Proposal for a regulation
Article 16 – paragraph 1 – point a b (new)

     Text proposed by the Commission                        Amendment

                                             (a b) ensure that natural persons to
                                             whom human oversight of high-risk AI
                                             systems is assigned are specifically made
                                             aware of the risk of automation or
                                             confirmation bias;


Amendment 335

Proposal for a regulation
Article 16 – paragraph 1 – point a c (new)

     Text proposed by the Commission                        Amendment

                                             (a c) provide specifications for the input
                                             data, or any other relevant information in
                                             terms of the datasets used, including their
                                             limitation and assumptions, taking into
                                             account the intended purpose and the
                                             foreseeable and reasonably foreseeable
                                             misuses of the AI system;
Amendment 336

Proposal for a regulation
Article 16 – paragraph 1 – point c

    Text proposed by the Commission                           Amendment

(c) draw-up the technical documentation       (c) draw-up and keep the technical
of the high-risk AI system;                   documentation of the high-risk AI system
                                              referred to in Article 11;


Amendment 337

Proposal for a regulation
Article 16 – paragraph 1 – point d

    Text proposed by the Commission                           Amendment

(d) when under their control, keep the        (d) when under their control, keep the
logs automatically generated by their high-   logs automatically generated by their high-
risk AI systems;                              risk AI systems that are required for
                                              ensuring and demonstrating compliance
                                              with this Regulation, in accordance with
                                              Article 20;


Amendment 338

Proposal for a regulation
Article 16 – paragraph 1 – point e

    Text proposed by the Commission                           Amendment

(e) ensure that the high-risk AI system       (e) ensure that the high-risk AI system
undergoes the relevant conformity             undergoes the relevant conformity
assessment procedure, prior to its placing    assessment procedure, prior to its placing
on the market or putting into service;        on the market or putting into service, in
                                              accordance with Article 43;


Amendment 339

Proposal for a regulation
Article 16 – paragraph 1 – point e a (new)

    Text proposed by the Commission                           Amendment

                                              (e a) draw up an EU declaration of
                                             conformity in accordance with Article 48;


Amendment 340

Proposal for a regulation
Article 16 – paragraph 1 – point e b (new)

    Text proposed by the Commission                         Amendment

                                             (e b) affix the CE marking to the high-
                                             risk AI system to indicate conformity with
                                             this Regulation, in accordance with
                                             Article 49;


Amendment 341

Proposal for a regulation
Article 16 – paragraph 1 – point g

    Text proposed by the Commission                         Amendment

(g) take the necessary corrective actions,   (g) take the necessary corrective actions
if the high-risk AI system is not in         as referred to in Article 21 and provide
conformity with the requirements set out     information in that regard;
in Chapter 2 of this Title;


Amendment 342

Proposal for a regulation
Article 16 – paragraph 1 – point h

    Text proposed by the Commission                         Amendment

(h) inform the national competent            deleted
authorities of the Member States in which
they made the AI system available or put
it into service and, where applicable, the
notified body of the non-compliance and
of any corrective actions taken;


Amendment 343

Proposal for a regulation
Article 16 – paragraph 1 – point i
    Text proposed by the Commission                           Amendment

(i) to affix the CE marking to their           deleted
high-risk AI systems to indicate the
conformity with this Regulation in
accordance with Article 49;


Amendment 344

Proposal for a regulation
Article 16 – paragraph 1 – point j

    Text proposed by the Commission                           Amendment

(j) upon request of a national competent       (j) upon a reasoned request of a national
authority, demonstrate the conformity of       supervisory authority, demonstrate the
the high-risk AI system with the               conformity of the high-risk AI system with
requirements set out in Chapter 2 of this      the requirements set out in Chapter 2 of
Title.                                         this Title.


Amendment 345

Proposal for a regulation
Article 16 – paragraph 1 – point j a (new)

    Text proposed by the Commission                           Amendment

                                               (j a) ensure that the high-risk AI system
                                               complies with accessibility requirements.


Amendment 346

Proposal for a regulation
Article 17 – paragraph 1 – introductory part

    Text proposed by the Commission                           Amendment

1.    Providers of high-risk AI systems        1.    Providers of high-risk AI systems
shall put a quality management system in       shall have a quality management system in
place that ensures compliance with this        place that ensures compliance with this
Regulation. That system shall be               Regulation. It shall be documented in a
documented in a systematic and orderly         systematic and orderly manner in the form
manner in the form of written policies,        of written policies, procedures or
procedures and instructions, and shall         instructions, and can be incorporated into
include at least the following aspects:        an existing quality management system
                                               under Union sectoral legislative acts. It
                                               shall include at least the following aspects:


Amendment 347

Proposal for a regulation
Article 17 – paragraph 1 – point a

     Text proposed by the Commission                            Amendment

(a) a strategy for regulatory                  deleted
compliance, including compliance with
conformity assessment procedures and
procedures for the management of
modifications to the high-risk AI system;


Amendment 348

Proposal for a regulation
Article 17 – paragraph 1 – point e

     Text proposed by the Commission                            Amendment

(e) technical specifications, including        (e) technical specifications, including
standards, to be applied and, where the        standards, to be applied and, where the
relevant harmonised standards are not          relevant harmonised standards are not
applied in full, the means to be used to       applied in full, or do not cover all of the
ensure that the high-risk AI system            relevant requirements, the means to be
complies with the requirements set out in      used to ensure that the high-risk AI system
Chapter 2 of this Title;                       complies with the requirements set out in
                                               Chapter 2 of this Title;


Amendment 349

Proposal for a regulation
Article 17 – paragraph 1 – point f

     Text proposed by the Commission                            Amendment

(f) systems and procedures for data            (f) systems and procedures for data
management, including data collection,         management, including data acquisition
data analysis, data labelling, data storage,   data collection, data analysis, data
data filtration, data mining, data             labelling, data storage, data filtration, data
aggregation, data retention and any other      mining, data aggregation, data retention
operation regarding the data that is           and any other operation regarding the data
performed before and for the purposes of       that is performed before and for the
the placing on the market or putting into      purposes of the placing on the market or
                                               putting into service of high-risk AI
service of high-risk AI systems;              systems;


Amendment 350

Proposal for a regulation
Article 17 – paragraph 1 – point j

     Text proposed by the Commission                          Amendment

(j) the handling of communication with        (j) the handling of communication with
national competent authorities, competent     relevant competent authorities, including
authorities, including sectoral ones,         sectoral ones;
providing or supporting the access to data,
notified bodies, other operators,
customers or other interested parties;


Amendment 351

Proposal for a regulation
Article 17 – paragraph 2

     Text proposed by the Commission                          Amendment

2.    The implementation of aspects           2.    The implementation of aspects
referred to in paragraph 1 shall be           referred to in paragraph 1 shall be
proportionate to the size of the provider’s   proportionate to the size of the provider’s
organisation.                                 organisation. Providers shall in any event
                                              respect the degree of rigour and the level
                                              of protection required to ensure
                                              compliance of their AI systems with this
                                              Regulation.


Amendment 352

Proposal for a regulation
Article 18 – title

     Text proposed by the Commission                          Amendment

Obligation to draw up technical               deleted
documentation


Amendment 353
Proposal for a regulation
Article 18 – paragraph 1

     Text proposed by the Commission                     Amendment

1.    Providers of high-risk AI systems        deleted
shall draw up the technical documen-
tation referred to in Article 11 in
accordance with Annex IV.


Amendment 354

Proposal for a regulation
Article 18 – paragraph 2

     Text proposed by the Commission                     Amendment

2.    Providers that are credit institutions   deleted
regulated by Directive 2013/36/EU shall
maintain the technical documentation as
part of the documentation concerning
internal governance, arrangements,
processes and mechanisms pursuant to
Article 74 of that Directive.


Amendment 355

Proposal for a regulation
Article 19

     Text proposed by the Commission                     Amendment

                 Article 19                    deleted
          Conformity assessment
1.    Providers of high-risk AI systems
shall ensure that their systems undergo
the relevant conformity assessment
procedure in accordance with Article 43,
prior to their placing on the market or
putting into service. Where the
compliance of the AI systems with the
requirements set out in Chapter 2 of this
Title has been demonstrated following
that conformity assessment, the providers
shall draw up an EU declaration of
conformity in accordance with Article 48
and affix the CE marking of conformity
in accordance with Article 49.
2.    For high-risk AI systems referred to
in point 5(b) of Annex III that are placed
on the market or put into service by
providers that are credit institutions
regulated by Directive 2013/36/EU, the
conformity assessment shall be carried
out as part of the procedure referred to in
Articles 97 to101 of that Directive.


Amendment 356

Proposal for a regulation
Article 20 – paragraph 1

     Text proposed by the Commission                             Amendment

1.    Providers of high-risk AI systems          1.    Providers of high-risk AI systems
shall keep the logs automatically generated      shall keep the logs automatically generated
by their high-risk AI systems, to the extent     by their high-risk AI systems, to the extent
such logs are under their control by virtue      such logs are under their control. Without
of a contractual arrangement with the            prejudice to applicable Union or national
user or otherwise by law. The logs shall be      law, the logs shall be kept for a period of at
kept for a period that is appropriate in the     least 6 months. The retention period shall
light of the intended purpose of high-risk       be in accordance with industry standards
AI system and applicable legal obligations       and appropriate to the intended purpose of
under Union or national law.                     high-risk AI system.


Amendment 357

Proposal for a regulation
Article 21 – paragraph 1

     Text proposed by the Commission                             Amendment

Providers of high-risk AI systems which          Providers of high-risk AI systems which
consider or have reason to consider that a       consider or have reason to consider that a
high-risk AI system which they have              high-risk AI system which they have
placed on the market or put into service is      placed on the market or put into service is
not in conformity with this Regulation           not in conformity with this Regulation
shall immediately take the necessary             shall immediately take the necessary
corrective actions to bring that system into     corrective actions to bring that system into
conformity, to withdraw it or to recall it, as   conformity, to withdraw it, to disable it or
appropriate. They shall inform the               to recall it, as appropriate.
distributors of the high-risk AI system in
question and, where applicable, the
authorised representative and importers
accordingly.
                                                In the cases referred to in the first
                                                paragraph, providers shall immediately
                                                inform:
                                                a. the distributors;
                                                b. the importers;
                                                c. the national competent authorities of
                                                the Member States in which they made the
                                                AI system available or put it into service;
                                                and
                                                d. where possible, the deployer.


Amendment 358

Proposal for a regulation
Article 21 – paragraph 1 a (new)

     Text proposed by the Commission                            Amendment

                                                The providers shall also inform the
                                                authorised representative, if one was
                                                appointed in accordance with Article 25,
                                                and the notified body if the high-risk AI
                                                system had to undergo a third-party
                                                conformity assessment in accordance with
                                                Article 43. Where applicable, they shall
                                                also investigate the causes in
                                                collaboration with the deployer.


Amendment 359

Proposal for a regulation
Article 22 – paragraph 1

     Text proposed by the Commission                            Amendment

Where the high-risk AI system presents a        Where the high-risk AI system presents a
risk within the meaning of Article 65(1)        risk within the meaning of Article 65(1)
and that risk is known to the provider of       and the provider of the system becomes
the system, that provider shall immediately     aware of that risk, that provider shall
inform the national competent authorities       immediately inform the national
of the Member States in which it made the       supervisory authorities of the Member
system available and, where applicable, the     States in which it made the system
notified body that issued a certificate for     available and, where applicable, the
the high-risk AI system, in particular of the   notified body that issued a certificate for
non-compliance and of any corrective            the high-risk AI system, in particular the
actions taken.                           nature of the non-compliance and of any
                                         relevant corrective actions taken.


Amendment 360

Proposal for a regulation
Article 22 – paragraph 1 a (new)

     Text proposed by the Commission                     Amendment

                                         In the cases referred to inthe first
                                         paragraph, providers of the high-risk AI
                                         system shall immediately inform:
                                         a) the distributors;
                                         b) the importers;
                                         c) the national competent authorities of
                                         the Member States in which they made the
                                         AI system available or put it into service;
                                         and
                                         d) where possible, the deployers.


Amendment 361

Proposal for a regulation
Article 22 – paragraph 1 b (new)

     Text proposed by the Commission                     Amendment

                                         The providers shall also inform the
                                         authorised representative, if one was
                                         appointed in accordance with Article 25.


Amendment 362

Proposal for a regulation
Article 23 – title

     Text proposed by the Commission                     Amendment

Cooperation with competent authorities   Cooperation with competent authorities,
                                         the Office and the Commission


Amendment 363
Proposal for a regulation
Article 23 – paragraph 1

    Text proposed by the Commission                           Amendment

Providers of high-risk AI systems shall,       Providers and where applicable, deployers
upon request by a national competent           of high-risk AI systems shall, upon a
authority, provide that authority with all     reasoned request by a national competent
the information and documentation              authority or where applicable, by the AI
necessary to demonstrate the conformity of     Office or the Commission, provide them
the high-risk AI system with the               with all the information and documentation
requirements set out in Chapter 2 of this      necessary to demonstrate the conformity of
Title, in an official Union language           the high-risk AI system with the
determined by the Member State                 requirements set out in Chapter 2 of this
concerned. Upon a reasoned request from        Title, in an official Union language
a national competent authority, providers      determined by the Member State
shall also give that authority access to the   concerned.
logs automatically generated by the high-
risk AI system, to the extent such logs are
under their control by virtue of a
contractual arrangement with the user or
otherwise by law.


Amendment 364

Proposal for a regulation
Article 23 – paragraph 1 a (new)

    Text proposed by the Commission                           Amendment

                                               Upon a reasoned request by a national
                                               competent authority or, where applicable,
                                               by the Commission, providers and, where
                                               applicable, deployers shall also give the
                                               requesting national competent authority
                                               or the Commission, as applicable, access
                                               to the logs automatically generated by the
                                               high-risk AI system, to the extent such
                                               logs are under their control.


Amendment 365

Proposal for a regulation
Article 23 – paragraph 1 b (new)

    Text proposed by the Commission                           Amendment

                                               Any information obtained by a national
                                             competent authority or by the Commission
                                             pursuant to the provisions of this Article
                                             shall be considered a trade secret and be
                                             treated in compliance with the
                                             confidentiality obligations set out in
                                             Article 70.


Amendment 366

Proposal for a regulation
Article 25 – paragraph 1

     Text proposed by the Commission                         Amendment

1.    Prior to making their systems          1.    Prior to making their systems
available on the Union market, where an      available on the Union market, providers
importer cannot be identified, providers     established outside the Union shall, by
established outside the Union shall, by      written mandate, appoint an authorised
written mandate, appoint an authorised       representative which is established in the
representative which is established in the   Union.
Union.


Amendment 367

Proposal for a regulation
Article 25 – paragraph 1 a (new)

     Text proposed by the Commission                         Amendment

                                             1 a. The authorised representative shall
                                             reside or be established in one of the
                                             Member States where the activities
                                             pursuant to Article 2, paragraphs 1(cb)
                                             are taking place.


Amendment 368

Proposal for a regulation
Article 25 – paragraph 1 b (new)

     Text proposed by the Commission                         Amendment

                                             1 b. The provider shall provide its
                                             authorised representative with the
                                             necessary powers and resources to comply
                                             with its tasks under this Regulation.
Amendment 369

Proposal for a regulation
Article 25 – paragraph 2 – introductory part

    Text proposed by the Commission                            Amendment

2.     The authorised representative shall     2.     The authorised representative shall
perform the tasks specified in the mandate     perform the tasks specified in the mandate
received from the provider. The mandate        received from the provider. It shall provide
shall empower the authorised                   a copy of the mandate to the market
representative to carry out the following      surveillance authorities upon request, in
tasks:                                         one of the official languages of the
                                               institution of the Union determined by the
                                               national competent authority. For the
                                               purpose of this Regulation, the mandate
                                               shall empower the authorised
                                               representative to carry out the following
                                               tasks:


Amendment 370

Proposal for a regulation
Article 25 – paragraph 2 – point a

    Text proposed by the Commission                            Amendment

(a) keep a copy of the EU declaration of       (a) ensure that the EU declaration of
conformity and the technical                   conformity and the technical
documentation at the disposal of the           documentation have been drawn up and
national competent authorities and             that an appropriate conformity
national authorities referred to in Article    assessment procedure has been carried
63(7);                                         out by the provider;


Amendment 371

Proposal for a regulation
Article 25 – paragraph 2 – point a a (new)

    Text proposed by the Commission                            Amendment

                                               (a a) keep at the disposal of the national
                                               competent authorities and national
                                               authorities referred to in Article 63(7), a
                                               copy of the EU declaration of conformity,
                                               the technical documentation and, if
                                                 applicable, the certificate issued by the
                                                 notified body;


Amendment 372

Proposal for a regulation
Article 25 – paragraph 2 – point b

     Text proposed by the Commission                             Amendment

(b) provide a national competent                 (b) provide a national competent
authority, upon a reasoned request, with all     authority, upon a reasoned request, with all
the information and documentation                the information and documentation
necessary to demonstrate the conformity of       necessary to demonstrate the conformity of
a high-risk AI system with the                   a high-risk AI system with the
requirements set out in Chapter 2 of this        requirements set out in Chapter 2 of this
Title, including access to the logs              Title, including access to the logs
automatically generated by the high-risk AI      automatically generated by the high-risk AI
system to the extent such logs are under the     system to the extent such logs are under the
control of the provider by virtue of a           control of the provider;
contractual arrangement with the user or
otherwise by law;


Amendment 373

Proposal for a regulation
Article 25 – paragraph 2 – point c

     Text proposed by the Commission                             Amendment

(c) cooperate with competent national            (c) cooperate with national supervisory
authorities, upon a reasoned request, on         authorities, upon a reasoned request, on
any action the latter takes in relation to the   any action the authority takes to reduce
high-risk AI system.                             and mitigate the risks posed by the high-
                                                 risk AI system;


Amendment 374

Proposal for a regulation
Article 25 – paragraph 2 – point c a (new)

     Text proposed by the Commission                             Amendment

                                                 (c a) where applicable, comply with the
                                                 registration obligations referred in Article
                                                 51, or, if the registration is carried out by
                                                 the provider itself, ensure that the
                                               information referred to in point 3 of
                                               Annex VIII is correct.


Amendment 375

Proposal for a regulation
Article 25 – paragraph 2 a (new)

    Text proposed by the Commission                           Amendment

                                               2 a. The authorised representative shall
                                               be mandated to be addressed, in addition
                                               to or instead of the provider, by, in
                                               particular, the national supervisory
                                               authority or the national competent
                                               authorities, on all issues related to
                                               ensuring compliance with this Regulation.


Amendment 376

Proposal for a regulation
Article 25 – paragraph 2 b (new)

    Text proposed by the Commission                           Amendment

                                               2 b. The authorised representative shall
                                               terminate the mandate if it considers or
                                               has reason to consider that the provider
                                               acts contrary to its obligations under this
                                               Regulation. In such a case, it shall also
                                               immediately inform the national
                                               supervisory authority of the Member State
                                               in which it is established, as well as,
                                               where applicable, the relevant notified
                                               body, about the termination of the
                                               mandate and the reasons thereof.


Amendment 377

Proposal for a regulation
Article 26 – paragraph 1 – introductory part

    Text proposed by the Commission                           Amendment

1.    Before placing a high-risk AI system     1.     Before placing a high-risk AI system
on the market, importers of such system        on the market, importers of such system
                                               shall ensure that such a system is in
shall ensure that:                           conformity with this Regulation by
                                             ensuring that:


Amendment 378

Proposal for a regulation
Article 26 – paragraph 1 – point a

     Text proposed by the Commission                         Amendment

(a) the appropriate conformity               (a) the relevant conformity assessment
assessment procedure has been carried out    procedure referred to in Article 43 has
by the provider of that AI system            been carried out by the provider of that AI
                                             system


Amendment 379

Proposal for a regulation
Article 26 – paragraph 1 – point b

     Text proposed by the Commission                         Amendment

(b) the provider has drawn up the            (b) the provider has drawn up the
technical documentation in accordance        technical documentation in accordance
with Annex IV;                               with Article 11 and Annex IV;


Amendment 380

Proposal for a regulation
Article 26 – paragraph 1 – point c a (new)

     Text proposed by the Commission                         Amendment

                                             (c a) where applicable, the provider has
                                             appointed an authorised representative in
                                             accordance with Article 25(1).


Amendment 381

Proposal for a regulation
Article 26 – paragraph 2

     Text proposed by the Commission                         Amendment

2.    Where an importer considers or has     2.    Where an importer considers or has
reason to consider that a high-risk AI       reason to consider that a high-risk AI
system is not in conformity with this          system is not in conformity with this
Regulation, it shall not place that system     Regulation, or is counterfeit, or
on the market until that AI system has been    accompanied by falsified documentation it
brought into conformity. Where the high-       shall not place that system on the market
risk AI system presents a risk within the      until that AI system has been brought into
meaning of Article 65(1), the importer         conformity. Where the high-risk AI system
shall inform the provider of the AI system     presents a risk within the meaning of
and the market surveillance authorities to     Article 65(1), the importer shall inform the
that effect.                                   provider of the AI system and the market
                                               surveillance authorities to that effect.


Amendment 382

Proposal for a regulation
Article 26 – paragraph 3

    Text proposed by the Commission                            Amendment

3.     Importers shall indicate their name,    3.     Importers shall indicate their name,
registered trade name or registered trade      registered trade name or registered trade
mark, and the address at which they can be     mark, and the address at which they can be
contacted on the high-risk AI system or,       contacted on the high-risk AI system and
where that is not possible, on its packaging   on its packaging or its accompanying
or its accompanying documentation, as          documentation, where applicable.
applicable.


Amendment 383

Proposal for a regulation
Article 26 – paragraph 5

    Text proposed by the Commission                            Amendment

5.    Importers shall provide national         5.    Importers shall provide national
competent authorities, upon a reasoned         competent authorities, upon a reasoned
request, with all necessary information and    request, with all the necessary information
documentation to demonstrate the               and documentation to demonstrate the
conformity of a high-risk AI system with       conformity of a high-risk AI system with
the requirements set out in Chapter 2 of       the requirements set out in Chapter 2 of
this Title in a language which can be easily   this Title in a language which can be easily
understood by that national competent          understood by them, including access to
authority, including access to the logs        the logs automatically generated by the
automatically generated by the high-risk AI    high-risk AI system to the extent such logs
system to the extent such logs are under the   are under the control of the provider in
control of the provider by virtue of a         accordance with Article 20.
contractual arrangement with the user or
otherwise by law. They shall also
cooperate with those authorities on any
action national competent authority takes
in relation to that system.


Amendment 384

Proposal for a regulation
Article 26 – paragraph 5 a (new)

     Text proposed by the Commission                          Amendment

                                              5 a. Importers shall cooperate with
                                              national competent authorities on any
                                              action those authorities take to reduce
                                              and mitigate the risks posed by the high-
                                              risk AI system.


Amendment 385

Proposal for a regulation
Article 27 – paragraph 1

     Text proposed by the Commission                          Amendment

1.     Before making a high-risk AI system    1.     Before making a high-risk AI system
available on the market, distributors shall   available on the market, distributors shall
verify that the high-risk AI system bears     verify that the high-risk AI system bears
the required CE conformity marking, that it   the required CE conformity marking, that it
is accompanied by the required                is accompanied by the required
documentation and instruction of use, and     documentation and instruction of use, and
that the provider and the importer of the     that the provider and the importer of the
system, as applicable, have complied with     system, as applicable, have complied with
the obligations set out in this Regulation.   their obligations set out in this Regulation
                                              in Articles 16 and 26 respectively.


Amendment 386

Proposal for a regulation
Article 27 – paragraph 2

     Text proposed by the Commission                          Amendment

2.     Where a distributor considers or has   2.    Where a distributor considers or has
reason to consider that a high-risk AI        reason to consider, on the basis of the
system is not in conformity with the          information in its possession that a high-
requirements set out in Chapter 2 of this     risk AI system is not in conformity with
Title, it shall not make the high-risk AI     the requirements set out in Chapter 2 of
system available on the market until that     this Title, it shall not make the high-risk AI
system has been brought into conformity         system available on the market until that
with those requirements. Furthermore,           system has been brought into conformity
where the system presents a risk within the     with those requirements. Furthermore,
meaning of Article 65(1), the distributor       where the system presents a risk within the
shall inform the provider or the importer of    meaning of Article 65(1), the distributor
the system, as applicable, to that effect.      shall inform the provider or the importer of
                                                the system, the relevant national
                                                competent authority, as applicable, to that
                                                effect.


Amendment 387

Proposal for a regulation
Article 27 – paragraph 4

     Text proposed by the Commission                            Amendment

4.     A distributor that considers or has      4.     A distributor that considers or has
reason to consider that a high-risk AI          reason to consider, on the basis of the
system which it has made available on the       information in its possession, that a high-
market is not in conformity with the            risk AI system which it has made available
requirements set out in Chapter 2 of this       on the market is not in conformity with the
Title shall take the corrective actions         requirements set out in Chapter 2 of this
necessary to bring that system into             Title shall take the corrective actions
conformity with those requirements, to          necessary to bring that system into
withdraw it or recall it or shall ensure that   conformity with those requirements, to
the provider, the importer or any relevant      withdraw it or recall it or shall ensure that
operator, as appropriate, takes those           the provider, the importer or any relevant
corrective actions. Where the high-risk AI      operator, as appropriate, takes those
system presents a risk within the meaning       corrective actions. Where the high-risk AI
of Article 65(1), the distributor shall         system presents a risk within the meaning
immediately inform the national competent       of Article 65(1), the distributor shall
authorities of the Member States in which       immediately inform the provider or
it has made the product available to that       importer of the system and the national
effect, giving details, in particular, of the   competent authorities of the Member
non-compliance and of any corrective            States in which it has made the product
actions taken.                                  available to that effect, giving details, in
                                                particular, of the non-compliance and of
                                                any corrective actions taken.


Amendment 388

Proposal for a regulation
Article 27 – paragraph 5

     Text proposed by the Commission                            Amendment

5.    Upon a reasoned request from a            5.    Upon a reasoned request from a
national competent authority, distributors      national competent authority, distributors
of high-risk AI systems shall provide that      of the high-risk AI system shall provide
authority with all the information and          that authority with all the information and
documentation necessary to demonstrate          documentation in their possession or
the conformity of a high-risk system with       available to them, in accordance with the
the requirements set out in Chapter 2 of        obligations of distributors as outlined in
this Title. Distributors shall also cooperate   paragraph 1, that are necessary to
with that national competent authority on       demonstrate the conformity of a high-risk
any action taken by that authority.             system with the requirements set out in
                                                Chapter 2 of this Title.


Amendment 389

Proposal for a regulation
Article 27 – paragraph 5 a (new)

     Text proposed by the Commission                            Amendment

                                                5 a. Distributors shall cooperate with
                                                national competent authorities on any
                                                action those authorities take to reduce
                                                and mitigate the risks posed by the high-
                                                risk AI system.


Amendment 390

Proposal for a regulation
Article 28 – title

     Text proposed by the Commission                            Amendment

Obligations of distributors, importers,         Responsibilities along the AI value chain
users or any other third-party                  of providers, distributors, importers,
                                                deployers or other third parties


Amendment 391

Proposal for a regulation
Article 28 – paragraph 1 – introductory part

     Text proposed by the Commission                            Amendment

1.    Any distributor, importer, user or        1.    Any distributor, importer, deployer
other third-party shall be considered a         or other third-party shall be considered a
provider for the purposes of this               provider of a high-risk AI system for the
Regulation and shall be subject to the          purposes of this Regulation and shall be
obligations of the provider under Article       subject to the obligations of the provider
16, in any of the following circumstances:    under Article 16, in any of the following
                                              circumstances:


Amendment 392

Proposal for a regulation
Article 28 – paragraph 1 – point a

    Text proposed by the Commission                           Amendment

(a) they place on the market or put into      (a) they put their name or trademarkt
service a high-risk AI system under their     on a high-risk AI system already placed
name or trademark;                            on the market or put into service;


Amendment 393

Proposal for a regulation
Article 28 – paragraph 1 – point b

    Text proposed by the Commission                           Amendment

(b) they modify the intended purpose of       (b) they make a substantial
a high-risk AI system already placed on the   modification to a high-risk AI system that
market or put into service;                   has already been placed on the market or
                                              has already been put into service and in a
                                              way that it remains a high-risk AI system
                                              in accordance with Article 6;


Amendment 394

Proposal for a regulation
Article 28 – paragraph 1 – point b a (new)

    Text proposed by the Commission                           Amendment

                                              (b a) they make a substantial
                                              modification to an AI system, including a
                                              general purpose AI system, which has not
                                              been classified as high-risk and has
                                              already been placed on the market or put
                                              into service in such manner that the AI
                                              system becomes a high risk AI system in
                                              accordance with Article 6


Amendment 395
Proposal for a regulation
Article 28 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    Where the circumstances referred to      2.    Where the circumstances referred to
in paragraph 1, point (b) or (c), occur, the   in paragraph 1, point (a) to (ba) occur, the
provider that initially placed the high-risk   provider that initially placed the AI system
AI system on the market or put it into         on the market or put it into service shall no
service shall no longer be considered a        longer be considered a provider of that
provider for the purposes of this              specific AI system for the purposes of this
Regulation.                                    Regulation. This former provider shall
                                               provide the new provider with the
                                               technical documentation and all other
                                               relevant and reasonably expected
                                               information capabilities of the AI system,
                                               technical access or other assistance based
                                               on the generally acknowledged state of
                                               the art that are required for the fulfilment
                                               of the obligations set out in this
                                               Regulation.
                                               This paragraph shall also apply to
                                               providers of foundation models as defined
                                               in Article 3 when the foundation model is
                                               directly integrated in an high-risk AI
                                               system.


Amendment 396

Proposal for a regulation
Article 28 – paragraph 2 a (new)

     Text proposed by the Commission                           Amendment

                                               2 a. The provider of a high risk AI
                                               system and the third party that supplies
                                               tools, services, components or processes
                                               that are used or integrated in the high risk
                                               AI system shall, by written agreement
                                               specify the information, capabilities,
                                               technical access, and or other assistance,
                                               based on the generally acknowledged state
                                               of the art, that the third party is required
                                               to provide in order to enable the provider
                                               of the high risk AI system to fully comply
                                               with the obligations under this
                                               Regulation.
                                      The Commission shall develop and
                                      recommend non-binding model
                                      contractual terms between providers of
                                      high-risk AI systems and third parties that
                                      supply tools, services, components or
                                      processes that are used or integrated in
                                      high-risk AI systems in order to assist
                                      both parties in drafting and negotiating
                                      contracts with balanced contractual rights
                                      and obligations, consistent with each
                                      party’s level of control. When developing
                                      non-binding model contractual terms, the
                                      Commission shall take into account
                                      possible contractual requirements
                                      applicable in specific sectors or business
                                      cases. The non-binding contractual terms
                                      shall be published and be available free of
                                      charge in an easily usable electronic
                                      format on the AI Office’s website.


Amendment 397

Proposal for a regulation
Article 28 – paragraph 2 b (new)

    Text proposed by the Commission                   Amendment

                                      2 b. For the purposes of this Article,
                                      trade secrets shall be preserved and shall
                                      only be disclosed provided that all specific
                                      necessary measures pursuant to Directive
                                      (EU) 2016/943 are taken in advance to
                                      preserve their confidentiality, in
                                      particular with respect to third parties.
                                      Where necessary, appropriate technical
                                      and organizational arrangements can be
                                      agreed to protect intellectual property
                                      rights or trade secrets.


Amendment 398

Proposal for a regulation
Article 28 a (new)

    Text proposed by the Commission                   Amendment

                                                      Article 28 a
  Unfair contractual terms unilaterally
    imposed on an SME or startup
1. A contractual term concerning the
supply of tools, services, components or
processes that are used or integrated in a
high risk AI system or the remedies for
the breach or the termination of related
obligations which has been unilaterally
imposed by an enterprise on a SME or
startup shall not be binding on the latter
enterprise if it is unfair.
2. A contractual term is not to be
considered unfair where it arises from
applicable Union law.
3. A contractual term is unfair if it is of
such a nature that it objectively impairs
the ability of the party upon whom the
term has been unilaterally imposed to
protect its legitimate commercial interest
in the information in question or its use
grossly deviates from good commercial
practice in the supply of tools, services,
components or processes that are used or
integrated in a high-risk AI system,
contrary to good faith and fair dealing or
creates a significant imbalance between
the rights and the obligations of the
parties in the contract. A contractual term
is also unfair if it has the effect of shifting
penalties referred to in Article 71 or
associated litigation costs across parties to
the contract, as referred to in Article
71(8).
4. A contractual term is unfair for the
purposes of this Article if its object or
effect is to:
(a) exclude or limit the liability of the
party that unilaterally imposed the term
for intentional acts or gross negligence;
(b) exclude the remedies available to the
party upon whom the term has been
unilaterally imposed in the case of non-
performance of contractual obligations or
the liability of the party that unilaterally
imposed the term in the case of a breach
of those obligations;
(c) give the party that unilaterally imposed
                                      the term the exclusive right to determine
                                      whether the technical documentation,
                                      information supplied are in conformity
                                      with the contract or to interpret any term
                                      of the contract.
                                      5. A contractual term shall be considered
                                      to be unilaterally imposed within the
                                      meaning of this Article if it has been
                                      supplied by one contracting party and the
                                      other contracting party has not been able
                                      to influence its content despite an attempt
                                      to negotiate it. The contracting party that
                                      supplied a contractual term shall bears
                                      the burden of proving that that term has
                                      not been unilaterally imposed.
                                      6. Where the unfair contractual term is
                                      severable from the remaining terms of the
                                      contract, those remaining terms shall
                                      remain binding. The party that supplied
                                      the contested term shall not argue that the
                                      term is an unfair term.
                                      7. This Article shall apply to all new
                                      contracts entered into force after ... [date
                                      of entry into force of this Regulation].
                                      Businesses shall review existing
                                      contractual obligations that are subject to
                                      this Regulation by …[three years after the
                                      date of entry into force of this
                                      Regulation].
                                      8. Given the rapidity in which innovations
                                      occur in the markets, the list of unfair
                                      contractual terms within Article 28a shall
                                      be reviewed regularly by the Commission
                                      and be updated to new business practices
                                      if necessary.


Amendment 399

Proposal for a regulation
Article 28 b (new)

    Text proposed by the Commission                   Amendment

                                                      Article 28 b
                                           Obligations of the provider of a
                                                 foundation model
1. A provider of a foundation model shall,
prior to making it available on the market
or putting it into service, ensure that it is
compliant with the requirements set out in
this Article, regardless of whether it is
provided as a standalone model or
embedded in an AI system or a product, or
provided under free and open source
licences, as a service, as well as other
distribution channels.
2. For the purpose of paragraph 1, the
provider of a foundation model shall:
(a) demonstrate through appropriate
design, testing and analysis the
identification, the reduction and
mitigation of reasonably foreseeable risks
to health, safety, fundamental rights, the
environment and democracy and the rule
of law prior and throughout development
with appropriate methods such as with the
involvement of independent experts, as
well as the documentation of remaining
non-mitigable risks after development
(b) process and incorporate only datasets
that are subject to appropriate data
governance measures for foundation
models, in particular measures to
examine the suitability of the data sources
and possible biases and appropriate
mitigation
(c) design and develop the foundation
model in order to achieve throughout its
lifecycle appropriate levels of
performance, predictability,
interpretability, corrigibility, safety and
cybersecurity assessed through
appropriate methods such as model
evaluation with the involvement of
independent experts, documented
analysis, and extensive testing during
conceptualisation, design, and
development;
(d) design and develop the foundation
model, making use of applicable
standards to reduce energy use, resource
use and waste, as well as to increase
energy efficiency, and the overall
efficiency of the system, whithout
prejudice to relevant existing Union and
national law. This obligation shall not
apply before the standards referred to in
Article 40 are published. Foundation
models shall be designed with capabilities
enabling the measurement and logging of
the consumption of energy and resources,
and, where technically feasible, other
environmental impact the deployment and
use of the systems may have over their
entire lifecycle;
(e) draw up extensive technical
documentation and intelligible
instructions for use, in order to enable the
downstream providers to comply with
their obligations pursuant to Articles 16
and 28(1);.
(f) establish a quality management system
to ensure and document compliance with
this Article, with the possibility to
experiment in fulfilling this requirement,
(g) register that foundation model in the
EU database referred to in Article 60, in
accordance with the instructions outlined
in Annex VIII point C.
When fulfilling those requirements, the
generally acknowledged state of the art
shall be taken into account, including as
reflected in relevant harmonised
standards or common specifications, as
well as the latest assessment and
measurement methods, reflected in
particular in benchmarking guidance and
capabilities referred to in Article 58a;
3. Providers of foundation models shall,
for a period ending 10 years after their
foundation models have been placed on
the market or put into service, keep the
technical documentation referred to in
paragraph 2(e) at the disposal of the
national competent authorities
4. Providers of foundation models used in
AI systems specifically intended to
generate, with varying levels of autonomy,
content such as complex text, images,
audio, or video (“generative AI”) and
providers who specialise a foundation
model into a generative AI system, shall
                                            in addition
                                            a) comply with the transparency
                                            obligations outlined in Article 52 (1),
                                            b) train, and where applicable, design and
                                            develop the foundation model in such a
                                            way as to ensure adequate safeguards
                                            against the generation of content in
                                            breach of Union law in line with the
                                            generally-acknowledged state of the art,
                                            and without prejudice to fundamental
                                            rights, including the freedom of
                                            expression,
                                            c) without prejudice to Union or national
                                            or Union legislation on copyright,
                                            document and make publicly available a
                                            sufficiently detailed summary of the use
                                            of training data protected under copyright
                                            law.



Amendment 400

Proposal for a regulation
Article 29 – paragraph 1

    Text proposed by the Commission                         Amendment

1.    Users of high-risk AI systems shall   1.     Deployers of high-risk AI systems
use such systems in accordance with the     shall take appropriate technical and
instructions of use accompanying the        organisational measures to ensure they
systems, pursuant to paragraphs 2 and 5.    use such systems in accordance with the
                                            instructions of use accompanying the
                                            systems, pursuant to paragraphs 2 and 5 of
                                            this Article.



Amendment 401

Proposal for a regulation
Article 29 – paragraph 1 a (new)

    Text proposed by the Commission                         Amendment

                                            1 a. To the extent deployers exercise
                                            control over the high-risk AI system, they
                                            shall
                                              i) implement human oversight according
                                              to the requirements laid down in this
                                              Regulation
                                              (ii) ensure that the natural persons
                                              assigned to ensure human oversight of the
                                              high-risk AI systems are competent,
                                              properly qualified and trained, and have
                                              the necessary resources in order to ensure
                                              the effective supervision of the AI system
                                              in accordance with Article 14
                                              (iii) ensure that relevant and appropriate
                                              robustness and cybersecurity measures
                                              are regularly monitored for effectiveness
                                              and are regularly adjusted or updated.


Amendment 402

Proposal for a regulation
Article 29 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    The obligations in paragraph 1 are      2.    The obligations in paragraph 1 and
without prejudice to other user obligations   1a, are without prejudice to other deployer
under Union or national law and to the        obligations under Union or national law
user’s discretion in organising its own       and to the deployer’s discretion in
resources and activities for the purpose of   organising its own resources and activities
implementing the human oversight              for the purpose of implementing the human
measures indicated by the provider.           oversight measures indicated by the
                                              provider.


Amendment 403

Proposal for a regulation
Article 29 – paragraph 3

    Text proposed by the Commission                           Amendment

3.    Without prejudice to paragraph 1, to    3.     Without prejudice to paragraph 1 and
the extent the user exercises control over    1a, to the extent the deployer exercises
the input data, that user shall ensure that   control over the input data, that deployer
input data is relevant in view of the         shall ensure that input data is relevant and
intended purpose of the high-risk AI          sufficiently representative in view of the
system.                                       intended purpose of the high-risk AI
                                              system.
Amendment 404

Proposal for a regulation
Article 29 – paragraph 4 – introductory part

     Text proposed by the Commission                            Amendment

4.     Users shall monitor the operation of     4.    Deployers shall monitor the
the high-risk AI system on the basis of the     operation of the high-risk AI system on the
instructions of use. When they have             basis of the instructions of use and when
reasons to consider that the use in             relevant, inform providers in accordance
accordance with the instructions of use         with Article 61. When they have reasons to
may result in the AI system presenting a        consider that the use in accordance with the
risk within the meaning of Article 65(1)        instructions of use may result in the AI
they shall inform the provider or distributor   system presenting a risk within the
and suspend the use of the system. They         meaning of Article 65(1) they shall,
shall also inform the provider or distributor   without undue delay, inform the provider
when they have identified any serious           or distributor and relevant national
incident or any malfunctioning within the       supervisory authorities and suspend the
meaning of Article 62 and interrupt the use     use of the system. They shall also
of the AI system. In case the user is not       immediately inform first the provider, and
able to reach the provider, Article 62 shall    then the importer or distributor and
apply mutatis mutandis.                         relevant national supervisory authorities
                                                when they have identified any serious
                                                incident or any malfunctioning within the
                                                meaning of Article 62 and interrupt the use
                                                of the AI system. If the deployer is not able
                                                to reach the provider, Article 62 shall apply
                                                mutatis mutandis.


Amendment 405

Proposal for a regulation
Article 29 – paragraph 4 – subparagraph 1

     Text proposed by the Commission                            Amendment

For users that are credit institutions          For deployers that are credit institutions
regulated by Directive 2013/36/EU, the          regulated by Directive 2013/36/EU, the
monitoring obligation set out in the first      monitoring obligation set out in the first
subparagraph shall be deemed to be              subparagraph shall be deemed to be
fulfilled by complying with the rules on        fulfilled by complying with the rules on
internal governance arrangements,               internal governance arrangements,
processes and mechanisms pursuant to            processes and mechanisms pursuant to
Article 74 of that Directive.                   Article 74 of that Directive.
Amendment 406

Proposal for a regulation
Article 29 – paragraph 5 – introductory part

     Text proposed by the Commission                          Amendment

5.     Users of high-risk AI systems shall     5.    Deployers of high-risk AI systems
keep the logs automatically generated by       shall keep the logs automatically generated
that high-risk AI system, to the extent such   by that high-risk AI system, to the extent
logs are under their control. The logs shall   that such logs are under their control and
be kept for a period that is appropriate in    are required for ensuring and
the light of the intended purpose of the       demonstrating compliance with this
high-risk AI system and applicable legal       Regulation, for ex-post audits of any
obligations under Union or national law.       reasonably foreseeable malfunction,
                                               incidents or misuses of the system, or for
                                               ensuring and monitoring for the proper
                                               functioning of the system throughout its
                                               lifecycle. Without prejudice to applicable
                                               Union or national law, the logs shall be
                                               kept for a period of at least six months.
                                               The retention period shall be in
                                               accordance with industry standards and
                                               appropriate to the intended purpose of the
                                               high-risk AI system.


Amendment 407

Proposal for a regulation
Article 29 – paragraph 5 – subparagraph 1

     Text proposed by the Commission                          Amendment

Users that are credit institutions regulated   Deployers that are credit institutions
by Directive 2013/36/EU shall maintain the     regulated by Directive 2013/36/EU shall
logs as part of the documentation              maintain the logs as part of the
concerning internal governance                 documentation concerning internal
arrangements, processes and mechanisms         governance arrangements, processes and
pursuant to Article 74 of that Directive.      mechanisms pursuant to Article 74 of that
                                               Directive.


Amendment 408

Proposal for a regulation
Article 29 – paragraph 5 a (new)
    Text proposed by the Commission                           Amendment

                                              5 a. Prior to putting into service or use a
                                              high-risk AI system at the workplace,
                                              deployers shall consult workers
                                              representatives with a view to reaching an
                                              agreement in accordance with Directive
                                              2002/14/EC and inform the affected
                                              employees that they will be subject to the
                                              system.


Amendment 409

Proposal for a regulation
Article 29 – paragraph 5 b (new)

    Text proposed by the Commission                           Amendment

                                              5 b. Deployers of high-risk AI systems
                                              that are public authorities or Union
                                              institutions, bodies, offices and agencies
                                              or undertakings referred to in Article
                                              51(1a)(b) shall comply with the
                                              registration obligations referred to in
                                              Article 51.

Amendment 410

Proposal for a regulation
Article 29 – paragraph 6

    Text proposed by the Commission                           Amendment

6.    Users of high-risk AI systems shall     6.     Where applicable, deployers of high-
use the information provided under Article    risk AI systems shall use the information
13 to comply with their obligation to carry   provided under Article 13 to comply with
out a data protection impact assessment       their obligation to carry out a data
under Article 35 of Regulation (EU)           protection impact assessment under Article
2016/679 or Article 27 of Directive (EU)      35 of Regulation (EU) 2016/679 or Article
2016/680, where applicable.                   27 of Directive (EU) 2016/680, a summary
                                              of which shall be published, having
                                              regard to the specific use and the specific
                                              context in which the AI system is intended
                                              to operate. Deployers may revert in part to
                                              those data protection impact assessments
                                              for fulfilling some of the obligations set
                                              out in this article, insofar as the data
                                              protection impact assesment fulfill those
                                      obligations.


Amendment 411

Proposal for a regulation
Article 29 – paragraph 6 a (new)

    Text proposed by the Commission                  Amendment

                                      6 a. Without prejudice to Article 52,
                                      deployers of high-risk AI systems referred
                                      to in Annex III, which make decisions or
                                      assist in making decisions related to
                                      natural persons, shall inform the natural
                                      persons that they are subject to the use of
                                      the high-risk AI system. This information
                                      shall include the intended purpose and
                                      the type of decisions it makes. The
                                      deployer shall also inform the natural
                                      person about its right to an explanation
                                      referred to in Article 68c.


Amendment 412

Proposal for a regulation
Article 29 – paragraph 6 b (new)

    Text proposed by the Commission                  Amendment

                                      6 b. Deployers shall cooperate with the
                                      relevant national competent authorities
                                      on any action those authorities take in
                                      relation with the high-risk system in order
                                      to implement this Regulation.


Amendment 413

Proposal for a regulation
Article 29 a (new)

    Text proposed by the Commission                  Amendment

                                                     Article 29 a
                                       Fundamental rights impact assessment
                                            for high-risk AI systems
Prior to putting a high-risk AI system as
defined in Article 6(2) into use, with the
exception of AI systems intended to be
used in area 2 of Annex III, deployers
shall conduct an assessment of the
systems’ impact in the specific context of
use. This assessment shall include, at a
minimum, the following elements:
(a) a clear outline of the intended purpose
for which the system will be used;
(b) a clear outline of the intended
geographic and temporal scope of the
system’s use;
(c) categories of natural persons and
groups likely to be affected by the use of
the system;
(d) verification that the use of the system
is compliant with relevant Union and
national law on fundamental rights;
(e) the reasonably foreseeable impact on
fundamental rights of putting the high-
risk AI system into use;
(f) specific risks of harm likely to impact
marginalised persons or vulnerable
groups;
(g) the reasonably foreseeable adverse
impact of the use of the system on the
environment;
(h) a detailed plan as to how the harms
and the negative impact on fundamental
rights identified will be mitigated.
(j) the governance system the deployer
will put in place, including human
oversight, complaint-handling and
redress.
2. If a detailed plan to mitigate the risks
outlined in the course of the assessment
outlined in paragraph 1 cannot be
identified, the deployer shall refrain from
putting the high-risk AI system into use
and inform the provider and the National
supervisory authority without undue
delay. National supervisory authorities,
pursuant to Articles 65 and 67, shall take
this information into account when
investigating systems which present a risk
at national level.
3. The obligation outlined under
paragraph 1 applies for the first use of the
high-risk AI system. The deployer may, in
similar cases, draw back on previously
conducted fundamental rights impact
assessment or existing assessment carried
out by providers. If, during the use of the
high-risk AI system, the deployer
considers that the criteria listed in
paragraph 1 are not longer met, it shall
conduct a new fundamental rights impact
assessment.
4. In the course of the impact assessment,
the deployer, with the exception of SMEs,
shall shall notify national supervisory
authority and relevant stakeholders and
shall, to best extent possible, involve
representatives of the persons or groups
of persons that are likely to be affected by
the high-risk AI system, as identified in
paragraph 1, including but not limited to:
equality bodies, consumer protection
agencies, social partners and data
protection agencies, with a view to
receiving input into the impact
assessment. The deployer shall allow a
period of six weeks for bodies to respond.
SMEs may voluntarily apply the
provisions laid down in this paragraph.
In the case referred to in Article 47(1),
public authorities may be exempted from
this obligations.
5. The deployer that is a public authority
or an undertaking referred to in Article
51(1a) (b) shall publish a summary of the
results of the impact assessment as part of
the registration of use pursuant to their
obligation under Article 51(2).
6. Where the deployer is already required
to carry out a data protection impact
assessment under Article 35 of Regulation
(EU) 2016/679 or Article 27 of Directive
(EU) 2016/680, the fundamental rights
impact assessment referred to in
paragraph 1 shall be conducted in
conjunction with the data protection
impact assessment. The data protection
                                               impact assessment shall be published as
                                               an addendum.


Amendment 414

Proposal for a regulation
Article 30 – paragraph 1


     Text proposed by the Commission                           Amendment

1.    Each Member State shall designate        1.    Each Member State shall designate
or establish a notifying authority             or establish a notifying authority
responsible for setting up and carrying out    responsible for setting up and carrying out
the necessary procedures for the               the necessary procedures for the
assessment, designation and notification of    assessment, designation and notification of
conformity assessment bodies and for their     conformity assessment bodies and for their
monitoring.                                    monitoring. Those procedures shall be
                                               developed in cooperation between the
                                               notifying authorities of all Member States.


Amendment 415

Proposal for a regulation
Article 30 – paragraph 7

     Text proposed by the Commission                           Amendment

7.     Notifying authorities shall have a      7.     Notifying authorities shall have a
sufficient number of competent personnel       sufficient number of competent personnel
at their disposal for the proper performance   at their disposal for the proper performance
of their tasks.                                of their tasks. Where applicable,
                                               competent personnel shall have the
                                               necessary expertise, such as a degree in
                                               an appropriate legal field, in the
                                               supervision of fundamental rights
                                               enshrined in the Charter of Fundamental
                                               Rights of the European Union.


Amendment 416

Proposal for a regulation
Article 30 – paragraph 8

     Text proposed by the Commission                           Amendment

8.   Notifying authorities shall make sure     8.   Notifying authorities shall make sure
that conformity assessments are carried out    that conformity assessments are carried out
in a proportionate manner, avoiding            in a proportionate and timely manner,
unnecessary burdens for providers and that     avoiding unnecessary burdens for
notified bodies perform their activities       providers, and that notified bodies perform
taking due account of the size of an           their activities taking due account of the
undertaking, the sector in which it            size of an undertaking, the sector in which
operates, its structure and the degree of      it operates, its structure and the degree of
complexity of the AI system in question.       complexity of the AI system in question.
                                               Particular attention shall be paid to
                                               minimising administrative burdens and
                                               compliance costs for micro and small
                                               enterprises as defined in the Annex to
                                               Commission Recommendation
                                               2003/361/EC.


Amendment 417

Proposal for a regulation
Article 32 – paragraph 1

     Text proposed by the Commission                           Amendment

1.     Notifying authorities may notify only   1.    Notifying authorities shall notify
conformity assessment bodies which have        only conformity assessment bodies which
satisfied the requirements laid down in        have satisfied the requirements laid down
Article 33.                                    in Article 33.


Amendment 418

Proposal for a regulation
Article 32 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    Notifying authorities shall notify the   2.    Notifying authorities shall notify the
Commission and the other Member States         Commission and the other Member States
using the electronic notification tool         using the electronic notification tool
developed and managed by the                   developed and managed by the
Commission.                                    Commission of each conformity
                                               assessment body referred to in paragraph
                                               1.


Amendment 419

Proposal for a regulation
Article 32 – paragraph 3
     Text proposed by the Commission                         Amendment

3.     The notification shall include full   3.    The notification referred to in
details of the conformity assessment         paragraph 2 shall include full details of the
activities, the conformity assessment        conformity assessment activities, the
module or modules and the artificial         conformity assessment module or modules
intelligence technologies concerned.         and the artificial intelligence technologies
                                             concerned, as well as the relevant
                                             attestation of competence.


Amendment 420

Proposal for a regulation
Article 32 – paragraph 4

     Text proposed by the Commission                         Amendment

4.    The conformity assessment body         4.    The conformity assessment body
concerned may perform the activities of a    concerned may perform the activities of a
notified body only where no objections are   notified body only where no objections are
raised by the Commission or the other        raised by the Commission or the other
Member States within one month of a          Member States within two weeks of the
notification.                                validation of the notification where it
                                             includes an accreditation certificate
                                             referred to in Article 31(2), or within two
                                             months of the notification where it
                                             incudes documentary evidence referred to
                                             in Article 31(3.


Amendment 421

Proposal for a regulation
Article 32 – paragraph 4 a (new)

     Text proposed by the Commission                         Amendment

                                             4 a. Where objections are raised, the
                                             Commission shall without delay enter into
                                             consultation with the relevant Member
                                             States and the conformity assessment
                                             body. In view thereof, the Commission
                                             shall decide whether the authorisation is
                                             justified or not. The Commission shall
                                             address its decision to the Member State
                                             concerned and the relevant conformity
                                             assessment body.
Amendment 422

Proposal for a regulation
Article 32 – paragraph 4 b (new)

     Text proposed by the Commission                           Amendment

                                               4 b. Member States shall notify the
                                               Commission and the other Member States
                                               of conformity assessment bodies.


Amendment 423

Proposal for a regulation
Article 33 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    Notified bodies shall satisfy the        2.    Notified bodies shall satisfy the
organisational, quality management,            organisational, quality management,
resources and process requirements that are    resources and process requirements that are
necessary to fulfil their tasks.               necessary to fulfil their tasks as well as the
                                               minimum cybersecurity requirements set
                                               out for public administration entities
                                               identified as operators of essential
                                               services pursuant to Directive (EU
                                               2022/2555.


Amendment 424

Proposal for a regulation
Article 33 – paragraph 4

     Text proposed by the Commission                           Amendment

4.     Notified bodies shall be independent    4.     Notified bodies shall be independent
of the provider of a high-risk AI system in    of the provider of a high-risk AI system in
relation to which it performs conformity       relation to which it performs conformity
assessment activities. Notified bodies shall   assessment activities. Notified bodies shall
also be independent of any other operator      also be independent of any other operator
having an economic interest in the high-       having an economic interest in the high-
risk AI system that is assessed, as well as    risk AI system that is assessed, as well as
of any competitors of the provider.            of any competitors of the provider. This
                                               shall not preclude the use of assessed AI
                                               systems that are necessary for the
                                               operations of the conformity assessment
                                               body or the use of such systems for
                                               personal purposes.
Amendment 425

Proposal for a regulation
Article 33 – paragraph 4 a (new)

    Text proposed by the Commission                            Amendment

                                               4 a. A conformity assessment pursuant
                                               to paragraph 1 shall be performed by
                                               employees of notified bodies who have not
                                               provided any other other service related to
                                               the matter assessed than the conformity
                                               assessment to the provider of a high-risk
                                               AI system nor to any legal person
                                               connected to that provider in the 12
                                               months’ period before the assessment and
                                               have committed to not providing them
                                               with such services in the 12 month period
                                               following the completion of the
                                               assessment.


Amendment 426

Proposal for a regulation
Article 33 – paragraph 6

    Text proposed by the Commission                            Amendment

6.     Notified bodies shall have              6.     Notified bodies shall have
documented procedures in place ensuring        documented procedures in place ensuring
that their personnel, committees,              that their personnel, committees,
subsidiaries, subcontractors and any           subsidiaries, subcontractors and any
associated body or personnel of external       associated body or personnel of external
bodies respect the confidentiality of the      bodies respect the confidentiality of the
information which comes into their             information which comes into their
possession during the performance of           possession during the performance of
conformity assessment activities, except       conformity assessment activities, except
when disclosure is required by law. The        when disclosure is required by law. The
staff of notified bodies shall be bound to     staff of notified bodies shall be bound to
observe professional secrecy with regard to    observe professional secrecy with regard to
all information obtained in carrying out       all information obtained in carrying out
their tasks under this Regulation, except in   their tasks under this Regulation, except in
relation to the notifying authorities of the   relation to the notifying authorities of the
Member State in which their activities are     Member State in which their activities are
carried out.                                   carried out. Any information and
                                               documentation obtained by notified bodies
                                               pursuant to the provisions of this Article
                                               shall be treated in compliance with the
                                               confidentiality obligations set out in
                                               Article 70.


Amendment 427

Proposal for a regulation
Article 34 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    Activities may be subcontracted or       3.    Activities may be subcontracted or
carried out by a subsidiary only with the      carried out by a subsidiary only with the
agreement of the provider.                     agreement of the provider. Notified bodies
                                               shall make a list of their subsidiaries
                                               publicly available.


Amendment 428

Proposal for a regulation
Article 34 – paragraph 4

     Text proposed by the Commission                           Amendment

4.    Notified bodies shall keep at the        4.    Notified bodies shall keep at the
disposal of the notifying authority the        disposal of the notifying authority the
relevant documents concerning the              relevant documents concerning the
assessment of the qualifications of the        verification of the qualifications of the
subcontractor or the subsidiary and the        subcontractor or the subsidiary and the
work carried out by them under this            work carried out by them under this
Regulation.                                    Regulation.


Amendment 429

Proposal for a regulation
Article 35 – title

     Text proposed by the Commission                           Amendment

Identification numbers and lists of notified   Identification numbers and lists of notified
bodies designated under this Regulation        bodies


Amendment 430
Proposal for a regulation
Article 36 – paragraph 1

     Text proposed by the Commission                                   Amendment

1.     Where a notifying authority has               1.     Where a notifying authority has
suspicions or has been informed that a               suspicions or has been informed that a
notified body no longer meets the                    notified body no longer meets the
requirements laid down in Article 33, or             requirements laid down in Article 33, or
that it is failing to fulfil its obligations, that   that it is failing to fulfil its obligations, that
authority shall without delay investigate            authority shall without delay investigate
the matter with the utmost diligence. In             the matter with the utmost diligence. In
that context, it shall inform the notified           that context, it shall inform the notified
body concerned about the objections raised           body concerned about the objections raised
and give it the possibility to make its views        and give it the possibility to make its views
known. If the notifying authority comes to           known. If the notifying authority comes to
the conclusion that the notified body                the conclusion that the notified body no
investigation no longer meets the                    longer meets the requirements laid down in
requirements laid down in Article 33 or              Article 33 or that it is failing to fulfil its
that it is failing to fulfil its obligations, it     obligations, it shall restrict, suspend or
shall restrict, suspend or withdraw the              withdraw the notification as appropriate,
notification as appropriate, depending on            depending on the seriousness of the failure.
the seriousness of the failure. It shall also        It shall also immediately inform the
immediately inform the Commission and                Commission and the other Member States
the other Member States accordingly.                 accordingly.


Amendment 431

Proposal for a regulation
Article 36 – paragraph 2

     Text proposed by the Commission                                   Amendment

2.    In the event of restriction, suspension        2.    In the event of restriction, suspension
or withdrawal of notification, or where the          or withdrawal of notification, or where the
notified body has ceased its activity, the           notified body has ceased its activity, the
notifying authority shall take appropriate           notifying authority shall take appropriate
steps to ensure that the files of that notified      steps to ensure that the files of that notified
body are either taken over by another                body are either taken over by another
notified body or kept available for the              notified body or kept available for the
responsible notifying authorities at their           responsible notifying authorities, and
request.                                             market surveillance authority at their
                                                     request.


Amendment 432

Proposal for a regulation
Article 37 – paragraph 1
     Text proposed by the Commission                            Amendment

1.    The Commission shall, where               1.    The Commission shall, where
necessary, investigate all cases where there    necessary, investigate all cases where there
are reasons to doubt whether a notified         are reasons to doubt the competence of a
body complies with the requirements laid        notified body or the continued fulfilment
down in Article 33.                             by a notified body of the applicable
                                                requirements and responsibilities.


Amendment 433

Proposal for a regulation
Article 37 – paragraph 2

     Text proposed by the Commission                            Amendment

2.    The Notifying authority shall provide     2.    The Notifying authority shall provide
the Commission, on request, with all            the Commission, on request, with all
relevant information relating to the            relevant information relating to the
notification of the notified body concerned.    notification or the maintenance of the
                                                competence of the notified body
                                                concerned.


Amendment 434

Proposal for a regulation
Article 37 – paragraph 3

     Text proposed by the Commission                            Amendment

3.    The Commission shall ensure that all      3.    The Commission shall ensure that all
confidential information obtained in the        sensitive information obtained in the
course of its investigations pursuant to this   course of its investigations pursuant to this
Article is treated confidentially.              Article is treated confidentially.


Amendment 435

Proposal for a regulation
Article 37 – paragraph 4

     Text proposed by the Commission                            Amendment

4.     Where the Commission ascertains          4.     Where the Commission ascertains
that a notified body does not meet or no        that a notified body does not meet or no
longer meets the requirements laid down in      longer meets the requirements for its
Article 33, it shall adopt a reasoned           notification, it shall inform the notifying
decision requesting the notifying Member        Member State accordingly and request it
State to take the necessary corrective          to take the necessary corrective measures,
measures, including withdrawal of               including suspension or withdrawal of the
notification if necessary. That                 notification if necessary. Where the
implementing act shall be adopted in            Member State fails to take the necessary
accordance with the examination procedure       corrective measures, the Commission
referred to in Article 74(2).                   may, by means of an implementing act,
                                                suspend, restrict or withdraw the
                                                designation. That implementing act shall
                                                be adopted in accordance with the
                                                examination procedure referred to in
                                                Article 74(2).


Amendment 436

Proposal for a regulation
Article 38 – paragraph 2 a (new)

     Text proposed by the Commission                           Amendment

                                                2 a. The Commission shall provide for
                                                the exchange of knowledge and best
                                                practices between the Member States'
                                                national authorities responsible for
                                                notification policy.


Amendment 437

Proposal for a regulation
Article 40 – paragraph 1

     Text proposed by the Commission                           Amendment

High-risk AI systems which are in               High-risk AI systems and foundation
conformity with harmonised standards or         models which are in conformity with
parts thereof the references of which have      harmonised standards or parts thereof the
been published in the Official Journal of       references of which have been published in
the European Union shall be presumed to         the Official Journal of the European Union
be in conformity with the requirements set      in accordance with Regulation (EU)
out in Chapter 2 of this Title, to the extent   1025/2012 shall be presumed to be in
those standards cover those requirements.       conformity with the requirements set out in
                                                Chapter 2 of this Title or Article 28b, to
                                                the extent those standards cover those
                                                requirements.


Amendment 438
Proposal for a regulation
Article 40 – paragraph 1 a (new)

    Text proposed by the Commission                  Amendment

                                      The Commission shall issue
                                      standardisation requests covering all
                                      requirements of this Regulation, in
                                      accordance with Article 10 of Regulation
                                      EU (No)1025/2012 by... [two months after
                                      the date of entry into force of this
                                      Regulation]. When preparing
                                      standardisation request, the Commission
                                      shall consult the AI Office and the
                                      Advisory Forum;


Amendment 439

Proposal for a regulation
Article 40 – paragraph 1 b (new)

    Text proposed by the Commission                  Amendment

                                      When issuing a standardisation request to
                                      European standardisation organisations,
                                      the Commission shall specify that
                                      standards have to be consistent, including
                                      with the sectorial law listed in Annex II,
                                      and aimed at ensuring that AI systems or
                                      foundation models placed on the market
                                      or put into service in the Union meet the
                                      relevant requirements laid down in this
                                      Regulation;


Amendment 440

Proposal for a regulation
Article 40 – paragraph 1 c (new)

    Text proposed by the Commission                  Amendment

                                      The actors involved in the standardisation
                                      process shall take into account the
                                      general principles for trustworthy AI set
                                      out in Article 4(a), seek to promote
                                      investment and innovation in AI as well
                                      as competitiveness and growth of the
                                      Union market, and contribute to
                                            strengthening global cooperation on
                                            standardisation and taking into account
                                            existing international standards in the
                                            field of AI that are consistent with Union
                                            values, fundamental rights and interests,
                                            and ensure a balanced representation of
                                            interests and effective participation of all
                                            relevant stakeholders in accordance with
                                            Articles 5, 6, and 7 of Regulation (EU) No
                                            1025/2012


Amendment 441

Proposal for a regulation
Article 41 – paragraph 1

    Text proposed by the Commission                         Amendment

1.     Where harmonised standards           deleted
referred to in Article 40 do not exist or
where the Commission considers that the
relevant harmonised standards are
insufficient or that there is a need to
address specific safety or fundamental
right concerns, the Commission may, by
means of implementing acts, adopt
common specifications in respect of the
requirements set out in Chapter 2 of this
Title. Those implementing acts shall be
adopted in accordance with the
examination procedure referred to in
Article 74(2).


Amendment 442

Proposal for a regulation
Article 41 – paragraph 1 a (new)

    Text proposed by the Commission                         Amendment

                                            1 a. The Commission may, by means of
                                            implementing act adopted in accordance
                                            with the examination procedure referred
                                            to in Article 74(2) and after consulting the
                                            AI Office and the AI Advisory Forum,
                                            adopt common specifications in respect of
                                            the requirements set out in Chapter 2 of
                                            this Title or Article 28b wherein all of the
                                      following conditions are fulfilled:
                                      (a) there is no reference to harmonised
                                      standards already published in the
                                      Official Journal of the European Union
                                      related to the essential requirement(s),
                                      unless the harmonised standard in
                                      question is an existing standard that must
                                      be revised;
                                      (b) the Commission has requested one or
                                      more European standardisation
                                      organisations to draft a harmonised
                                      standard for the essential requirement(s)
                                      set out in Chapter 2;
                                      (c) the request referred to in point (b) has
                                      not been accepted by any of the European
                                      standardisation organisations; or there
                                      are undue delays in the establishment of
                                      an appropriate harmonised standard; or
                                      the standard provided does not satisfy the
                                      requirements of the relevant Union law,
                                      or does not comply with the request of the
                                      Commission.


Amendment 443

Proposal for a regulation
Article 41 – paragraph 1 b (new)

    Text proposed by the Commission                   Amendment

                                      1 b. Where the Commission considers
                                      there to be a need to address specific
                                      fundamental rights concerns, common
                                      specifications adopted by the Commission
                                      in accordance with paragraph 1a shall
                                      also address those specific fundamental
                                      rights concerns.


Amendment 444

Proposal for a regulation
Article 41 – paragraph 1 c (new)

    Text proposed by the Commission                   Amendment

                                      1 c. The Commission shall develop
                                      common specifications for the
                                             methodology to fulfil the reporting and
                                             documentation requirement on the
                                             consumption of energy and resources
                                             during development, training and
                                             deployment of the high risk AI system.


Amendment 445

Proposal for a regulation
Article 41 – paragraph 2

    Text proposed by the Commission                          Amendment

2.    The Commission, when preparing         2.     The Commission shall, throughout
the common specifications referred to in     the whole process of drafting the common
paragraph 1, shall gather the views of       specifications referred to in paragraphs 1a
relevant bodies or expert groups             and 1b, regularly consult the AI Office
established under relevant sectorial Union   and the Advisory Forum, the European
law.                                         standardisation organisations and bodies
                                             or expert groups established under
                                             relevant sectorial Union law as well as
                                             other relevant stakeholders. The
                                             Commission shall fulfil the objectives
                                             referred to in Article 40 (1c) and duly
                                             justify why it decided to resort to common
                                             specifications.
                                             Where the Commission intends to adopt
                                             common specifications pursuant to
                                             paragraph 1a of this Article, it shall also
                                             clearly identify the specific fundamental
                                             rights concern to be addressed.
                                             When adopting common specifications
                                             pursuant to paragraphs 1a and 1b of this
                                             Article, the Commission shall take into
                                             account the opinion issued by the AI
                                             Office referred to in Article 56e(b) of this
                                             Regulation. Where the Commission
                                             decides not to follow the opinion of the AI
                                             Office, it shall provide a reasoned
                                             explanation to the AI Office.


Amendment 446

Proposal for a regulation
Article 41 – paragraph 3
    Text proposed by the Commission                         Amendment

3.     High-risk AI systems which are in     3.     High-risk AI systems which are in
conformity with the common specifications    conformity with the common specifications
referred to in paragraph 1 shall be          referred to in paragraph 1a and 1b shall be
presumed to be in conformity with the        presumed to be in conformity with the
requirements set out in Chapter 2 of this    requirements set out in Chapter 2 of this
Title, to the extent those common            Title, to the extent those common
specifications cover those requirements.     specifications cover those requirements


Amendment 447

Proposal for a regulation
Article 41 – paragraph 3 a (new)

    Text proposed by the Commission                         Amendment

                                             3 a. Where a harmonised standard is
                                             adopted by a European standardisation
                                             organisation and proposed to the
                                             Commission for the publication of its
                                             reference in the Official Journal of the
                                             European Union, the Commission shall
                                             assess the harmonised standard in
                                             accordance with Regulation (EU) No
                                             1025/2012. When reference of a
                                             harmonised standard is published in the
                                             Official Journal of the European Union,
                                             the Commission shall repeal acts referred
                                             to in paragraph 1 and 1b, or parts thereof
                                             which cover the same requirements set
                                             out in Chapter 2 of this Title.


Amendment 448

Proposal for a regulation
Article 41 – paragraph 4

    Text proposed by the Commission                         Amendment

4.    Where providers do not comply with     4.    Where providers of high-risk AI
the common specifications referred to in     systems do not comply with the common
paragraph 1, they shall duly justify that    specifications referred to in paragraph 1,
they have adopted technical solutions that   they shall duly justify that they have
are at least equivalent thereto.             adopted technical solutions that meet the
                                             requirements referred to in Chapter II to
                                             a level at least equivalent thereto;
Amendment 449

Proposal for a regulation
Article 42 – paragraph 1

     Text proposed by the Commission                           Amendment

1.    Taking into account their intended       1.    Taking into account their intended
purpose, high-risk AI systems that have        purpose, high-risk AI systems that have
been trained and tested on data concerning     been trained and tested on data concerning
the specific geographical, behavioural and     the specific geographical, behavioural
functional setting within which they are       contextual and functional setting within
intended to be used shall be presumed to be    which they are intended to be used shall be
in compliance with the requirement set out     presumed to be in compliance with the
in Article 10(4).                              respective requirements set out in Article
                                               10(4).


Amendment 450

Proposal for a regulation
Article 43 – paragraph 1 – introductory part

     Text proposed by the Commission                           Amendment

1.    For high-risk AI systems listed in       1.    For high-risk AI systems listed in
point 1 of Annex III, where, in                point 1 of Annex III, where, in
demonstrating the compliance of a high-        demonstrating the compliance of a high-
risk AI system with the requirements set       risk AI system with the requirements set
out in Chapter 2 of this Title, the provider   out in Chapter 2 of this Title, the provider
has applied harmonised standards referred      has applied harmonised standards referred
to in Article 40, or, where applicable,        to in Article 40, or, where applicable,
common specifications referred to in           common specifications referred to in
Article 41, the provider shall follow one of   Article 41, the provider shall opt for one of
the following procedures:                      the following procedures;


Amendment 451

Proposal for a regulation
Article 43 – paragraph 1 – point a

     Text proposed by the Commission                           Amendment

(a) the conformity assessment procedure        (a) the conformity assessment procedure
based on internal control referred to in       based on internal control referred to in
Annex VI;                                      Annex VI; or
Amendment 452

Proposal for a regulation
Article 43 – paragraph 1 – point b

    Text proposed by the Commission                           Amendment

(b) the conformity assessment procedure       (b) the conformity assessment procedure
based on assessment of the quality            based on assessment of the quality
management system and assessment of the       management system and of the technical
technical documentation, with the             documentation, with the involvement of a
involvement of a notified body, referred to   notified body, referred to in Annex VII;
in Annex VII.


Amendment 453

Proposal for a regulation
Article 43 – paragraph 1 – subparagraph 1

    Text proposed by the Commission                           Amendment

Where, in demonstrating the compliance of     In demonstrating the compliance of a high-
a high-risk AI system with the                risk AI system with the requirements set
requirements set out in Chapter 2 of this     out in Chapter 2 of this Title, the provider
Title, the provider has not applied or has    shall follow the conformity assessment
applied only in part harmonised standards     procedure set out in Annex VII in the
referred to in Article 40, or where such      following cases:
harmonised standards do not exist and
common specifications referred to in
Article 41 are not available, the provider
shall follow the conformity assessment
procedure set out in Annex VII.
                                              (a) where harmonised standards referred to
                                              in Article 40, the reference number of
                                              which has been published in the Official
                                              Journal of the European Union, covering
                                              all relevant safety requirements for the AI
                                              system, do not exist and common
                                              specifications referred to in Article 41 are
                                              not available;
                                              (b) where the technical specifications
                                              referred to in point (a) exist but the
                                              provider has not applied them or has
                                              applied them only in part;
                                              (c) where one or more of the technical
                                              specifications referred to in point (a) has
                                              been published with a restriction and only
                                              on the part of the standard that was
                                                 restricted;
                                                 (d) when the provider considers that the
                                                 nature, design, construction or purpose of
                                                 the AI system necessitate third party
                                                 verification, regardless of its risk level.


Amendment 454

Proposal for a regulation
Article 43 – paragraph 1 – subparagraph 2

     Text proposed by the Commission                             Amendment

For the purpose of the conformity                For the purpose of carrying out the
assessment procedure referred to in Annex        conformity assessment procedure referred
VII, the provider may choose any of the          to in Annex VII, the provider may choose
notified bodies. However, when the system        any of the notified bodies. However, when
is intended to be put into service by law        the system is intended to be put into
enforcement, immigration or asylum               service by law enforcement, immigration
authorities as well as EU institutions,          or asylum authorities as well as EU
bodies or agencies, the market surveillance      institutions, bodies or agencies, the market
authority referred to in Article 63(5) or (6),   surveillance authority referred to in Article
as applicable, shall act as a notified body.     63(5) or (6), as applicable, shall act as a
                                                 notified body.


Amendment 455

Proposal for a regulation
Article 43 – paragraph 4 – introductory part

     Text proposed by the Commission                             Amendment

4.     High-risk AI systems shall undergo a      4.     High-risk AI systems that have
new conformity assessment procedure              already been subject to a conformity
whenever they are substantially modified,        assessment procedure shall undergo a new
regardless of whether the modified system        conformity assessment procedure
is intended to be further distributed or         whenever they are substantially modified,
continues to be used by the current user.        regardless of whether the modified system
                                                 is intended to be further distributed or
                                                 continues to be used by the current
                                                 deployer;


Amendment 456

Proposal for a regulation
Article 43 – paragraph 4 a (new)
     Text proposed by the Commission                          Amendment

                                              4 a. The specific interests and needs of
                                              SMEs shall be taken into account when
                                              setting the fees for third-party conformity
                                              assessment under this Article, reducing
                                              those fees proportionately to their size and
                                              market share;

Amendment 457

Proposal for a regulation
Article 43 – paragraph 5

     Text proposed by the Commission                          Amendment

5.    The Commission is empowered to          5.    The Commission is empowered to
adopt delegated acts in accordance with       adopt delegated acts in accordance with
Article 73 for the purpose of updating        Article 73 for the purpose of updating
Annexes VI and Annex VII in order to          Annexes VI and Annex VII in order to
introduce elements of the conformity          introduce elements of the conformity
assessment procedures that become             assessment procedures that become
necessary in light of technical progress.     necessary in light of technical progress.
                                              When preparing such delegated acts, the
                                              Commission shall consult the AI Office
                                              and the stakeholders affected;


Amendment 458

Proposal for a regulation
Article 43 – paragraph 6

     Text proposed by the Commission                          Amendment

6.    The Commission is empowered to          6.    The Commission is empowered to
adopt delegated acts to amend paragraphs 1    adopt delegated acts to amend paragraphs 1
and 2 in order to subject high-risk AI        and 2 in order to subject high-risk AI
systems referred to in points 2 to 8 of       systems referred to in points 2 to 8 of
Annex III to the conformity assessment        Annex III to the conformity assessment
procedure referred to in Annex VII or parts   procedure referred to in Annex VII or parts
thereof. The Commission shall adopt such      thereof. The Commission shall adopt such
delegated acts taking into account the        delegated acts taking into account the
effectiveness of the conformity assessment    effectiveness of the conformity assessment
procedure based on internal control           procedure based on internal control
referred to in Annex VI in preventing or      referred to in Annex VI in preventing or
minimizing the risks to health and safety     minimizing the risks to health and safety
and protection of fundamental rights posed    and protection of fundamental rights posed
by such systems as well as the availability   by such systems as well as the availability
of adequate capacities and resources           of adequate capacities and resources
among notified bodies.                         among notified bodies. When preparing
                                               such delegated acts, the Commission shall
                                               consult the AI Office and the stakeholders
                                               affected;


Amendment 459

Proposal for a regulation
Article 44 – paragraph 1

     Text proposed by the Commission                           Amendment

1.    Certificates issued by notified bodies   1.    Certificates issued by notified bodies
in accordance with Annex VII shall be          in accordance with Annex VII shall be
drawn-up in an official Union language         drawn-up in one or several official Union
determined by the Member State in which        languages determined by the Member
the notified body is established or in an      State in which the notified body is
official Union language otherwise              established or in one or several official
acceptable to the notified body.               Union languages otherwise acceptable to
                                               the notified body;


Amendment 460

Proposal for a regulation
Article 44 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    Certificates shall be valid for the      2.    Certificates shall be valid for the
period they indicate, which shall not          period they indicate, which shall not
exceed five years. On application by the       exceed four years. On application by the
provider, the validity of a certificate may    provider, the validity of a certificate may
be extended for further periods, each not      be extended for further periods, each not
exceeding five years, based on a re-           exceeding four years, based on a re-
assessment in accordance with the              assessment in accordance with the
applicable conformity assessment               applicable conformity assessment
procedures.                                    procedures;


Amendment 461

Proposal for a regulation
Article 44 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    Where a notified body finds that an      3.    Where a notified body finds that an
AI system no longer meets the                  AI system no longer meets the
requirements set out in Chapter 2 of this      requirements set out in Chapter 2 of this
Title, it shall, taking account of the         Title, it shall suspend or withdraw the
principle of proportionality, suspend or       certificate issued or impose any restrictions
withdraw the certificate issued or impose      on it, unless compliance with those
any restrictions on it, unless compliance      requirements is ensured by appropriate
with those requirements is ensured by          corrective action taken by the provider of
appropriate corrective action taken by the     the system within an appropriate deadline
provider of the system within an               set by the notified body. The notified body
appropriate deadline set by the notified       shall give reasons for its decision.
body. The notified body shall give reasons
for its decision.


Amendment 462

Proposal for a regulation
Article 45 – paragraph 1

     Text proposed by the Commission                           Amendment

Member States shall ensure that an appeal      Member States shall ensure that an appeal
procedure against decisions of the notified    procedure against decisions of the notified
bodies is available to parties having a        bodies, including on issued conformity
legitimate interest in that decision.          certificates is available to parties having a
                                               legitimate interest in that decision.


Amendment 463

Proposal for a regulation
Article 46 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    Each notified body shall provide the     3.    Each notified body shall provide the
other notified bodies carrying out similar     other notified bodies carrying out similar
conformity assessment activities covering      conformity assessment activities with
the same artificial intelligence               relevant information on issues relating to
technologies with relevant information on      negative and, on request, positive
issues relating to negative and, on request,   conformity assessment results.
positive conformity assessment results.


Amendment 464

Proposal for a regulation
Article 47 – paragraph 1
     Text proposed by the Commission                           Amendment

1.    By way of derogation from Article         1.    By way of derogation from Article
43, any market surveillance authority may       43, any national supervisory authority may
authorise the placing on the market or          request a judicial authority to authorise
putting into service of specific high-risk AI   the placing on the market or putting into
systems within the territory of the Member      service of specific high-risk AI systems
State concerned, for exceptional reasons of     within the territory of the Member State
public security or the protection of life and   concerned, for exceptional reasons of the
health of persons, environmental protection     protection of life and health of persons,
and the protection of key industrial and        environmental protection and the
infrastructural assets. That authorisation      protection of critical infrastructure. That
shall be for a limited period of time, while    authorisation shall be for a limited period
the necessary conformity assessment             of time, while the necessary conformity
procedures are being carried out, and shall     assessment procedures are being carried
terminate once those procedures have been       out, and shall terminate once those
completed. The completion of those              procedures have been completed. The
procedures shall be undertaken without          completion of those procedures shall be
undue delay.                                    undertaken without undue delay;


Amendment 465

Proposal for a regulation
Article 47 – paragraph 2

     Text proposed by the Commission                           Amendment

2.     The authorisation referred to in         2.   The authorisation referred to in
paragraph 1 shall be issued only if the         paragraph 1 shall be issued only if the
market surveillance authority concludes         national supervisory authority and judicial
that the high-risk AI system complies with      authority conclude that the high-risk AI
the requirements of Chapter 2 of this Title.    system complies with the requirements of
The market surveillance authority shall         Chapter 2 of this Title. The national
inform the Commission and the other             supervisory authority shall inform the
Member States of any authorisation issued       Commission, the AI office, and the other
pursuant to paragraph 1.                        Member States of any request made and
                                                any subsequent authorisation issued
                                                pursuant to paragraph 1;


Amendment 466

Proposal for a regulation
Article 47 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    Where, within 15 calendar days of         3.   Where, within 15 calendar days of
receipt of the information referred to in     receipt of the information referred to in
paragraph 2, no objection has been raised     paragraph 2, no objection has been raised
by either a Member State or the               by either a Member State or the
Commission in respect of an authorisation     Commission in respect to the request of
issued by a market surveillance authority     the national supervisory authority for an
of a Member State in accordance with          authorisation issued by a national
paragraph 1, that authorisation shall be      supervisory authority of a Member State in
deemed justified.                             accordance with paragraph 1, that
                                              authorisation shall be deemed justified;


Amendment 467

Proposal for a regulation
Article 47 – paragraph 4

     Text proposed by the Commission                          Amendment

4.    Where, within 15 calendar days of       4.    Where, within 15 calendar days of
receipt of the notification referred to in    receipt of the notification referred to in
paragraph 2, objections are raised by a       paragraph 2, objections are raised by a
Member State against an authorisation         Member State against a request issued by a
issued by a market surveillance authority     national supervisory authority of another
of another Member State, or where the         Member State, or where the Commission
Commission considers the authorisation to     considers the authorisation to be contrary
be contrary to Union law or the conclusion    to Union law or the conclusion of the
of the Member States regarding the            Member States regarding the compliance
compliance of the system as referred to in    of the system as referred to in paragraph 2
paragraph 2 to be unfounded, the              to be unfounded, the Commission shall
Commission shall without delay enter into     without delay enter into consultation with
consultation with the relevant Member         the relevant Member State and the AI
State; the operator(s) concerned shall be     Office; the operator(s) concerned shall be
consulted and have the possibility to         consulted and have the possibility to
present their views. In view thereof, the     present their views. In view thereof, the
Commission shall decide whether the           Commission shall decide whether the
authorisation is justified or not. The        authorisation is justified or not. The
Commission shall address its decision to      Commission shall address its decision to
the Member State concerned and the            the Member State concerned and the
relevant operator or operators.               relevant operator(s);


Amendment 468

Proposal for a regulation
Article 47 – paragraph 5

     Text proposed by the Commission                          Amendment

5.    If the authorisation is considered      5.    If the authorisation is considered
unjustified, this shall be withdrawn by the   unjustified, this shall be withdrawn by the
market surveillance authority of the          national supervisory authority of the
Member State concerned.                       Member State concerned;


Amendment 469

Proposal for a regulation
Article 48 – paragraph 1

    Text proposed by the Commission                           Amendment

1.     The provider shall draw up a written   1.    The provider shall draw up a written
EU declaration of conformity for each AI      machine readable, physical or electronic
system and keep it at the disposal of the     EU declaration of conformity for each
national competent authorities for 10 years   high-risk AI system and keep it at the
after the AI system has been placed on the    disposal of the national supervisory
market or put into service. The EU            authority and the national competent
declaration of conformity shall identify      authorities for 10 years after the AI high-
the AI system for which it has been drawn     risk system has been placed on the market
up. A copy of the EU declaration of           or put into service. A copy of the EU
conformity shall be given to the relevant     declaration of conformity shall be
national competent authorities upon           submitted to the national supervisory
request.                                      authority and the relevant national
                                              competent authorities upon request;


Amendment 470

Proposal for a regulation
Article 48 – paragraph 2

    Text proposed by the Commission                           Amendment

2.     The EU declaration of conformity       2.     The EU declaration of conformity
shall state that the high-risk AI system in   shall state that the high-risk AI system in
question meets the requirements set out in    question meets the requirements set out in
Chapter 2 of this Title. The EU declaration   Chapter 2 of this Title. The EU declaration
of conformity shall contain the information   of conformity shall contain the information
set out in Annex V and shall be translated    set out in Annex V and shall be translated
into an official Union language or            into an official Union language or
languages required by the Member State(s)     languages required by the Member State(s)
in which the high-risk AI system is made      in which the high-risk AI system is placed
available.                                    on the market or made available;


Amendment 471

Proposal for a regulation
Article 48 – paragraph 3
     Text proposed by the Commission                            Amendment

3.    Where high-risk AI systems are            3.    Where high-risk AI systems are
subject to other Union harmonisation            subject to other Union harmonisation
legislation which also requires an EU           legislation which also requires an EU
declaration of conformity, a single EU          declaration of conformity, a single EU
declaration of conformity shall be drawn        declaration of conformity may be drawn up
up in respect of all Union legislations         in respect of all Union legislations
applicable to the high-risk AI system. The      applicable to the high-risk AI system. The
declaration shall contain all the information   declaration shall contain all the information
required for identification of the Union        required for identification of the Union
harmonisation legislation to which the          harmonisation legislation to which the
declaration relates.                            declaration relates.


Amendment 472

Proposal for a regulation
Article 48 – paragraph 5

     Text proposed by the Commission                            Amendment

5.     The Commission shall be empowered        5.    After consulting the AI Office, the
to adopt delegated acts in accordance with      Commission shall be empowered to adopt
Article 73 for the purpose of updating the      delegated acts in accordance with Article
content of the EU declaration of                73 for the purpose of updating the content
conformity set out in Annex V in order to       of the EU declaration of conformity set out
introduce elements that become necessary        in Annex V in order to introduce elements
in light of technical progress.                 that become necessary in light of technical
                                                progress;


Amendment 473

Proposal for a regulation
Article 49 – paragraph 1

     Text proposed by the Commission                            Amendment

1.    The CE marking shall be affixed           1.     The physical CE marking shall be
visibly, legibly and indelibly for high-risk    affixed visibly, legibly and indelibly for
AI systems. Where that is not possible or       high-risk AI systems before the high-risk
not warranted on account of the nature of       AI system is placed on the market Where
the high-risk AI system, it shall be affixed    that is not possible or not warranted on
to the packaging or to the accompanying         account of the nature of the high-risk AI
documentation, as appropriate.                  system, it shall be affixed to the packaging
                                                or to the accompanying documentation, as
                                                appropriate. It may be followed by a
                                                pictogram or any other marking
                                              indicating a special risk of use;


Amendment 474

Proposal for a regulation
Article 49 – paragraph 1 a (new)

    Text proposed by the Commission                           Amendment

                                              1 a. For digital only high-risk AI
                                              systems, a digital CE marking shall be
                                              used, only if it can be easily accessed via
                                              the interface from which the AI system is
                                              accessed or via an easily accessible
                                              machine-readable code or other electronic
                                              means.


Amendment 475

Proposal for a regulation
Article 49 – paragraph 3

    Text proposed by the Commission                           Amendment

3.    Where applicable, the CE marking        3.     Where applicable, the CE marking
shall be followed by the identification       shall be followed by the identification
number of the notified body responsible for   number of the notified body responsible for
the conformity assessment procedures set      the conformity assessment procedures set
out in Article 43. The identification         out in Article 43. The identification
number shall also be indicated in any         number of the notified body shall be
promotional material which mentions that      affixed by the body itself or, under its
the high-risk AI system fulfils the           instructions, by the provider’s authorised
requirements for CE marking.                  representative. The identification number
                                              shall also be indicated in any promotional
                                              material which mentions that the high-risk
                                              AI system fulfils the requirements for CE
                                              marking;


Amendment 476

Proposal for a regulation
Article 49 – paragraph 3 a (new)

    Text proposed by the Commission                           Amendment

                                              3 a. Where high-risk AI systems are
                                              subject to other Union law which also
                                               provides for the affixing of the CE
                                               marking, the CE marking shall indicate
                                               that the high-risk AI system also fulfil the
                                               requirements of that other law.


Amendment 477

Proposal for a regulation
Article 50 – paragraph 1 – introductory part

    Text proposed by the Commission                            Amendment

The provider shall, for a period ending 10     The provider shall, for a period ending 10
years after the AI system has been placed      years, after the AI system has been placed
on the market or put into service, keep at     on the market or put into service keep at
the disposal of the national competent         the disposal of the national supervisory
authorities:                                   authority and the national competent
                                               authorities:


Amendment 478

Proposal for a regulation
Article 51 – paragraph 1

    Text proposed by the Commission                            Amendment

Before placing on the market or putting        Before placing on the market or putting
into service a high-risk AI system referred    into service a high-risk AI system referred
to in Article 6(2), the provider or, where     to in Article 6(2) the provider or, where
applicable, the authorised representative      applicable, the authorised representative
shall register that system in the EU           shall register that system in the EU
database referred to in Article 60.            database referred to in Article 60, in
                                               accordance with Article 60(2);


Amendment 479

Proposal for a regulation
Article 51 – paragraph 1 a (new)

    Text proposed by the Commission                            Amendment

                                               Before putting into service or using a
                                               high-risk AI system in accordance with
                                               Article 6(2), the following categories of
                                               deployers shall register the use of that AI
                                               system in the EU database referred to in
                                      Article 60:
                                      a) deployers who are public authorities or
                                      Union institutions, bodies, offices or
                                      agencies or deployers acting on their
                                      behalf;
                                      b) deployers who are undertakings
                                      designated as a gatekeeper under
                                      Regulation (EU) 2022/1925.


Amendment 480

Proposal for a regulation
Article 51 – paragraph 1 b (new)

    Text proposed by the Commission                   Amendment

                                      Deployers who do not fall under
                                      subparagraph 1a. shall be entitled to
                                      voluntarily register the use of a high-risk
                                      AI system referred to in Article 6(2) in the
                                      EU database referred to in Article 60.


Amendment 481

Proposal for a regulation
Article 51 – paragraph 1 c (new)

    Text proposed by the Commission                   Amendment

                                      An updated registration entry must be
                                      completed immediately following each
                                      substantial modification.


Amendment 482

Proposal for a regulation
Title IV

    Text proposed by the Commission                   Amendment

TRANSPARENCY OBLIGATIONS FOR          TRANSPARENCY OBLIGATIONS
CERTAIN AI SYSTEMS


Amendment 483
Proposal for a regulation
Article 52 – title

     Text proposed by the Commission                            Amendment

Transparency obligations for certain AI         Transparency obligations
systems


Amendment 484

Proposal for a regulation
Article 52 – paragraph 1

     Text proposed by the Commission                            Amendment

1.    Providers shall ensure that AI            1.     Providers shall ensure that AI
systems intended to interact with natural       systems intended to interact with natural
persons are designed and developed in           persons are designed and developed in
such a way that natural persons are             such a way that the AI system, the provider
informed that they are interacting with an      itself or the user informs the natural
AI system, unless this is obvious from the      person exposed to an AI system that they
circumstances and the context of use. This      are interacting with an AI system in a
obligation shall not apply to AI systems        timely, clear and intelligible manner,
authorised by law to detect, prevent,           unless this is obvious from the
investigate and prosecute criminal              circumstances and the context of use.
offences, unless those systems are
available for the public to report a criminal
offence.
                                                Where appropriate and relevant, this
                                                information shall also include which
                                                functions are AI enabled, if there is
                                                human oversight, and who is responsible
                                                for the decision-making process, as well
                                                as the existing rights and processes that,
                                                according to Union and national law,
                                                allow natural persons or their
                                                representatives to object against the
                                                application of such systems to them and to
                                                seek judicial redress against decisions
                                                taken by or harm caused by AI systems,
                                                including their right to seek an
                                                explanation. This obligation shall not
                                                apply to AI systems authorised by law to
                                                detect, prevent, investigate and prosecute
                                                criminal offences, unless those systems are
                                                available for the public to report a criminal
                                                offence.
Amendment 485

Proposal for a regulation
Article 52 – paragraph 2

     Text proposed by the Commission                             Amendment

2.    Users of an emotion recognition            2.    Users of an emotion recognition
system or a biometric categorisation             system or a biometric categorisation
system shall inform of the operation of the      system which is not prohibited pursuant
system the natural persons exposed thereto.      to Article 5 shall inform in a timely, clear
This obligation shall not apply to AI            and intelligible manner of the operation of
systems used for biometric categorisation,       the system the natural persons exposed
which are permitted by law to detect,            thereto and obtain their consent prior to
prevent and investigate criminal offences.       the processing of their biometric and
                                                 other personal data in accordance with
                                                 Regulation (EU) 2016/679, Regulation
                                                 (EU) 2016/1725 and Directive (EU)
                                                 2016/280, as applicable. This obligation
                                                 shall not apply to AI systems used for
                                                 biometric categorisation, which are
                                                 permitted by law to detect, prevent and
                                                 investigate criminal offences.


Amendment 486

Proposal for a regulation
Article 52 – paragraph 3 – subparagraph 1

     Text proposed by the Commission                             Amendment

3.     Users of an AI system that generates      3.     Users of an AI system that generates
or manipulates image, audio or video             or manipulates text, audio or visual content
content that appreciably resembles               that would falsely appear to be authentic or
existing persons, objects, places or other       truthful and which features depictions of
entities or events and would falsely appear      people appearing to say or do things they
to a person to be authentic or truthful          did not say or do, without their consent
(‘deep fake’), shall disclose that the content   (‘deep fake’), shall disclose in an
has been artificially generated or               appropriate, timely, clear and visible
manipulated.                                     manner that the content has been
                                                 artificially generated or manipulated, as
                                                 well as, whenever possible, the name of
                                                 the natural or legal person that generated
                                                 or manipulated it. Disclosure shall mean
                                                 labelling the content in a way that informs
                                                 that the content is inauthentic and that is
                                                 clearly visible for the recipient of that
                                                 content. To label the content, users shall
                                                 take into account the generally
                                               acknowledged state of the art and relevant
                                               harmonised standards and specifications.


Amendment 487

Proposal for a regulation
Article 52 – paragraph 3 – subparagraph 2

     Text proposed by the Commission                           Amendment

However, the first subparagraph shall not      3a. Paragraph 3 shall not apply where
apply where the use is authorised by law to    the use of an AI system that generates or
detect, prevent, investigate and prosecute     manipulates text, audio or visual content
criminal offences or it is necessary for the   is authorized by law or if it is necessary for
exercise of the right to freedom of            the exercise of the right to freedom of
expression and the right to freedom of the     expression and the right to freedom of the
arts and sciences guaranteed in the Charter    arts and sciences guaranteed in the Charter
of Fundamental Rights of the EU, and           of Fundamental Rights of the EU, and
subject to appropriate safeguards for the      subject to appropriate safeguards for the
rights and freedoms of third parties.          rights and freedoms of third parties. Where
                                               the content forms part of an evidently
                                               creative, satirical, artistic or fictional
                                               cinematographic, video games visuals and
                                               analogous work or programme,
                                               transparency obligations set out in
                                               paragraph 3 are limited to disclosing of
                                               the existence of such generated or
                                               manipulated content in an appropriate
                                               clear and visible manner that does not
                                               hamper the display of the work and
                                               disclosing the applicable copyrights,
                                               where relevant. It shall also not prevent
                                               law enforcement authorities from using
                                               AI systems intended to detect deep fakes
                                               and prevent, investigate and prosecute
                                               criminal offences linked with their use


Amendment 488

Proposal for a regulation
Article 52 – paragraph 3 b (new)

     Text proposed by the Commission                           Amendment

                                               3b. The information referred to in
                                               paragraphs 1 to 3 shall be provided to the
                                               natural persons at the latest at the time of
                                               the first interaction or exposure. It shall
                                              be accessible to vulnerable persons, such
                                              as persons with disabilities or children,
                                              complete, where relevant and appropriate,
                                              with intervention or flagging procedures
                                              for the exposed natural person taking into
                                              account the generally acknowledged state
                                              of the art and relevant harmonised
                                              standards and common specifications.

Amendment 489

Proposal for a regulation
Article 53 – paragraph 1

    Text proposed by the Commission                           Amendment

1.    AI regulatory sandboxes established     1.    Member States shall establish at
by one or more Member States competent        least one AI regulatory sandbox at
authorities or the European Data              national level, which shall be operational
Protection Supervisor shall provide a         at the latest on the day of the entry into
controlled environment that facilitates the   application of this Regulation This
development, testing and validation of        sandbox can also be established jointly
innovative AI systems for a limited time      with one or several other Member States;
before their placement on the market or
putting into service pursuant to a specific
plan. This shall take place under the
direct supervision and guidance by the
competent authorities with a view to
ensuring compliance with the
requirements of this Regulation and,
where relevant, other Union and Member
States legislation supervised within the
sandbox.


Amendment 490

Proposal for a regulation
Article 53 – paragraph 1 a (new)

    Text proposed by the Commission                           Amendment

                                              1 a. Additional AI regulatory sandboxes
                                              at regional or local levels or jointly with
                                              other Member States may also be
                                              established;


Amendment 491
Proposal for a regulation
Article 53 – paragraph 1 b (new)

    Text proposed by the Commission                   Amendment

                                      1 b. The Commission and the European
                                      Data Protection Supervisor, on their own,
                                      jointly or in collaboration with one or
                                      more Member States may also establish
                                      AI regulatory sandboxes at Union level;


Amendment 492

Proposal for a regulation
Article 53 – paragraph 1 c (new)

    Text proposed by the Commission                   Amendment

                                      1 c. Establishing authorities shall
                                      allocate sufficient resources to comply
                                      with this Article effectively and in a timely
                                      manner;


Amendment 493

Proposal for a regulation
Article 53 – paragraph 1 d (new)

    Text proposed by the Commission                   Amendment

                                      1 d. AI regulatory sandboxes shall, in
                                      accordance with criteria set out in Article
                                      53a, provide for a controlled environment
                                      that fosters innovation and facilitates the
                                      development, testing and validation of
                                      innovative AI systems for a limited time
                                      before their placement on the market or
                                      putting into service pursuant to a specific
                                      plan agreed between the prospective
                                      providers and the establishing authority;


Amendment 494

Proposal for a regulation
Article 53 – paragraph 1 e (new)
    Text proposed by the Commission                  Amendment

                                      1 e. The establishment of AI regulatory
                                      sandboxes shall aim to contribute to the
                                      following objectives:
                                      a) for the competent authorities to provide
                                      guidance to AI systems prospective
                                      providers providers to achieve regulatory
                                      compliance with this Regulation or where
                                      relevant other applicable Union and
                                      Member States legislation;
                                      b) for the prospective providers to allow
                                      and facilitate the testing and development
                                      of innovative solutions related to AI
                                      systems;
                                      c) regulatory learning in a controlled
                                      environment.


Amendment 495

Proposal for a regulation
Article 53 – paragraph 1 f (new)


    Text proposed by the Commission                  Amendment

                                      1 f. Establishing authorities shall
                                      provide guidance and supervision within
                                      the sandbox with a view to identify risks,
                                      in particular to fundamental rights,
                                      democracy and rule of law, health and
                                      safety and the environment, test and
                                      demonstrate mitigation measures for
                                      identified risks, and their effectiveness
                                      and ensure compliance with the
                                      requirements of this Regulation and,
                                      where relevant, other Union and Member
                                      States legislation;


Amendment 496

Proposal for a regulation
Article 53 – paragraph 1 f (new)
     Text proposed by the Commission                          Amendment

                                              1 g. Establishing authorities shall
                                              provide sandbox prospective providers
                                              who develop high-risk AI systems with
                                              guidance and supervision on how to fulfil
                                              the requirements set out in this
                                              Regulation, so that the AI systems may
                                              exit the sandbox being in presumption of
                                              conformity with the specific requirements
                                              of this Regulation that were assessed
                                              within the sandbox. Insofar as the AI
                                              system complies with the requirements
                                              when exiting the sandbox, it shall be
                                              presumed to be in conformity with this
                                              regulation. In this regard, the exit reports
                                              created by the establishing authority shall
                                              be taken into account by market
                                              surveillance authorities or notified bodies,
                                              as applicable, in the context of conformity
                                              assessment procedures or market
                                              surveillance checks;


Amendment 497

Proposal for a regulation
Article 53 – paragraph 2

     Text proposed by the Commission                          Amendment

2.    Member States shall ensure that to      2.     Establishing authorities shall ensure
the extent the innovative AI systems          that, to the extent the innovative AI
involve the processing of personal data or    systems involve the processing of personal
otherwise fall under the supervisory remit    data or otherwise fall under the supervisory
of other national authorities or competent    remit of other national authorities or
authorities providing or supporting access    competent authorities providing or
to data, the national data protection         supporting access to personal data, the
authorities and those other national          national data protection authorities, or in
authorities are associated to the operation   cases referred to in paragraph 1b the
of the AI regulatory sandbox.                 EDPS, and those other national authorities
                                              are associated to the operation of the AI
                                              regulatory sandbox and involved in the
                                              supervision of those aspects to the full
                                              extent of their respective tasks and
                                              powers;


Amendment 498
Proposal for a regulation
Article 53 – paragraph 3

     Text proposed by the Commission                           Amendment

3.     The AI regulatory sandboxes shall       3.    The AI regulatory sandboxes shall
not affect the supervisory and corrective      not affect the supervisory and corrective
powers of the competent authorities. Any       powers of the competent authorities,
significant risks to health and safety and     including at regional or local level. Any
fundamental rights identified during the       significant risks to fundamental rights,
development and testing of such systems        democracy and rule of law, health and
shall result in immediate mitigation and,      safety or the environment identified during
failing that, in the suspension of the         the development and testing of such AI
development and testing process until          systems shall result in immediate and
such mitigation takes place.                   adequate mitigation. Competent
                                               authorities shall have the power to
                                               temporarily or permanently suspend the
                                               testing process, or participation in the
                                               sandbox if no effective mitigation is
                                               possible and inform the AI office of such
                                               decision;


Amendment 499

Proposal for a regulation
Article 53 – paragraph 4

     Text proposed by the Commission                           Amendment

4.     Participants in the AI regulatory       4.     Prospective providers in the AI
sandbox shall remain liable under              regulatory sandbox shall remain liable
applicable Union and Member States             under applicable Union and Member States
liability legislation for any harm inflicted   liability legislation for any harm inflicted
on third parties as a result from the          on third parties as a result of the
experimentation taking place in the            experimentation taking place in the
sandbox.                                       sandbox. However, provided that the
                                               prospective provider(s) respect the specific
                                               plan referred to in paragraph 1c and the
                                               terms and conditions for their
                                               participation and follow in good faith the
                                               guidance given by the establishing
                                               authorities, no administrative fines shall
                                               be imposed by the authorities for
                                               infringements of this Regulation;


Amendment 500
Proposal for a regulation
Article 53 – paragraph 5

    Text proposed by the Commission                          Amendment

5.     Member States’ competent              5.    Establishing authorities shall
authorities that have established AI         coordinate their activities and cooperate
regulatory sandboxes shall coordinate        within the framework of the AI office;
their activities and cooperate within the
framework of the European Artificial
Intelligence Board. They shall submit
annual reports to the Board and the
Commission on the results from the
implementation of those scheme,
including good practices, lessons learnt
and recommendations on their setup and,
where relevant, on the application of this
Regulation and other Union legislation
supervised within the sandbox.


Amendment 501

Proposal for a regulation
Article 53 – paragraph 5 a (new)

    Text proposed by the Commission                          Amendment

                                             5 a. Establishing authorities shall
                                             inform the AI Office of the establishment
                                             of a sandbox and may ask for support and
                                             guidance. A list of planned and existing
                                             sandboxes shall be made publicly
                                             available by the AI office and kept up to
                                             date in order to encourage more
                                             interaction in the regulatory sandboxes
                                             and transnational cooperation;


Amendment 502

Proposal for a regulation
Article 53 – paragraph 5 b (new)

    Text proposed by the Commission                          Amendment

                                             5 b. Establishing authorities shall
                                             submit to the AI office and, unless the
                                             Commission is the sole establishing
                                             authority, to the Commission, annual
                                                reports, starting one year after the
                                                establishment of the sandbox and then
                                                every year until its termination and a final
                                                report. Those reports shall provide
                                                information on the progress and results of
                                                the implementation of those sandboxes,
                                                including best practices, incidents, lessons
                                                learnt and recommendations on their
                                                setup and, where relevant, on the
                                                application and possible revision of this
                                                Regulation and other Union law
                                                supervised within the sandbox. Those
                                                annual reports or abstracts thereof shall
                                                be made available to the public, online;


Amendment 503

Proposal for a regulation
Article 53 – paragraph 6

     Text proposed by the Commission                            Amendment

6.    The modalities and the conditions of      6.     The Commission shall develop a
the operation of the AI regulatory              single and dedicated interface containing
sandboxes, including the eligibility criteria   all relevant information related to
and the procedure for the application,          sandboxes, together with a single contact
selection, participation and exiting from       point at Union level to interact with the
the sandbox, and the rights and                 regulatory sandboxes and to allow
obligations of the participants shall be set    stakeholders to raise enquiries with
out in implementing acts. Those                 competent authorities, and to seek non-
implementing acts shall be adopted in           binding guidance on the conformity of
accordance with the examination                 innovative products, services, business
procedure referred to in Article 74(2).         models embedding AI technologies;
                                                The Commission shall proactively
                                                coordinate with national, regional and
                                                also local authorities, where relevant;


Amendment 504

Proposal for a regulation
Article 53 – paragraph 6 a (new)


     Text proposed by the Commission                            Amendment

                                                6 a. For the purpose of paragraph 1 and
                                                1a, the Commission shall play a
                                      complementary role, enabling Member
                                      States to build on their expertise and, on
                                      the other hand, assisting and providing
                                      technical understanding and resources to
                                      those Member States that seek guidance
                                      on the set-up and running of these
                                      regulatory sandboxes;


Amendment 505

Proposal for a regulation
Article 53 a (new)


    Text proposed by the Commission                   Amendment

                                                      Article 53 a
                                          Modalities and functioning of AI
                                              regulatory sandboxes
                                      1. In order to avoid fragmentation across
                                      the Union, the Commission, in
                                      consultation with the AI office, shall
                                      adopt a delegated act detailing the
                                      modalities for the establishment,
                                      development, implementation, functioning
                                      and supervision of the AI regulatory
                                      sandboxes, including the eligibility
                                      criteria and the procedure for the
                                      application, selection, participation and
                                      exiting from the sandbox, and the rights
                                      and obligations of the participants based
                                      on the provisions set out in this Article;
                                      2. The Commission is empowered to adopt
                                      delegated acts in accordance with the
                                      procedure referred to in Article 73, no
                                      later than 12 months following the entry
                                      into force of this Regulation and shall
                                      ensure that:
                                      a) regulatory sandboxes are open to any
                                      applying prospective provider of an AI
                                      system who fulfils eligibility and selection
                                      criteria. The criteria for accessing to the
                                      regulatory sandbox are transparent and
                                      fair and establishing authorities inform
                                      applicants of their decision within 3
                                      months of the application;
b) regulatory sandboxes allow broad and
equal access and keep up with demand for
participation;
c) access to the AI regulatory sandboxes is
free of charge for SMEs and start-ups
without prejudice to exceptional costs that
establishing authorities may recover in a
fair and proportionate manner;
d) regulatory sandboxes facilitate the
involvement of other relevant actors
within the AI ecosystem, such as notified
bodies and standardisation organisations
(SMEs, start-ups, enterprises, innovators,
testing and experimentation facilities,
research and experimentation labs and
digital innovation hubs, centers of
excellence, individual researchers), in
order to allow and facilitate cooperation
with the public and private sector;
e) they allow prospective providers to to
fulfil, in a controlled environment, the
conformity assessment obligations of this
Regulation or the voluntary application of
the codes of conduct referred to in Article
69;
f) procedures, processes and
administrative requirements for
application, selection, participation and
exiting the sandbox are simple, easily
intelligible, clearly communicated in
order to facilitate the participation of
SMEs and start-ups with limited legal and
administrative capacities and are
streamlined across the Union, in order to
avoid fragmentation and that
participation in a regulatory sandbox
established by a Member State, by the
Commission, or by the EDPS is mutually
and uniformly recognised and carries the
same legal effects across the Union;
g) participation in the AI regulatory
sandbox is limited to a period that is
appropriate to the complexity and scale of
the project.
h) the sandboxes shall facilitate the
development of tools and infrastructure
for testing, benchmarking, assessing and
explaining dimensions of AI systems
                                               relevant to sandboxes, such as accuracy,
                                               robustness and cybersecurity as well as
                                               minimisation of risks to fundamental
                                               rights, environment and the society at
                                               large
                                               3. Prospective providers in the sandboxes,
                                               in particular SMEs and start-ups, shall be
                                               facilitated access to pre-deployment
                                               services such as guidance on the
                                               implementation of this Regulation, to
                                               other value-adding services such as help
                                               with standardisation documents and
                                               certification and consultation, and to
                                               other Digital Single Market initiatives
                                               such as Testing & Experimentation
                                               Facilities, Digital Hubs, Centres of
                                               Excellence, and EU benchmarking
                                               capabilities;


Amendment 506

Proposal for a regulation
Article 54 – title

    Text proposed by the Commission                            Amendment

Further processing of personal data for        Further processing of data for developing
developing certain AI systems in the public    certain AI systems in the public interest in
interest in the AI regulatory sandbox          the AI regulatory sandbox


Amendment 507

Proposal for a regulation
Article 54 – paragraph 1 – introductory part

    Text proposed by the Commission                            Amendment

1.   In the AI regulatory sandbox              1.    In the AI regulatory sandbox
personal data lawfully collected for other     personal data lawfully collected for other
purposes shall be processed for the            purposes may be processed solely for the
purposes of developing and testing certain     purposes of developing and testing certain
innovative AI systems in the sandbox           AI systems in the sandbox when all of the
under the following conditions:                following conditions are met:


Amendment 508
Proposal for a regulation
Article 54 – paragraph 1 – point a – introductory part

    Text proposed by the Commission                            Amendment

(a) the innovative AI systems shall be         (a) AI systems shall be developed for
developed for safeguarding substantial         safeguarding substantial public interest in
public interest in one or more of the          one or more of the following areas:
following areas:
                                               (ii) public safety and public health,
                                               including disease detection, diagnosis
                                               prevention, control and treatment;
                                               (iii) a high level of protection and
                                               improvement of the quality of the
                                               environment, protection of biodiversity,
                                               pollution as well as climate change
                                               mitigation and adaptation;
                                               (iii a) safety and resilience of transport
                                               systems, critical infrastructure and
                                               networks.


Amendment 509

Proposal for a regulation
Article 54 – paragraph 1 – point a – point i

    Text proposed by the Commission                            Amendment

(i) the prevention, investigation,             deleted
detection or prosecution of criminal
offences or the execution of criminal
penalties, including the safeguarding
against and the prevention of threats to
public security, under the control and
responsibility of the competent
authorities. The processing shall be based
on Member State or Union law;


Amendment 510

Proposal for a regulation
Article 54 – paragraph 1 – point c

    Text proposed by the Commission                            Amendment

(c) there are effective monitoring             (c) there are effective monitoring
mechanisms to identify if any high risks to    mechanisms to identify if any high risks to
the fundamental rights of the data subjects   the rights and freedoms of the data
may arise during the sandbox                  subjects, as referred to in Article 35 of
experimentation as well as response           Regulation (EU) 2016/679 and in Article
mechanism to promptly mitigate those          35 of Regulation (EU) 2018/1725 may
risks and, where necessary, stop the          arise during the sandbox experimentation
processing;                                   as well as response mechanism to promptly
                                              mitigate those risks and, where necessary,
                                              stop the processing;


Amendment 511

Proposal for a regulation
Article 54 – paragraph 1 – point d

    Text proposed by the Commission                           Amendment

(d) any personal data to be processed in      (d) any personal data to be processed in
the context of the sandbox are in a           the context of the sandbox are in a
functionally separate, isolated and           functionally separate, isolated and
protected data processing environment         protected data processing environment
under the control of the participants and     under the control of the prospective
only authorised persons have access to that   provider and only authorised persons have
data;                                         access to that those data;


Amendment 512

Proposal for a regulation
Article 54 – paragraph 1 – point f

    Text proposed by the Commission                           Amendment

(f) any processing of personal data in the    (f) any processing of personal data in the
context of the sandbox do not lead to         context of the sandbox do not lead to
measures or decisions affecting the data      measures or decisions affecting the data
subjects;                                     subjects nor affect the application of their
                                              rights laid down in Union law on the
                                              protection of personal data;


Amendment 513

Proposal for a regulation
Article 54 – paragraph 1 – point g

    Text proposed by the Commission                           Amendment

(g) any personal data processed in the        (g) any personal data processed in the
context of the sandbox are deleted once the   context of the sandbox are protected by
participation in the sandbox has terminated    means of appropriate technical and
or the personal data has reached the end of    organisational measures and deleted once
its retention period;                          the participation in the sandbox has
                                               terminated or the personal data has reached
                                               the end of its retention period;


Amendment 514

Proposal for a regulation
Article 54 – paragraph 1 – point h

    Text proposed by the Commission                            Amendment

(h) the logs of the processing of personal     (h) the logs of the processing of personal
data in the context of the sandbox are kept    data in the context of the sandbox are kept
for the duration of the participation in the   for the duration of the participation in the
sandbox and 1 year after its termination,      sandbox;
solely for the purpose of and only as long
as necessary for fulfilling accountability
and documentation obligations under this
Article or other application Union or
Member States legislation;


Amendment 515

Proposal for a regulation
Article 54 – paragraph 1 – point j

    Text proposed by the Commission                            Amendment

(j) a short summary of the AI project          (j) a short summary of the AI system
developed in the sandbox, its objectives       developed in the sandbox, its objectives,
and expected results published on the          hypotheses, and expected results,
website of the competent authorities.          published on the website of the competent
                                               authorities;


Amendment 516

Proposal for a regulation
Article 54 a (new)

    Text proposed by the Commission                            Amendment

                                                               Article 54 a
                                                     Promotion of AI research and
                                                 development in support of socially and
                                           environmentally beneficial outcomes
                                         1. Member States shall promote research
                                         and development of AI solutions which
                                         support socially and environmentally
                                         beneficial outcomes, including but not
                                         limited to development of AI-based
                                         solutions to increase accessibility for
                                         persons with disabilities, tackle socio-
                                         economic inequalities, and meet
                                         sustainability and environmental targets,
                                         by:
                                         (a) providing relevant projects with
                                         priority access to the AI regulatory
                                         sandboxes to the extent that they fulfil the
                                         eligibility conditions;
                                         (b) earmarking public funding, including
                                         from relevant EU funds, for AI research
                                         and development in support of socially
                                         and environmentally beneficial outcomes;
                                         (c) organising specific awareness raising
                                         activities about the application of this
                                         Regulation, the availability of and
                                         application procedures for dedicated
                                         funding, tailored to the needs of those
                                         projects;
                                         (d) where appropriate, establishing
                                         accessible dedicated channels, including
                                         within the sandboxes, for communication
                                         with projects to provide guidance and
                                         respond to queries about the
                                         implementation of this Regulation.
                                         Member States shall support civil society
                                         and social stakeholders to lead or
                                         participate in such projects;


Amendment 517

Proposal for a regulation
Article 55 – title

    Text proposed by the Commission                      Amendment

Measures for small-scale providers and   Measures for SMEs, start-ups and users
users
Amendment 518

Proposal for a regulation
Article 55 – paragraph 1 – point a

    Text proposed by the Commission                            Amendment

(a) provide small-scale providers and          (a) provide SMEs and start-ups,
start-ups with priority access to the AI       established in the Union, with priority
regulatory sandboxes to the extent that they   access to the AI regulatory sandboxes, to
fulfil the eligibility conditions;             the extent that they fulfil the eligibility
                                               conditions;


Amendment 519

Proposal for a regulation
Article 55 – paragraph 1 – point b

    Text proposed by the Commission                            Amendment

(b) organise specific awareness raising        (b) organise specific awareness raising
activities about the application of this       and enhanced digital skills development
Regulation tailored to the needs of the        activities on the application of this
small-scale providers and users;               Regulation tailored to the needs of SMEs,
                                               start-ups and users;


Amendment 520

Proposal for a regulation
Article 55 – paragraph 1 – point c

    Text proposed by the Commission                            Amendment

(c) where appropriate, establish a             (c) utilise existing dedicated channels
dedicated channel for communication with       and where appropriate, establish new
small-scale providers and user and other       dedicated channels for communication
innovators to provide guidance and             with SMEs, start-ups, users and other
respond to queries about the                   innovators to provide guidance and
implementation of this Regulation.             respond to queries about the
                                               implementation of this Regulation;


Amendment 521

Proposal for a regulation
Article 55 – paragraph 1 – point c a (new)
     Text proposed by the Commission                           Amendment

                                               (ca) foster the participation of SMEs and
                                               other relevant stakeholders in the
                                               standardisation development process.


Amendment 522

Proposal for a regulation
Article 55 – paragraph 2

     Text proposed by the Commission                           Amendment

2.    The specific interests and needs of      2.    The specific interests and needs of
the small-scale providers shall be taken       the SMEs, start-ups and users shall be
into account when setting the fees for         taken into account when setting the fees for
conformity assessment under Article 43,        conformity assessment under Article 43,
reducing those fees proportionately to their   reducing those fees proportionately to
size and market size.                          development stage, their size, market size
                                               and market demand. The Commission
                                               shall regularly assess the certification and
                                               compliance costs for SMEs and start-ups,
                                               including through transparent
                                               consultations with SMEs, start-ups and
                                               users and shall work with Member States
                                               to lower such costs where possible. The
                                               Commission shall report on these findings
                                               to the European Parliament and to the
                                               Council as part of the report on the
                                               evaluation and review of this Regulation
                                               provided for in Article 84(2).


Amendment 523

Proposal for a regulation
Article 56 – SECTION 1 – Title

     Text proposed by the Commission                           Amendment

                                                                  Title
                                               SECTION 1: General provisions on the
                                               European Artificial Intelligence Office


Amendment 524
Proposal for a regulation
Article 56 – title

    Text proposed by the Commission                            Amendment

Establishment of the European Artificial       Establishment of the European Artificial
Intelligence Board                             Intelligence Office


Amendment 525

Proposal for a regulation
Article 56 – paragraph 1

    Text proposed by the Commission                            Amendment

1.   A ‘European Artificial Intelligence       1.    The ‘European Artificial Intelligence
Board’ (the ‘Board’) is established.           Office’ (the ‘AI Office’) is hereby
                                               established. The AI Office shall be an
                                               independent body of the Union. It shall
                                               have legal personality.


Amendment 526

Proposal for a regulation
Article 56 – paragraph 2 – introductory part

    Text proposed by the Commission                            Amendment

2.    The Board shall provide advice and       2.    The AI Office shall have a
assistance to the Commission in order to:      secretariat, and shall be adequately
                                               funded and staffed for the purpose of
                                               performing its tasks pursuant to this
                                               Regulation.


Amendment 527

Proposal for a regulation
Article 56 – paragraph 2 a (new)

    Text proposed by the Commission                            Amendment

                                               2 a. The seat of the AI Office shall be in
                                               Brussels.


Amendment 528
Proposal for a regulation
Article 56 a (new)

    Text proposed by the Commission                  Amendment

                                                     Article 56 a
                                                      Structure
                                      The administrative and management
                                      structure of the AI Office shall comprise:
                                      (a) a management board, including a
                                      chair
                                      (b) a secretariat managed by an executive
                                      director;
                                      (c) an advisory forum.


Amendment 529

Proposal for a regulation
Article 56 b (new)

    Text proposed by the Commission                  Amendment

                                                     Article 56 b
                                                Tasks of the AI Office
                                      The AI Office shall carry out the
                                      following tasks:
                                      a) support, advise, and cooperate with
                                      Member States, national supervisory
                                      authorities, the Commission and other
                                      Union institutions, bodies, offices and
                                      agencies with regard to the
                                      implementation of this Regulation;
                                      b) monitor and ensure the effective and
                                      consistent application of this Regulation,
                                      without prejudice to the tasks of national
                                      supervisory authorities;
                                      c) contribute to the coordination among
                                      national supervisory authorities
                                      responsible for the application of this
                                      Regulation,
                                      d) serve as a mediator in discussions
                                      about serious disagreements that may
                                      arise between competent authorities
                                      regarding the application of the
Regulation
e) coordinate joint investigations,
pursuant to Article 66a;
f) contribute to the effective cooperation
with the competent authorities of third
countries and with international
organisations,
g) collect and share Member States’
expertise and best practices and to assist
Member States national supervisory
authorities and the Commission in
developing the organizational and
technical expertise required for the
implementation of this Regulation,
including by means of facilitating the
creation and maintenance of a Union
pool of experts
h) examine, on its own initiative or upon
the request of its management board or
the Commission, questions relating to the
implementation of this Regulation and to
issue opinions, recommendations or
written contributions including with
regard to:
(i) technical specifications or existing
standards; (ii) the Commission’s
guidelines
(iii) codes of conduct and the application
thereof, in close cooperation with industry
and other relevant stakeholders;
(iv) the possible revision of the
Regulation, the preparation of the
delegated acts, and possible alignments of
this Regulation with the legal acts listed in
Annex II;
(v) trends, such as European global
competitiveness in artificial intelligence,
the uptake of artificial intelligence in the
Union, the development of digital skills,
and emerging systemic threats relating to
artificial intelligence
(vi) guidance on how this Regulation
applies to the ever evolving typology of AI
value chains, in particular on the
resulting implications in terms of
accountability of all the entities involved
i) issue:
(i) an annual report that includes an
evaluation of the implementation of this
Regulation, a review of serious incident
reports as referred to in Article 62 and the
functioning of the database referred to in
Article 60 and
(ii) recommendations to the Commission
on the categorisation of prohibited
practices, high-risk AI systems referred to
in Annex III, the codes of conduct
referred to in Article 69, and the
application of the general principles
outlines in Article 4a
j) assist authorities in the establishment
and development of regulatory sandboxes
and to facilitate cooperation among
regulatory sandboxes;
k) organise meetings with Union agencies
and governance bodies whose tasks are
related to artificial intelligence and the
implementation of this Regulation;
l)organise quarterly consultations with
the advisory forum, and, where
appropriate, public consultations with
other stakeholders, and to make the
results of those consultations public on its
website;
m) promote public awareness and
understanding of the benefits, risks,
safeguards and rights and obligations in
relation to the use of AI systems;
n) facilitate the development of common
criteria and a shared understanding
among market operators and competent
authorities of the relevant concepts
provided for in this Regulation;
o) provide monitoring of foundation
models and to organise a regular dialogue
with the developers of foundation models
with regard to their compliance as well as
AI systems that make use of such AI
models
p) provide interpretive guidance on how
the AI Act applies to the ever evolving
typology of AI value chains, and what the
                                      resulting implications in terms of
                                      accountability of all the entities involved
                                      will be under the different scenarios based
                                      on the generally acknowledged state of
                                      the art, including as reflected in relevant
                                      harmonized standards;
                                      q) provide particular oversight and
                                      monitoring and institutionalize regular
                                      dialogue with the providers of foundation
                                      models about the compliance of
                                      foundation models as well as AI systems
                                      that make use of such AI models with
                                      Article 28b of this Regulation, and about
                                      industry best practices for self-
                                      governance. Any such meeting shall be
                                      open to national supervisory authorities,
                                      notified bodies and market surveillance
                                      authorities to attend and contribute
                                      r) issue and periodically update guidelines
                                      on the thresholds that qualify training a
                                      foundation model as a large training run,
                                      record and monitor known instances of
                                      large training runs, and issue an annual
                                      report on the state of play in the
                                      development, proliferation, and use of
                                      foundation models alongside policy
                                      options to address risks and opportunities
                                      specific to foundation models.
                                      s) promote AI literacy pursuant to Article
                                      4b.


Amendment 530

Proposal for a regulation
Article 56 c (new)

    Text proposed by the Commission                  Amendment

                                                     Article 56 c
                                          Accountability, independence, and
                                                   transparency
                                      1. The AI Office shall:
                                      a. be accountable to the European
                                      Parliament and to the Council in
                                      accordance with this Regulation;
                                      b. act independently when carrying out its
                                           tasks or exercising its powers; and
                                           c. ensure a high level of transparency
                                           concerning its activities and develop good
                                           administrative practices in that regard.
                                           Regulation (EC) No 1049/2001 shall
                                           apply to documents held by the AI Office.


Amendment 531

Proposal for a regulation
Article - 57 a (new) – SECTION 2 – title

    Text proposed by the Commission                       Amendment

                                                              Title
                                               SECTION 2: Management Board


Amendment 532

Proposal for a regulation
Article - 57 a (new)

    Text proposed by the Commission                       Amendment

                                                          Article - 57 a
                                            Composition of the management board
                                           1. The management board shall be
                                           composed of the following members:
                                           (a) one representative of each Member
                                           State’s national supervisory authority;
                                           (b) one representative from the
                                           Commission;
                                           (c) one representative from the European
                                           Data Protection Supervisor (EDPS);
                                           (d) one representative from the European
                                           Union Agency for Cybersecurity
                                           (ENISA);
                                           (e) one representative from the
                                           Fundamental Rights Agency (FRA)
                                           Each representative of a national
                                           supervisory authority shall have one vote.
                                           The representatives of the Commission,
                                           the EDPS, the ENISA and the FRA shall
                                      not have voting rights. Each member shall
                                      have a substitute. The appointment of
                                      members and substitute members of the
                                      management board shall take into
                                      account the need to gender balance. The
                                      members of the management board and
                                      their substitute members shall be made
                                      public.
                                      2. The members and substitutes members
                                      of the management board shall not hold
                                      conflicting positions or commercial
                                      interests with regard to any topic related
                                      to the application of this Regulation.
                                      3. The rules for the meetings and voting
                                      of the management board and the
                                      appointment and removal of the Executive
                                      Director shall be laid down in the rules of
                                      procedure referred to in Article – 57 b,
                                      point (a).


Amendment 533

Proposal for a regulation
Article - 57 b (new)

    Text proposed by the Commission                   Amendment

                                                     Article - 57 b
                                         Functions of the management board
                                      1. The management board shall have the
                                      following tasks:
                                      (a) to make strategic decisions on the
                                      activities of the AI Office and to adopt its
                                      rules of procedure by a two-thirds
                                      majority of its members;
                                      (b) to implement its rules of procedure;
                                      (c) to adopt the AI Office’s single
                                      programming document as well as it
                                      annual public report and transmit both to
                                      the European Parliament, to the Council,
                                      to the Commission, and to the Court of
                                      Auditors;
                                      (d) to adopt the AI Office’s budget;
                                      (e) to appoint the executive director and,
                                      where relevant, to extend or curtail the
                                              executive director’s term of office or
                                              remove him or her from office;
                                              (f) to decide on the establishment of the
                                              AI Office’s internal structures and, where
                                              necessary, the modification of those
                                              internal structures necessary for the
                                              fulfilment of the AI Office tasks;


Amendment 534

Proposal for a regulation
Article - 57 c (new)

    Text proposed by the Commission                           Amendment

                                                             Article - 57 c
                                                   Chair of the management board
                                              1. The management board shall elect a
                                              Chair and two deputy Chairs from among
                                              its voting members, by simple majority.
                                              2. The term of office of the Chair and of
                                              the deputy Chairs shall be four years. The
                                              terms of the Chair and of the deputy
                                              Chairs renewable once.


Amendment 535

Proposal for a regulation
Article 57 – SECTION 3 – title

    Text proposed by the Commission                           Amendment

Structure of the Board                        Secretariat


Amendment 536

Proposal for a regulation
Article 57 – paragraph 1

    Text proposed by the Commission                           Amendment

1.    The Board shall be composed of the      1.   The activities of the secretariat shall
national supervisory authorities, who shall   be managed by an executive director. The
be represented by the head or equivalent      executive director shall be accountable to
high-level official of that authority, and    the management board. Without prejudice
the European Data Protection Supervisor.       to the respective powers of the
Other national authorities may be invited      management board and the Union
to the meetings, where the issues              institutions, the executive director shall
discussed are of relevance for them.           neither seek nor take instructions from
                                               any government or from any other body


Amendment 537

Proposal for a regulation
Article 57 – paragraph 2

    Text proposed by the Commission                            Amendment

2.    The Board shall adopt its rules of       2.    The executive director shall attend
procedure by a simple majority of its          hearings on any matter linked to the AI
members, following the consent of the          Office's activities and shall report on the
Commission. The rules of procedure shall       performance of the executive director’s
also contain the operational aspects           duties when invited to do so by the
related to the execution of the Board’s        European Parliament or the Council.
tasks as listed in Article 58. The Board
may establish sub-groups as appropriate
for the purpose of examining specific
questions.


Amendment 538

Proposal for a regulation
Article 57 – paragraph 3

    Text proposed by the Commission                            Amendment

3.    The Board shall be chaired by the        3.    The executive director shall
Commission. The Commission shall               represent the AI Office, including in
convene the meetings and prepare the           international fora for cooperation with
agenda in accordance with the tasks of         regard to artificial intelligence;
the Board pursuant to this Regulation and
with its rules of procedure. The
Commission shall provide administrative
and analytical support for the activities of
the Board pursuant to this Regulation.


Amendment 539

Proposal for a regulation
Article 57 – paragraph 4
     Text proposed by the Commission                           Amendment

4.     The Board may invite external           4.    The secretariat shall provide the
experts and observers to attend its            management board and the advisory
meetings and may hold exchanges with           forum with the analytical, administrative
interested third parties to inform its         and logistical support necessary to fulfil
activities to an appropriate extent. To that   the tasks of the AI Office, including by:
end the Commission may facilitate
exchanges between the Board and other
Union bodies, offices, agencies and
advisory groups.
                                               (a) Implementing the decisions,
                                               programmes and activities adopted by the
                                               management board;
                                               (b) preparing each year the draft single
                                               programming document, the draft budget,
                                               the annual activity report on the AI
                                               Office, the draft opinions and the draft
                                               positions of the AI Office, and submit
                                               them to the management board
                                               (c) Coordinating with international fora
                                               for cooperation on artificial intelligence;


Amendment 540

Proposal for a regulation
Article 58 – SECTION 4 – title

     Text proposed by the Commission                           Amendment

Tasks of the Board                             Advisory Forum


Amendment 541

Proposal for a regulation
Article 58 – paragraph 1 – introductory part

     Text proposed by the Commission                           Amendment

When providing advice and assistance to        The advisory forum shall provide the AI
the Commission in the context of Article       Office with stakeholder input in matters
56(2), the Board shall in particular:          relating to this Regulation, in particular
                                               with regard to the tasks set out in Article
                                               56b point (l).
Amendment 542

Proposal for a regulation
Article 58 – paragraph 2 (new)

    Text proposed by the Commission                  Amendment

                                      The membership of the advisory forum
                                      shall represent a balanced selection of
                                      stakeholders, including industry, start-
                                      ups, SMEs, civil society, the social
                                      partners and academia. The membership
                                      of the advisory forum shall be balanced
                                      with regard to commercial and non-
                                      commercial interests and, within the
                                      category of commercial interests, with
                                      regards to SMEs and other undertakings.


Amendment 543

Proposal for a regulation
Article 58 – paragraph 3 (new)

    Text proposed by the Commission                  Amendment

                                      The management board shall appoint the
                                      members of the advisory forum in
                                      accordance with the selection procedure
                                      established in the AI Office’s rules of
                                      procedure and taking into account the
                                      need for transparency and in accordance
                                      with the criteria set out in paragraph 2;


Amendment 544

Proposal for a regulation
Article 58 – paragraph 4 (new)

    Text proposed by the Commission                  Amendment

                                      The term of office of the members of the
                                      advisory forum shall be two years, which
                                      may be extended by up to no more than
                                      four years.


Amendment 545
Proposal for a regulation
Article 58 – paragraph 5 (new)

    Text proposed by the Commission                  Amendment

                                      The European Committee for
                                      Standardization (CEN), the European
                                      Committee for Electrotechnical
                                      Standardization (CENELEC), and the
                                      European Telecommunications Standards
                                      Institute (ETSI) shall be permanent
                                      members of the Advisory Forum. The
                                      Joint Research Centre shall be permanent
                                      member, without voting rights.


Amendment 546

Proposal for a regulation
Article 58 – paragraph 6 (new)

    Text proposed by the Commission                  Amendment

                                      The advisory forum shall draw up its rules
                                      of procedure. It shall elect two co-Chairs
                                      from among its members, in accordance
                                      with criteria set out in paragraph 2. The
                                      term of office of the co-Chairs shall be
                                      two years, renewable once.


Amendment 547

Proposal for a regulation
Article 58 – paragraph 7 (new)

    Text proposed by the Commission                  Amendment

                                      The advisory forum shall hold meetings at
                                      least four times a year. The advisory
                                      forum may invite experts and other
                                      stakeholders to its meetings. The
                                      executive director may attend, ex officio,
                                      the meetings of the advisory forum.


Amendment 548

Proposal for a regulation
Article 58 – paragraph 8 (new)
    Text proposed by the Commission                   Amendment

                                      In fulfilling its role as set out in
                                      paragraph 1, the advisory forum may
                                      prepare opinions, recommendations and
                                      written contributions.


Amendment 549

Proposal for a regulation
Article 58 – paragraph 9 (new)

    Text proposed by the Commission                   Amendment

                                      The advisory forum may establish
                                      standing or temporary subgroups as
                                      appropriate for the purpose of examining
                                      specific questions related to the objectives
                                      of this Regulation.


Amendment 550

Proposal for a regulation
Article 58 – paragraph 10 (new)

    Text proposed by the Commission                   Amendment

                                      The advisory forum shall prepare an
                                      annual report of its activities. That report
                                      shall be made publicly available.


Amendment 551

Proposal for a regulation
Article 58 a – SECTION 5 – title

    Text proposed by the Commission                   Amendment

                                      European Authorities on benchmarking


Amendment 552

Proposal for a regulation
Article 58 a (new)
    Text proposed by the Commission                          Amendment

                                                             Article 58 a
                                                            Benchmarking
                                             The European authorities on
                                             benchmarking referred to in Article 15
                                             (1a) and the AI Office shall, in close
                                             cooperation with international partners,
                                             jointly develop cost-effective guidance and
                                             capabilities to measure and benchmark
                                             aspects of AI systems and AI components,
                                             and in particular of foundation models
                                             relevant to the compliance and
                                             enforcement of this Regulation based on
                                             the generally acknowledged state of the
                                             art, including as reflected in relevant
                                             harmonized standards.


Amendment 553

Proposal for a regulation
Article 59 – title

    Text proposed by the Commission                          Amendment

Designation of national competent            Designation of national supervisory
authorities                                  authorities


Amendment 554

Proposal for a regulation
Article 59 – paragraph 1

    Text proposed by the Commission                          Amendment

1.    National competent authorities shall   1.    Each Member State shall designate
be established or designated by each         one national supervisory authority, which
Member State for the purpose of ensuring     shall be organised so as to safeguard the
the application and implementation of this   objectivity and impartiality of its activities
Regulation. National competent               and tasks by ...[three months after the date
authorities shall be organised so as to      of entry into force of this Regulation].
safeguard the objectivity and impartiality
of their activities and tasks.


Amendment 555
Proposal for a regulation
Article 59 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    Each Member State shall designate       2.    The national supervisory authority
a national supervisory authority among the    shall ensure the application and
national competent authorities. The           implementation of this Regulation. With
national supervisory authority shall act as   regard to high-risk AI systems, related to
notifying authority and market                products to which legal acts listed in
surveillance authority unless a Member        Annex II apply, the competent authorities
State has organisational and                  designated under those legal acts shall
administrative reasons to designate more      continue to lead the administrative
than one authority.                           procedures. However, to the extent a case
                                              involves aspects exclusively covered by
                                              this Regulation, those competent
                                              authorities shall be bound by the
                                              measures related to those aspects issued
                                              by the national supervisory authority
                                              designated under this Regulation. The
                                              national supervisory authority shall act as
                                              market surveillance authority.


Amendment 556

Proposal for a regulation
Article 59 – paragraph 3

    Text proposed by the Commission                           Amendment

3.   Member States shall inform the           3.    Member States shall make publicly
Commission of their designation or            available and communicate to the AI
designations and, where applicable, the       Office and the Commission the national
reasons for designating more than one         supervisory authority and information on
authority.                                    how it can be contacted, by… [three
                                              months after the date of entry into force
                                              of this Regulation]. The national
                                              supervisory authority shall act as single
                                              point of contact for this Regulation and
                                              should be contactable though electronic
                                              communications means.


Amendment 557

Proposal for a regulation
Article 59 – paragraph 4
    Text proposed by the Commission                          Amendment

4.     Member States shall ensure that        4.     Member States shall ensure that the
national competent authorities are            national supervisory authority is provided
provided with adequate financial and          with adequate technical, financial and
human resources to fulfil their tasks under   human resources, and infrastructure to
this Regulation. In particular, national      fulfil their tasks effectively under this
competent authorities shall have a            Regulation. In particular, the national
sufficient number of personnel                supervisory authority shall have a
permanently available whose competences       sufficient number of personnel
and expertise shall include an in-depth       permanently available whose competences
understanding of artificial intelligence      and expertise shall include an in-depth
technologies, data and data computing,        understanding of artificial intelligence
fundamental rights, health and safety risks   technologies, data and data computing,
and knowledge of existing standards and       personal data protection, cybersecurity,
legal requirements.                           competition law, fundamental rights,
                                              health and safety risks and knowledge of
                                              existing standards and legal requirements.
                                              Member States shall assess and, if deemed
                                              necessary, update competence and
                                              resource requirements referred to in this
                                              paragraph on an annual basis.


Amendment 558

Proposal for a regulation
Article 59 – paragraph 4 a (new)

    Text proposed by the Commission                          Amendment

                                              4 a. Each national supervisory authority
                                              shall exercise their powers and carry out
                                              their duties independently, impartially and
                                              without bias. The members of each
                                              national supervisory authority, in the
                                              performance of their tasks and exercise of
                                              their powers under this Regulation, shall
                                              neither seek nor take instructions from
                                              any body and shall refrain from any
                                              action incompatible with their duties.


Amendment 559

Proposal for a regulation
Article 59 – paragraph 4 b (new)
    Text proposed by the Commission                           Amendment

                                              4 b. National supervisory authorities
                                              shall satisfy the minimum cybersecurity
                                              requirements set out for public
                                              administration entities identified as
                                              operators of essential services pursuant to
                                              Directive (EU) 2022/2555.


Amendment 560

Proposal for a regulation
Article 59 – paragraph 4 c (new)

    Text proposed by the Commission                           Amendment

                                              4 c. When performing their tasks, the
                                              national supervisory authority shall act in
                                              compliance with the confidentiality
                                              obligations set out in Article 70.


Amendment 561

Proposal for a regulation
Article 59 – paragraph 5

    Text proposed by the Commission                           Amendment

5.    Member States shall report to the       5.    Member States shall report to the
Commission on an annual basis on the          Commission on an annual basis on the
status of the financial and human resources   status of the financial and human resources
of the national competent authorities with    of the national supervisory authority with
an assessment of their adequacy. The          an assessment of their adequacy. The
Commission shall transmit that information    Commission shall transmit that information
to the Board for discussion and possible      to the AI Office for discussion and possible
recommendations.                              recommendations.


Amendment 562

Proposal for a regulation
Article 59 – paragraph 6

    Text proposed by the Commission                           Amendment

6.   The Commission shall facilitate the      deleted
exchange of experience between national
competent authorities.


Amendment 563

Proposal for a regulation
Article 59 – paragraph 7

    Text proposed by the Commission                         Amendment

7.    National competent authorities may     7.    National supervisory authorities may
provide guidance and advice on the           provide guidance and advice on the
implementation of this Regulation,           implementation of this Regulation,
including to small-scale providers.          including to SMEs and start-ups, taking
Whenever national competent authorities      into account the AI Office or the
intend to provide guidance and advice with   Commission’s guidance and advice.
regard to an AI system in areas covered by   Whenever the national supervisory
other Union legislation, the competent       authority intend to provide guidance and
national authorities under that Union        advice with regard to an AI system in areas
legislation shall be consulted, as           covered by other Union law, the guidance
appropriate. Member States may also          shall be drafted in consultation with the
establish one central contact point for      competent national authorities under that
communication with operators.                Union law, as appropriate.


Amendment 564

Proposal for a regulation
Article 59 – paragraph 8

    Text proposed by the Commission                         Amendment

8.   When Union institutions, agencies       8.   When Union institutions, agencies
and bodies fall within the scope of this     and bodies fall within the scope of this
Regulation, the European Data Protection     Regulation, the European Data Protection
Supervisor shall act as the competent        Supervisor shall act as the competent
authority for their supervision.             authority for their supervision and
                                             coordination.


Amendment 565

Proposal for a regulation
Article 59 a (new)

    Text proposed by the Commission                         Amendment

                                                            Article 59 a
                                             Cooperation mechanism between national
                                           supervisory authorities in cases involving
                                                 two or more Member States
                                           1. Each national supervisory authority
                                           shall perform its tasks and powers
                                           conferred on in accordance with this
                                           Regulation on the territory of its own
                                           Member State.
                                           2. In the event of a case involving two or
                                           more national supervisory authorities, the
                                           national supervisory authority of the
                                           Member State where the infringement
                                           took place shall be considered the lead
                                           supervisory authority.
                                           3. In the cases referred to in paragraph 2,
                                           the relevant supervisory authorities shall
                                           cooperate and exchange all relevant
                                           information in due time. National
                                           supervisory authorities shall cooperate in
                                           order to reach a consensus.


Amendment 566

Proposal for a regulation
Title VII

    Text proposed by the Commission                       Amendment

VII EU DATABASE FOR STAND-                 EU DATABASE FOR HIGH-RISK AI
ALONE HIGH-RISK AI SYSTEMS                 SYSTEMS


Amendment 567

Proposal for a regulation
Article 60 – title

    Text proposed by the Commission                       Amendment

EU database for stand-alone high-risk AI   EU database for high-risk AI systems
systems


Amendment 568

Proposal for a regulation
Article 60 – paragraph 1
    Text proposed by the Commission                          Amendment

1.    The Commission shall, in                1.    The Commission shall, in
collaboration with the Member States, set     collaboration with the Member States, set
up and maintain a EU database containing      up and maintain a public EU database
information referred to in paragraph 2        containing information referred to in
concerning high-risk AI systems referred to   paragraphs 2 and 2a concerning high-risk
in Article 6(2) which are registered in       AI systems referred to in Article 6 (2)
accordance with Article 51.                   which are registered in accordance with
                                              Article 51.


Amendment 569

Proposal for a regulation
Article 60 – paragraph 2

    Text proposed by the Commission                          Amendment

2.    The data listed in Annex VIII shall     2.    The data listed in Annex VIII,
be entered into the EU database by the        Section A, shall be entered into the EU
providers. The Commission shall provide       database by the providers.
them with technical and administrative
support.


Amendment 570

Proposal for a regulation
Article 60 – paragraph 2 a (new)

    Text proposed by the Commission                          Amendment

                                              2 a. The data listed in Annex VIII,
                                              Section B, shall be entered into the EU
                                              database by the deployers who are or who
                                              act on behalf of public authorities or
                                              Union institutions, bodies, offices or
                                              agencies and by deployers who are
                                              undertakings referred to in Article 51(1a)
                                              and (1b).


Amendment 571

Proposal for a regulation
Article 60 – paragraph 3
     Text proposed by the Commission                           Amendment

3.   Information contained in the EU           3.    Information contained in the EU
database shall be accessible to the public.    database shall be freely available to the
                                               public, user-friendly and accessible, easily
                                               navigable and machine-readable
                                               containing structured digital data based
                                               on a standardised protocol.


Amendment 572

Proposal for a regulation
Article 60 – paragraph 4

     Text proposed by the Commission                           Amendment

4.    The EU database shall contain            4.    The EU database shall contain
personal data only insofar as necessary for    personal data only insofar as necessary for
collecting and processing information in       collecting and processing information in
accordance with this Regulation. That          accordance with this Regulation. That
information shall include the names and        information shall include the names and
contact details of natural persons who are     contact details of natural persons who are
responsible for registering the system and     responsible for registering the system and
have the legal authority to represent the      have the legal authority to represent the
provider.                                      provider or the deployer which is a public
                                               authority or Union institution, body,
                                               office or agency or a deployer acting on
                                               their behalf or a deployer which is an
                                               undertaking referred to in Article
                                               51(1a)(b) and (1b).


Amendment 573

Proposal for a regulation
Article 60 – paragraph 5

     Text proposed by the Commission                           Amendment

5.    The Commission shall be the              5.    The Commission shall be the
controller of the EU database. It shall also   controller of the EU database. It shall also
ensure to providers adequate technical and     ensure to providers and deployers adequate
administrative support.                        technical and administrative support.
                                               The database shall comply with the
                                               accessibility requirements of Annex I to
                                               Directive (EU) 2019/882.
Amendment 574

Proposal for a regulation
Article 61 – paragraph 2

    Text proposed by the Commission                           Amendment

2.     The post-market monitoring system      2.     The post-market monitoring system
shall actively and systematically collect,    shall actively and systematically collect,
document and analyse relevant data            document and analyse relevant data
provided by users or collected through        provided by deployers or collected through
other sources on the performance of high-     other sources on the performance of high-
risk AI systems throughout their lifetime,    risk AI systems throughout their lifetime,
and allow the provider to evaluate the        and allow the provider to evaluate the
continuous compliance of AI systems with      continuous compliance of AI systems with
the requirements set out in Title III,        the requirements set out in Title III,
Chapter 2.                                    Chapter 2. Where relevant, post-market
                                              monitoring shall include an analysis of
                                              the interaction with other AI systems
                                              environment, including other devices and
                                              software taking into account the rules
                                              applicable from areas such as data
                                              protection, intellectual property rights and
                                              competition law.


Amendment 575

Proposal for a regulation
Article 61 – paragraph 3

    Text proposed by the Commission                           Amendment

3.    The post-market monitoring system       3.    The post-market monitoring system
shall be based on a post-market monitoring    shall be based on a post-market monitoring
plan. The post-market monitoring plan         plan. The post-market monitoring plan
shall be part of the technical                shall be part of the technical
documentation referred to in Annex IV.        documentation referred to in Annex IV.
The Commission shall adopt an                 The Commission shall adopt an
implementing act laying down detailed         implementing act laying down detailed
provisions establishing a template for the    provisions establishing a template for the
post-market monitoring plan and the list of   post-market monitoring plan and the list of
elements to be included in the plan.          elements to be included in the plan by
                                              [twelve months after the date of entry into
                                              force of this Regulation].


Amendment 576
Proposal for a regulation
Article 62 – title

     Text proposed by the Commission                           Amendment

Reporting of serious incidents and of          Reporting of serious incidents
malfunctioning


Amendment 577

Proposal for a regulation
Article 62 – paragraph 1 – introductory part

     Text proposed by the Commission                           Amendment

1.     Providers of high-risk AI systems       1.    Providers and, where deployers have
placed on the Union market shall report        identified a serious incident, deployers of
any serious incident or any                    high-risk AI systems placed on the Union
malfunctioning of those systems which          market shall report any serious incident of
constitutes a breach of obligations under      those systems which constitutes a breach of
Union law intended to protect fundamental      obligations under Union law intended to
rights to the market surveillance              protect fundamental rights to the national
authorities of the Member States where         supervisory authority of the Member
that incident or breach occurred.              States where that incident or breach
                                               occurred.


Amendment 578

Proposal for a regulation
Article 62 – paragraph 1 – subparagraph 1

     Text proposed by the Commission                           Amendment

Such notification shall be made                Such notification shall be made without
immediately after the provider has             undue delay after the provider, or, where
established a causal link between the AI       applicable the deployer, has established a
system and the incident or malfunctioning      causal link between the AI system and the
or the reasonable likelihood of such a link,   incident or the reasonable likelihood of
and, in any event, not later than 15 days      such a link, and, in any event, not later than
after the providers becomes aware of the       72 hours after the provider or, where
serious incident or of the malfunctioning.     applicable, the deployer becomes aware of
                                               the serious incident.


Amendment 579

Proposal for a regulation
Article 62 – paragraph 1 a (new)
    Text proposed by the Commission                          Amendment

                                              1 a. Upon establishing a causal link
                                              between the AI system and the serious
                                              incident or the reasonable likelihood of
                                              such a link, providers shall take
                                              appropriate corrective actions pursuant to
                                              Article 21.


Amendment 580

Proposal for a regulation
Article 62 – paragraph 2

    Text proposed by the Commission                          Amendment

2.    Upon receiving a notification related   2.    Upon receiving a notification related
to a breach of obligations under Union law    to a breach of obligations under Union law
intended to protect fundamental rights, the   intended to protect fundamental rights, the
market surveillance authority shall inform    national supervisory authority shall inform
the national public authorities or bodies     the national public authorities or bodies
referred to in Article 64(3). The             referred to in Article 64(3). The
Commission shall develop dedicated            Commission shall develop dedicated
guidance to facilitate compliance with the    guidance to facilitate compliance with the
obligations set out in paragraph 1. That      obligations set out in paragraph 1. That
guidance shall be issued 12 months after      guidance shall be issued by [the entry into
the entry into force of this Regulation, at   force of this Regulation] and shall be
the latest.                                   assessed regularly.


Amendment 581

Proposal for a regulation
Article 62 – paragraph 2 a (new)

    Text proposed by the Commission                          Amendment

                                              2 a. The national supervisory authority
                                              shall take appropriate measures within 7
                                              days from the date it received the
                                              notification referred to in paragraph 1.
                                              Where the infringement takes place or is
                                              likely to take place in other Member
                                              States, the national supervisory authority
                                              shall notify the AI Office and the relevant
                                              national supervisory authorities of these
                                              Member States.
Amendment 582

Proposal for a regulation
Article 62 – paragraph 3

    Text proposed by the Commission                            Amendment

3.    For high-risk AI systems referred to     3.    For high-risk AI systems referred to
in point 5(b) of Annex III which are placed    in Annex III that are placed on the market
on the market or put into service by           or put into service by providers that are
providers that are credit institutions         subject to Union legislative instruments
regulated by Directive 2013/36/EU and          laying down reporting obligations
for high-risk AI systems which are safety      equivalent to those set out in this
components of devices, or are themselves       Regulation, the notification of serious
devices, covered by Regulation (EU)            incidents constituting a breach of
2017/745 and Regulation (EU) 2017/746,         fundamental rights under Union law shall
the notification of serious incidents or       be transferred to the national supervisory
malfunctioning shall be limited to those       authority.
that that constitute a breach of obligations
under Union law intended to protect
fundamental rights.


Amendment 583

Proposal for a regulation
Article 62 – paragraph 3 a (new)

    Text proposed by the Commission                            Amendment

                                               3 a. National supervisory authorities
                                               shall on an annual basis notify the AI
                                               Office of the serious incidents reported to
                                               them in accordance with this Article.


Amendment 584

Proposal for a regulation
Article 63 – paragraph 1 – introductory part

    Text proposed by the Commission                            Amendment

1.    Regulation (EU) 2019/1020 shall          1.    Regulation (EU) 2019/1020 shall
apply to AI systems covered by this            apply to AI systems and foundation
Regulation. However, for the purpose of        models covered by this Regulation.
the effective enforcement of this              However, for the purpose of the effective
Regulation:                                    enforcement of this Regulation:
Amendment 585

Proposal for a regulation
Article 63 – paragraph 1 – point b a (new)

     Text proposed by the Commission                           Amendment

                                               (b a) the national supervisory authorities
                                               shall act as market surveillance
                                               authorities under this Regulation and
                                               have the same powers and obligations as
                                               market surveillance authorities under
                                               Regulation (EU) 2019/1020.


Amendment 586

Proposal for a regulation
Article 63 – paragraph 2

     Text proposed by the Commission                           Amendment

2.     The national supervisory authority      2.     The national supervisory authority
shall report to the Commission on a            shall report to the Commission and the AI
regular basis the outcomes of relevant         Office annually the outcomes of relevant
market surveillance activities. The national   market surveillance activities. The national
supervisory authority shall report, without    supervisory authority shall report, without
delay, to the Commission and relevant          delay, to the Commission and relevant
national competition authorities any           national competition authorities any
information identified in the course of        information identified in the course of
market surveillance activities that may be     market surveillance activities that may be
of potential interest for the application of   of potential interest for the application of
Union law on competition rules.                Union law on competition rules.


Amendment 587

Proposal for a regulation
Article 63 – paragraph 3 a (new)

     Text proposed by the Commission                           Amendment

                                               3 a. For the purpose of ensuring the
                                               effective enforcement of this Regulation,
                                               national supervisory authorities may:
                                               (a) carry out unannounced on-site and
                                               remote inspections of high-risk AI
                                               systems;
                                               (b) acquire samples related to high-risk
                                                AI systems, including through remote
                                                inspections, to reverse-engineer the AI
                                                systems and to acquire evidence to
                                                identify non-compliance.


Amendment 588

Proposal for a regulation
Article 63 – paragraph 5

     Text proposed by the Commission                            Amendment

5.     For AI systems listed in point 1(a) in   5.    For AI systems that are used for law
so far as the systems are used for law          enforcement purposes, Member States shall
enforcement purposes, points 6 and 7 of         designate as market surveillance authorities
Annex III, Member States shall designate        for the purposes of this Regulation the
as market surveillance authorities for the      competent data protection supervisory
purposes of this Regulation either the          authorities under Directive (EU) 2016/680.
competent data protection supervisory
authorities under Directive (EU) 2016/680,
or Regulation 2016/679 or the national
competent authorities supervising the
activities of the law enforcement,
immigration or asylum authorities putting
into service or using those systems.


Amendment 589

Proposal for a regulation
Article 63 – paragraph 7

     Text proposed by the Commission                            Amendment

7.    Member States shall facilitate the        7.     National supervisory authorities
coordination between market surveillance        designated under this Regulation shall
authorities designated under this               coordinate with other relevant national
Regulation and other relevant national          authorities or bodies which supervise the
authorities or bodies which supervise the       application of Union harmonisation law
application of Union harmonisation              listed in Annex II or other Union law that
legislation listed in Annex II or other         might be relevant for the high-risk AI
Union legislation that might be relevant for    systems referred to in Annex III.
the high-risk AI systems referred to in
Annex III.


Amendment 590
Proposal for a regulation
Article 64 – paragraph 1

    Text proposed by the Commission                           Amendment

1.     Access to data and documentation in    1.    In the context of their activities, and
the context of their activities, the market   upon their reasoned request the national
surveillance authorities shall be granted     supervisory authority shall be granted full
full access to the training, validation and   access to the training, validation and
testing datasets used by the provider,        testing datasets used by the provider, or,
including through application                 where relevant, the deployer, that are
programming interfaces (‘API’) or other       relevant and strictly necessary for the
appropriate technical means and tools         purpose of its request through appropriate
enabling remote access.                       technical means and tools.


Amendment 591

Proposal for a regulation
Article 64 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    Where necessary to assess the           2.     Where necessary to assess the
conformity of the high-risk AI system with    conformity of the high-risk AI system with
the requirements set out in Title III,        the requirements set out in Title III,
Chapter 2 and upon a reasoned request, the    Chapter 2, after all other reasonable ways
market surveillance authorities shall be      to verify conformity including paragraph
granted access to the source code of the AI   1 have been exhausted and have proven to
system.                                       be insufficient, and upon a reasoned
                                              request, the national supervisory authority
                                              shall be granted access to the training and
                                              trained models of the AI system, including
                                              its relevant model parameters. All
                                              information in line with Article 70
                                              obtained shall be treated as confidential
                                              information and shall be subject to
                                              existing Union law on the protection of
                                              intellectual property and trade secrets and
                                              shall be deleted upon the completion of
                                              the investigation for which the
                                              information was requested.


Amendment 592

Proposal for a regulation
Article 64 – paragraph 2 a (new)
     Text proposed by the Commission                             Amendment

                                                 2 a. Paragraphs 1 and 2 are without
                                                 prejudice to the procedural rights of the
                                                 concerned operator in accordance with
                                                 Article 18 of Regulation (EU) 2019/1020.


Amendment 593

Proposal for a regulation
Article 64 – paragraph 3

     Text proposed by the Commission                             Amendment

3.     National public authorities or bodies     3.     National public authorities or bodies
which supervise or enforce the respect of        which supervise or enforce the respect of
obligations under Union law protecting           obligations under Union law protecting
fundamental rights in relation to the use of     fundamental rights in relation to the use of
high-risk AI systems referred to in Annex        high-risk AI systems referred to in Annex
III shall have the power to request and          III shall have the power to request and
access any documentation created or              access any documentation created or
maintained under this Regulation when            maintained under this Regulation when
access to that documentation is necessary        access to that documentation is necessary
for the fulfilment of the competences under      for the fulfilment of the competences under
their mandate within the limits of their         their mandate within the limits of their
jurisdiction. The relevant public authority      jurisdiction. The relevant public authority
or body shall inform the market                  or body shall inform the national
surveillance authority of the Member State       supervisory authority of the Member State
concerned of any such request.                   concerned of any such request.


Amendment 594

Proposal for a regulation
Article 64 – paragraph 4

     Text proposed by the Commission                             Amendment

4.     By 3 months after the entering into       4.     By 3 months after the entering into
force of this Regulation, each Member            force of this Regulation, each Member
State shall identify the public authorities or   State shall identify the public authorities or
bodies referred to in paragraph 3 and make       bodies referred to in paragraph 3 and make
a list publicly available on the website of      a list publicly available on the website of
the national supervisory authority. Member       the national supervisory authority.
States shall notify the list to the              National supervisory authorities shall
Commission and all other Member States           notify the list to the Commission, the AI
and keep the list up to date.                    Office, and all other national supervisory
                                                 authorities and keep the list up to date.
                                                The Commission shall publish in a
                                                dedicated website the list of all the
                                                competent authorities designated by the
                                                Member States in accordance with this
                                                Article.


Amendment 595

Proposal for a regulation
Article 64 – paragraph 5

     Text proposed by the Commission                            Amendment

5.    Where the documentation referred to       5.    Where the documentation referred to
in paragraph 3 is insufficient to ascertain     in paragraph 3 is insufficient to ascertain
whether a breach of obligations under           whether a breach of obligations under
Union law intended to protect fundamental       Union law intended to protect fundamental
rights has occurred, the public authority or    rights has occurred, the public authority or
body referred to paragraph 3 may make a         body referred to in paragraph 3 may make
reasoned request to the market                  a reasoned request to the national
surveillance authority to organise testing      supervisory authority, to organise testing
of the high-risk AI system through              of the high-risk AI system through
technical means. The market surveillance        technical means. The national supervisory
authority shall organise the testing with the   authority shall organise the testing with the
close involvement of the requesting public      close involvement of the requesting public
authority or body within reasonable time        authority or body within reasonable time
following the request.                          following the request.


Amendment 596

Proposal for a regulation
Article 65 – paragraph 1

     Text proposed by the Commission                            Amendment

1.     AI systems presenting a risk shall be    1.    AI systems presenting a risk shall be
understood as a product presenting a risk       understood as an AI system having the
defined in Article 3, point 19 of               potential to affect adversely health and
Regulation (EU) 2019/1020 insofar as            safety, fundamental rights of persons in
risks to the health or safety or to the         general, including in the workplace,
protection of fundamental rights of persons     protection of consumers, the environment,
are concerned.                                  public security, or democracy or the rule
                                                of law and other public interests, that are
                                                protected by the applicable Union
                                                harmonisation law, to a degree which
                                                goes beyond that considered reasonable
                                                and acceptable in relation to its intended
                                                purpose or under the normal or
                                               reasonably foreseeable conditions of use
                                               of the system are concerned, including the
                                               duration of use and, where applicable, its
                                               putting into service, installation and
                                               maintenance requirements.


Amendment 597

Proposal for a regulation
Article 65 – paragraph 2 – introductory part

     Text proposed by the Commission                           Amendment

2.    Where the market surveillance            2.     Where the national supervisory
authority of a Member State has sufficient     authority of a Member State has sufficient
reasons to consider that an AI system          reasons to consider that an AI system
presents a risk as referred to in paragraph    presents a risk as referred to in paragraph
1, they shall carry out an evaluation of the   1, it shall carry out an evaluation of the AI
AI system concerned in respect of its          system concerned in respect of its
compliance with all the requirements and       compliance with all the requirements and
obligations laid down in this Regulation.      obligations laid down in this Regulation.
When risks to the protection of                When risks to fundamental rights are
fundamental rights are present, the market     present, the national supervisory authority
surveillance authority shall also inform the   shall also immediately inform and fully
relevant national public authorities or        cooperate with the relevant national public
bodies referred to in Article 64(3). The       authorities or bodies referred to in Article
relevant operators shall cooperate as          64(3); Where there is sufficient reason to
necessary with the market surveillance         consider that that an AI system exploits
authorities and the other national public      the vulnerabilities of vulnerable groups or
authorities or bodies referred to in Article   violates their rights intentionally or
64(3).                                         unintentionally, the national supervisory
                                               authority shall have the duty to investigate
                                               the design goals, data inputs, model
                                               selection, implementation and outcomes
                                               of the AI system . The relevant operators
                                               shall cooperate as necessary with the
                                               national supervisory authority and the
                                               other national public authorities or bodies
                                               referred to in Article 64(3);


Amendment 598

Proposal for a regulation
Article 65 – paragraph 2 – subparagraph 1

     Text proposed by the Commission                           Amendment

Where, in the course of that evaluation, the   Where, in the course of that evaluation, the
market surveillance authority finds that the   national supervisory authority or, where
AI system does not comply with the             relevant, the national public authority
requirements and obligations laid down in      referred to in Article 64(3) finds that the
this Regulation, it shall without delay        AI system does not comply with the
require the relevant operator to take all      requirements and obligations laid down in
appropriate corrective actions to bring the    this Regulation, it shall without delay
AI system into compliance, to withdraw         require the relevant operator to take all
the AI system from the market, or to recall    appropriate corrective actions to bring the
it within a reasonable period,                 AI system into compliance, to withdraw
commensurate with the nature of the risk,      the AI system from the market, or to recall
as it may prescribe.                           it within a reasonable period,
                                               commensurate with the nature of the risk,
                                               as it may prescribe and in any event no
                                               later than fifteen working days or as
                                               provided for in the relevant Union
                                               harmonisation law as applicable


Amendment 599

Proposal for a regulation
Article 65 – paragraph 2 – subparagraph 2

     Text proposed by the Commission                           Amendment

The market surveillance authority shall        The national supervisory authority shall
inform the relevant notified body              inform the relevant notified body
accordingly. Article 18 of Regulation (EU)     accordingly. Article 18 of Regulation (EU)
2019/1020 shall apply to the measures          2019/1020 shall apply to the measures
referred to in the second subparagraph.        referred to in the second subparagraph.


Amendment 600

Proposal for a regulation
Article 65 – paragraph 3

     Text proposed by the Commission                           Amendment

3.     Where the market surveillance           3.     Where the national supervisory
authority considers that non-compliance is     authority considers that non-compliance is
not restricted to its national territory, it   not restricted to its national territory, it
shall inform the Commission and the other      shall inform the Commission, the AI
Member States of the results of the            Office and the national supervisory
evaluation and of the actions which it has     authority of the other Member States
required the operator to take.                 without undue delay of the results of the
                                               evaluation and of the actions which it has
                                               required the operator to take.
Amendment 601

Proposal for a regulation
Article 65 – paragraph 5

     Text proposed by the Commission                            Amendment

5.     Where the operator of an AI system       5.     Where the operator of an AI system
does not take adequate corrective action        does not take adequate corrective action
within the period referred to in paragraph      within the period referred to in paragraph
2, the market surveillance authority shall      2, the national supervisory authority shall
take all appropriate provisional measures to    take all appropriate provisional measures to
prohibit or restrict the AI system's being      prohibit or restrict the AI system's being
made available on its national market, to       made available on its national market or
withdraw the product from that market or        put into service, to withdraw the AI system
to recall it. That authority shall inform the   from that market or to recall it. That
Commission and the other Member States,         authority shall immediately inform the
without delay, of those measures.               Commission, the AI Office and the
                                                national supervisory authority of the other
                                                Member States of those measures.


Amendment 602

Proposal for a regulation
Article 65 – paragraph 6 – introductory part

     Text proposed by the Commission                            Amendment

6.     The information referred to in           6.    The information referred to in
paragraph 5 shall include all available         paragraph 5 shall include all available
details, in particular the data necessary for   details, in particular the data necessary for
the identification of the non-compliant AI      the identification of the non-compliant AI
system, the origin of the AI system, the        system, the origin of the AI system and the
nature of the non-compliance alleged and        supply chain, the nature of the non-
the risk involved, the nature and duration      compliance alleged and the risk involved,
of the national measures taken and the          the nature and duration of the national
arguments put forward by the relevant           measures taken and the arguments put
operator. In particular, the market             forward by the relevant operator. In
surveillance authorities shall indicate         particular, the national supervisory
whether the non-compliance is due to one        authority shall indicate whether the non-
or more of the following:                       compliance is due to one or more of the
                                                following:


Amendment 603

Proposal for a regulation
Article 65 – paragraph 6 – point a
    Text proposed by the Commission                           Amendment

(a) a failure of the AI system to meet         (a) a failure of the high-risk AI system
requirements set out in Title III, Chapter     to meet requirements set out this
2;                                             Regulation;


Amendment 604

Proposal for a regulation
Article 65 – paragraph 6 – point b a (new)

    Text proposed by the Commission                           Amendment

                                               (b a) non-compliance with the prohibition
                                               of the artificial intelligence practices
                                               referred to in Article 5;


Amendment 605

Proposal for a regulation
Article 65 – paragraph 6 – point b b (new)

    Text proposed by the Commission                           Amendment

                                               (b b) non-compliance with provisions set
                                               out in Article 52.


Amendment 606

Proposal for a regulation
Article 65 – paragraph 7

    Text proposed by the Commission                           Amendment

7.     The market surveillance authorities     7.     The national supervisory authorities
of the Member States other than the market     of the Member States other than the
surveillance authority of the Member State     national supervisory authority of the
initiating the procedure shall without delay   Member State initiating the procedure shall
inform the Commission and the other            without delay inform the Commission, the
Member States of any measures adopted          AI Office and the other Member States of
and of any additional information at their     any measures adopted and of any
disposal relating to the non-compliance of     additional information at their disposal
the AI system concerned, and, in the event     relating to the non-compliance of the AI
of disagreement with the notified national     system concerned, and, in the event of
measure, of their objections.                  disagreement with the notified national
                                             measure, of their objections.


Amendment 607

Proposal for a regulation
Article 65 – paragraph 8

    Text proposed by the Commission                          Amendment

8.    Where, within three months of          8.    Where, within three months of
receipt of the information referred to in    receipt of the information referred to in
paragraph 5, no objection has been raised    paragraph 5, no objection has been raised
by either a Member State or the              by either a national supervisory authority
Commission in respect of a provisional       of a Member State or the Commission in
measure taken by a Member State, that        respect of a provisional measure taken by a
measure shall be deemed justified. This is   national supervisory authority of another
without prejudice to the procedural rights   Member State, that measure shall be
of the concerned operator in accordance      deemed justified. This is without prejudice
with Article 18 of Regulation (EU)           to the procedural rights of the concerned
2019/1020.                                   operator in accordance with Article 18 of
                                             Regulation (EU) 2019/1020. The period
                                             referred to in the first sentence of this
                                             paragraph shall be reduced to thirty days
                                             in the event of non-compliance with the
                                             prohibition of the artificial intelligence
                                             practices referred to in Article 5.


Amendment 608

Proposal for a regulation
Article 65 – paragraph 9

    Text proposed by the Commission                          Amendment

9.     The market surveillance authorities   9.     The national supervisory authorities
of all Member States shall ensure that       of all Member States shall ensure that
appropriate restrictive measures are taken   appropriate restrictive measures are taken
in respect of the product concerned, such    in respect of the AI system concerned, such
as withdrawal of the product from their      as withdrawal of the AI system from their
market, without delay.                       market, without delay.


Amendment 609

Proposal for a regulation
Article 65 – paragraph 9 a (new)
     Text proposed by the Commission                            Amendment

                                                9 a. National supervisory authorities
                                                shall annually report to the AI Office
                                                about the use of prohibited practices that
                                                occurred during that year and about the
                                                measures taken to eliminate or mitigate
                                                the risks in accordance with this Article.


Amendment 610

Proposal for a regulation
Article 66 – paragraph 1

     Text proposed by the Commission                            Amendment

1.     Where, within three months of            1.    Where, within three months of
receipt of the notification referred to in      receipt of the notification referred to in
Article 65(5), objections are raised by a       Article 65(5), or 30 days in the case of
Member State against a measure taken by         non-compliance with the prohibition of
another Member State, or where the              the artificial intelligence practices
Commission considers the measure to be          referred to in Article 5, objections are
contrary to Union law, the Commission           raised by the national supervisory
shall without delay enter into consultation     authority of a Member State against a
with the relevant Member State and              measure taken by another national
operator or operators and shall evaluate the    supervisory authority, or where the
national measure. On the basis of the           Commission considers the measure to be
results of that evaluation, the Commission      contrary to Union law, the Commission
shall decide whether the national measure       shall without delay enter into consultation
is justified or not within 9 months from the    with the national supervisory authority of
notification referred to in Article 65(5) and   the relevant Member State and operator or
notify such decision to the Member State        operators and shall evaluate the national
concerned.                                      measure. On the basis of the results of that
                                                evaluation, the Commission shall decide
                                                whether the national measure is justified or
                                                not within three months, or 60 days in the
                                                case of non-compliance with the
                                                prohibition of the artificial intelligence
                                                practices referred to in Article 5, starting
                                                from the notification referred to in Article
                                                65(5) and notify such decision to the
                                                national supervisory authority of the
                                                Member State concerned. The Commission
                                                shall also inform all other national
                                                supervisory authorities of such decision.


Amendment 611
Proposal for a regulation
Article 66 – paragraph 2

     Text proposed by the Commission                           Amendment

2.     If the national measure is considered   2.     If the national measure is considered
justified, all Member States shall take the    justified, all national supervisory
measures necessary to ensure that the non-     authorities designated under this
compliant AI system is withdrawn from          Regulation shall take the measures
their market, and shall inform the             necessary to ensure that the non-compliant
Commission accordingly. If the national        AI system is withdrawn from their market
measure is considered unjustified, the         without delay, and shall inform the
Member State concerned shall withdraw          Commission and the AI Office
the measure.                                   accordingly. If the national measure is
                                               considered unjustified, the national
                                               supervisory authority of the Member State
                                               concerned shall withdraw the measure.


Amendment 612

Proposal for a regulation
Article 66 a (new)

     Text proposed by the Commission                           Amendment

                                                               Article 66 a
                                                           Joint investigations
                                               Where a national supervisory authority
                                               has reasons to suspect that the
                                               infringement by a provider or a deployer
                                               of a high-risk AI system or foundation
                                               model to this Regulation amount to a
                                               widespread infringement with a Union
                                               dimension, or affects or is likely affect at
                                               least 45 million individuals, in more than
                                               one Member State, that national
                                               supervisory authority shall inform the AI
                                               Office and may request the national
                                               supervisory authorities of the Member
                                               States where such infringement took place
                                               to start a joint investigation. The AI
                                               Office shall provide central coordination
                                               to the joint investigation. Investigation
                                               powers shall remain within the
                                               competence of the national supervisory
                                               authorities.
Amendment 613

Proposal for a regulation
Article 67 – paragraph 1

     Text proposed by the Commission                              Amendment

1.     Where, having performed an                 1.     Where, having performed an
evaluation under Article 65, the market           evaluation under Article 65, in full
surveillance authority of a Member State          cooperation with the relevant national
finds that although an AI system is in            public authority referred to in Article
compliance with this Regulation, it               64(3), the national supervisory authority
presents a risk to the health or safety of        of a Member State finds that although an
persons, to the compliance with obligations       AI system is in compliance with this
under Union or national law intended to           Regulation, it presents a serious risk to the
protect fundamental rights or to other            health or safety of persons, to the
aspects of public interest protection, it shall   compliance with obligations under Union
require the relevant operator to take all         or national law intended to protect
appropriate measures to ensure that the AI        fundamental rights, or the environment or
system concerned, when placed on the              the democracy and rule of law or to other
market or put into service, no longer             aspects of public interest protection , it
presents that risk, to withdraw the AI            shall require the relevant operator to take
system from the market or to recall it            all appropriate measures to ensure that the
within a reasonable period,                       AI system concerned, when placed on the
commensurate with the nature of the risk,         market or put into service, no longer
as it may prescribe.                              presents that risk.


Amendment 614

Proposal for a regulation
Article 67 – paragraph 2

     Text proposed by the Commission                              Amendment

2.     The provider or other relevant             2.     The provider or other relevant
operators shall ensure that corrective action     operators shall ensure that corrective action
is taken in respect of all the AI systems         is taken in respect of all the AI systems
concerned that they have made available           concerned that they have made available
on the market throughout the Union within         on the market throughout the Union within
the timeline prescribed by the market             the timeline prescribed by the national
surveillance authority of the Member State        supervisory authority authority of the
referred to in paragraph 1.                       Member State referred to in paragraph 1.


Amendment 615

Proposal for a regulation
Article 67 – paragraph 2 a (new)
     Text proposed by the Commission                           Amendment

                                               2 a. Where the provider or other relevant
                                               operators fail to take corrective action as
                                               referred to in paragraph 2 and the AI
                                               system continues to present a risk as
                                               referred to in paragraph 1, the national
                                               supervisory authority may require the
                                               relevant operator to withdraw the AI
                                               system from the market or to recall it
                                               within a reasonable period,
                                               commensurate with the nature of the risk.


Amendment 616

Proposal for a regulation
Article 67 – paragraph 3

     Text proposed by the Commission                           Amendment

3.    The Member State shall immediately       3.     The national supervisory authority
inform the Commission and the other            shall immediately inform the Commission,
Member States. That information shall          the AI Office and the other national
include all available details, in particular   supervisory authorities. That information
the data necessary for the identification of   shall include all available details, in
the AI system concerned, the origin and the    particular the data necessary for the
supply chain of the AI system, the nature      identification of the AI system concerned,
of the risk involved and the nature and        the origin and the supply chain of the AI
duration of the national measures taken.       system, the nature of the risk involved and
                                               the nature and duration of the national
                                               measures taken.


Amendment 617

Proposal for a regulation
Article 67 – paragraph 4

     Text proposed by the Commission                           Amendment

4.    The Commission shall without delay       4.    The Commission, in consultation
enter into consultation with the Member        with the AI Office shall without delay
States and the relevant operator and shall     enter into consultation with the national
evaluate the national measures taken. On       supervisory authorities concerned and the
the basis of the results of that evaluation,   relevant operator and shall evaluate the
the Commission shall decide whether the        national measures taken. On the basis of
measure is justified or not and, where         the results of that evaluation, the AI Office
necessary, propose appropriate measures.       shall decide whether the measure is
                                               justified or not and, where necessary,
                                               propose appropriate measures.


Amendment 618

Proposal for a regulation
Article 67 – paragraph 5

     Text proposed by the Commission                           Amendment

5.    The Commission shall address its         5.     The Commission, in consultation
decision to the Member States.                 with the AI Office shall immediately
                                               communicate its decision to the national
                                               supervisory authorities of the Member
                                               States concerned and to the relevant
                                               operators. It shall also inform the decision
                                               to all other national supervisory
                                               authorities.


Amendment 619

Proposal for a regulation
Article 67 – paragraph 5 a (new)

     Text proposed by the Commission                           Amendment

                                               5 a. The Commission shall adopt
                                               guidelines to help national competent
                                               authorities to identify and rectify, where
                                               necessary, similar problems arising in
                                               other AI systems.


Amendment 620

Proposal for a regulation
Article 68 – paragraph 1 – introductory part

     Text proposed by the Commission                           Amendment

1.    Where the market surveillance            1.    Where the national supervisory
authority of a Member State makes one of       authority of a Member State makes one of
the following findings, it shall require the   the following findings, it shall require the
relevant provider to put an end to the non-    relevant provider to put an end to the non-
compliance concerned:                          compliance concerned:
Amendment 621

Proposal for a regulation
Article 68 – paragraph 1 – point a

    Text proposed by the Commission                         Amendment

(a) the conformity marking has been          (a) the CE marking has been affixed in
affixed in violation of Article 49;          violation of Article 49;


Amendment 622

Proposal for a regulation
Article 68 – paragraph 1 – point b

    Text proposed by the Commission                         Amendment

(b) the conformity marking has not been      (b)   the CE marking has not been affixed;
affixed;


Amendment 623

Proposal for a regulation
Article 68 – paragraph 1 – point e a (new)

    Text proposed by the Commission                         Amendment

                                             (e a) the technical documentation is not
                                             available;


Amendment 624

Proposal for a regulation
Article 68 – paragraph 1 – point e b (new)

    Text proposed by the Commission                         Amendment

                                             (e b) the registration in the EU database
                                             has not been carried out;


Amendment 625

Proposal for a regulation
Article 68 – paragraph 1 – point e c (new)
    Text proposed by the Commission                          Amendment

                                             (e c) where applicable, the authorised
                                             representative has not been appointed.


Amendment 626

Proposal for a regulation
Article 68 – paragraph 2

    Text proposed by the Commission                          Amendment

2.     Where the non-compliance referred     2.      Where the non-compliance referred
to in paragraph 1 persists, the Member       to in paragraph 1 persists, the national
State concerned shall take all appropriate   supervisory authority of the Member State
measures to restrict or prohibit the high-   concerned shall take appropriate and
risk AI system being made available on the   proportionate measures to restrict or
market or ensure that it is recalled or      prohibit the high-risk AI system being
withdrawn from the market.                   made available on the market or ensure that
                                             it is recalled or withdrawn from the market
                                             without delay. The national supervisory
                                             authority of the Member State concerned
                                             shall immediately inform the AI Office of
                                             the non-compliance and the measures
                                             taken.


Amendment 627

Proposal for a regulation
Article 68 – Chapter 3a (new)

    Text proposed by the Commission                          Amendment

                                             3 a. Remedies


Amendment 628

Proposal for a regulation
Article 68 a (new)

    Text proposed by the Commission                          Amendment

                                                             Article 68 a
                                             Right to lodge a complaint with a national
                                                        supervisory authority
                                      1. Without prejudice to any other
                                      administrative or judicial remedy, every
                                      natural persons or groups of natural
                                      persons shall have the right to lodge a
                                      complaint with a national supervisory
                                      authority, in particular in the Member
                                      State of his or her habitual residence,
                                      place of work or place of the alleged
                                      infringement if they consider that the AI
                                      system relating to him or her infringes
                                      this Regulation.
                                      2. The national supervisory authority with
                                      which the complaint has been lodged
                                      shall inform the complainant on the
                                      progress and the outcome of the
                                      complaint including the possibility of a
                                      judicial remedy pursuant to Article 78.


Amendment 629

Proposal for a regulation
Article 68 b (new)

    Text proposed by the Commission                   Amendment

                                                     Article 68 b
                                         Right to an effective judicial remedy
                                       against a national supervisory authority
                                      1. Without prejudice to any other
                                      administrative or non-judicial remedy,
                                      each natural or legal person shall have
                                      the right to an effective judicial remedy
                                      against a legally binding decision of a
                                      national supervisory authority concerning
                                      them.
                                      2. Without prejudice to any other
                                      administrative or non-judicial remedy,
                                      each natural or legal person shall have
                                      the right to a an effective judicial remedy
                                      where the national supervisory authority
                                      which is competent pursuant to Articles
                                      59 does not handle a complaint or does
                                      not inform the data subject within three
                                      months on the progress or outcome of the
                                      complaint lodged pursuant to Article 68a.
                                      3. Proceedings against a national
                                      supervisory authority shall be brought
                                      before the courts of the Member State
                                      where the national supervisory authority
                                      is established.
                                      4. Where proceedings are brought against
                                      a decision of a national supervisory
                                      authority which was preceded by an
                                      opinion or a decision of the Commission
                                      in the union safeguard procedure, the
                                      supervisory authority shall forward that
                                      opinion or decision to the court.


Amendment 630

Proposal for a regulation
Article 68 c (new)

    Text proposed by the Commission                  Amendment

                                                     Article 68 c
                                         A right to explanation of individual
                                                   decision-making
                                      1. Any affected person subject to a
                                      decision which is taken by the deployer on
                                      the basis of the output from an high-risk
                                      AI system which produces legal effects or
                                      similarly significantly affects him or her
                                      in a way that they consider to adversely
                                      impact their health, safety, fundamental
                                      rights, socio-economic well-being or any
                                      other of the rights deriving from the
                                      obligations laid down in this Regulation,
                                      shall have the right to request from the
                                      deployer clear and meaningful
                                      explanation pursuant to Article 13(1) on
                                      the role of the AI system in the decision-
                                      making procedure, the main parameters
                                      of the decision taken and the related input
                                      data.
                                      2. Paragraph 1 shall not apply to the use
                                      of AI systems for which exceptions from,
                                      or restrictions to, the obligation under
                                      paragraph 1 follow from Union or
                                      national law are provided in so far as
                                      such exception or restrictions respect the
                                      essence of the fundamental rights and
                                      freedoms and is a necessary and
                                      proportionate measure in a democratic
                                      society.
                                      3. This Article shall apply without
                                      prejudice to Articles 13, 14, 15, and 22 of
                                      the Regulation 2016/679.


Amendment 631

Proposal for a regulation
Article 68 d (new)

    Text proposed by the Commission                   Amendment

                                                      Article 68 d
                                      Amendment to Directive (EU) 2020/1828
                                      In Annex I to Directive (EU) 2020/1828 of
                                      the European Parliament and of the
                                      Council 1a, the following point is added:
                                       “(67a) Regulation xxxx/xxxx of the
                                      European Parliament and of the Council
                                      [laying down harmonised rules on
                                      artificial intelligence (Artificial
                                      Intelligence Act) and amending certain
                                      Union legislative acts (OJ L ...)]”.
                                      _________________
                                      1a Directive (EU) 2020/1828 of the

                                      European Parliament and of the Council
                                      of 25 November 2020 on representative
                                      actions for the protection of the collective
                                      interests of consumers and repealing
                                      Directive 2009/22/EC (OJ L 409,
                                      4.12.2020, p. 1).


Amendment 632

Proposal for a regulation
Article 68 e (new)

    Text proposed by the Commission                   Amendment

                                                      Article 68 e
                                       Reporting of breaches and protection of
                                                 reporting persons
                                      Directive (EU) 2019/1937 of the
                                      European Parliament and of the Council
                                              shall apply to the reporting of breaches of
                                              this Regulation and the protection of
                                              persons reporting such breaches.


Amendment 633

Proposal for a regulation
Article 69 – paragraph 1

    Text proposed by the Commission                           Amendment

1.    The Commission and the Member           1.     The Commission, the AI Office and
States shall encourage and facilitate the     the Member States shall encourage and
drawing up of codes of conduct intended to    facilitate the drawing up of codes of
foster the voluntary application to AI        conduct intended, including where they
systems other than high-risk AI systems of    are drawn up in order to demonstrate how
the requirements set out in Title III,        AI systems respect the principles set out in
Chapter 2 on the basis of technical           Article 4a and can thereby be considered
specifications and solutions that are         trustworthy, to foster the voluntary
appropriate means of ensuring compliance      application to AI systems other than high-
with such requirements in light of the        risk AI systems of the requirements set out
intended purpose of the systems.              in Title III, Chapter 2 on the basis of
                                              technical specifications and solutions that
                                              are appropriate means of ensuring
                                              compliance with such requirements in light
                                              of the intended purpose of the systems.


Amendment 634

Proposal for a regulation
Article 69 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    The Commission and the Board            2.    Codes of conduct intended to foster
shall encourage and facilitate the drawing    the voluntary compliance with the
up of codes of conduct intended to foster     principles underpinning trustworthy AI
the voluntary application to AI systems of    systems, shall, in particular:
requirements related for example to
environmental sustainability, accessibility
for persons with a disability, stakeholders
participation in the design and
development of the AI systems and
diversity of development teams on the
basis of clear objectives and key
performance indicators to measure the
achievement of those objectives.
                                        (a) aim for a sufficient level of AI
                                        literacy among their staff and other
                                        persons dealing with the operation and
                                        use of AI systems in order to observe such
                                        principles;
                                        (b) assess to what extent their AI
                                        systems may affect vulnerable persons or
                                        groups of persons, including children, the
                                        elderly, migrants and persons with
                                        disabilities or whether measures could be
                                        put in place in order to increase
                                        accessibility, or otherwise support such
                                        persons or groups of persons;
                                        (c) consider the way in which the use of
                                        their AI systems may have an impact or
                                        can increase diversity, gender balance
                                        and equality;
                                        (d) have regard to whether their AI
                                        systems can be used in a way that, directly
                                        or indirectly, may residually or
                                        significantly reinforce existing biases or
                                        inequalities;
                                        (e) reflect on the need and relevance of
                                        having in place diverse development
                                        teams in view of securing an inclusive
                                        design of their systems;
                                        (f) give careful consideration to
                                        whether their systems can have a negative
                                        societal impact, notably concerning
                                        political institutions and democratic
                                        processes;
                                        (g) evaluate how AI systems can
                                        contribute to environmental sustainability
                                        and in particular to the Union’s
                                        commitments under the European Green
                                        Deal and the European Declaration on
                                        Digital Rights and Principles.


Amendment 635

Proposal for a regulation
Article 69 – paragraph 3

     Text proposed by the Commission                   Amendment

3.   Codes of conduct may be drawn up   3.   Codes of conduct may be drawn up
by individual providers of AI systems or by     by individual providers of AI systems or by
organisations representing them or by both,     organisations representing them or by both,
including with the involvement of users         including with the involvement of users
and any interested stakeholders and their       and any interested stakeholders, including
representative organisations. Codes of          scientific researchers, and their
conduct may cover one or more AI systems        representative organisations, in particular
taking into account the similarity of the       trade unions, and consumer organisations.
intended purpose of the relevant systems.       Codes of conduct may cover one or more
                                                AI systems taking into account the
                                                similarity of the intended purpose of the
                                                relevant systems. Providers adopting codes
                                                of conduct will designate at least one
                                                natural person responsible for internal
                                                monitoring.


Amendment 636

Proposal for a regulation
Article 69 – paragraph 4

     Text proposed by the Commission                            Amendment

4.     The Commission and the Board shall       4.     The Commission and the AI Office
take into account the specific interests and    shall take into account the specific interests
needs of the small-scale providers and          and needs of SMEs and start-ups when
start-ups when encouraging and facilitating     encouraging and facilitating the drawing up
the drawing up of codes of conduct.             of codes of conduct.


Amendment 637

Proposal for a regulation
Article 70 – paragraph 1 – introductory part

     Text proposed by the Commission                            Amendment

1.     National competent authorities and       1.    The Commission, national competent
notified bodies involved in the application     authorities and notified bodies, the AI
of this Regulation shall respect the            Office and any other natural or legal
confidentiality of information and data         person involved in the application of this
obtained in carrying out their tasks and        Regulation shall respect the confidentiality
activities in such a manner as to protect, in   of information and data obtained in
particular:                                     carrying out their tasks and activities in
                                                such a manner as to protect, in particular;


Amendment 638
Proposal for a regulation
Article 70 – paragraph 1 – point a

     Text proposed by the Commission                           Amendment

(a) intellectual property rights, and          (a) intellectual property rights, and
confidential business information or trade     confidential business information or trade
secrets of a natural or legal person,          secrets of a natural or legal person, in
including source code, except the cases        accordance with the provisions of
referred to in Article 5 of Directive          Directives 2004/48/EC and 2016/943/EC,
2016/943 on the protection of undisclosed      including source code, except the cases
know-how and business information (trade       referred to in Article 5 of Directive
secrets) against their unlawful acquisition,   2016/943 on the protection of undisclosed
use and disclosure apply.                      know-how and business information (trade
                                               secrets) against their unlawful acquisition,
                                               use and disclosure apply;


Amendment 639

Proposal for a regulation
Article 70 – paragraph 1 – point b a (new)


     Text proposed by the Commission                           Amendment

                                               (b a) public and national security
                                               interests


Amendment 640

Proposal for a regulation
Article 70 – paragraph 1 a (new)

     Text proposed by the Commission                           Amendment

                                               1 a. The authorities involved in the
                                               application of this Regulation pursuant to
                                               paragraph 1 shall minimise the quantity
                                               of data requested for disclosure to the
                                               data that is strictly necessary for the
                                               perceived risk and the assessment of that
                                               risk. They shall delete the data as soon as
                                               it is no longer needed for the purpose it
                                               was requested for. They shall put in place
                                               adequate and effective cybersecurity,
                                               technical and organisational measures to
                                               protect the security and confidentiality of
                                               the information and data obtained in
                                               carrying out their tasks and activities;


Amendment 641

Proposal for a regulation
Article 70 – paragraph 2 – introductory part

     Text proposed by the Commission                           Amendment

2.    Without prejudice to paragraph 1,        2.    Without prejudice to paragraphs 1
information exchanged on a confidential        and 1a, information exchanged on a
basis between the national competent           confidential basis between the national
authorities and between national competent     competent authorities and between national
authorities and the Commission shall not       competent authorities and the Commission
be disclosed without the prior consultation    shall not be disclosed without the prior
of the originating national competent          consultation of the originating national
authority and the user when high-risk AI       competent authority and the deployer when
systems referred to in points 1, 6 and 7 of    high-risk AI systems referred to in points
Annex III are used by law enforcement,         1, 6 and 7 of Annex III are used by law
immigration or asylum authorities, when        enforcement, immigration or asylum
such disclosure would jeopardise public        authorities, when such disclosure would
and national security interests.               jeopardise public or national security.


Amendment 642

Proposal for a regulation
Article 70 – paragraph 3

     Text proposed by the Commission                           Amendment

3.     Paragraphs 1 and 2 shall not affect     3.    Paragraphs 1, 1a and 2 shall not
the rights and obligations of the              affect the rights and obligations of the
Commission, Member States and notified         Commission, Member States and notified
bodies with regard to the exchange of          bodies with regard to the exchange of
information and the dissemination of           information and the dissemination of
warnings, nor the obligations of the parties   warnings, nor the obligations of the parties
concerned to provide information under         concerned to provide information under
criminal law of the Member States.             criminal law of the Member States;


Amendment 643

Proposal for a regulation
Article 70 – paragraph 4

     Text proposed by the Commission                           Amendment

4.    The Commission and Member States         4.    The Commission and Member States
may exchange, where necessary,                  may exchange, where strictly necessary
confidential information with regulatory        and in accordance with relevant
authorities of third countries with which       provisions of international and trade
they have concluded bilateral or                agreements, confidential information with
multilateral confidentiality arrangements       regulatory authorities of third countries
guaranteeing an adequate level of               with which they have concluded bilateral
confidentiality.                                or multilateral confidentiality arrangements
                                                guaranteeing an adequate level of
                                                confidentiality.


Amendment 644

Proposal for a regulation
Article 71 – title

     Text proposed by the Commission                            Amendment

Penalties and fines                                              Penalties


Amendment 645

Proposal for a regulation
Article 71 – paragraph 1

     Text proposed by the Commission                            Amendment

1.     In compliance with the terms and         1.    In compliance with the terms and
conditions laid down in this Regulation,        conditions laid down in this Regulation,
Member States shall lay down the rules on       Member States shall lay down the rules on
penalties, including administrative fines,      penalties, applicable to infringements of
applicable to infringements of this             this Regulation by any operator, and shall
Regulation and shall take all measures          take all measures necessary to ensure that
necessary to ensure that they are properly      they are properly and effectively
and effectively implemented. The penalties      implemented and aligned with the
provided for shall be effective,                guidelines issued by the Commission and
proportionate, and dissuasive. They shall       the AI Office pursuant to Article 82b. The
take into particular account the interests of   penalties provided for shall be effective,
small-scale providers and start-up and          proportionate, and dissuasive. They shall
their economic viability.                       take into account the interests of SMEs
                                                and start-ups and their economic viability;


Amendment 646

Proposal for a regulation
Article 71 – paragraph 2
     Text proposed by the Commission                           Amendment

2.    The Member States shall notify the       2.    The Member States shall notify the
Commission of those rules and of those         Commission and the Office by [ 12
measures and shall notify it, without delay,   months after the date of entry into force
of any subsequent amendment affecting          of this Regulation] of those rules and of
them.                                          those measures and shall notify them,
                                               without delay, of any subsequent
                                               amendment affecting them.


Amendment 647

Proposal for a regulation
Article 71 – paragraph 3 – introductory part

     Text proposed by the Commission                           Amendment

3.    The following infringements shall be     3.    Non compliance with the
subject to administrative fines of up to 30    prohibition of the artificial intelligence
000 000 EUR or, if the offender is             practices referred to in Article 5 shall be
company, up to 6 % of its total worldwide      subject to administrative fines of up to 40
annual turnover for the preceding financial    000 000 EUR or, if the offender is a
year, whichever is higher:                     company, up to 7 % of its total worldwide
                                               annual turnover for the preceding financial
                                               year, whichever is higher:


Amendment 648

Proposal for a regulation
Article 71 – paragraph 3 – point a

     Text proposed by the Commission                           Amendment

(a) non-compliance with the prohibition        deleted
of the artificial intelligence practices
referred to in Article 5;


Amendment 649

Proposal for a regulation
Article 71 – paragraph 3 – point b

     Text proposed by the Commission                           Amendment

(b) non-compliance of the AI system            deleted
with the requirements laid down in Article
10.


Amendment 650

Proposal for a regulation
Article 71 – paragraph 3 a (new)

      Text proposed by the Commission                         Amendment

                                              3 a. Non-compliance of the AI system
                                              with the requirements laid down in Article
                                              10 and 13 shall be subject to
                                              administrative fines of up to EUR 20 000
                                              000 or, if the offender is a company, up to
                                              4% of its total worldwide annual turnover
                                              for the preceding financial year,
                                              whichever is the higher.


Amendment 651

Proposal for a regulation
Article 71 – paragraph 4

      Text proposed by the Commission                         Amendment

4.    The non-compliance of the AI            4.     Non-compliance of the AI system or
system with any requirements or               foundation model with any requirements
obligations under this Regulation, other      or obligations under this Regulation, other
than those laid down in Articles 5 and 10,    than those laid down in Articles 5, 10 and
shall be subject to administrative fines of   13, shall be subject to administrative fines
up to 20 000 000 EUR or, if the offender is   of up to EUR 10 000 000 or, if the offender
a company, up to 4 % of its total             is a company, up to 2% of its total
worldwide annual turnover for the             worldwide annual turnover for the
preceding financial year, whichever is        preceding financial year, whichever is
higher.                                       higher;


Amendment 652

Proposal for a regulation
Article 71 – paragraph 5

      Text proposed by the Commission                         Amendment

5.    The supply of incorrect, incomplete     5.    The supply of incorrect, incomplete
or misleading information to notified         or misleading information to notified
bodies and national competent authorities     bodies and national competent authorities
in reply to a request shall be subject to     in reply to a request shall be subject to
administrative fines of up to 10 000 000       administrative fines of up to 5 000 000
EUR or, if the offender is a company, up to    EUR or, if the offender is a company, up to
2 % of its total worldwide annual turnover     1 % of its total worldwide annual turnover
for the preceding financial year, whichever    for the preceding financial year, whichever
is higher.                                     is higher.


Amendment 653

Proposal for a regulation
Article 71 – paragraph 6 – introductory part

     Text proposed by the Commission                           Amendment

6.     When deciding on the amount of the      6.     Fines may be imposed in addition to
administrative fine in each individual case,   or instead of non-monetary measures
all relevant circumstances of the specific     such as orders or warnings. When
situation shall be taken into account and      deciding on the amount of the
due regard shall be given to the following:    administrative fine in each individual case,
                                               all relevant circumstances of the specific
                                               situation shall be taken into account and
                                               due regard shall be given to the following;


Amendment 654

Proposal for a regulation
Article 71 – paragraph 6 – point a

     Text proposed by the Commission                           Amendment

(a) the nature, gravity and duration of        (a) the nature, gravity and duration of
the infringement and of its consequences;      the infringement and of its consequences,
                                               taking into account the purpose of the AI
                                               system, as well as, where appropriate, the
                                               number of affected persons and the level
                                               of damage suffered by them;


Amendment 655

Proposal for a regulation
Article 71 – paragraph 6 – point b

     Text proposed by the Commission                           Amendment

(b) whether administrative fines have          (b) whether administrative fines have
been already applied by other market           been already applied by other national
surveillance authorities to the same           supervisory authorities of one or more
                                               Member States to the same operator for the
operator for the same infringement.          same infringement;


Amendment 656

Proposal for a regulation
Article 71 – paragraph 6 – point c

    Text proposed by the Commission                         Amendment

(c) the size and market share of the         (c) the size and annual turnover of the
operator committing the infringement;        operator committing the infringement;


Amendment 657

Proposal for a regulation
Article 71 – paragraph 6 – point c a (new)

    Text proposed by the Commission                         Amendment

                                             (c a) any action taken by the operator to
                                             mitigate the harm of damage suffered by
                                             the affected persons;


Amendment 658

Proposal for a regulation
Article 71 – paragraph 6 – point c b (new)

    Text proposed by the Commission                         Amendment

                                             (c b) the intentional or negligent
                                             character of the infringement;


Amendment 659

Proposal for a regulation
Article 71 – paragraph 6 – point c c (new)

    Text proposed by the Commission                         Amendment

                                             (c c) the degree of cooperation with the
                                             national competent authorities, in order to
                                             remedy the infringement and mitigate the
                                             possible adverse effects of the
                                             infringement;
Amendment 660

Proposal for a regulation
Article 71 – paragraph 6 – point c d (new)

    Text proposed by the Commission                         Amendment

                                             (c d) the degree of responsibility of the
                                             operator taking into account the technical
                                             and organisational measures implemented
                                             by them;


Amendment 661

Proposal for a regulation
Article 71 – paragraph 6 – point c e (new)

    Text proposed by the Commission                         Amendment

                                             (c e) the manner in which the
                                             infringement became known to the
                                             national competent authorities, in
                                             particular whether, and if so to what
                                             extent, the operator notified the
                                             infringement;


Amendment 662

Proposal for a regulation
Article 71 – paragraph 6 – point c f (new)

    Text proposed by the Commission                         Amendment

                                             (c f) adherence to approved codes of
                                             conduct or approved certification
                                             mechanisms;


Amendment 663

Proposal for a regulation
Article 71 – paragraph 6 – point c g (new)

    Text proposed by the Commission                         Amendment

                                             (c g) any relevant previous infringements
                                               by the operator;


Amendment 664

Proposal for a regulation
Article 71 – paragraph 6 – point c h (new)

     Text proposed by the Commission                           Amendment

                                               (c h) any other aggravating or mitigating
                                               factor applicable to the circumstances of
                                               the case.


Amendment 665

Proposal for a regulation
Article 71 – paragraph 7

     Text proposed by the Commission                           Amendment

7.    Each Member State shall lay down         7.    each Member State shall lay down
rules on whether and to what extent            rules on administrative fines to be imposed
administrative fines may be imposed on         on public authorities and bodies established
public authorities and bodies established in   in that Member State;
that Member State.


Amendment 666

Proposal for a regulation
Article 71 – paragraph 8 a (new)

     Text proposed by the Commission                           Amendment

                                               8 a. The penalties referred to in this
                                               article as well as the associated litigation
                                               costs and indemnification claims may not
                                               be the subject of contractual clauses or
                                               other form of burden-sharing agreements
                                               between providers and distributors,
                                               importers, deployers, or any other third
                                               parties;


Amendment 667
Proposal for a regulation
Article 71 – paragraph 8 b (new)

    Text proposed by the Commission                         Amendment

                                             8 b. National supervisory authorities
                                             shall, on an annual basis, report to the AI
                                             Office about the fines they have issued
                                             during that year, in accordance with this
                                             Article;


Amendment 668

Proposal for a regulation
Article 71 – paragraph 8 c (new)

    Text proposed by the Commission                         Amendment

                                             8 c. The exercise by competent
                                             authorities of their powers under this
                                             Article shall be subject to appropriate
                                             procedural safeguards in accordance with
                                             Union and national law, including
                                             judicial remedy and due process;


Amendment 669

Proposal for a regulation
Article 72 – paragraph 1 – point a

    Text proposed by the Commission                         Amendment

(a) the nature, gravity and duration of      (a) the nature, gravity and duration of
the infringement and of its consequences;    the infringement and of its consequences;,
                                             taking into account the purpose of the AI
                                             system concerned as well as the number
                                             of affected persons and the level of
                                             damage suffered by them, and any
                                             relevant previous infringement;


Amendment 670

Proposal for a regulation
Article 72 – paragraph 1 – point a a (new)
    Text proposed by the Commission                          Amendment

                                             (a a) any action taken by the Union
                                             institution, agency or body to mitigate the
                                             damage suffered by affected persons;


Amendment 671

Proposal for a regulation
Article 72 – paragraph 1 – point a b (new)

    Text proposed by the Commission                          Amendment

                                             (a b) the degree of responsibility of the
                                             Union institution, agency or body, taking
                                             into account technical and organisational
                                             measures implemented by them;


Amendment 672

Proposal for a regulation
Article 72 – paragraph 1 – point b

    Text proposed by the Commission                          Amendment

(b) the cooperation with the European        (b) the degree of cooperation with the
Data Protection Supervisor in order to       European Data Protection Supervisor in
remedy the infringement and mitigate the     order to remedy the infringement and
possible adverse effects of the              mitigate the possible adverse effects of the
infringement, including compliance with      infringement, including compliance with
any of the measures previously ordered by    any of the measures previously ordered by
the European Data Protection Supervisor      the European Data Protection Supervisor
against the Union institution or agency or   against the Union institution or agency or
body concerned with regard to the same       body concerned with regard to the same
subject matter;                              subject matter;


Amendment 673

Proposal for a regulation
Article 72 – paragraph 1 – point c a (new)


    Text proposed by the Commission                          Amendment

                                             (c a) the manner in which the
                                             infringement became known to the
                                               European Data Protection Supervisor, in
                                               particular whether, and if so to what
                                               extent, the Union institution or body
                                               notified the infringement;


Amendment 674

Proposal for a regulation
Article 72 – paragraph 1 – point c b (new)


    Text proposed by the Commission                            Amendment

                                               (c b) the annual budget of the body;


Amendment 675

Proposal for a regulation
Article 72 – paragraph 2 – introductory part

    Text proposed by the Commission                            Amendment

2.    The following infringements shall be     2.    Non compliance with the
subject to administrative fines of up to 500   prohibition of the artificial intelligence
000 EUR:                                       practices referred to in Article 5 shall be
                                               subject to administrative fines of up to
                                               EUR 1 500 000.


Amendment 676

Proposal for a regulation
Article 72 – paragraph 2 – point a

    Text proposed by the Commission                            Amendment

(a) non-compliance with the prohibition        deleted
of the artificial intelligence practices
referred to in Article 5;


Amendment 677

Proposal for a regulation
Article 72 – paragraph 2 a (new)
     Text proposed by the Commission                            Amendment

                                               2 a. non-compliance of the AI system
                                               with the requirements laid down in Article
                                               10 shall be subject to administrative fines
                                               of up to 1 000 000 EUR.


Amendment 678

Proposal for a regulation
Article 72 – paragraph 3

     Text proposed by the Commission                            Amendment

3.    The non-compliance of the AI             3.    the non-compliance of the AI system
system with any requirements or                with any requirements or obligations under
obligations under this Regulation, other       this Regulation, other than those laid down
than those laid down in Articles 5 and 10,     in Articles 5 and 10, shall be subject to
shall be subject to administrative fines of    administrative fines of up to EUR 750 000.
up to 250 000 EUR.


Amendment 679

Proposal for a regulation
Article 72 – paragraph 6

     Text proposed by the Commission                            Amendment

6.     Funds collected by imposition of        6.     Funds collected by imposition of
fines in this Article shall be the income of   fines in this Article shall contribute to the
the general budget of the Union.               general budget of the Union. The fines
                                               shall not affect the effective operation of
                                               the Union institution, body or agency
                                               fined.


Amendment 680

Proposal for a regulation
Article 72 – paragraph 6 a (new)

     Text proposed by the Commission                            Amendment

                                               6 a. the European Data Protection
                                               Supervisor shall, on an annual basis,
                                               notify the AI Office of the fines it has
                                             imposed pursuant to this Article.


Amendment 681

Proposal for a regulation
Article 73 – paragraph 2

    Text proposed by the Commission                           Amendment

2.    The delegation of power referred to    2.    The power to adopt delegated acts
in Article 4, Article 7(1), Article 11(3),   referred to in Article 4, Article 7(1), Article
Article 43(5) and (6) and Article 48(5)      11(3), Article 43(5) and (6) and Article
shall be conferred on the Commission for     48(5) shall be conferred on the
an indeterminate period of time from         Commission for a period of five years from
[entering into force of the Regulation].     … [the date of entry into force of the
                                             Regulation].The Commission shall draw
                                             up a report in respect of the delegation of
                                             power not later than 9 months before the
                                             end of the five-year period. The delegation
                                             of power shall be tacitly extended for
                                             periods of an identical duration, unless
                                             the European Parliament or the Council
                                             opposes such extension not later than
                                             three months before the end of each
                                             period.


Amendment 682

Proposal for a regulation
Article 73 – paragraph 3 a (new)

    Text proposed by the Commission                           Amendment

                                             3 a. Before adopting a delegated act, the
                                             Commission shall consult with the
                                             relevant institutions, the Office, the
                                             Advisory Forum and other relevant
                                             stakeholders in accordance with the
                                             principles laid down in the
                                             Interinstitutional Agreement of 13 April
                                             2016 on Better Law-Making.
                                             Once the Commission decides to draft a
                                             delegated act, it shall notify the European
                                             Parliament of this fact. This notification
                                             does not place an obligation on the
                                             Commission to adopt the said act.
Amendment 683

Proposal for a regulation
Article 81 a (new)

    Text proposed by the Commission                  Amendment

                                                     Article 81 a
                                           Amendment to Regulation (EU)
                                                  2019/1020
                                      Regulation (EU) 2019/1020 is amended as
                                      follows:
                                      in Article 14(4), the following paragraph
                                      is added:
                                      “(l). the power to implement the powers
                                      provided for in this Article remotely,
                                      where applicable;”


Amendment 684

Proposal for a regulation
Article 82 a (new)

    Text proposed by the Commission                  Amendment

                                                     Article 82 a
                                                  Better Regulation
                                      in taking into account the requirements of
                                      this Regulation pursuant to the
                                      Amendments in Articles 75, 76, 77, 78, 79,
                                      80, 81, and 82, the Commission shall
                                      conduct an analysis and consult relevant
                                      stakeholders to determine potential gaps
                                      as well as overlaps between existing
                                      sectoral legislation and the provisions of
                                      this Regulation.


Amendment 685

Proposal for a regulation
Article 82 b (new)

    Text proposed by the Commission                  Amendment

                                                     Article 82 b
 Guidelines from the Commission on the
   implementation of this Regulation
1. The Commission shall develop, in
consultation with the AI office, guidelines
on the practical implementation of this
Regulation, and in particular on:
(a) the application of the requirements
referred to in Articles 8 - 15 and Article
28 to 28b;
(b) the prohibited practices referred to in
Article 5;
(c) the practical implementation of the
provisions related to substantial
modification;
(d) the practical circumstances where the
output of an AI system referred to in
Annex III would pose a significant risk of
harm to the health, safety or fundamental
rights of natural persons as referred to in
Article 6, paragraph 2, including
examples in relation to high risk AI
systems referred to in Annex III;
(e) the practical implementation of
transparency obligations laid down in
Article 52;
(f) the development of codes of conduct
referred to in Article 69;
(g) the relationship of this Regulation
with other relevant Union law, including
as regards consistency in their
enforcement.
(h) the practical implementation of Article
12, Article 28b on environmental impact
of foundation models and Annex IV 3(b),
particularly the measurement and logging
methods to enable calculations and
reporting of the environmental impact of
systems to comply with the obligations in
this Regulation, including carbon
footprint and energy efficiency, taking
into account state-of-the-art methods and
economies of scale.
When issuing such guidelines, the
Commission shall pay particular attention
to the needs of SMEs including start-ups,
local public authorities and sectors most
                                               likely to be affected by this Regulation.
                                               2. Upon request of the Member States or
                                               the AI Office, or on its own initiative, the
                                               Commission shall update already adopted
                                               guidelines when deemed necessary.


Amendment 686

Proposal for a regulation
Article 83 – paragraph 1 – introductory part

    Text proposed by the Commission                            Amendment

1.     This Regulation shall not apply to      1.    Operators of the AI systems which
the AI systems which are components of         are components of the large-scale IT
the large-scale IT systems established by      systems established by the legal acts listed
the legal acts listed in Annex IX that have    in Annex IX that have been placed on the
been placed on the market or put into          market or put into service prior to ... [the
service before [12 months after the date of    date of entry into force of this Regulation]
application of this Regulation referred to     shall take the necessary steps to comply
in Article 85(2)], unless the replacement      with the requirements laid down in this
or amendment of those legal acts leads to      Regulation by … [four years after the date
a significant change in the design or          of entry into force of this Regulation].
intended purpose of the AI system or AI
systems concerned.


Amendment 687

Proposal for a regulation
Article 83 – paragraph 1 – subparagraph 1

    Text proposed by the Commission                            Amendment

The requirements laid down in this             The requirements laid down in this
Regulation shall be taken into account,        Regulation shall be taken into account in
where applicable, in the evaluation of each    the evaluation of each large-scale IT
large-scale IT systems established by the      systems established by the legal acts listed
legal acts listed in Annex IX to be            in Annex IX to be undertaken as provided
undertaken as provided for in those            for in those respective acts and whenever
respective acts.                               those legal acts are replaced or amended.


Amendment 688

Proposal for a regulation
Article 83 – paragraph 2
     Text proposed by the Commission                          Amendment

2.    This Regulation shall apply to the      2.    This Regulation shall apply to
high-risk AI systems, other than the ones     operators of high-risk AI systems, other
referred to in paragraph 1, that have been    than the ones referred to in paragraph 1,
placed on the market or put into service      that have been placed on the market or put
before [date of application of this           into service before [date of application of
Regulation referred to in Article 85(2)],     this Regulation referred to in Article
only if, from that date, those systems are    85(2)], only if, from that date, those
subject to significant changes in their       systems are subject to substantial
design or intended purpose.                   modifications as defined in Article 3(23).
                                              In the case of high-risk AI systems
                                              intended to be used by public authorities,
                                              providers and deployers of such systems
                                              shall take the necessary steps to comply
                                              with the requirements of the present
                                              Regulation [two years after the date of
                                              entry into force of this Regulation].


Amendment 689

Proposal for a regulation
Article 84 – paragraph 1

     Text proposed by the Commission                          Amendment

1.     The Commission shall assess the        1.     After consulting the AI Office, the
need for amendment of the list in Annex III   Commission shall assess the need for
once a year following the entry into force    amendment of the list in Annex III,
of this Regulation.                           including the extension of existing area
                                              headings or addition of new area
                                              headings in that Annex the list of
                                              prohibited AI practices in Article 5, and
                                              the list of AI systems requiring additional
                                              transparency measures in Article 52 once
                                              a year following the entry into force of this
                                              Regulation and following a
                                              recommendation of the Office.
                                              the Commission shall submit the findings
                                              of that assessment to the European
                                              Parliament and the Council.


Amendment 690

Proposal for a regulation
Article 84 – paragraph 2
     Text proposed by the Commission                            Amendment

2.    By [three years after the date of         2.    By … [two years after the date of
application of this Regulation referred to in   application of this Regulation referred to in
Article 85(2)] and every four years             Article 85(2)] and every two years
thereafter, the Commission shall submit a       thereafter, the Commission, together with
report on the evaluation and review of this     the AI office, shall submit a report on the
Regulation to the European Parliament and       evaluation and review of this Regulation to
to the Council. The reports shall be made       the European Parliament and to the
public.                                         Council. The reports shall be made public.


Amendment 691

Proposal for a regulation
Article 84 – paragraph 3 – point a

     Text proposed by the Commission                            Amendment

(a) the status of the financial and human       (a) the status of the financial, technical
resources of the national competent             and human resources of the national
authorities in order to effectively perform     competent authorities in order to
the tasks assigned to them under this           effectively perform the tasks assigned to
Regulation;                                     them under this Regulation;


Amendment 692

Proposal for a regulation
Article 84 – paragraph 3 – point b a (new)

     Text proposed by the Commission                            Amendment

                                                (b a) the level of the development of
                                                harmonised standards and common
                                                specifications for Artificial Intelligence;


Amendment 693

Proposal for a regulation
Article 84 – paragraph 3 – point b b (new)

     Text proposed by the Commission                            Amendment

                                                (b b) the levels of investments in research,
                                                development and application of AI
                                                systems throughout the Union;
Amendment 694

Proposal for a regulation
Article 84 – paragraph 3 – point b c (new)

    Text proposed by the Commission                         Amendment

                                             (b c) the competitiveness of the
                                             aggregated European AI sector compared
                                             to AI sectors in third countries;


Amendment 695

Proposal for a regulation
Article 84 – paragraph 3 – point b d (new)

    Text proposed by the Commission                         Amendment

                                             (b d) the impact of the Regulation with
                                             regards to the resource and energy use, as
                                             well as waste production and other
                                             environmental impact;


Amendment 696

Proposal for a regulation
Article 84 – paragraph 3 – point b e (new)

    Text proposed by the Commission                         Amendment

                                             (b e) the implementation of the
                                             coordinated plan on AI, taking into
                                             account the different level of progress
                                             among Member States and identifying
                                             existing barriers to innovation in AI;


Amendment 697

Proposal for a regulation
Article 84 – paragraph 3 – point b f (new)

    Text proposed by the Commission                         Amendment

                                             (b f) the update of the specific
                                             requirements regarding the sustainability
                                             of AI systems and foundation models,
                                             building on the reporting and
                                             documentation requirement in Annex IV
                                             and in Article 28b;


Amendment 698

Proposal for a regulation
Article 84 – paragraph 3 – point b g (new)

    Text proposed by the Commission                          Amendment

                                             (b g) the legal regime governing
                                             foundation models;


Amendment 699

Proposal for a regulation
Article 84 – paragraph 3 – point b h (new)

    Text proposed by the Commission                          Amendment

                                             (b h) the list of unfair contractual terms
                                             within Article 28a taking into account
                                             new business practices if necessary;


Amendment 700

Proposal for a regulation
Article 84 – paragraph 3 a (new)

    Text proposed by the Commission                          Amendment

                                             3 a. By ... [two years after the date of
                                             entry into application of this Regulation
                                             referred to in Article 85(2)] the
                                             Commission shall evaluate the
                                             functioning of the AI office, whether the
                                             office has been given sufficient powers
                                             and competences to fulfil its tasks and
                                             whether it would be relevant and needed
                                             for the proper implementation and
                                             enforcement of this Regulation to upgrade
                                             the Office and its enforcement
                                             competences and to increase its resources.
                                             The Commission shall submit this
                                             evaluation report to the European
                                                Parliament and to the Council.


Amendment 701

Proposal for a regulation
Article 84 – paragraph 4

     Text proposed by the Commission                            Amendment

4.    Within [three years after the date of     4.    Within … [one year after the date of
application of this Regulation referred to in   application of this Regulation referred to in
Article 85(2)] and every four years             Article 85(2)] and every two years
thereafter, the Commission shall evaluate       thereafter, the Commission shall evaluate
the impact and effectiveness of codes of        the impact and effectiveness of codes of
conduct to foster the application of the        conduct to foster the application of the
requirements set out in Title III, Chapter 2    requirements set out in Title III, Chapter 2
and possibly other additional requirements      and possibly other additional requirements
for AI systems other than high-risk AI          for AI systems other than high-risk AI
systems.                                        systems;


Amendment 702

Proposal for a regulation
Article 84 – paragraph 5

     Text proposed by the Commission                            Amendment

5.   For the purpose of paragraphs 1 to 4       5.     For the purpose of paragraphs 1 to 4
the Board, the Member States and national       the AI Office, the Member States and
competent authorities shall provide the         national competent authorities shall
Commission with information on its              provide the Commission with information
request.                                        on its request without undue delay.


Amendment 703

Proposal for a regulation
Article 84 – paragraph 6

     Text proposed by the Commission                            Amendment

6.    In carrying out the evaluations and       6.    in carrying out the evaluations and
reviews referred to in paragraphs 1 to 4 the    reviews referred to in paragraphs 1 to 4 the
Commission shall take into account the          Commission shall take into account the
positions and findings of the Board, of the     positions and findings of the -AI Office of
European Parliament, of the Council, and        the European Parliament, of the Council,
of other relevant bodies or sources.            and of other relevant bodies or sources and
                                                shall consult relevant stakeholders. The
                                             result of such consultation shall be
                                             attached to the report;


Amendment 704

Proposal for a regulation
Article 84 – paragraph 7

    Text proposed by the Commission                          Amendment

7.     The Commission shall, if necessary,   7.    the Commission shall, if necessary,
submit appropriate proposals to amend this   submit appropriate proposals to amend this
Regulation, in particular taking into        Regulation, in particular taking into
account developments in technology and in    account developments in technology, the
the light of the state of progress in the    effect of AI systems on health and safety,
information society.                         fundamental rights, the environment,
                                             equality, and accessibility for persons with
                                             disabilities, democracy and rule of law
                                             and in the light of the state of progress in
                                             the information society.


Amendment 705

Proposal for a regulation
Article 84 – paragraph 7 a (new)

    Text proposed by the Commission                          Amendment

                                             7 a. To guide the evaluations and
                                             reviews referred to in paragraphs 1 to 4 of
                                             this Article, the Office shall undertake to
                                             develop an objective and participative
                                             methodology for the evaluation of risk
                                             level based on the criteria outlined in the
                                             relevant articles and inclusion of new
                                             systems in: the list in Annex III, including
                                             the extension of existing area headings or
                                             addition of new area headings in that
                                             Annex; the list of prohibited practices laid
                                             down in Article 5; and the list of AI
                                             systems requiring additional transparency
                                             measures pursuant to Article 52.


Amendment 706

Proposal for a regulation
Article 84 – paragraph 7 b (new)
    Text proposed by the Commission                   Amendment

                                      7 b. Any amendment to this Regulation
                                      pursuant to paragraph 7 of this Article, or
                                      relevant future delegated or implementing
                                      acts, which concern sectoral legislation
                                      listed in Annex II Ssection B, shall take
                                      into account the regulatory specificities of
                                      each sector, and existing governance,
                                      conformity assessment and enforcement
                                      mechanisms and authorities established
                                      therein.


Amendment 707

Proposal for a regulation
Article 84 – paragraph 7 c (new)

    Text proposed by the Commission                   Amendment

                                      7 c. By … [five years from the date of
                                      application of this Regulation], the
                                      Commission shall carry out an assessment
                                      of the enforcement of this Regulation and
                                      shall report it to the European
                                      Parliament, the Council and the
                                      European Economic and Social
                                      Committee, taking into account the first
                                      years of application of the Regulation. On
                                      the basis of the findings that report shall,
                                      where appropriate, be accompanied by a
                                      proposal for amendment of this
                                      Regulation with regard to the structure of
                                      enforcement and the need for an Union
                                      agency to resolve any identified
                                      shortcomings.


Amendment 708

Proposal for a regulation
Annex I

    Text proposed by the Commission                   Amendment

ARTIFICIAL INTELLIGENCE               deleted
TECHNIQUES AND APPROACHES
referred to in Article 3, point 1
(a) Machine learning approaches,
including supervised, unsupervised and
reinforcement learning, using a wide
variety of methods including deep
learning;
(b) Logic- and knowledge-based
approaches, including knowledge
representation, inductive (logic)
programming, knowledge bases, inference
and deductive engines, (symbolic)
reasoning and expert systems;
(c) Statistical approaches, Bayesian
estimation, search and optimization
methods.


Amendment 709

Proposal for a regulation
Annex III – paragraph 1 – introductory part

    Text proposed by the Commission                            Amendment

High-risk AI systems pursuant to Article       The AI systems specifically refered to in
6(2) are the AI systems listed in any of the   under points 1 to 8a stand for critical use
following areas:                               cases and are each considered to be high-
                                               risk AI systems pursuant to Article 6(2),
                                               provided that they fulfil the criteria set out
                                               in that Article:


Amendment 710

Proposal for a regulation
Annex III – paragraph 1 – point 1 – introductory part

    Text proposed by the Commission                            Amendment

1.   Biometric identification and              1.    Biometric and biometrics-based
categorisation of natural persons:             systems


Amendment 711

Proposal for a regulation
Annex III – paragraph 1 – point 1 – point a
    Text proposed by the Commission                            Amendment

(a) AI systems intended to be used for         (a) AI systems intended to be used for
the ‘real-time’ and ‘post’ remote biometric    biometric identification of natural persons,
identification of natural persons;             with the exception of those mentioned in
                                               Article 5;


Amendment 712

Proposal for a regulation
Annex III – paragraph 1 – point 1 – point a a (new)

    Text proposed by the Commission                            Amendment

                                               (a a) AI systems intended to be used to
                                               make inferences about personal
                                               characteristics of natural persons on the
                                               basis of biometric or biometrics-based
                                               data, including emotion recognition
                                               systems, with the exception of those
                                               mentioned in Article 5;
                                               Point 1 shall not include AI systems
                                               intended to be used for biometric
                                               verification whose sole purpose is to
                                               confirm that a specific natural person is
                                               the person he or she claims to be.


Amendment 713

Proposal for a regulation
Annex III – paragraph 1 – point 2 – point a

    Text proposed by the Commission                            Amendment

(a) AI systems intended to be used as          (a) AI systems intended to be used as
safety components in the management and        safety components in the management and
operation of road traffic and the supply of    operation of road, rail and air traffic
water, gas, heating and electricity.           unless they are regulated in
                                               harmonisation or sectoral law.


Amendment 714

Proposal for a regulation
Annex III – paragraph 1 – point 2 – point a a (new)
     Text proposed by the Commission                             Amendment

                                                 (a a) AI systems intended to be used as
                                                 safety components in the management
                                                 and operation of the supply of water, gas,
                                                 heating, electricity and critical digital
                                                 infrastructure;


Amendment 715

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point a

     Text proposed by the Commission                             Amendment

(a) AI systems intended to be used for           (a) AI systems intended to be used for
the purpose of determining access or             the purpose of determining access or
assigning natural persons to educational         materially influence decisions on
and vocational training institutions;            admission or assigning natural persons to
                                                 educational and vocational training
                                                 institutions;


Amendment 716

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b

     Text proposed by the Commission                             Amendment

(b) AI systems intended to be used for           (b) AI systems intended to be used for
the purpose of assessing students in             the purpose of assessing students in
educational and vocational training              educational and vocational training
institutions and for assessing participants in   institutions and for assessing participants in
tests commonly required for admission to         tests commonly required for admission to
educational institutions.                        those institutions;


Amendment 717

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b a (new)

     Text proposed by the Commission                             Amendment

                                                 (b a) AI systems intended to be used for
                                                 the purpose of assessing the appropriate
                                                 level of education for an individual and
                                               materially influencing the level of
                                               education and vocational training that
                                               individual will receive or will be able to
                                               access;


Amendment 718

Proposal for a regulation
Annex III – paragraph 1 – point 3 – point b b (new)

     Text proposed by the Commission                           Amendment

                                               (b b) AI systems intended to be used for
                                               monitoring and detecting prohibited
                                               behaviour of students during tests in the
                                               context of/within education and
                                               vocational training institutions;


Amendment 719

Proposal for a regulation
Annex III – paragraph 1 – point 4 – point a

     Text proposed by the Commission                           Amendment

(a) AI systems intended to be used for         (a) AI systems intended to be used for
recruitment or selection of natural persons,   recruitment or selection of natural persons,
notably for advertising vacancies,             notably for placing targeted job
screening or filtering applications,           advertisements screening or filtering
evaluating candidates in the course of         applications, evaluating candidates in the
interviews or tests;                           course of interviews or tests;


Amendment 720

Proposal for a regulation
Annex III – paragraph 1 – point 4 – point b

     Text proposed by the Commission                           Amendment

(b) AI intended to be used for making          (b) AI systems intended to be used to
decisions on promotion and termination of      make or materially influence decisions
work-related contractual relationships, for    affecting the initiation, promotion and
task allocation and for monitoring and         termination of work-related contractual
evaluating performance and behavior of         relationships, task allocation based on
persons in such relationships.                 individual behaviour or personal traits or
                                               characteristics, or for monitoring and
                                               evaluating performance and behavior of
                                                persons in such relationships;


Amendment 721

Proposal for a regulation
Annex III – paragraph 1 – point 5 – point a

     Text proposed by the Commission                            Amendment

(a) AI systems intended to be used by           (a) AI systems intended to be used by or
public authorities or on behalf of public       on behalf of public authorities to evaluate
authorities to evaluate the eligibility of      the eligibility of natural persons for public
natural persons for public assistance           assistance benefits and services, including
benefits and services, as well as to grant,     healthcare services and essential services,
reduce, revoke, or reclaim such benefits        including but not limited to housing,
and services;                                   electricity, heating/cooling and internet,
                                                as well as to grant, reduce, revoke,
                                                increase or reclaim such benefits and
                                                services;


Amendment 722

Proposal for a regulation
Annex III – paragraph 1 – point 5 – point b

     Text proposed by the Commission                            Amendment

(b) AI systems intended to be used to           (b) AI systems intended to be used to
evaluate the creditworthiness of natural        evaluate the creditworthiness of natural
persons or establish their credit score, with   persons or establish their credit score , with
the exception of AI systems put into            the exception of AI systems used for the
service by small scale providers for their      purpose of detecting financial fraud;
own use;


Amendment 723

Proposal for a regulation
Annex III – paragraph 1 – point 5 – point b a (new)

     Text proposed by the Commission                            Amendment

                                                (b a) AI systems intended to be used for
                                                making decisions or materially
                                                influencing decisions on the eligibility of
                                                natural persons for health and life
                                                insurance;
Amendment 724

Proposal for a regulation
Annex III – paragraph 1 – point 5 – point c

     Text proposed by the Commission                           Amendment

(c) AI systems intended to be used to          (c) AI systems intended to evaluate and
dispatch, or to establish priority in the      classify emergency calls by natural
dispatching of emergency first response        persons or to be used to dispatch, or to
services, including by firefighters and        establish priority in the dispatching of
medical aid.                                   emergency first response services,
                                               including by police and law enforcement,
                                               firefighters and medical aid, as well as of
                                               emergency healthcare patient triage
                                               systems;


Amendment 725

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point a

     Text proposed by the Commission                           Amendment

(a) AI systems intended to be used by          deleted
law enforcement authorities for making
individual risk assessments of natural
persons in order to assess the risk of a
natural person for offending or
reoffending or the risk for potential
victims of criminal offences;


Amendment 726

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point b

     Text proposed by the Commission                           Amendment

(b) AI systems intended to be used by          (b) AI systems intended to be used by or
law enforcement authorities as polygraphs      on behalf of law enforcement authorities,
and similar tools or to detect the emotional   or by Union agencies, offices or bodies in
state of a natural person;                     support of law enforcement authorities as
                                               polygraphs and similar tools, insofar as
                                               their use is permitted under relevant
                                               Union and national law;
Amendment 727

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point c

     Text proposed by the Commission                          Amendment

(c) AI systems intended to be used by          deleted
law enforcement authorities to detect deep
fakes as referred to in article 52(3);


Amendment 728

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point d

     Text proposed by the Commission                          Amendment

(d) AI systems intended to be used by          (d) AI systems intended to be used by or
law enforcement authorities for evaluation     on behalf of law enforcement authorities,
of the reliability of evidence in the course   or by Union agencies, offices or bodies in
of investigation or prosecution of criminal    support of law enforcement authorities to
offences;                                      evaluate the reliability of evidence in the
                                               course of investigation or prosecution of
                                               criminal offences;


Amendment 729

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point e

     Text proposed by the Commission                          Amendment

(e) AI systems intended to be used by          deleted
law enforcement authorities for predicting
the occurrence or reoccurrence of an
actual or potential criminal offence based
on profiling of natural persons as referred
to in Article 3(4) of Directive (EU)
2016/680 or assessing personality traits
and characteristics or past criminal
behaviour of natural persons or groups;


Amendment 730
Proposal for a regulation
Annex III – paragraph 1 – point 6 – point f

     Text proposed by the Commission                            Amendment

(f) AI systems intended to be used by           (f) AI systems intended to be used by or
law enforcement authorities for profiling of    on behalf of law enforcement authorities
natural persons as referred to in Article       or by Union agencies, offices or bodies in
3(4) of Directive (EU) 2016/680 in the          support of law enforcement authorities for
course of detection, investigation or           profiling of natural persons as referred to in
prosecution of criminal offences;               Article 3(4) of Directive (EU) 2016/680 in
                                                the course of detection, investigation or
                                                prosecution of criminal offences or, in the
                                                case of Union agencies, offices or bodies,
                                                as referred to in Article 3(5) of Regulation
                                                (EU) 2018/1725;


Amendment 731

Proposal for a regulation
Annex III – paragraph 1 – point 6 – point g

     Text proposed by the Commission                            Amendment

(g) AI systems intended to be used for          (g) AI systems intended to be used by or
crime analytics regarding natural persons,      on behalf of law enforcement authorities
allowing law enforcement authorities to         or by Union agencies, offices or bodies in
search complex related and unrelated large      support of law enforcement authorities for
data sets available in different data sources   crime analytics regarding natural persons,
or in different data formats in order to        allowing law enforcement authorities to
identify unknown patterns or discover           search complex related and unrelated large
hidden relationships in the data.               data sets available in different data sources
                                                or in different data formats in order to
                                                identify unknown patterns or discover
                                                hidden relationships in the data.


Amendment 732

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point a

     Text proposed by the Commission                            Amendment

(a) AI systems intended to be used by           (a) AI systems intended to be used by or
competent public authorities as polygraphs      on behalf of competent public authorities
and similar tools or to detect the emotional    or by Union agencies, offices or bodies as
state of a natural person;                      polygraphs and similar tools insofar as
                                                their use is permitted under relevant
                                               Union or national law


Amendment 733

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point b

     Text proposed by the Commission                            Amendment

(b) AI systems intended to be used by          (b) AI systems intended to be used by or
competent public authorities to assess a       on behalf of competent public authorities
risk, including a security risk, a risk of     or by Union agencies, offices or bodies to
irregular immigration, or a health risk,       assess a risk, including a security risk, a
posed by a natural person who intends to       risk of irregular immigration, or a health
enter or has entered into the territory of a   risk, posed by a natural person who intends
Member State;                                  to enter or has entered into the territory of a
                                               Member State;


Amendment 734

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point c

     Text proposed by the Commission                            Amendment

(c) AI systems intended to be used by          (c) AI systems intended to be used by or
competent public authorities for the           on behalf of competent public authorities
verification of the authenticity of travel     or by Union agencies, offices or bodies for
documents and supporting documentation         the verification of the authenticity of travel
of natural persons and detect non-authentic    documents and supporting documentation
documents by checking their security           of natural persons and detect non-authentic
features;                                      documents by checking their security
                                               features;


Amendment 735

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d

     Text proposed by the Commission                            Amendment

(d) AI systems intended to assist              (d) AI systems intended to be used by or
competent public authorities for the           on behalf of competent public authorities
examination of applications for asylum,        or by Union agencies, offices or bodies to
visa and residence permits and associated      assist competent public authorities for the
complaints with regard to the eligibility of   examination and assessment of the
                                               veracity of evidence in relation to
the natural persons applying for a status.     applications for asylum, visa and residence
                                               permits and associated complaints with
                                               regard to the eligibility of the natural
                                               persons applying for a status;


Amendment 736

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d a (new)

     Text proposed by the Commission                          Amendment

                                               (d a) AI systems intended to be used by or
                                               on behalf of competent public authorities
                                               or by Union agencies, offices or bodies in
                                               migration, asylum and border control
                                               management to monitor, surveil or
                                               process data in the context of border
                                               management activities, for the purpose of
                                               detecting, recognising or identifying
                                               natural persons;


Amendment 737

Proposal for a regulation
Annex III – paragraph 1 – point 7 – point d b (new)

     Text proposed by the Commission                          Amendment

                                               (d b) AI systems intended to be used by or
                                               on behalf of competent public authorities
                                               or by Union agencies, offices or bodies in
                                               migration, asylum and border control
                                               management for the forecasting or
                                               prediction of trends related to migration
                                               movement and border crossing;


Amendment 738

Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a

     Text proposed by the Commission                          Amendment

(a) AI systems intended to assist a            (a) AI systems intended to be used by a
judicial authority in researching and          judicial authority ot administrative body
interpreting facts and the law and in          or on their behalf to assist a judicial
applying the law to a concrete set of facts.   authority or administrative body in
                                               researching and interpreting facts and the
                                               law and in applying the law to a concrete
                                               set of facts or used in a similar way in
                                               alternative dispute resolution.


Amendment 739

Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a a (new)

     Text proposed by the Commission                           Amendment

                                               (a a) AI systems intended to be used for
                                               influencing the outcome of an election or
                                               referendum or the voting behaviour of
                                               natural persons in the exercise of their
                                               vote in elections or referenda. This does
                                               not include AI systems whose output
                                               natural persons are not directly exposed
                                               to, such as tools used to organise, optimise
                                               and structure political campaigns from an
                                               administrative and logistic point of view.


Amendment 740

Proposal for a regulation
Annex III – paragraph 1 – point 8 – point a b (new)

     Text proposed by the Commission                           Amendment

                                               (a b) AI systems intended to be used by
                                               social media platforms that have been
                                               designated as very large online platforms
                                               within the meaning of Article 33 of
                                               Regulation EU 2022/2065, in their
                                               recommender systems to recommend to
                                               the recipient of the service user-generated
                                               content available on the platform.


Amendment 741

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point a
     Text proposed by the Commission                          Amendment

(a) its intended purpose, the person/s        (a) its intended purpose, the name of the
developing the system the date and the        provider and the version of the system
version of the system;                        reflecting its relation to previous and,
                                              where applicable, more recent, versions in
                                              the succession of revisions;


Amendment 742

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point a a (new)

     Text proposed by the Commission                          Amendment

                                              (a a) the nature of data likely or intended
                                              to be processed by the system and, in the
                                              case of personal data, the categories of
                                              natural persons and groups likely or
                                              intended to be affected;


Amendment 743

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point b

     Text proposed by the Commission                          Amendment

(b) how the AI system interacts or can        (b) how the AI system can interact or
be used to interact with hardware or          can be used to interact with hardware or
software that is not part of the AI system    software, including other AI systems, that
itself, where applicable;                     are not part of the AI system itself, where
                                              applicable;


Amendment 744

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point c

     Text proposed by the Commission                          Amendment

(c) the versions of relevant software or      (c) the versions of relevant software or
firmware and any requirement related to       firmware and, where applicable,
version update;                               information for the deployer on any
                                              requirement related to version update;
Amendment 745

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point d

     Text proposed by the Commission                          Amendment

(d) the description of all forms in which     (d) the description of the various
the AI system is placed on the market or      configurations and variants of the AI
put into service;                             system which are intended to be placed on
                                              the market or put into service;


Amendment 746

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point f a (new)

     Text proposed by the Commission                          Amendment

                                              (f a) the description of the deployer
                                              interface;


Amendment 747

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g

     Text proposed by the Commission                          Amendment

(g) instructions of use for the user and,     (g) instructions of use for the deployer in
where applicable installation instructions;   accordance with Article 13(2) and (3) as
                                              well as 14(4)(e) and, where applicable
                                              installation instructions;


Amendment 748

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g a (new)

     Text proposed by the Commission                          Amendment

                                              (g a) a detailed and easily intellegible
                                              description of the system’s main
                                              optimisation goal or goals;
Amendment 749

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g b (new)

    Text proposed by the Commission                           Amendment

                                              (g b) a detailed and easily intellegible
                                              description of the system’s expected
                                              output and expected output quality;


Amendment 750

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g c (new)

    Text proposed by the Commission                           Amendment

                                              (g c) detailed and easily intellegible
                                              instructions for interpreting the system’s
                                              output;


Amendment 751

Proposal for a regulation
Annex IV – paragraph 1 – point 1 – point g d (new)

    Text proposed by the Commission                           Amendment

                                              (g d) examples of scenarios for which the
                                              system should not be used;


Amendment 752

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point b

    Text proposed by the Commission                           Amendment

(b) the design specifications of the          (b) a description of the architecture,
system, namely the general logic of the AI    design specifications, algorithms and the
system and of the algorithms; the key         data structures including a decomposition
design choices including the rationale and    of its components and interfaces, how
assumptions made, also with regard to         they relate to one another and how they
persons or groups of persons on which the     provide for the overall processing or logic
system is intended to be used; the main       of the AI system; the key design choices
classification choices; what the system is    including the rationale and assumptions
designed to optimise for and the relevance      made, also with regard to persons or
of the different parameters; the decisions      groups of persons on which the system is
about any possible trade-off made               intended to be used; the main classification
regarding the technical solutions adopted to    choices; what the system is designed to
comply with the requirements set out in         optimise for and the relevance of the
Title III, Chapter 2;                           different parameters; the decisions about
                                                any possible trade-off made regarding the
                                                technical solutions adopted to comply with
                                                the requirements set out in Title III,
                                                Chapter 2;


Amendment 753

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point c

     Text proposed by the Commission                            Amendment

(c) the description of the system               (c)   deleted
architecture explaining how software
components build on or feed into each
other and integrate into the overall
processing; the computational resources
used to develop, train, test and validate the
AI system;


Amendment 754

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point e

     Text proposed by the Commission                            Amendment

(e) assessment of the human oversight           (e) assessment of the human oversight
measures needed in accordance with              measures needed in accordance with
Article 14, including an assessment of the      Article 14, including an assessment of the
technical measures needed to facilitate the     technical measures needed to facilitate the
interpretation of the outputs of AI systems     interpretation of the outputs of AI systems
by the users, in accordance with Articles       by the deployers, in accordance with
13(3)(d);                                       Articles 13(3)(d);


Amendment 755

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point g
    Text proposed by the Commission                            Amendment

(g) the validation and testing procedures      (g) the validation and testing procedures
used, including information about the          used, including information about the
validation and testing data used and their     validation and testing data used and their
main characteristics; metrics used to          main characteristics; metrics used to
measure accuracy, robustness,                  measure accuracy, robustness and
cybersecurity and compliance with other        compliance with other relevant
relevant requirements set out in Title III,    requirements set out in Title III, Chapter 2
Chapter 2 as well as potentially               as well as potentially discriminatory
discriminatory impacts; test logs and all      impacts; test logs and all test reports dated
test reports dated and signed by the           and signed by the responsible persons,
responsible persons, including with regard     including with regard to pre-determined
to pre-determined changes as referred to       changes as referred to under point (f).
under point (f).


Amendment 756

Proposal for a regulation
Annex IV – paragraph 1 – point 2 – point g a (new)

    Text proposed by the Commission                            Amendment

                                               (g a) cybersecurity measures put in place.


Amendment 757

Proposal for a regulation
Annex IV – paragraph 1 – point 3

    Text proposed by the Commission                            Amendment

3.     Detailed information about the          3.     Detailed information about the
monitoring, functioning and control of the     monitoring, functioning and control of the
AI system, in particular with regard to: its   AI system, in particular with regard to: its
capabilities and limitations in performance,   capabilities and limitations in performance,
including the degrees of accuracy for          including the degrees of accuracy for
specific persons or groups of persons on       specific persons or groups of persons on
which the system is intended to be used        which the system is intended to be used
and the overall expected level of accuracy     and the overall expected level of accuracy
in relation to its intended purpose; the       in relation to its intended purpose; the
foreseeable unintended outcomes and            foreseeable unintended outcomes and
sources of risks to health and safety,         sources of risks to health and safety,
fundamental rights and discrimination in       fundamental rights and discrimination in
view of the intended purpose of the AI         view of the intended purpose of the AI
system; the human oversight measures           system; the human oversight measures
needed in accordance with Article 14,          needed in accordance with Article 14,
including the technical measures put in         including the technical measures put in
place to facilitate the interpretation of the   place to facilitate the interpretation of the
outputs of AI systems by the users;             outputs of AI systems by the deployers;
specifications on input data, as appropriate;   specifications on input data, as appropriate;


Amendment 758

Proposal for a regulation
Annex IV – paragraph 1 – point 3 a (new)

     Text proposed by the Commission                            Amendment

                                                3 a. A description of the appropriateness
                                                of the performance metrics for the
                                                specific AI system;


Amendment 759

Proposal for a regulation
Annex IV – paragraph 1 – point 3 b (new)

     Text proposed by the Commission                            Amendment

                                                3 b. Information about the energy
                                                consumption of the AI system during the
                                                development phase and the expected
                                                energy consumption during use, taking
                                                into account, where applicable, relevant
                                                Union and national law;


Amendment 760

Proposal for a regulation
Annex IV – paragraph 1 – point 5

     Text proposed by the Commission                            Amendment

5.    A description of any change made to       5.      A description of any relevant change
the system through its lifecycle;               made by providers to the system through
                                                its lifecycle ;


Amendment 761

Proposal for a regulation
Annex IV – paragraph 1 – point 6
     Text proposed by the Commission                           Amendment

6.     A list of the harmonised standards      6.     A list of the harmonised standards
applied in full or in part the references of   applied in full or in part the references of
which have been published in the Official      which have been published in the Official
Journal of the European Union; where no        Journal of the European Union; where no
such harmonised standards have been            such harmonised standards have been
applied, a detailed description of the         applied, a detailed description of the
solutions adopted to meet the requirements     solutions adopted to meet the requirements
set out in Title III, Chapter 2, including a   set out in Title III, Chapter 2, including a
list of other relevant standards and           list of other relevant standards or common
technical specifications applied;              specifications applied;


Amendment 762

Proposal for a regulation
Annex V – paragraph 1 – point 4 a (new)

     Text proposed by the Commission                           Amendment

                                               4 a. Where an AI system involves the
                                               processing of personal data, a statement
                                               that that AI system complies with
                                               Regulations (EU) 2016/679 and (EU)
                                               2018/1725 and Directive (EU) 2016/680.


Amendment 763

Proposal for a regulation
Annex V – paragraph 1 – point 7

     Text proposed by the Commission                           Amendment

7.    Place and date of issue of the           7.    Place and date of issue of the
declaration, name and function of the          declaration, signature, name and function
person who signed it as well as an             of the person who signed it as well as an
indication for, and on behalf of whom, that    indication for, and on behalf of whom, that
person signed, signature.                      person signed, signature.


Amendment 764

Proposal for a regulation
Annex VII – point 4 – point 4.5
    Text proposed by the Commission                          Amendment

4.5. Where necessary to assess the           4.5. Where necessary to assess the
conformity of the high-risk AI system with   conformity of the high-risk AI system with
the requirements set out in Title III,       the requirements set out in Title III,
Chapter 2 and upon a reasoned request, the   Chapter 2, after all other reasonable ways
notified body shall also be granted access   to verify conformity have been exhausted
to the source code of the AI system.         and have proven to be insufficient, and
                                             upon a reasoned request, the notified body
                                             shall also be granted access to the training
                                             and trained models of the AI system,
                                             including its relevant parameters. Such
                                             access shall be subject to existing Union
                                             law on the protection of intellectual
                                             property and trade secrets. They shall take
                                             technical and organisational measures to
                                             ensure the protection of intellectual
                                             property and trade secrets.


Amendment 765

Proposal for a regulation
Annex VIII – paragraph 1

    Text proposed by the Commission                          Amendment

The following information shall be           Section A - The following information
provided and thereafter kept up to date      shall be provided and thereafter kept up to
with regard to high-risk AI systems to be    date with regard to high-risk AI systems to
registered in accordance with Article 51.    be registered in accordance with Article 51
                                             (1).


Amendment 766

Proposal for a regulation
Annex VIII – point 4 a (new)

    Text proposed by the Commission                          Amendment

                                             4 a. Foundation model trade name and
                                             any additional unambiguous refernce
                                             allowing identification and traceability


Amendment 767
Proposal for a regulation
Annex VIII – point 5

    Text proposed by the Commission                         Amendment

5.    Description of the intended purpose   5.    A simple and comprehensible
of the AI system;                           description of
                                            a. the intended purpose of the AI system;
                                            b. the components and functions
                                            supported through AI;
                                            c. a basic explanation of the logic of the
                                            AI system


Amendment 768

Proposal for a regulation
Annex VIII – point 5 a (new)

    Text proposed by the Commission                         Amendment

                                            5 a. where applicable, the categories and
                                            nature of data likely or foreseen to be
                                            processed by the AI system.


Amendment 769

Proposal for a regulation
Annex VIII – point 11

    Text proposed by the Commission                         Amendment

11. Electronic instructions for use; this   deleted
information shall not be provided for
high-risk AI systems in the areas of law
enforcement and migration, asylum and
border control management referred to in
Annex III, points 1, 6 and 7.


Amendment 770

Proposal for a regulation
ANNEX VIII – SECTION B (new)
   Text proposed by the Commission                  Amendment

                                     SECTION B - The following information
                                     shall be provided and thereafter kept up to
                                     date with regard to high-risk AI systems to
                                     be registered in accordance with Article
                                     51 (1a) (a) and (1b).
                                     1.    the name, address and contact
                                     details of the deployer ;
                                     2.    the name, address and contact
                                     details of the person submitting
                                     information on behalf of the deployer ;
                                     3.    the high risk AI system trade name
                                     and any additional unambiguous
                                     reference allowing identification and
                                     traceability of the AI system used;
                                     4.    a) A simple and comprehensible
                                     description of the intended use of the AI
                                     system, including the specific outcomes
                                     sought through the use of the systemn, the
                                     geographic and temporal scope of
                                     application
                                     b. Where applicable, the categories and
                                     nature of data to be processed by the AI
                                     system;
                                     c. Arrangements for human oversight and
                                     governance
                                     d. Where relevant, the bodies or natural
                                     persons responsible for decisions taken or
                                     supported by the AI system;
                                     5. a summary of the findings of the
                                     fundamental rights impact assessment
                                     conducted in accordance with Article 29a
                                     6. The URL of the entry of the AI system
                                     in the EU database by its provider
                                     7. A summary of the data protection
                                     impact assessment carried out in
                                     accordance with Article 35 of Regulation
                                     (EU) 2016/679 or Article 27 of Directive
                                     (EU) 2016/680 as specified in paragraph
                                     6 of Article 29 of this Regulation, where
                                     applicable.


Amendment 771
Proposal for a regulation
Annex VIII – Section C (new)

    Text proposed by the Commission                   Amendment

                                      Section C - The following information
                                      shall be provided and thereafter kept up to
                                      date with regard to foundation models to
                                      be registered in accordance with Article
                                      28b (e).
                                      1. Name, address and contact details of
                                      the provider;
                                      2. Where submission of information is
                                      carried out by another person on behalf of
                                      the provider, the name, address and
                                      contact details of that person;
                                      3. Name, address and contact details of
                                      the authorised representative, where
                                      applicable;
                                      4. Trade name and any additional
                                      unambiguous reference allowing the
                                      identification of the foundation model
                                      5. Description of the data sources used in
                                      the development of the foundational
                                      model
                                      6. Description of the capabilities and
                                      limitations of the foundation model,
                                      including the reasonably foreseeable risks
                                      and the measures that have been taken to
                                      mitigate them as well as remaining non-
                                      mitigated risks with an explanation on the
                                      reason why they cannot be mitigated
                                      7. Description of the training resources
                                      used by the foundation model including
                                      computing power required, training time,
                                      and other relevant information related to
                                      the size and power of the model 8.
                                      Description of the model’s performance,
                                      including on public benchmarks or state
                                      of the art industry benchmarks
                                      8. Description of the results of relevant
                                      internal and external testing and
                                      optimisation of the model
                                      9. Member States in which the foundation
                                      model is or has been placed on the
market, put into service or made available
in the Union;
10. URL for additional information
(optional).
